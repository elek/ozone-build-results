rm: cannot remove '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/*': No such file or directory
Executing test in ozone-csi
Removing network ozone-csi_default
Network ozone-csi_default not found.
Creating network "ozone-csi_default" with the default driver
Pulling datanode (apache/ozone-runner:20220623-1)...
20220623-1: Pulling from apache/ozone-runner
Digest: sha256:ba2ed07322bc8f888150fa2a1ec0523fca85e09c8eb9779445f8bca0d58cff97
Status: Downloaded newer image for apache/ozone-runner:20220623-1
Creating ozone-csi_datanode_1 ... 
Creating ozone-csi_datanode_2 ... 
Creating ozone-csi_datanode_3 ... 
Creating ozone-csi_scm_1      ... 
Creating ozone-csi_om_1       ... 
Creating ozone-csi_csi_1      ... 
Creating ozone-csi_datanode_3 ... done
Creating ozone-csi_csi_1      ... done
Creating ozone-csi_scm_1      ... done
Creating ozone-csi_om_1       ... done
Creating ozone-csi_datanode_1 ... done
Creating ozone-csi_datanode_2 ... done
SECONDS: 45
com.google.protobuf.ServiceException: java.net.ConnectException: Call From 50ebea4ac758/172.18.0.3 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 50ebea4ac758/172.18.0.3 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 50ebea4ac758/172.18.0.3 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From 50ebea4ac758/172.18.0.3 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:ce4749fd-4c00-4f03-9abf-db8e129bb786 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:ce4749fd-4c00-4f03-9abf-db8e129bb786 is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy20.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.3:9860 after 6 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:false, DataNodeSafeModeRule, registered datanodes (=0) >= required datanodes (=1) validated:true, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=0) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 62
SCM is out of safe mode.
Safe mode is off
No OM HA service, no need to wait
==============================================================================
Csi :: Smoketest Ozone CSI service                                            
==============================================================================
Check if CSI server is started                                        | PASS |
------------------------------------------------------------------------------
Test CSI identity service                                             | PASS |
------------------------------------------------------------------------------
Csi :: Smoketest Ozone CSI service                                    | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-csi/result/robot-ozone-csi-ozone-csi-csi-csi.xml
Stopping ozone-csi_csi_1      ... 
Stopping ozone-csi_om_1       ... 
Stopping ozone-csi_datanode_1 ... 
Stopping ozone-csi_datanode_2 ... 
Stopping ozone-csi_scm_1      ... 
Stopping ozone-csi_datanode_3 ... 
Stopping ozone-csi_csi_1      ... done
Stopping ozone-csi_om_1       ... done
Stopping ozone-csi_datanode_2 ... done
Stopping ozone-csi_datanode_1 ... done
Stopping ozone-csi_datanode_3 ... done
Stopping ozone-csi_scm_1      ... done
Removing ozone-csi_csi_1      ... 
Removing ozone-csi_om_1       ... 
Removing ozone-csi_datanode_1 ... 
Removing ozone-csi_datanode_2 ... 
Removing ozone-csi_scm_1      ... 
Removing ozone-csi_datanode_3 ... 
Removing ozone-csi_csi_1      ... done
Removing ozone-csi_datanode_1 ... done
Removing ozone-csi_datanode_3 ... done
Removing ozone-csi_scm_1      ... done
Removing ozone-csi_om_1       ... done
Removing ozone-csi_datanode_2 ... done
Removing network ozone-csi_default
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-csi/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-csi/result/report.html
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-csi.xml
removed 'ozone-csi/result/robot-ozone-csi-ozone-csi-csi-csi.xml'
removed 'ozone-csi/result/log.html'
removed 'ozone-csi/result/report.html'
renamed 'ozone-csi/result/dn-audit-50788feaeb17.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-csi/dn-audit-50788feaeb17.log'
renamed 'ozone-csi/result/dn-audit-60a8825702c8.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-csi/dn-audit-60a8825702c8.log'
renamed 'ozone-csi/result/dn-audit-b74c6ad7c6b5.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-csi/dn-audit-b74c6ad7c6b5.log'
renamed 'ozone-csi/result/docker-ozone-csi-ozone-csi-csi-csi.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi-ozone-csi-csi-csi.log'
renamed 'ozone-csi/result/om-audit-1acdbae34fb1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-csi/om-audit-1acdbae34fb1.log'
renamed 'ozone-csi/result/scm-audit-50ebea4ac758.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-csi/scm-audit-50ebea4ac758.log'
Executing test in ozone-om-prepare
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data/om2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data/scm': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data/om3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data/om1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data/dn1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data/dn2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data/dn3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/ozone-om-prepare/data': Operation not permitted
Removing network ozone-om-prepare_net
Network ozone-om-prepare_net not found.
Creating network "ozone-om-prepare_net" with driver "bridge"
Creating ozone-om-prepare_dn1_1 ... 
Creating ozone-om-prepare_om2_1 ... 
Creating ozone-om-prepare_om3_1 ... 
Creating ozone-om-prepare_om1_1 ... 
Creating ozone-om-prepare_scm_1 ... 
Creating ozone-om-prepare_dn2_1 ... 
Creating ozone-om-prepare_dn3_1 ... 
Creating ozone-om-prepare_dn2_1 ... done
Creating ozone-om-prepare_om3_1 ... done
Creating ozone-om-prepare_scm_1 ... done
Creating ozone-om-prepare_om1_1 ... done
Creating ozone-om-prepare_dn3_1 ... done
Creating ozone-om-prepare_dn1_1 ... done
Creating ozone-om-prepare_om2_1 ... done
SECONDS: 44
com.google.protobuf.ServiceException: java.net.ConnectException: Call From daeae6b7f857/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From daeae6b7f857/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From daeae6b7f857/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: java.net.ConnectException: Call From daeae6b7f857/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 4 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:cd2d8e8c-2a29-4fd8-b2ea-30d9e48cf43d is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 5 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:cd2d8e8c-2a29-4fd8-b2ea-30d9e48cf43d is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 6 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:cd2d8e8c-2a29-4fd8-b2ea-30d9e48cf43d is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 7 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:true, DataNodeSafeModeRule, registered datanodes (=3) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:true, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=0)
SECONDS: 65
SCM is out of safe mode.
Safe mode is off
Found OM leader for service omservice: om1 : LEADER (om1)
==============================================================================
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.           
==============================================================================
Prepare Ozone Manager                                                 | PASS |
------------------------------------------------------------------------------
Checks if the expected data is present in OM                          | PASS |
------------------------------------------------------------------------------
Test write operation fails                                            | PASS |
------------------------------------------------------------------------------
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.   | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm.xml
==============================================================================
Om-Cancel-Prepare :: Smoke test for ozone manager cancel prepare              
==============================================================================
Cancel Ozone Manager Prepare                                          | PASS |
------------------------------------------------------------------------------
Test write operations                                                 | PASS |
------------------------------------------------------------------------------
Om-Cancel-Prepare :: Smoke test for ozone manager cancel prepare      | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm-1.xml
==============================================================================
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.           
==============================================================================
Prepare Ozone Manager                                                 | PASS |
------------------------------------------------------------------------------
Checks if the expected data is present in OM                          | PASS |
------------------------------------------------------------------------------
Test write operation fails                                            | PASS |
------------------------------------------------------------------------------
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.   | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm-2.xml
==============================================================================
Om-Prepared :: Smoke test to test that OMs are prepared in an OM HA cluster.  
==============================================================================
Test create volume fails                                              | PASS |
------------------------------------------------------------------------------
Test list volumes succeeds                                            | PASS |
------------------------------------------------------------------------------
Om-Prepared :: Smoke test to test that OMs are prepared in an OM H... | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm-3.xml
Stopping ozone-om-prepare_scm_1 ... 
Stopping ozone-om-prepare_dn3_1 ... 
Stopping ozone-om-prepare_om1_1 ... 
Stopping ozone-om-prepare_dn2_1 ... 
Stopping ozone-om-prepare_om3_1 ... 
Stopping ozone-om-prepare_dn1_1 ... 
Stopping ozone-om-prepare_om2_1 ... 
Stopping ozone-om-prepare_om2_1 ... done
Stopping ozone-om-prepare_om1_1 ... done
Stopping ozone-om-prepare_om3_1 ... done
Stopping ozone-om-prepare_dn3_1 ... done
Stopping ozone-om-prepare_dn1_1 ... done
Stopping ozone-om-prepare_dn2_1 ... done
Stopping ozone-om-prepare_scm_1 ... done
Removing ozone-om-prepare_scm_1 ... 
Removing ozone-om-prepare_dn3_1 ... 
Removing ozone-om-prepare_om1_1 ... 
Removing ozone-om-prepare_dn2_1 ... 
Removing ozone-om-prepare_om3_1 ... 
Removing ozone-om-prepare_dn1_1 ... 
Removing ozone-om-prepare_om2_1 ... 
Removing ozone-om-prepare_om3_1 ... done
Removing ozone-om-prepare_dn3_1 ... done
Removing ozone-om-prepare_om2_1 ... done
Removing ozone-om-prepare_scm_1 ... done
Removing ozone-om-prepare_dn2_1 ... done
Removing ozone-om-prepare_dn1_1 ... done
Removing ozone-om-prepare_om1_1 ... done
Removing network ozone-om-prepare_net
Removing network ozone-om-prepare_net
Network ozone-om-prepare_net not found.
Creating network "ozone-om-prepare_net" with driver "bridge"
Creating ozone-om-prepare_dn2_1 ... 
Creating ozone-om-prepare_om2_1 ... 
Creating ozone-om-prepare_om1_1 ... 
Creating ozone-om-prepare_om3_1 ... 
Creating ozone-om-prepare_scm_1 ... 
Creating ozone-om-prepare_dn3_1 ... 
Creating ozone-om-prepare_dn1_1 ... 
Creating ozone-om-prepare_dn3_1 ... done
Creating ozone-om-prepare_dn2_1 ... done
Creating ozone-om-prepare_scm_1 ... done
Creating ozone-om-prepare_dn1_1 ... done
Creating ozone-om-prepare_om1_1 ... done
Creating ozone-om-prepare_om3_1 ... done
Creating ozone-om-prepare_om2_1 ... done
SECONDS: 40
com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:cd2d8e8c-2a29-4fd8-b2ea-30d9e48cf43d is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:cd2d8e8c-2a29-4fd8-b2ea-30d9e48cf43d is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:false, DataNodeSafeModeRule, registered datanodes (=0) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:false, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=2)
SECONDS: 56
SCM is out of safe mode.
Safe mode is off
Found OM leader for service omservice: om1 : LEADER (om1)
==============================================================================
Om-Prepared :: Smoke test to test that OMs are prepared in an OM HA cluster.  
==============================================================================
Test create volume fails                                              | PASS |
------------------------------------------------------------------------------
Test list volumes succeeds                                            | PASS |
------------------------------------------------------------------------------
Om-Prepared :: Smoke test to test that OMs are prepared in an OM H... | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm-4.xml
Stopping ozone-om-prepare_om3_1 ... 
Stopping ozone-om-prepare_dn3_1 ... 
Stopping ozone-om-prepare_scm_1 ... 
Stopping ozone-om-prepare_dn1_1 ... 
Stopping ozone-om-prepare_om1_1 ... 
Stopping ozone-om-prepare_dn2_1 ... 
Stopping ozone-om-prepare_om2_1 ... 
Stopping ozone-om-prepare_om2_1 ... done
Stopping ozone-om-prepare_om1_1 ... done
Stopping ozone-om-prepare_om3_1 ... done
Stopping ozone-om-prepare_dn2_1 ... done
Stopping ozone-om-prepare_dn3_1 ... done
Stopping ozone-om-prepare_dn1_1 ... done
Stopping ozone-om-prepare_scm_1 ... done
Removing ozone-om-prepare_om3_1 ... 
Removing ozone-om-prepare_dn3_1 ... 
Removing ozone-om-prepare_scm_1 ... 
Removing ozone-om-prepare_dn1_1 ... 
Removing ozone-om-prepare_om1_1 ... 
Removing ozone-om-prepare_dn2_1 ... 
Removing ozone-om-prepare_om2_1 ... 
Removing ozone-om-prepare_om1_1 ... done
Removing ozone-om-prepare_om3_1 ... done
Removing ozone-om-prepare_dn3_1 ... done
Removing ozone-om-prepare_dn2_1 ... done
Removing ozone-om-prepare_om2_1 ... done
Removing ozone-om-prepare_dn1_1 ... done
Removing ozone-om-prepare_scm_1 ... done
Removing network ozone-om-prepare_net
Removing network ozone-om-prepare_net
Network ozone-om-prepare_net not found.
Creating network "ozone-om-prepare_net" with driver "bridge"
Creating ozone-om-prepare_dn3_1 ... 
Creating ozone-om-prepare_om3_1 ... 
Creating ozone-om-prepare_om2_1 ... 
Creating ozone-om-prepare_dn2_1 ... 
Creating ozone-om-prepare_scm_1 ... 
Creating ozone-om-prepare_dn1_1 ... 
Creating ozone-om-prepare_om1_1 ... 
Creating ozone-om-prepare_om3_1 ... done
Creating ozone-om-prepare_dn3_1 ... done
Creating ozone-om-prepare_scm_1 ... done
Creating ozone-om-prepare_dn1_1 ... done
Creating ozone-om-prepare_om1_1 ... done
Creating ozone-om-prepare_om2_1 ... done
Creating ozone-om-prepare_dn2_1 ... done
SECONDS: 39
com.google.protobuf.ServiceException: java.net.ConnectException: Call From e003a90f9311/10.9.0.17 to scm:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:cd2d8e8c-2a29-4fd8-b2ea-30d9e48cf43d is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms. com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:cd2d8e8c-2a29-4fd8-b2ea-30d9e48cf43d is not the leader. Could not determine the leader node. at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109) at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246) at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:193) at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976) , while invoking $Proxy19.submitRequest over nodeId=scmNodeId,nodeAddress=scm/10.9.0.17:9860 after 3 failover attempts. Trying to failover after sleeping for 2000ms. SCM is in safe mode. validated:false, DataNodeSafeModeRule, registered datanodes (=0) >= required datanodes (=3) validated:false, HealthyPipelineSafeModeRule, healthy Ratis/THREE pipelines (=0) >= healthyPipelineThresholdCount (=1) validated:true, ContainerSafeModeRule, % of containers with at least one reported replica (=1.00) >= safeModeCutoff (=0.99) validated:false, AtleastOneDatanodeReportedRule, reported Ratis/THREE pipelines with at least one datanode (=0) >= threshold (=2)
SECONDS: 56
SCM is out of safe mode.
Safe mode is off
Found OM leader for service omservice: om1 : LEADER (om1)
==============================================================================
Loaddata :: Smoketest ozone cluster startup                                   
==============================================================================
Create a volume, bucket and key                                       | PASS |
------------------------------------------------------------------------------
Loaddata :: Smoketest ozone cluster startup                           | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm-5.xml
==============================================================================
Readdata :: Smoketest ozone cluster startup                                   
==============================================================================
Read data from previously created key                                 | PASS |
------------------------------------------------------------------------------
Readdata :: Smoketest ozone cluster startup                           | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm-6.xml
Stopping ozone-om-prepare_om1_1 ... 
Stopping ozone-om-prepare_dn1_1 ... 
Stopping ozone-om-prepare_scm_1 ... 
Stopping ozone-om-prepare_om2_1 ... 
Stopping ozone-om-prepare_om3_1 ... 
Stopping ozone-om-prepare_dn2_1 ... 
Stopping ozone-om-prepare_dn3_1 ... 
Stopping ozone-om-prepare_om2_1 ... done
Stopping ozone-om-prepare_om1_1 ... done
Stopping ozone-om-prepare_om3_1 ... done
Stopping ozone-om-prepare_dn3_1 ... done

ERROR: for ozone-om-prepare_scm_1  UnixHTTPConnectionPool(host='localhost', port=None): Read timed out. (read timeout=70)

ERROR: for ozone-om-prepare_dn1_1  UnixHTTPConnectionPool(host='localhost', port=None): Read timed out. (read timeout=70)

ERROR: for ozone-om-prepare_dn2_1  UnixHTTPConnectionPool(host='localhost', port=None): Read timed out. (read timeout=70)
An HTTP request took too long to complete. Retry with --verbose to obtain debug information.
If you encounter this issue regularly because of slow network conditions, consider setting COMPOSE_HTTP_TIMEOUT to a higher value (current value: 60).
ERROR: Test execution of ozone-om-prepare is FAILED!!!!
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare.xml
removed 'ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm-1.xml'
removed 'ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm-2.xml'
removed 'ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm-3.xml'
removed 'ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm-4.xml'
removed 'ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm-5.xml'
removed 'ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm-6.xml'
removed 'ozone-om-prepare/result/robot-ozone-om-prepare-ozone-om-prepare-om-prepare-scm.xml'
renamed 'ozone-om-prepare/result/dn-audit-1ae889018cc3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-1ae889018cc3.log'
renamed 'ozone-om-prepare/result/dn-audit-409f8793feb3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-409f8793feb3.log'
renamed 'ozone-om-prepare/result/dn-audit-497f23e875bc.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-497f23e875bc.log'
renamed 'ozone-om-prepare/result/dn-audit-826bc9f968a5.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-826bc9f968a5.log'
renamed 'ozone-om-prepare/result/dn-audit-a568e289dcd3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-a568e289dcd3.log'
renamed 'ozone-om-prepare/result/dn-audit-d29e40dd5cc5.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-d29e40dd5cc5.log'
renamed 'ozone-om-prepare/result/dn-audit-e35f33e6f480.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-e35f33e6f480.log'
renamed 'ozone-om-prepare/result/dn-audit-eb84822be4a7.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-eb84822be4a7.log'
renamed 'ozone-om-prepare/result/dn-audit-f9f570e8a123.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-f9f570e8a123.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare-ozone-om-prepare-om-prepare-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare-ozone-om-prepare-om-prepare-scm.log'
renamed 'ozone-om-prepare/result/om-audit-074046b66696.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-074046b66696.log'
renamed 'ozone-om-prepare/result/om-audit-2199b7de101f.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-2199b7de101f.log'
renamed 'ozone-om-prepare/result/om-audit-49384b86f067.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-49384b86f067.log'
renamed 'ozone-om-prepare/result/om-audit-5664afae846c.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-5664afae846c.log'
renamed 'ozone-om-prepare/result/om-audit-614ee506cf27.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-614ee506cf27.log'
renamed 'ozone-om-prepare/result/om-audit-87b6208d520f.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-87b6208d520f.log'
renamed 'ozone-om-prepare/result/om-audit-c5554d0c6dcc.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-c5554d0c6dcc.log'
renamed 'ozone-om-prepare/result/om-audit-dc32f1964196.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-dc32f1964196.log'
renamed 'ozone-om-prepare/result/om-audit-e619bfca5008.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-e619bfca5008.log'
renamed 'ozone-om-prepare/result/scm-audit-daeae6b7f857.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/scm-audit-daeae6b7f857.log'
renamed 'ozone-om-prepare/result/scm-audit-e003a90f9311.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/scm-audit-e003a90f9311.log'
renamed 'ozone-om-prepare/result/scm-audit-ecf8823c8a55.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/ozone-om-prepare/scm-audit-ecf8823c8a55.log'
Executing test in ozone-topology
An HTTP request took too long to complete. Retry with --verbose to obtain debug information.
If you encounter this issue regularly because of slow network conditions, consider setting COMPOSE_HTTP_TIMEOUT to a higher value (current value: 60).
ERROR: Test execution of ozone-topology is FAILED!!!!
mv: cannot stat 'ozone-topology/result/*': No such file or directory
Executing test in ozones3-haproxy
An HTTP request took too long to complete. Retry with --verbose to obtain debug information.
If you encounter this issue regularly because of slow network conditions, consider setting COMPOSE_HTTP_TIMEOUT to a higher value (current value: 60).
ERROR: Test execution of ozones3-haproxy is FAILED!!!!
mv: cannot stat 'ozones3-haproxy/result/*': No such file or directory
Executing test in ozonescripts
An HTTP request took too long to complete. Retry with --verbose to obtain debug information.
If you encounter this issue regularly because of slow network conditions, consider setting COMPOSE_HTTP_TIMEOUT to a higher value (current value: 60).
ERROR: Test execution of ozonescripts is FAILED!!!!
mv: cannot stat 'ozonescripts/result/*': No such file or directory
Executing test in restart
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data/om': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data/scm': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data/s3g': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data/recon': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data/dn1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data/dn2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data/dn3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/restart/data': Operation not permitted
An HTTP request took too long to complete. Retry with --verbose to obtain debug information.
If you encounter this issue regularly because of slow network conditions, consider setting COMPOSE_HTTP_TIMEOUT to a higher value (current value: 60).
ERROR: Test execution of restart is FAILED!!!!
mv: cannot stat 'restart/result/*': No such file or directory
Exception in thread "main" java.net.SocketException: Socket closed
	at java.base/java.net.PlainSocketImpl.socketAccept(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:474)
	at java.base/java.net.ServerSocket.implAccept(ServerSocket.java:565)
	at java.base/java.net.ServerSocket.accept(ServerSocket.java:533)
	at org.apache.hadoop.test.JacocoServer.main(JacocoServer.java:60)
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.3.0-SNAPSHOT/compose/result/report.html
