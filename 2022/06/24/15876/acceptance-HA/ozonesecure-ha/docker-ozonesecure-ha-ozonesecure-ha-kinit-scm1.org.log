Attaching to ozonesecure-ha_om2_1, ozonesecure-ha_om1_1, ozonesecure-ha_kdc_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_om3_1, ozonesecure-ha_kms_1, ozonesecure-ha_recon_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_s3g_1, ozonesecure-ha_datanode2_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_scm3.org_1
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2022-06-24 01:16:08,354 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = 9b9d0279a7ce/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:51Z
datanode2_1  | STARTUP_MSG:   java = 11.0.14.1
datanode2_1  | ************************************************************/
datanode2_1  | 2022-06-24 01:16:08,419 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2022-06-24 01:16:08,678 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2022-06-24 01:16:09,691 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2022-06-24 01:16:10,924 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2022-06-24 01:16:10,925 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2022-06-24 01:16:11,619 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:9b9d0279a7ce ip:172.25.0.103
datanode2_1  | 2022-06-24 01:16:14,442 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2022-06-24 01:16:15,153 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2022-06-24 01:16:15,156 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2022-06-24 01:16:16,888 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2022-06-24 01:16:16,902 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2022-06-24 01:16:16,908 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2022-06-24 01:16:16,910 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2022-06-24 01:16:22,076 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2022-06-24 01:16:22,123 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:9b9d0279a7ce
datanode2_1  | 2022-06-24 01:16:22,145 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2022-06-24 01:16:22,164 [main] ERROR client.DNCertificateClient: Invalid domain 9b9d0279a7ce
datanode2_1  | 2022-06-24 01:16:22,170 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@9b9d0279a7ce
datanode2_1  | 2022-06-24 01:16:27,652 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2022-06-24 01:16:27,719 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2022-06-24 01:16:27,733 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/897348533486.crt.
datanode2_1  | 2022-06-24 01:16:27,776 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-811320438653.crt.
datanode2_1  | 2022-06-24 01:16:27,776 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2022-06-24 01:16:27,937 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode2_1  | 2022-06-24 01:16:29,265 [main] INFO reflections.Reflections: Reflections took 1009 ms to scan 2 urls, producing 89 keys and 195 values 
datanode2_1  | 2022-06-24 01:16:29,809 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode2_1  | 2022-06-24 01:16:30,869 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2022-06-24 01:16:30,992 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode2_1  | 2022-06-24 01:16:31,004 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2022-06-24 01:16:31,024 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2022-06-24 01:16:31,212 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2022-06-24 01:16:31,351 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-06-24 01:16:31,354 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2022-06-24 01:16:31,370 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2022-06-24 01:16:31,370 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2022-06-24 01:16:31,371 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode2_1  | 2022-06-24 01:16:31,519 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2022-06-24 01:16:31,531 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2022-06-24 01:16:36,819 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode2_1  | 2022-06-24 01:16:37,978 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-06-24 01:16:38,560 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2022-06-24 01:16:39,160 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2022-06-24 01:16:39,160 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2022-06-24 01:16:39,167 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2022-06-24 01:16:39,177 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2022-06-24 01:16:39,180 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-06-24 01:16:39,190 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2022-06-24 01:16:39,195 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-06-24 01:16:39,317 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode2_1  | 2022-06-24 01:16:39,331 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode2_1  | 2022-06-24 01:16:45,735 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2022-06-24 01:16:45,743 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2022-06-24 01:16:09,661 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = 2b7ec0a4d217/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:51Z
datanode1_1  | STARTUP_MSG:   java = 11.0.14.1
datanode1_1  | ************************************************************/
datanode1_1  | 2022-06-24 01:16:09,829 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2022-06-24 01:16:10,193 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2022-06-24 01:16:10,837 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2022-06-24 01:16:11,818 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2022-06-24 01:16:11,818 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2022-06-24 01:16:12,634 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:2b7ec0a4d217 ip:172.25.0.102
datanode1_1  | 2022-06-24 01:16:15,309 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2022-06-24 01:16:16,145 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2022-06-24 01:16:16,153 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2022-06-24 01:16:18,024 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2022-06-24 01:16:18,035 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2022-06-24 01:16:18,035 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2022-06-24 01:16:18,043 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2022-06-24 01:16:20,333 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2022-06-24 01:16:20,397 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:2b7ec0a4d217
datanode1_1  | 2022-06-24 01:16:20,397 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2022-06-24 01:16:20,438 [main] ERROR client.DNCertificateClient: Invalid domain 2b7ec0a4d217
datanode1_1  | 2022-06-24 01:16:20,453 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@2b7ec0a4d217
datanode1_1  | 2022-06-24 01:16:24,904 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2022-06-24 01:16:24,993 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2022-06-24 01:16:25,023 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-811320438653.crt.
datanode1_1  | 2022-06-24 01:16:25,043 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/894868778582.crt.
datanode1_1  | 2022-06-24 01:16:25,043 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2022-06-24 01:16:25,159 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode1_1  | 2022-06-24 01:16:26,009 [main] INFO reflections.Reflections: Reflections took 690 ms to scan 2 urls, producing 89 keys and 195 values 
datanode1_1  | 2022-06-24 01:16:26,512 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode1_1  | 2022-06-24 01:16:27,768 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2022-06-24 01:16:27,911 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode1_1  | 2022-06-24 01:16:27,925 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2022-06-24 01:16:27,929 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2022-06-24 01:16:28,124 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2022-06-24 01:16:28,273 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-06-24 01:16:28,280 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2022-06-24 01:16:28,288 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2022-06-24 01:16:28,288 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2022-06-24 01:16:28,289 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2022-06-24 01:16:28,500 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2022-06-24 01:16:28,511 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2022-06-24 01:16:33,285 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode1_1  | 2022-06-24 01:16:34,735 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-06-24 01:16:34,968 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2022-06-24 01:16:35,626 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2022-06-24 01:16:35,639 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2022-06-24 01:16:35,643 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2022-06-24 01:16:35,643 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2022-06-24 01:16:35,655 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-06-24 01:16:35,656 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2022-06-24 01:16:35,670 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-06-24 01:16:35,808 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode1_1  | 2022-06-24 01:16:35,832 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode1_1  | 2022-06-24 01:16:41,965 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2022-06-24 01:16:41,974 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode1_1  | 2022-06-24 01:16:41,986 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode1_1  | 2022-06-24 01:16:41,992 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-06-24 01:16:41,992 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-06-24 01:16:42,013 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-06-24 01:16:42,525 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode1_1  | 2022-06-24 01:16:43,724 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode1_1  | 2022-06-24 01:16:43,745 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode1_1  | 2022-06-24 01:16:44,237 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2022-06-24 01:16:44,237 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2022-06-24 01:16:44,239 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2022-06-24 01:16:44,389 [main] INFO util.log: Logging initialized @45123ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2022-06-24 01:16:45,029 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2022-06-24 01:16:45,136 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2022-06-24 01:16:45,147 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2022-06-24 01:16:45,150 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2022-06-24 01:16:45,150 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2022-06-24 01:16:45,184 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2022-06-24 01:16:45,710 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2022-06-24 01:16:45,721 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode1_1  | 2022-06-24 01:16:46,014 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2022-06-24 01:16:46,015 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2022-06-24 01:16:46,023 [main] INFO server.session: node0 Scavenging every 660000ms
datanode1_1  | 2022-06-24 01:16:46,165 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-06-24 01:16:46,179 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4dfe5727{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2022-06-24 01:16:46,189 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1f612968{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2022-06-24 01:16:46,931 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-06-24 01:16:47,018 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@440309c5{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-5309940405668514886/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2022-06-24 01:16:47,068 [main] INFO server.AbstractConnector: Started ServerConnector@4075c0d8{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2022-06-24 01:16:47,076 [main] INFO server.Server: Started @47810ms
datanode1_1  | 2022-06-24 01:16:47,084 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2022-06-24 01:16:47,085 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2022-06-24 01:16:47,096 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2022-06-24 01:16:47,111 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode1_1  | 2022-06-24 01:16:47,333 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1ceff42e] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2022-06-24 01:16:47,715 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2022-06-24 01:16:47,782 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode1_1  | 2022-06-24 01:16:52,251 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86/DS-a03e7055-2036-4eed-85a8-6a42ebc5d6d8/container.db for volume DS-a03e7055-2036-4eed-85a8-6a42ebc5d6d8
datanode1_1  | 2022-06-24 01:16:52,298 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86/DS-a03e7055-2036-4eed-85a8-6a42ebc5d6d8/container.db for volume DS-a03e7055-2036-4eed-85a8-6a42ebc5d6d8
datanode1_1  | 2022-06-24 01:16:52,310 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2022-06-24 01:16:52,313 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2022-06-24 01:16:52,761 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis f015cc2c-a406-4fd0-a15c-edabddeafb23
datanode1_1  | 2022-06-24 01:16:52,881 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: f015cc2c-a406-4fd0-a15c-edabddeafb23: start RPC server
datanode1_1  | 2022-06-24 01:16:52,937 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: f015cc2c-a406-4fd0-a15c-edabddeafb23: GrpcService started, listening on 9856
datanode1_1  | 2022-06-24 01:16:52,952 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: f015cc2c-a406-4fd0-a15c-edabddeafb23: GrpcService started, listening on 9857
datanode1_1  | 2022-06-24 01:16:52,960 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: f015cc2c-a406-4fd0-a15c-edabddeafb23: GrpcService started, listening on 9858
datanode1_1  | 2022-06-24 01:16:52,991 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis f015cc2c-a406-4fd0-a15c-edabddeafb23 is started using port 9858 for RATIS
datanode1_1  | 2022-06-24 01:16:52,991 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$388/0x00000008405de840@774a1ed9] INFO util.JvmPauseMonitor: JvmPauseMonitor-f015cc2c-a406-4fd0-a15c-edabddeafb23: Started
datanode1_1  | 2022-06-24 01:16:52,991 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis f015cc2c-a406-4fd0-a15c-edabddeafb23 is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2022-06-24 01:16:45,747 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode2_1  | 2022-06-24 01:16:45,748 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-06-24 01:16:45,748 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-06-24 01:16:45,765 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-06-24 01:16:46,372 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode2_1  | 2022-06-24 01:16:47,666 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-06-24 01:16:47,685 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-06-24 01:16:48,013 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2022-06-24 01:16:48,015 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2022-06-24 01:16:48,015 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2022-06-24 01:16:48,126 [main] INFO util.log: Logging initialized @49817ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2022-06-24 01:16:48,711 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2022-06-24 01:16:48,772 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2022-06-24 01:16:48,780 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2022-06-24 01:16:48,780 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2022-06-24 01:16:48,786 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2022-06-24 01:16:48,789 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2022-06-24 01:16:49,044 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2022-06-24 01:16:49,050 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode2_1  | 2022-06-24 01:16:49,316 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2022-06-24 01:16:49,321 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2022-06-24 01:16:49,325 [main] INFO server.session: node0 Scavenging every 660000ms
datanode2_1  | 2022-06-24 01:16:49,466 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-06-24 01:16:49,469 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@13617139{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2022-06-24 01:16:49,488 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57e9cd2{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2022-06-24 01:16:50,245 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-06-24 01:16:50,368 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4eb313ed{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-1128068473393675680/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2022-06-24 01:16:50,457 [main] INFO server.AbstractConnector: Started ServerConnector@7c8537e9{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2022-06-24 01:16:50,471 [main] INFO server.Server: Started @52162ms
datanode2_1  | 2022-06-24 01:16:50,473 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2022-06-24 01:16:50,479 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2022-06-24 01:16:50,481 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2022-06-24 01:16:50,506 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode2_1  | 2022-06-24 01:16:50,852 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@30240a5f] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2022-06-24 01:16:51,493 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2022-06-24 01:16:51,578 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode2_1  | 2022-06-24 01:16:54,021 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86/DS-48adc880-7c00-4d4d-930c-1729b28aa9a2/container.db for volume DS-48adc880-7c00-4d4d-930c-1729b28aa9a2
datanode2_1  | 2022-06-24 01:16:54,045 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86/DS-48adc880-7c00-4d4d-930c-1729b28aa9a2/container.db for volume DS-48adc880-7c00-4d4d-930c-1729b28aa9a2
datanode2_1  | 2022-06-24 01:16:54,060 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2022-06-24 01:16:54,063 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2022-06-24 01:16:54,636 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 171701ce-d9aa-46d7-a310-34f3f137a6a3
datanode2_1  | 2022-06-24 01:16:54,956 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.RaftServer: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start RPC server
datanode2_1  | 2022-06-24 01:16:55,084 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 171701ce-d9aa-46d7-a310-34f3f137a6a3: GrpcService started, listening on 9856
datanode2_1  | 2022-06-24 01:16:55,094 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 171701ce-d9aa-46d7-a310-34f3f137a6a3: GrpcService started, listening on 9857
datanode2_1  | 2022-06-24 01:16:55,102 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 171701ce-d9aa-46d7-a310-34f3f137a6a3: GrpcService started, listening on 9858
datanode2_1  | 2022-06-24 01:16:55,129 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 171701ce-d9aa-46d7-a310-34f3f137a6a3 is started using port 9858 for RATIS
datanode2_1  | 2022-06-24 01:16:55,129 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 171701ce-d9aa-46d7-a310-34f3f137a6a3 is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2022-06-24 01:16:55,129 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 171701ce-d9aa-46d7-a310-34f3f137a6a3 is started using port 9856 for RATIS_SERVER
datanode2_1  | 2022-06-24 01:16:55,134 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$389/0x00000008405de840@16cf2ec] INFO util.JvmPauseMonitor: JvmPauseMonitor-171701ce-d9aa-46d7-a310-34f3f137a6a3: Started
datanode2_1  | 2022-06-24 01:16:55,332 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-06-24 01:16:55,332 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-06-24 01:17:00,107 [Command processor thread] INFO server.RaftServer: 171701ce-d9aa-46d7-a310-34f3f137a6a3: addNew group-1CA046E16E6E:[171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-1CA046E16E6E:java.util.concurrent.CompletableFuture@60a0f905[Not completed]
datanode2_1  | 2022-06-24 01:17:00,232 [pool-23-thread-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3: new RaftServerImpl for group-1CA046E16E6E:[171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-06-24 01:17:00,252 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-06-24 01:17:00,255 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-06-24 01:17:00,256 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-06-24 01:17:00,263 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-06-24 01:17:00,267 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-06-24 01:17:00,272 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-06-24 01:17:00,309 [pool-23-thread-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E: ConfigurationManager, init=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-06-24 01:17:00,318 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-06-24 01:17:00,349 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-06-24 01:17:00,355 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-06-24 01:17:00,368 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/0eb29a31-b4b1-466e-a46a-1ca046e16e6e does not exist. Creating ...
datanode2_1  | 2022-06-24 01:17:00,412 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0eb29a31-b4b1-466e-a46a-1ca046e16e6e/in_use.lock acquired by nodename 8@9b9d0279a7ce
datanode2_1  | 2022-06-24 01:17:00,439 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/0eb29a31-b4b1-466e-a46a-1ca046e16e6e has been successfully formatted.
datanode2_1  | 2022-06-24 01:17:00,535 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-1CA046E16E6E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-06-24 01:17:00,537 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-06-24 01:17:00,570 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-06-24 01:17:00,649 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-06-24 01:17:00,676 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-06-24 01:17:00,679 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-06-24 01:17:00,802 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-06-24 01:17:00,847 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-06-24 01:17:00,854 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-06-24 01:17:00,911 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/0eb29a31-b4b1-466e-a46a-1ca046e16e6e
datanode2_1  | 2022-06-24 01:17:00,914 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-06-24 01:17:00,917 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-06-24 01:17:00,922 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-06-24 01:17:00,924 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-06-24 01:17:00,971 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-06-24 01:17:00,976 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-06-24 01:17:00,977 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-06-24 01:17:00,977 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-06-24 01:17:01,136 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2022-06-24 01:16:09,169 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = becb59e2a5e3/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:51Z
datanode3_1  | STARTUP_MSG:   java = 11.0.14.1
datanode3_1  | ************************************************************/
datanode3_1  | 2022-06-24 01:16:09,246 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2022-06-24 01:16:09,853 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2022-06-24 01:16:10,612 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2022-06-24 01:16:11,401 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2022-06-24 01:16:11,401 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2022-06-24 01:16:12,246 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:becb59e2a5e3 ip:172.25.0.104
datanode3_1  | 2022-06-24 01:16:14,988 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2022-06-24 01:16:15,869 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2022-06-24 01:16:15,869 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2022-06-24 01:16:17,754 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2022-06-24 01:16:17,775 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2022-06-24 01:16:17,776 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2022-06-24 01:16:17,792 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2022-06-24 01:16:21,251 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2022-06-24 01:16:21,355 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:becb59e2a5e3
datanode3_1  | 2022-06-24 01:16:21,363 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2022-06-24 01:16:21,380 [main] ERROR client.DNCertificateClient: Invalid domain becb59e2a5e3
datanode3_1  | 2022-06-24 01:16:21,391 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:root@becb59e2a5e3
datanode3_1  | 2022-06-24 01:16:26,258 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2022-06-24 01:16:26,341 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2022-06-24 01:16:26,349 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-811320438653.crt.
datanode3_1  | 2022-06-24 01:16:26,377 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/896230875764.crt.
datanode3_1  | 2022-06-24 01:16:26,380 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2022-06-24 01:16:26,452 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode3_1  | 2022-06-24 01:16:27,193 [main] INFO reflections.Reflections: Reflections took 536 ms to scan 2 urls, producing 89 keys and 195 values 
datanode3_1  | 2022-06-24 01:16:27,641 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode3_1  | 2022-06-24 01:16:28,559 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2022-06-24 01:16:28,637 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode3_1  | 2022-06-24 01:16:28,724 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2022-06-24 01:16:28,725 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2022-06-24 01:16:28,949 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2022-06-24 01:16:29,109 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-06-24 01:16:29,121 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2022-06-24 01:16:29,137 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2022-06-24 01:16:29,137 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2022-06-24 01:16:29,137 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2022-06-24 01:16:29,380 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2022-06-24 01:16:29,399 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2022-06-24 01:16:34,801 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode3_1  | 2022-06-24 01:16:36,529 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-06-24 01:16:36,900 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2022-06-24 01:16:37,388 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2022-06-24 01:16:37,390 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2022-06-24 01:16:37,392 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2022-06-24 01:16:37,400 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2022-06-24 01:16:37,403 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-06-24 01:16:37,404 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2022-06-24 01:16:37,411 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-06-24 01:16:37,700 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode3_1  | 2022-06-24 01:16:37,729 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode3_1  | 2022-06-24 01:16:43,724 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | 2022-06-24 01:16:43,758 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode1_1  | 2022-06-24 01:16:52,996 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis f015cc2c-a406-4fd0-a15c-edabddeafb23 is started using port 9856 for RATIS_SERVER
datanode1_1  | 2022-06-24 01:16:53,113 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-06-24 01:16:53,125 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-06-24 01:17:06,233 [grpc-default-executor-0] INFO server.RaftServer: f015cc2c-a406-4fd0-a15c-edabddeafb23: addNew group-14B5EFD07C11:[171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1] returns group-14B5EFD07C11:java.util.concurrent.CompletableFuture@689194a4[Not completed]
datanode1_1  | 2022-06-24 01:17:06,426 [pool-23-thread-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23: new RaftServerImpl for group-14B5EFD07C11:[171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-06-24 01:17:06,439 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-06-24 01:17:06,450 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-06-24 01:17:06,473 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-06-24 01:17:06,475 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-06-24 01:17:06,475 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-06-24 01:17:06,476 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-06-24 01:17:06,509 [pool-23-thread-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11: ConfigurationManager, init=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-06-24 01:17:06,527 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-06-24 01:17:06,593 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-06-24 01:17:06,619 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-06-24 01:17:06,630 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11 does not exist. Creating ...
datanode1_1  | 2022-06-24 01:17:06,696 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11/in_use.lock acquired by nodename 9@2b7ec0a4d217
datanode1_1  | 2022-06-24 01:17:06,726 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11 has been successfully formatted.
datanode1_1  | 2022-06-24 01:17:06,787 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-14B5EFD07C11: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-06-24 01:17:06,852 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-06-24 01:17:06,882 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-06-24 01:17:06,958 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-06-24 01:17:06,967 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-06-24 01:17:06,974 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-06-24 01:17:07,007 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-06-24 01:17:07,191 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-06-24 01:17:07,194 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-06-24 01:17:07,300 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11
datanode1_1  | 2022-06-24 01:17:07,316 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-06-24 01:17:07,324 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-06-24 01:17:07,330 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-06-24 01:17:07,338 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-06-24 01:17:07,343 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-06-24 01:17:07,402 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-06-24 01:17:07,420 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-06-24 01:17:07,420 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-06-24 01:17:07,522 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-06-24 01:17:07,537 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-06-24 01:17:07,538 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-06-24 01:17:07,677 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-06-24 01:17:07,690 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-06-24 01:17:07,830 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-06-24 01:17:01,141 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-06-24 01:17:01,143 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-06-24 01:17:01,175 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-06-24 01:17:01,176 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-06-24 01:17:01,189 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-06-24 01:17:01,195 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-06-24 01:17:01,196 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-06-24 01:17:01,198 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-06-24 01:17:01,204 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-06-24 01:17:01,212 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-06-24 01:17:01,424 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
kdc_1        | Jun 24 01:14:39 kdc krb5kdc[9](info): Loaded
kdc_1        | Jun 24 01:14:39 kdc krb5kdc[9](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Jun 24 01:14:39 kdc krb5kdc[9](info): setting up network...
kdc_1        | Jun 24 01:14:39 kdc krb5kdc[9](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Jun 24 01:14:39 kdc krb5kdc[9](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Jun 24 01:14:39 kdc krb5kdc[9](info): set up 4 sockets
kdc_1        | Jun 24 01:14:39 kdc krb5kdc[9](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Jun 24 01:14:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033281, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:14:47 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.114: ISSUE: authtime 1656033287, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:14:50 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.115: ISSUE: authtime 1656033290, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:14:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033297, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:15:04 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1656033304, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:15:10 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1656033310, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:15:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1656033290, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:15:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033297, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:15:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1656033304, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:15:27 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033327, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:15:30 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1656033330, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:15:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033327, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:15:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1656033330, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:15:40 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033340, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:15:44 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1656033344, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:15:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1656033344, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:15:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033340, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:15:51 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1656033351, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:15:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033352, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:15:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1656033351, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:16:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033352, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:16:10 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033370, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:16:14 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1656033374, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:16:15 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1656033375, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:16:15 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1656033375, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:16:18 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1656033378, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:16:19 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1656033379, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:16:21 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1656033381, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:16:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1656033379, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:16:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1656033378, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:16:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1656033375, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:16:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1656033381, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:16:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1656033375, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:16:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1656033374, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:16:40 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033370, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:16:46 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033406, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:16:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1656033375, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
datanode3_1  | 2022-06-24 01:16:43,775 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode3_1  | 2022-06-24 01:16:43,775 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-06-24 01:16:43,775 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-06-24 01:16:43,796 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-06-24 01:16:44,196 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode3_1  | 2022-06-24 01:16:45,521 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-06-24 01:16:45,584 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-06-24 01:16:45,981 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2022-06-24 01:16:45,981 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2022-06-24 01:16:45,981 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2022-06-24 01:16:46,174 [main] INFO util.log: Logging initialized @46725ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2022-06-24 01:16:46,770 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2022-06-24 01:16:46,853 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2022-06-24 01:16:46,856 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2022-06-24 01:16:46,874 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2022-06-24 01:16:46,875 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2022-06-24 01:16:46,889 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2022-06-24 01:16:47,298 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2022-06-24 01:16:47,329 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode3_1  | 2022-06-24 01:16:47,520 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2022-06-24 01:16:47,525 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2022-06-24 01:16:47,542 [main] INFO server.session: node0 Scavenging every 600000ms
datanode3_1  | 2022-06-24 01:16:47,712 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-06-24 01:16:47,734 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@45cce4c2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2022-06-24 01:16:47,741 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@619944a7{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2022-06-24 01:16:48,398 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-06-24 01:16:48,494 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4f7a2262{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-3637484466817170689/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2022-06-24 01:16:48,560 [main] INFO server.AbstractConnector: Started ServerConnector@58f259bd{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2022-06-24 01:16:48,561 [main] INFO server.Server: Started @49112ms
datanode3_1  | 2022-06-24 01:16:48,564 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2022-06-24 01:16:48,575 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2022-06-24 01:16:48,589 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2022-06-24 01:17:01,428 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-06-24 01:17:01,430 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-06-24 01:17:01,431 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-06-24 01:17:01,437 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-06-24 01:17:01,440 [pool-23-thread-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E: start as a follower, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-06-24 01:17:01,441 [pool-23-thread-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-06-24 01:17:01,442 [pool-23-thread-1] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-FollowerState
datanode2_1  | 2022-06-24 01:17:01,469 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1CA046E16E6E,id=171701ce-d9aa-46d7-a310-34f3f137a6a3
datanode2_1  | 2022-06-24 01:17:01,536 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=0eb29a31-b4b1-466e-a46a-1ca046e16e6e
datanode2_1  | 2022-06-24 01:17:01,554 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=0eb29a31-b4b1-466e-a46a-1ca046e16e6e.
datanode2_1  | 2022-06-24 01:17:01,555 [Command processor thread] INFO server.RaftServer: 171701ce-d9aa-46d7-a310-34f3f137a6a3: addNew group-14B5EFD07C11:[171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-14B5EFD07C11:java.util.concurrent.CompletableFuture@2c873128[Not completed]
datanode2_1  | 2022-06-24 01:17:01,572 [pool-23-thread-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3: new RaftServerImpl for group-14B5EFD07C11:[171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-06-24 01:17:01,575 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-06-24 01:17:01,575 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-06-24 01:17:01,575 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-06-24 01:17:01,575 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-06-24 01:17:01,575 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-06-24 01:17:01,579 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-06-24 01:17:01,579 [pool-23-thread-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11: ConfigurationManager, init=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-06-24 01:17:01,580 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-06-24 01:17:01,582 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-06-24 01:17:01,595 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-06-24 01:17:01,595 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11 does not exist. Creating ...
datanode2_1  | 2022-06-24 01:17:01,597 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11/in_use.lock acquired by nodename 8@9b9d0279a7ce
datanode2_1  | 2022-06-24 01:17:01,603 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11 has been successfully formatted.
datanode2_1  | 2022-06-24 01:17:01,646 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-14B5EFD07C11: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-06-24 01:17:01,647 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-06-24 01:17:01,648 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-06-24 01:17:01,649 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-06-24 01:17:01,650 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-06-24 01:17:01,650 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-06-24 01:17:01,652 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-06-24 01:17:01,675 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-06-24 01:17:01,680 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-06-24 01:17:01,683 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11
datanode2_1  | 2022-06-24 01:17:01,683 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-06-24 01:17:01,683 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-06-24 01:17:01,689 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-06-24 01:17:01,689 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-06-24 01:17:01,689 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-06-24 01:17:01,690 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-06-24 01:17:01,690 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-06-24 01:17:01,690 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-06-24 01:17:01,690 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-06-24 01:17:01,700 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-06-24 01:17:01,700 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-06-24 01:17:01,700 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-06-24 01:17:01,700 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-06-24 01:17:01,732 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-06-24 01:17:01,733 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-06-24 01:17:01,733 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-06-24 01:17:01,734 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-06-24 01:17:01,734 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-06-24 01:17:01,736 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-06-24 01:17:01,737 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-06-24 01:17:01,737 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-06-24 01:17:01,737 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-06-24 01:17:01,737 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-06-24 01:17:01,738 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-06-24 01:17:01,738 [pool-23-thread-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11: start as a follower, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2022-06-24 01:17:01,740 [pool-23-thread-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-06-24 01:17:01,740 [pool-23-thread-1] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11-FollowerState
datanode2_1  | 2022-06-24 01:17:01,741 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-14B5EFD07C11,id=171701ce-d9aa-46d7-a310-34f3f137a6a3
datanode2_1  | 2022-06-24 01:17:01,772 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11
datanode2_1  | 2022-06-24 01:17:05,672 [grpc-default-executor-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-14B5EFD07C11, 1, (t:0, i:0))
datanode2_1  | 2022-06-24 01:17:05,683 [grpc-default-executor-1] INFO impl.VoteContext: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11-FOLLOWER: accept ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: our priority 0 <= candidate's priority 1
datanode2_1  | 2022-06-24 01:17:05,695 [grpc-default-executor-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:f7360d38-a163-48e1-bebb-4404a3285b4b
datanode2_1  | 2022-06-24 01:17:05,698 [grpc-default-executor-1] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: shutdown 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11-FollowerState
datanode2_1  | 2022-06-24 01:17:05,699 [grpc-default-executor-1] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11-FollowerState
datanode2_1  | 2022-06-24 01:17:05,700 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11-FollowerState] INFO impl.FollowerState: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11-FollowerState was interrupted
datanode2_1  | 2022-06-24 01:17:05,738 [grpc-default-executor-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11 replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:OK-t1. Peer's state: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11:t1, leader=null, voted=f7360d38-a163-48e1-bebb-4404a3285b4b, raftlog=171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode2_1  | 2022-06-24 01:17:06,518 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-FollowerState] INFO impl.FollowerState: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5076282007ns, electionTimeout:5036ms
datanode2_1  | 2022-06-24 01:17:06,519 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-FollowerState] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: shutdown 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-FollowerState
datanode2_1  | 2022-06-24 01:17:06,519 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-FollowerState] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-06-24 01:17:06,521 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-06-24 01:17:06,522 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-FollowerState] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1
datanode2_1  | 2022-06-24 01:17:06,542 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO impl.LeaderElection: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-06-24 01:17:06,548 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO impl.LeaderElection: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2022-06-24 01:16:48,627 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode3_1  | 2022-06-24 01:16:48,848 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4d406678] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2022-06-24 01:16:49,114 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2022-06-24 01:16:49,160 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode3_1  | 2022-06-24 01:16:52,319 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86/DS-c303fbc9-a19e-4702-88f3-0484eaa34b70/container.db for volume DS-c303fbc9-a19e-4702-88f3-0484eaa34b70
datanode3_1  | 2022-06-24 01:16:52,333 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86/DS-c303fbc9-a19e-4702-88f3-0484eaa34b70/container.db for volume DS-c303fbc9-a19e-4702-88f3-0484eaa34b70
datanode3_1  | 2022-06-24 01:16:52,348 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2022-06-24 01:16:52,359 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2022-06-24 01:16:52,825 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis f7360d38-a163-48e1-bebb-4404a3285b4b
datanode3_1  | 2022-06-24 01:16:52,932 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode3_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:298)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:493)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode3_1  | Caused by: java.util.concurrent.TimeoutException
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode3_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	... 1 more
datanode3_1  | 2022-06-24 01:16:53,024 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: f7360d38-a163-48e1-bebb-4404a3285b4b: start RPC server
datanode3_1  | 2022-06-24 01:16:53,048 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: f7360d38-a163-48e1-bebb-4404a3285b4b: GrpcService started, listening on 9856
datanode3_1  | 2022-06-24 01:16:53,088 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: f7360d38-a163-48e1-bebb-4404a3285b4b: GrpcService started, listening on 9857
datanode3_1  | 2022-06-24 01:16:53,097 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: f7360d38-a163-48e1-bebb-4404a3285b4b: GrpcService started, listening on 9858
datanode3_1  | 2022-06-24 01:16:53,116 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis f7360d38-a163-48e1-bebb-4404a3285b4b is started using port 9858 for RATIS
datanode3_1  | 2022-06-24 01:16:53,122 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis f7360d38-a163-48e1-bebb-4404a3285b4b is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2022-06-24 01:16:53,122 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis f7360d38-a163-48e1-bebb-4404a3285b4b is started using port 9856 for RATIS_SERVER
datanode3_1  | 2022-06-24 01:16:53,123 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$388/0x00000008405de840@294df115] INFO util.JvmPauseMonitor: JvmPauseMonitor-f7360d38-a163-48e1-bebb-4404a3285b4b: Started
datanode3_1  | 2022-06-24 01:16:53,220 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-06-24 01:16:53,220 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-06-24 01:16:58,104 [Command processor thread] INFO server.RaftServer: f7360d38-a163-48e1-bebb-4404a3285b4b: addNew group-CBAD1B5E890A:[f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-CBAD1B5E890A:java.util.concurrent.CompletableFuture@5cba10a8[Not completed]
datanode3_1  | 2022-06-24 01:16:58,168 [pool-23-thread-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b: new RaftServerImpl for group-CBAD1B5E890A:[f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-06-24 01:16:58,180 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-06-24 01:16:58,180 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-06-24 01:16:58,181 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-06-24 01:16:58,186 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-06-24 01:16:58,187 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-06-24 01:16:58,192 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-06-24 01:16:58,211 [pool-23-thread-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A: ConfigurationManager, init=-1: [f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-06-24 01:16:58,212 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-06-24 01:16:58,233 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-06-24 01:16:58,238 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-06-24 01:16:58,244 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fae297c5-ae4f-43a4-9b48-cbad1b5e890a does not exist. Creating ...
datanode3_1  | 2022-06-24 01:16:58,265 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fae297c5-ae4f-43a4-9b48-cbad1b5e890a/in_use.lock acquired by nodename 8@becb59e2a5e3
datanode3_1  | 2022-06-24 01:16:58,288 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fae297c5-ae4f-43a4-9b48-cbad1b5e890a has been successfully formatted.
datanode3_1  | 2022-06-24 01:16:58,322 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-CBAD1B5E890A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-06-24 01:16:58,324 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-06-24 01:16:58,326 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-06-24 01:16:58,360 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-06-24 01:16:58,367 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-06-24 01:16:58,375 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-06-24 01:16:58,514 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-06-24 01:16:58,754 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-06-24 01:16:58,768 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-06-24 01:16:58,853 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fae297c5-ae4f-43a4-9b48-cbad1b5e890a
datanode3_1  | 2022-06-24 01:16:58,874 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-06-24 01:16:58,875 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-06-24 01:16:58,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-06-24 01:16:58,887 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-06-24 01:16:58,887 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-06-24 01:16:58,888 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-06-24 01:16:58,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-06-24 01:17:07,848 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-06-24 01:17:07,856 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-06-24 01:17:07,899 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-06-24 01:17:07,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-06-24 01:17:07,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-06-24 01:17:08,137 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-06-24 01:17:08,139 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-06-24 01:17:08,141 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-06-24 01:17:08,142 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-06-24 01:17:08,149 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-06-24 01:17:08,204 [pool-23-thread-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11: start as a follower, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-06-24 01:17:08,205 [grpc-default-executor-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-14B5EFD07C11, 1, (t:0, i:0))
datanode1_1  | 2022-06-24 01:17:08,222 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: f015cc2c-a406-4fd0-a15c-edabddeafb23: Failed requestVote f7360d38-a163-48e1-bebb-4404a3285b4b->f015cc2c-a406-4fd0-a15c-edabddeafb23#0: org.apache.ratis.protocol.exceptions.ServerNotReadyException: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11 is not in [RUNNING]: current state is STARTING
datanode1_1  | 2022-06-24 01:17:08,213 [pool-23-thread-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-06-24 01:17:08,251 [pool-23-thread-1] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11-FollowerState
datanode1_1  | 2022-06-24 01:17:08,286 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-14B5EFD07C11,id=f015cc2c-a406-4fd0-a15c-edabddeafb23
datanode1_1  | 2022-06-24 01:17:09,008 [grpc-default-executor-1] INFO server.RaftServer: f015cc2c-a406-4fd0-a15c-edabddeafb23: addNew group-C3AF98EA0F8C:[171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] returns group-C3AF98EA0F8C:java.util.concurrent.CompletableFuture@6fbed5d8[Not completed]
datanode1_1  | 2022-06-24 01:17:09,011 [pool-23-thread-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23: new RaftServerImpl for group-C3AF98EA0F8C:[171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-06-24 01:17:09,012 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-06-24 01:17:09,012 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-06-24 01:17:09,012 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-06-24 01:17:09,013 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-06-24 01:17:09,015 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-06-24 01:17:09,015 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-06-24 01:17:09,015 [pool-23-thread-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: ConfigurationManager, init=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-06-24 01:17:09,016 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-06-24 01:17:09,016 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-06-24 01:17:09,016 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-06-24 01:17:09,017 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c does not exist. Creating ...
datanode1_1  | 2022-06-24 01:17:09,019 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c/in_use.lock acquired by nodename 9@2b7ec0a4d217
datanode1_1  | 2022-06-24 01:17:09,021 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c has been successfully formatted.
datanode1_1  | 2022-06-24 01:17:09,049 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-C3AF98EA0F8C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-06-24 01:17:09,055 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-06-24 01:17:09,056 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-06-24 01:17:09,056 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-06-24 01:17:09,056 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-06-24 01:17:09,056 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-06-24 01:17:09,056 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-06-24 01:17:09,057 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-06-24 01:16:58,914 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-06-24 01:16:58,946 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-06-24 01:16:58,958 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-06-24 01:16:58,959 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-06-24 01:16:59,000 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-06-24 01:16:59,002 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-06-24 01:16:59,020 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-06-24 01:16:59,021 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-06-24 01:16:59,027 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-06-24 01:16:59,029 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-06-24 01:16:59,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-06-24 01:16:59,041 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-06-24 01:16:59,208 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-06-24 01:16:59,219 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-06-24 01:16:59,220 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-06-24 01:16:59,223 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-06-24 01:16:59,225 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-06-24 01:16:59,226 [pool-23-thread-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A: start as a follower, conf=-1: [f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-06-24 01:16:59,230 [pool-23-thread-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-06-24 01:16:59,234 [pool-23-thread-1] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-FollowerState
datanode3_1  | 2022-06-24 01:16:59,251 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CBAD1B5E890A,id=f7360d38-a163-48e1-bebb-4404a3285b4b
datanode3_1  | 2022-06-24 01:16:59,338 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=fae297c5-ae4f-43a4-9b48-cbad1b5e890a
datanode3_1  | 2022-06-24 01:16:59,344 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=fae297c5-ae4f-43a4-9b48-cbad1b5e890a.
datanode3_1  | 2022-06-24 01:16:59,344 [Command processor thread] INFO server.RaftServer: f7360d38-a163-48e1-bebb-4404a3285b4b: addNew group-14B5EFD07C11:[171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-14B5EFD07C11:java.util.concurrent.CompletableFuture@52d775eb[Not completed]
datanode3_1  | 2022-06-24 01:16:59,379 [pool-23-thread-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b: new RaftServerImpl for group-14B5EFD07C11:[171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-06-24 01:16:59,383 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-06-24 01:16:59,383 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-06-24 01:16:59,383 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-06-24 01:16:59,384 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-06-24 01:16:59,384 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-06-24 01:16:59,399 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-06-24 01:16:59,399 [pool-23-thread-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11: ConfigurationManager, init=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-06-24 01:16:59,400 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-06-24 01:16:59,403 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-06-24 01:16:59,403 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-06-24 01:16:59,403 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11 does not exist. Creating ...
datanode3_1  | 2022-06-24 01:16:59,405 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11/in_use.lock acquired by nodename 8@becb59e2a5e3
datanode3_1  | 2022-06-24 01:16:59,407 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11 has been successfully formatted.
datanode3_1  | 2022-06-24 01:16:59,408 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-14B5EFD07C11: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-06-24 01:16:59,408 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-06-24 01:16:59,408 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-06-24 01:16:59,409 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
kdc_1        | Jun 24 01:16:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1656033375, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Jun 24 01:16:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1656033374, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Jun 24 01:16:55 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1656033415, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:16:58 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1656033418, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:16:59 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1656033419, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:16:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1656033415, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:17:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1656033418, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:17:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1656033419, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:17:14 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033406, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 24 01:17:17 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033437, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:17:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1656033290, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:17:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:17:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:17:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:17:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:17:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033437, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:17:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:17:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:17:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode1_1  | 2022-06-24 01:17:09,057 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-06-24 01:17:09,057 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c
datanode1_1  | 2022-06-24 01:17:09,057 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-06-24 01:17:09,058 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-06-24 01:17:09,059 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-06-24 01:17:09,059 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-06-24 01:17:09,059 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-06-24 01:17:09,059 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-06-24 01:17:09,059 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-06-24 01:17:09,059 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-06-24 01:17:09,060 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-06-24 01:17:09,078 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-06-24 01:17:09,078 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-06-24 01:17:09,079 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-06-24 01:17:09,080 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-06-24 01:17:09,085 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-06-24 01:17:09,085 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-06-24 01:17:09,086 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-06-24 01:17:09,086 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-06-24 01:17:09,087 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-06-24 01:17:09,087 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-06-24 01:17:09,102 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-06-24 01:17:09,109 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-06-24 01:17:09,109 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-06-24 01:17:09,110 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-06-24 01:17:09,110 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-06-24 01:17:09,112 [pool-23-thread-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: start as a follower, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-06-24 01:17:09,136 [pool-23-thread-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-06-24 01:17:09,136 [pool-23-thread-1] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:09,137 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C3AF98EA0F8C,id=f015cc2c-a406-4fd0-a15c-edabddeafb23
datanode1_1  | 2022-06-24 01:17:09,238 [f015cc2c-a406-4fd0-a15c-edabddeafb23-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-14B5EFD07C11 with new leaderId: f7360d38-a163-48e1-bebb-4404a3285b4b
datanode1_1  | 2022-06-24 01:17:09,238 [f015cc2c-a406-4fd0-a15c-edabddeafb23-server-thread1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11: change Leader from null to f7360d38-a163-48e1-bebb-4404a3285b4b at term 1 for appendEntries, leader elected after 2442ms
datanode1_1  | 2022-06-24 01:17:09,241 [f015cc2c-a406-4fd0-a15c-edabddeafb23-server-thread1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode1_1  | 2022-06-24 01:17:09,262 [f015cc2c-a406-4fd0-a15c-edabddeafb23-server-thread1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11: inconsistency entries. Reply:f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#3:FAIL-t0,INCONSISTENCY,nextIndex=0,followerCommit=-1
datanode1_1  | 2022-06-24 01:17:09,365 [f015cc2c-a406-4fd0-a15c-edabddeafb23-server-thread1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11: set configuration 0: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-06-24 01:17:09,385 [f015cc2c-a406-4fd0-a15c-edabddeafb23-server-thread1] INFO segmented.SegmentedRaftLogWorker: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-06-24 01:17:09,917 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-14B5EFD07C11-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11/current/log_inprogress_0
datanode1_1  | 2022-06-24 01:17:13,031 [grpc-default-executor-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-C3AF98EA0F8C, 1, (t:0, i:0))
datanode1_1  | 2022-06-24 01:17:13,033 [grpc-default-executor-1] INFO impl.VoteContext: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FOLLOWER: reject ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: our priority 1 > candidate's priority 0
datanode2_1  | 2022-06-24 01:17:06,551 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: shutdown 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1
datanode2_1  | 2022-06-24 01:17:06,552 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-06-24 01:17:06,552 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-1CA046E16E6E with new leaderId: 171701ce-d9aa-46d7-a310-34f3f137a6a3
datanode2_1  | 2022-06-24 01:17:06,563 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E: change Leader from null to 171701ce-d9aa-46d7-a310-34f3f137a6a3 at term 1 for becomeLeader, leader elected after 6016ms
datanode2_1  | 2022-06-24 01:17:06,621 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-06-24 01:17:06,667 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-06-24 01:17:06,670 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-06-24 01:17:06,712 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-06-24 01:17:06,721 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-06-24 01:17:06,737 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-06-24 01:17:06,799 [171701ce-d9aa-46d7-a310-34f3f137a6a3-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-14B5EFD07C11 with new leaderId: f7360d38-a163-48e1-bebb-4404a3285b4b
datanode2_1  | 2022-06-24 01:17:06,799 [171701ce-d9aa-46d7-a310-34f3f137a6a3-server-thread1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11: change Leader from null to f7360d38-a163-48e1-bebb-4404a3285b4b at term 1 for appendEntries, leader elected after 5152ms
datanode2_1  | 2022-06-24 01:17:06,807 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-06-24 01:17:06,860 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-06-24 01:17:06,912 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderStateImpl
datanode2_1  | 2022-06-24 01:17:06,987 [171701ce-d9aa-46d7-a310-34f3f137a6a3-server-thread1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11: set configuration 0: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-06-24 01:17:07,003 [171701ce-d9aa-46d7-a310-34f3f137a6a3-server-thread1] INFO segmented.SegmentedRaftLogWorker: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-06-24 01:17:07,099 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-06-24 01:17:07,195 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-LeaderElection1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E: set configuration 0: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-06-24 01:17:07,652 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-1CA046E16E6E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0eb29a31-b4b1-466e-a46a-1ca046e16e6e/current/log_inprogress_0
datanode2_1  | 2022-06-24 01:17:07,693 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-14B5EFD07C11-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11/current/log_inprogress_0
datanode2_1  | 2022-06-24 01:17:08,372 [grpc-default-executor-1] INFO server.RaftServer: 171701ce-d9aa-46d7-a310-34f3f137a6a3: addNew group-C3AF98EA0F8C:[171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] returns group-C3AF98EA0F8C:java.util.concurrent.CompletableFuture@115e1c34[Not completed]
datanode2_1  | 2022-06-24 01:17:08,374 [pool-23-thread-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3: new RaftServerImpl for group-C3AF98EA0F8C:[171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-06-24 01:17:08,375 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-06-24 01:17:08,375 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-06-24 01:17:08,375 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-06-24 01:17:08,376 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-06-24 01:17:08,376 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-06-24 01:17:08,376 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-06-24 01:17:08,376 [pool-23-thread-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: ConfigurationManager, init=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-06-24 01:17:08,376 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-06-24 01:17:08,377 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-06-24 01:17:08,377 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-06-24 01:17:08,377 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c does not exist. Creating ...
datanode2_1  | 2022-06-24 01:17:08,381 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c/in_use.lock acquired by nodename 8@9b9d0279a7ce
datanode2_1  | 2022-06-24 01:17:08,385 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c has been successfully formatted.
datanode2_1  | 2022-06-24 01:17:08,441 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-C3AF98EA0F8C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-06-24 01:17:08,441 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-06-24 01:17:08,441 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-06-24 01:17:08,444 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-06-24 01:17:08,444 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-06-24 01:17:08,444 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-06-24 01:17:08,451 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-06-24 01:17:08,455 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-06-24 01:17:08,455 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-06-24 01:17:08,457 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c
datanode2_1  | 2022-06-24 01:17:08,457 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-06-24 01:17:08,457 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-06-24 01:17:08,457 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-06-24 01:17:08,459 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-06-24 01:17:08,459 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-06-24 01:17:08,460 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-06-24 01:17:08,460 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-06-24 01:17:08,460 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-06-24 01:17:08,461 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-06-24 01:17:08,461 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-06-24 01:17:08,461 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-06-24 01:17:08,477 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-06-24 01:17:08,477 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-06-24 01:17:08,479 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-06-24 01:17:08,480 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-06-24 01:17:08,480 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-06-24 01:17:08,485 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-06-24 01:17:08,485 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-06-24 01:17:08,486 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-06-24 01:17:08,487 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-06-24 01:17:08,492 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-06-24 01:17:08,492 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-06-24 01:17:08,493 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-06-24 01:17:08,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
kdc_1        | Jun 24 01:18:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:18:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:18:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:18:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:18:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:18:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:18:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:18:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:18:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:18:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:18:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:19:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:19:13 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:19:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:19:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:19:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:19:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:19:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:19:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode3_1  | 2022-06-24 01:16:59,409 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-06-24 01:16:59,409 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-06-24 01:16:59,409 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-06-24 01:16:59,411 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-06-24 01:16:59,419 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-06-24 01:16:59,420 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11
datanode3_1  | 2022-06-24 01:16:59,421 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-06-24 01:16:59,421 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-06-24 01:16:59,422 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-06-24 01:16:59,423 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-06-24 01:16:59,423 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-06-24 01:16:59,423 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-06-24 01:16:59,424 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-06-24 01:16:59,424 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-06-24 01:16:59,427 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-06-24 01:16:59,433 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-06-24 01:16:59,434 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-06-24 01:16:59,434 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-06-24 01:16:59,467 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-06-24 01:16:59,475 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-06-24 01:16:59,476 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-06-24 01:16:59,476 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-06-24 01:16:59,476 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-06-24 01:16:59,476 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-06-24 01:16:59,476 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-06-24 01:16:59,477 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-06-24 01:16:59,483 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-06-24 01:16:59,484 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-06-24 01:16:59,484 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-06-24 01:16:59,484 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-06-24 01:16:59,485 [pool-23-thread-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11: start as a follower, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-06-24 01:16:59,487 [pool-23-thread-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-06-24 01:16:59,487 [pool-23-thread-1] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-FollowerState
datanode3_1  | 2022-06-24 01:16:59,487 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-14B5EFD07C11,id=f7360d38-a163-48e1-bebb-4404a3285b4b
datanode3_1  | 2022-06-24 01:16:59,519 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11
datanode3_1  | 2022-06-24 01:17:04,430 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-FollowerState] INFO impl.FollowerState: f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5196235367ns, electionTimeout:5166ms
datanode3_1  | 2022-06-24 01:17:04,431 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-FollowerState
datanode3_1  | 2022-06-24 01:17:04,432 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-FollowerState] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-06-24 01:17:04,436 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-06-24 01:17:04,437 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1
datanode3_1  | 2022-06-24 01:17:04,462 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-06-24 01:17:04,464 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2022-06-24 01:17:04,467 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1
kdc_1        | Jun 24 01:19:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:19:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:19:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:20:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033454, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:20:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033607, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:20:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033607, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:20:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033607, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:20:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:20:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:20:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:20:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:20:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:20:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:20:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033620, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:20:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033657, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:21:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033657, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:21:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033657, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2022-06-24 01:17:08,495 [pool-23-thread-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: start as a follower, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-24 01:17:08,497 [pool-23-thread-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-06-24 01:17:08,498 [pool-23-thread-1] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode2_1  | 2022-06-24 01:17:08,499 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C3AF98EA0F8C,id=171701ce-d9aa-46d7-a310-34f3f137a6a3
datanode2_1  | 2022-06-24 01:17:09,804 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11.
datanode2_1  | 2022-06-24 01:17:12,997 [grpc-default-executor-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-C3AF98EA0F8C, 1, (t:0, i:0))
datanode2_1  | 2022-06-24 01:17:12,999 [grpc-default-executor-1] INFO impl.VoteContext: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FOLLOWER: accept ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: our priority 0 <= candidate's priority 0
datanode2_1  | 2022-06-24 01:17:13,000 [grpc-default-executor-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:f7360d38-a163-48e1-bebb-4404a3285b4b
datanode2_1  | 2022-06-24 01:17:13,000 [grpc-default-executor-1] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: shutdown 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode2_1  | 2022-06-24 01:17:13,000 [grpc-default-executor-1] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode2_1  | 2022-06-24 01:17:13,000 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState was interrupted
datanode2_1  | 2022-06-24 01:17:13,002 [grpc-default-executor-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:OK-t1. Peer's state: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C:t1, leader=null, voted=f7360d38-a163-48e1-bebb-4404a3285b4b, raftlog=171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-24 01:17:18,158 [grpc-default-executor-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-C3AF98EA0F8C, 2, (t:0, i:0))
datanode2_1  | 2022-06-24 01:17:18,158 [grpc-default-executor-1] INFO impl.VoteContext: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FOLLOWER: accept ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: our priority 0 <= candidate's priority 0
datanode2_1  | 2022-06-24 01:17:18,158 [grpc-default-executor-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:f7360d38-a163-48e1-bebb-4404a3285b4b
datanode2_1  | 2022-06-24 01:17:18,158 [grpc-default-executor-1] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: shutdown 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode2_1  | 2022-06-24 01:17:18,158 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState was interrupted
datanode2_1  | 2022-06-24 01:17:18,159 [grpc-default-executor-1] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode2_1  | 2022-06-24 01:17:18,161 [grpc-default-executor-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:OK-t2. Peer's state: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C:t2, leader=null, voted=f7360d38-a163-48e1-bebb-4404a3285b4b, raftlog=171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-24 01:17:19,325 [grpc-default-executor-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: receive requestVote(ELECTION, f015cc2c-a406-4fd0-a15c-edabddeafb23, group-C3AF98EA0F8C, 2, (t:0, i:0))
datanode2_1  | 2022-06-24 01:17:19,327 [grpc-default-executor-1] INFO impl.VoteContext: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FOLLOWER: reject ELECTION from f015cc2c-a406-4fd0-a15c-edabddeafb23: already has voted for f7360d38-a163-48e1-bebb-4404a3285b4b at current term 2
datanode2_1  | 2022-06-24 01:17:19,327 [grpc-default-executor-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C replies to ELECTION vote request: f015cc2c-a406-4fd0-a15c-edabddeafb23<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:FAIL-t2. Peer's state: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C:t2, leader=null, voted=f7360d38-a163-48e1-bebb-4404a3285b4b, raftlog=171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-24 01:17:23,168 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5007285789ns, electionTimeout:5002ms
datanode2_1  | 2022-06-24 01:17:23,169 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: shutdown 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode2_1  | 2022-06-24 01:17:23,169 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode2_1  | 2022-06-24 01:17:23,169 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-06-24 01:17:23,170 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-LeaderElection2
datanode2_1  | 2022-06-24 01:17:23,173 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-LeaderElection2] INFO impl.LeaderElection: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-LeaderElection2 ELECTION round 0: submit vote requests at term 3 for -1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-24 01:17:23,339 [grpc-default-executor-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-C3AF98EA0F8C, 3, (t:0, i:0))
datanode2_1  | 2022-06-24 01:17:23,346 [grpc-default-executor-1] INFO impl.VoteContext: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-CANDIDATE: reject ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: already has voted for 171701ce-d9aa-46d7-a310-34f3f137a6a3 at current term 3
datanode2_1  | 2022-06-24 01:17:23,346 [grpc-default-executor-1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:FAIL-t3. Peer's state: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C:t3, leader=null, voted=171701ce-d9aa-46d7-a310-34f3f137a6a3, raftlog=171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-24 01:17:23,596 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-LeaderElection2] INFO impl.LeaderElection: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2022-06-24 01:17:23,597 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-LeaderElection2] INFO impl.LeaderElection:   Response 0: 171701ce-d9aa-46d7-a310-34f3f137a6a3<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t3
datanode2_1  | 2022-06-24 01:17:23,597 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-LeaderElection2] INFO impl.LeaderElection:   Response 1: 171701ce-d9aa-46d7-a310-34f3f137a6a3<-f7360d38-a163-48e1-bebb-4404a3285b4b#0:FAIL-t3
datanode2_1  | 2022-06-24 01:17:23,598 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-LeaderElection2] INFO impl.LeaderElection: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-LeaderElection2 ELECTION round 0: result REJECTED
datanode2_1  | 2022-06-24 01:17:23,607 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-LeaderElection2] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode2_1  | 2022-06-24 01:17:23,607 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-LeaderElection2] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: shutdown 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-LeaderElection2
datanode2_1  | 2022-06-24 01:17:23,607 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-LeaderElection2] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode2_1  | 2022-06-24 01:17:28,438 [grpc-default-executor-0] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-C3AF98EA0F8C, 4, (t:0, i:0))
datanode2_1  | 2022-06-24 01:17:28,438 [grpc-default-executor-0] INFO impl.VoteContext: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FOLLOWER: accept ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: our priority 0 <= candidate's priority 0
datanode2_1  | 2022-06-24 01:17:28,439 [grpc-default-executor-0] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:f7360d38-a163-48e1-bebb-4404a3285b4b
datanode2_1  | 2022-06-24 01:17:28,439 [grpc-default-executor-0] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: shutdown 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode2_1  | 2022-06-24 01:17:28,439 [grpc-default-executor-0] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode2_1  | 2022-06-24 01:17:28,439 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState was interrupted
datanode1_1  | 2022-06-24 01:17:13,033 [grpc-default-executor-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:f7360d38-a163-48e1-bebb-4404a3285b4b
datanode1_1  | 2022-06-24 01:17:13,033 [grpc-default-executor-1] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: shutdown f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:13,033 [grpc-default-executor-1] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:13,034 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState was interrupted
datanode1_1  | 2022-06-24 01:17:13,050 [grpc-default-executor-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t1. Peer's state: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C:t1, leader=null, voted=null, raftlog=f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-06-24 01:17:18,092 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5058481316ns, electionTimeout:5043ms
datanode1_1  | 2022-06-24 01:17:18,093 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: shutdown f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:18,093 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode1_1  | 2022-06-24 01:17:18,097 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-06-24 01:17:18,097 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection1
datanode1_1  | 2022-06-24 01:17:18,113 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection1] INFO impl.LeaderElection: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for -1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-06-24 01:17:18,209 [grpc-default-executor-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-C3AF98EA0F8C, 2, (t:0, i:0))
datanode1_1  | 2022-06-24 01:17:18,209 [grpc-default-executor-1] INFO impl.VoteContext: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-CANDIDATE: reject ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: already has voted for f015cc2c-a406-4fd0-a15c-edabddeafb23 at current term 2
datanode1_1  | 2022-06-24 01:17:18,209 [grpc-default-executor-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t2. Peer's state: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C:t2, leader=null, voted=f015cc2c-a406-4fd0-a15c-edabddeafb23, raftlog=f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-06-24 01:17:19,453 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection1] INFO impl.LeaderElection: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode1_1  | 2022-06-24 01:17:19,459 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection1] INFO impl.LeaderElection:   Response 0: f015cc2c-a406-4fd0-a15c-edabddeafb23<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:FAIL-t2
datanode1_1  | 2022-06-24 01:17:19,459 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection1] INFO impl.LeaderElection:   Response 1: f015cc2c-a406-4fd0-a15c-edabddeafb23<-f7360d38-a163-48e1-bebb-4404a3285b4b#0:FAIL-t2
datanode1_1  | 2022-06-24 01:17:19,460 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection1] INFO impl.LeaderElection: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection1 ELECTION round 0: result REJECTED
datanode1_1  | 2022-06-24 01:17:19,460 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode1_1  | 2022-06-24 01:17:19,462 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection1] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: shutdown f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection1
datanode1_1  | 2022-06-24 01:17:19,478 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection1] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:23,289 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-C3AF98EA0F8C, 3, (t:0, i:0))
datanode1_1  | 2022-06-24 01:17:23,291 [grpc-default-executor-2] INFO impl.VoteContext: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FOLLOWER: reject ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: our priority 1 > candidate's priority 0
datanode1_1  | 2022-06-24 01:17:23,291 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:f7360d38-a163-48e1-bebb-4404a3285b4b
datanode1_1  | 2022-06-24 01:17:23,291 [grpc-default-executor-2] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: shutdown f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:23,291 [grpc-default-executor-2] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
datanode1_1  | 2022-06-24 01:17:23,291 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState was interrupted
datanode1_1  | 2022-06-24 01:17:23,296 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t3. Peer's state: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C:t3, leader=null, voted=null, raftlog=f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-06-24 01:17:23,565 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: receive requestVote(ELECTION, 171701ce-d9aa-46d7-a310-34f3f137a6a3, group-C3AF98EA0F8C, 3, (t:0, i:0))
datanode1_1  | 2022-06-24 01:17:23,565 [grpc-default-executor-2] INFO impl.VoteContext: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FOLLOWER: reject ELECTION from 171701ce-d9aa-46d7-a310-34f3f137a6a3: our priority 1 > candidate's priority 0
datanode1_1  | 2022-06-24 01:17:23,565 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:171701ce-d9aa-46d7-a310-34f3f137a6a3
datanode1_1  | 2022-06-24 01:17:23,565 [grpc-default-executor-2] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: shutdown f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:23,565 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState was interrupted
datanode1_1  | 2022-06-24 01:17:23,571 [grpc-default-executor-2] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:23,586 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C replies to ELECTION vote request: 171701ce-d9aa-46d7-a310-34f3f137a6a3<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t3. Peer's state: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C:t3, leader=null, voted=null, raftlog=f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-06-24 01:17:26,389 [Command processor thread] INFO server.RaftServer: f015cc2c-a406-4fd0-a15c-edabddeafb23: addNew group-AD98D1005D0C:[f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-AD98D1005D0C:java.util.concurrent.CompletableFuture@51160f6[Not completed]
datanode1_1  | 2022-06-24 01:17:26,393 [pool-23-thread-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23: new RaftServerImpl for group-AD98D1005D0C:[f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-06-24 01:17:26,396 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-06-24 01:17:26,396 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-06-24 01:17:26,397 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-06-24 01:17:26,397 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-06-24 01:17:26,397 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-06-24 01:17:26,397 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-06-24 01:17:26,397 [pool-23-thread-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C: ConfigurationManager, init=-1: [f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-06-24 01:17:26,398 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-06-24 01:17:26,398 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-06-24 01:17:26,399 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-06-24 01:17:26,399 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d398541e-69bc-4b5f-864d-ad98d1005d0c does not exist. Creating ...
datanode1_1  | 2022-06-24 01:17:26,403 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d398541e-69bc-4b5f-864d-ad98d1005d0c/in_use.lock acquired by nodename 9@2b7ec0a4d217
datanode1_1  | 2022-06-24 01:17:26,406 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d398541e-69bc-4b5f-864d-ad98d1005d0c has been successfully formatted.
datanode1_1  | 2022-06-24 01:17:26,407 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-AD98D1005D0C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-06-24 01:17:26,407 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-06-24 01:17:26,407 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-06-24 01:17:26,407 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-06-24 01:17:26,407 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-06-24 01:17:26,408 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-06-24 01:17:26,408 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-06-24 01:17:26,417 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-06-24 01:17:26,417 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-06-24 01:17:26,417 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/d398541e-69bc-4b5f-864d-ad98d1005d0c
datanode1_1  | 2022-06-24 01:17:26,417 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-06-24 01:17:26,417 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-06-24 01:17:28,443 [grpc-default-executor-0] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:OK-t4. Peer's state: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C:t4, leader=null, voted=f7360d38-a163-48e1-bebb-4404a3285b4b, raftlog=171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-24 01:17:33,583 [grpc-default-executor-0] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-C3AF98EA0F8C, 5, (t:0, i:0))
datanode2_1  | 2022-06-24 01:17:33,583 [grpc-default-executor-0] INFO impl.VoteContext: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FOLLOWER: accept ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: our priority 0 <= candidate's priority 0
datanode2_1  | 2022-06-24 01:17:33,585 [grpc-default-executor-0] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:f7360d38-a163-48e1-bebb-4404a3285b4b
datanode2_1  | 2022-06-24 01:17:33,585 [grpc-default-executor-0] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: shutdown 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode2_1  | 2022-06-24 01:17:33,586 [grpc-default-executor-0] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode2_1  | 2022-06-24 01:17:33,586 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState was interrupted
datanode2_1  | 2022-06-24 01:17:33,609 [grpc-default-executor-0] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:OK-t5. Peer's state: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C:t5, leader=null, voted=f7360d38-a163-48e1-bebb-4404a3285b4b, raftlog=171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-24 01:17:38,647 [grpc-default-executor-0] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-C3AF98EA0F8C, 6, (t:0, i:0))
datanode2_1  | 2022-06-24 01:17:38,647 [grpc-default-executor-0] INFO impl.VoteContext: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FOLLOWER: accept ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: our priority 0 <= candidate's priority 0
datanode2_1  | 2022-06-24 01:17:38,647 [grpc-default-executor-0] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:f7360d38-a163-48e1-bebb-4404a3285b4b
datanode2_1  | 2022-06-24 01:17:38,647 [grpc-default-executor-0] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: shutdown 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:04,472 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-06-24 01:17:04,473 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CBAD1B5E890A with new leaderId: f7360d38-a163-48e1-bebb-4404a3285b4b
datanode3_1  | 2022-06-24 01:17:04,496 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A: change Leader from null to f7360d38-a163-48e1-bebb-4404a3285b4b at term 1 for becomeLeader, leader elected after 6148ms
datanode3_1  | 2022-06-24 01:17:04,528 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-06-24 01:17:04,554 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-FollowerState] INFO impl.FollowerState: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5067033529ns, electionTimeout:5062ms
datanode3_1  | 2022-06-24 01:17:04,586 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-FollowerState
datanode3_1  | 2022-06-24 01:17:04,587 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-FollowerState] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-06-24 01:17:04,587 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-06-24 01:17:04,587 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2
datanode3_1  | 2022-06-24 01:17:04,616 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-06-24 01:17:04,658 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-06-24 01:17:04,680 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-06-24 01:17:04,805 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-06-24 01:17:04,827 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-06-24 01:17:04,848 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-06-24 01:17:04,879 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-06-24 01:17:04,976 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-06-24 01:17:05,039 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderStateImpl
datanode3_1  | 2022-06-24 01:17:05,404 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-06-24 01:17:05,727 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-LeaderElection1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A: set configuration 0: [f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-06-24 01:17:06,025 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-06-24 01:17:06,063 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO impl.LeaderElection:   Response 0: f7360d38-a163-48e1-bebb-4404a3285b4b<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:OK-t1
datanode3_1  | 2022-06-24 01:17:06,064 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2 ELECTION round 0: result PASSED
datanode3_1  | 2022-06-24 01:17:06,064 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2
datanode3_1  | 2022-06-24 01:17:06,064 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-06-24 01:17:06,064 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-14B5EFD07C11 with new leaderId: f7360d38-a163-48e1-bebb-4404a3285b4b
datanode3_1  | 2022-06-24 01:17:06,065 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11: change Leader from null to f7360d38-a163-48e1-bebb-4404a3285b4b at term 1 for becomeLeader, leader elected after 6656ms
datanode3_1  | 2022-06-24 01:17:06,065 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-06-24 01:17:06,086 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-06-24 01:17:06,087 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-06-24 01:17:06,147 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-06-24 01:17:06,151 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-06-24 01:17:06,157 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-06-24 01:17:06,157 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-06-24 01:17:06,158 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-06-24 01:17:06,273 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-06-24 01:17:06,288 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-06-24 01:17:06,288 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-06-24 01:17:06,321 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-06-24 01:17:06,355 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-06-24 01:17:06,358 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-06-24 01:17:06,370 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-06-24 01:17:06,374 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-06-24 01:17:06,387 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-06-24 01:17:06,388 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-06-24 01:17:06,389 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-06-24 01:17:06,389 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-06-24 01:17:06,424 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderStateImpl
datanode3_1  | 2022-06-24 01:17:06,433 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-06-24 01:17:06,500 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-LeaderElection2] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11: set configuration 0: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-06-24 01:17:06,745 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/68c11d03-dba9-4490-9bc6-14b5efd07c11/current/log_inprogress_0
datanode3_1  | 2022-06-24 01:17:06,751 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f7360d38-a163-48e1-bebb-4404a3285b4b@group-CBAD1B5E890A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fae297c5-ae4f-43a4-9b48-cbad1b5e890a/current/log_inprogress_0
datanode3_1  | 2022-06-24 01:17:07,610 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11.
datanode3_1  | 2022-06-24 01:17:07,610 [Command processor thread] INFO server.RaftServer: f7360d38-a163-48e1-bebb-4404a3285b4b: addNew group-C3AF98EA0F8C:[171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] returns group-C3AF98EA0F8C:java.util.concurrent.CompletableFuture@6c453f1[Not completed]
datanode3_1  | 2022-06-24 01:17:07,621 [pool-23-thread-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b: new RaftServerImpl for group-C3AF98EA0F8C:[171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-06-24 01:17:07,622 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-06-24 01:17:07,622 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-06-24 01:17:07,623 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-06-24 01:17:07,623 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-06-24 01:17:07,627 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-06-24 01:17:07,627 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-06-24 01:17:07,627 [pool-23-thread-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: ConfigurationManager, init=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-06-24 01:17:38,647 [grpc-default-executor-0] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode2_1  | 2022-06-24 01:17:38,647 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState was interrupted
datanode2_1  | 2022-06-24 01:17:38,659 [grpc-default-executor-0] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:OK-t6. Peer's state: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C:t6, leader=null, voted=f7360d38-a163-48e1-bebb-4404a3285b4b, raftlog=171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-24 01:17:43,884 [grpc-default-executor-0] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: receive requestVote(ELECTION, f015cc2c-a406-4fd0-a15c-edabddeafb23, group-C3AF98EA0F8C, 7, (t:0, i:0))
datanode2_1  | 2022-06-24 01:17:43,884 [grpc-default-executor-0] INFO impl.VoteContext: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FOLLOWER: accept ELECTION from f015cc2c-a406-4fd0-a15c-edabddeafb23: our priority 0 <= candidate's priority 1
datanode2_1  | 2022-06-24 01:17:43,884 [grpc-default-executor-0] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: changes role from  FOLLOWER to FOLLOWER at term 7 for candidate:f015cc2c-a406-4fd0-a15c-edabddeafb23
datanode2_1  | 2022-06-24 01:17:43,884 [grpc-default-executor-0] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: shutdown 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode2_1  | 2022-06-24 01:17:43,885 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState was interrupted
datanode2_1  | 2022-06-24 01:17:43,885 [grpc-default-executor-0] INFO impl.RoleInfo: 171701ce-d9aa-46d7-a310-34f3f137a6a3: start 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FollowerState
datanode2_1  | 2022-06-24 01:17:43,893 [grpc-default-executor-0] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C replies to ELECTION vote request: f015cc2c-a406-4fd0-a15c-edabddeafb23<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:OK-t7. Peer's state: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C:t7, leader=null, voted=f015cc2c-a406-4fd0-a15c-edabddeafb23, raftlog=171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-24 01:17:43,898 [grpc-default-executor-0] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-C3AF98EA0F8C, 7, (t:0, i:0))
datanode2_1  | 2022-06-24 01:17:43,898 [grpc-default-executor-0] INFO impl.VoteContext: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-FOLLOWER: reject ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: already has voted for f015cc2c-a406-4fd0-a15c-edabddeafb23 at current term 7
datanode2_1  | 2022-06-24 01:17:43,899 [grpc-default-executor-0] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:FAIL-t7. Peer's state: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C:t7, leader=null, voted=f015cc2c-a406-4fd0-a15c-edabddeafb23, raftlog=171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-24 01:17:44,218 [171701ce-d9aa-46d7-a310-34f3f137a6a3-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C3AF98EA0F8C with new leaderId: f015cc2c-a406-4fd0-a15c-edabddeafb23
datanode2_1  | 2022-06-24 01:17:44,218 [171701ce-d9aa-46d7-a310-34f3f137a6a3-server-thread1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: change Leader from null to f015cc2c-a406-4fd0-a15c-edabddeafb23 at term 7 for appendEntries, leader elected after 35776ms
datanode2_1  | 2022-06-24 01:17:44,241 [171701ce-d9aa-46d7-a310-34f3f137a6a3-server-thread1] INFO server.RaftServer$Division: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C: set configuration 0: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-24 01:17:44,241 [171701ce-d9aa-46d7-a310-34f3f137a6a3-server-thread1] INFO segmented.SegmentedRaftLogWorker: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-06-24 01:17:44,247 [171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 171701ce-d9aa-46d7-a310-34f3f137a6a3@group-C3AF98EA0F8C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c/current/log_inprogress_0
datanode2_1  | 2022-06-24 01:17:51,224 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:903548285013.
datanode1_1  | 2022-06-24 01:17:26,417 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-06-24 01:17:26,418 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-06-24 01:17:26,418 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-06-24 01:17:26,418 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-06-24 01:17:26,418 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-06-24 01:17:26,418 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-06-24 01:17:26,420 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-06-24 01:17:26,421 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-06-24 01:17:26,422 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-06-24 01:17:26,438 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-06-24 01:17:26,480 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-06-24 01:17:26,493 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-06-24 01:17:26,494 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-06-24 01:17:26,494 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-06-24 01:17:26,494 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-06-24 01:17:26,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-06-24 01:17:26,495 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-06-24 01:17:26,502 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-06-24 01:17:26,502 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-06-24 01:17:26,502 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-06-24 01:17:26,503 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-06-24 01:17:26,503 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-06-24 01:17:26,503 [pool-23-thread-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C: start as a follower, conf=-1: [f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-06-24 01:17:26,505 [pool-23-thread-1] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-06-24 01:17:26,505 [pool-23-thread-1] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-FollowerState
datanode1_1  | 2022-06-24 01:17:26,513 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AD98D1005D0C,id=f015cc2c-a406-4fd0-a15c-edabddeafb23
datanode1_1  | 2022-06-24 01:17:26,518 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=d398541e-69bc-4b5f-864d-ad98d1005d0c
datanode1_1  | 2022-06-24 01:17:26,519 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=d398541e-69bc-4b5f-864d-ad98d1005d0c.
datanode1_1  | 2022-06-24 01:17:28,451 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-C3AF98EA0F8C, 4, (t:0, i:0))
datanode1_1  | 2022-06-24 01:17:28,452 [grpc-default-executor-2] INFO impl.VoteContext: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FOLLOWER: reject ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: our priority 1 > candidate's priority 0
datanode1_1  | 2022-06-24 01:17:28,452 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:f7360d38-a163-48e1-bebb-4404a3285b4b
datanode1_1  | 2022-06-24 01:17:28,452 [grpc-default-executor-2] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: shutdown f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:28,453 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState was interrupted
datanode1_1  | 2022-06-24 01:17:28,454 [grpc-default-executor-2] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:28,457 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t4. Peer's state: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C:t4, leader=null, voted=null, raftlog=f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-06-24 01:17:31,619 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-FollowerState] INFO impl.FollowerState: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5113804018ns, electionTimeout:5105ms
datanode1_1  | 2022-06-24 01:17:31,619 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-FollowerState] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: shutdown f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-FollowerState
datanode1_1  | 2022-06-24 01:17:31,619 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-FollowerState] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-06-24 01:17:31,619 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-06-24 01:17:31,620 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-FollowerState] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2
kdc_1        | Jun 24 01:21:14 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033674, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:21:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033674, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:21:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033674, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:21:23 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033683, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:21:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033683, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:21:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033683, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:21:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:21:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:21:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033692, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:21:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033692, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:21:36 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033696, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:21:40 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033696, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:21:41 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033701, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:21:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033701, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:21:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033701, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:21:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033701, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:21:57 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033701, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033701, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033701, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033727, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:22:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033727, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033727, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:20 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033727, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033727, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:25 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:22:25 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:22:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:29 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033749, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:22:29 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033749, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:22:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:22:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:22:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033749, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033753, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:22:33 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033753, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:22:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033753, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033753, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:42 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033762, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:22:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033762, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033762, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033762, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033762, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:22:59 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033779, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:23:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033779, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:23:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033779, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:23:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033779, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:23:19 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033799, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:23:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033799, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:23:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033799, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:23:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:23:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:23:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033799, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:23:58 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033838, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:24:00 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033838, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode1_1  | 2022-06-24 01:17:31,633 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO impl.LeaderElection: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-06-24 01:17:31,634 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO impl.LeaderElection: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2022-06-24 01:17:31,634 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: shutdown f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2
datanode1_1  | 2022-06-24 01:17:31,634 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2022-06-24 01:17:31,635 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AD98D1005D0C with new leaderId: f015cc2c-a406-4fd0-a15c-edabddeafb23
datanode1_1  | 2022-06-24 01:17:31,635 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C: change Leader from null to f015cc2c-a406-4fd0-a15c-edabddeafb23 at term 1 for becomeLeader, leader elected after 5227ms
datanode1_1  | 2022-06-24 01:17:31,654 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-06-24 01:17:31,684 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-06-24 01:17:31,687 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-06-24 01:17:31,697 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-06-24 01:17:31,697 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-06-24 01:17:31,702 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-06-24 01:17:31,707 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-06-24 01:17:31,713 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-06-24 01:17:31,716 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderStateImpl
datanode1_1  | 2022-06-24 01:17:31,722 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-06-24 01:17:31,723 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d398541e-69bc-4b5f-864d-ad98d1005d0c/current/log_inprogress_0
datanode1_1  | 2022-06-24 01:17:31,730 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C-LeaderElection2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-AD98D1005D0C: set configuration 0: [f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-06-24 01:17:33,592 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-C3AF98EA0F8C, 5, (t:0, i:0))
datanode1_1  | 2022-06-24 01:17:33,592 [grpc-default-executor-2] INFO impl.VoteContext: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FOLLOWER: reject ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: our priority 1 > candidate's priority 0
datanode1_1  | 2022-06-24 01:17:33,592 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:f7360d38-a163-48e1-bebb-4404a3285b4b
datanode1_1  | 2022-06-24 01:17:33,592 [grpc-default-executor-2] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: shutdown f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:33,592 [grpc-default-executor-2] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:33,593 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState was interrupted
datanode1_1  | 2022-06-24 01:17:33,598 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t5. Peer's state: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C:t5, leader=null, voted=null, raftlog=f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-06-24 01:17:38,654 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-C3AF98EA0F8C, 6, (t:0, i:0))
datanode1_1  | 2022-06-24 01:17:38,655 [grpc-default-executor-2] INFO impl.VoteContext: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FOLLOWER: reject ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: our priority 1 > candidate's priority 0
datanode1_1  | 2022-06-24 01:17:38,655 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:f7360d38-a163-48e1-bebb-4404a3285b4b
datanode1_1  | 2022-06-24 01:17:38,655 [grpc-default-executor-2] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: shutdown f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:38,655 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState was interrupted
datanode1_1  | 2022-06-24 01:17:38,657 [grpc-default-executor-2] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-06-24 01:16:09,516 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:52Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-06-24 01:16:09,602 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-06-24 01:16:16,750 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-06-24 01:16:19,507 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-06-24 01:16:20,185 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-06-24 01:16:20,191 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-06-24 01:16:20,192 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-06-24 01:16:21,478 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-06-24 01:16:21,482 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-06-24 01:16:21,559 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-06-24 01:16:22,568 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-06-24 01:16:25,292 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2022-06-24 01:16:28,642 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2022-06-24 01:16:28,648 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2022-06-24 01:16:28,661 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2022-06-24 01:16:34,193 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2022-06-24 01:16:34,552 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2022-06-24 01:16:34,556 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2022-06-24 01:16:34,585 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2022-06-24 01:16:34,594 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-06-24 01:16:34,600 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-06-24 01:16:34,623 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-06-24 01:16:34,623 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-06-24 01:16:34,625 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:53b8a25c-b7d5-4020-bf2c-829236b7c472,clusterId:CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86,subject:om1
om1_1        | 2022-06-24 01:16:35,533 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2022-06-24 01:16:37,296 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86;layoutVersion=3
om1_1        | 2022-06-24 01:16:37,415 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-06-24 01:16:47,298 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | 2022-06-24 01:17:07,627 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-06-24 01:17:07,627 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-06-24 01:17:07,627 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-06-24 01:17:07,628 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c does not exist. Creating ...
datanode3_1  | 2022-06-24 01:17:07,631 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c/in_use.lock acquired by nodename 8@becb59e2a5e3
datanode3_1  | 2022-06-24 01:17:07,638 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c has been successfully formatted.
datanode3_1  | 2022-06-24 01:17:07,638 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-C3AF98EA0F8C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-06-24 01:17:07,639 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-06-24 01:17:07,639 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-06-24 01:17:07,651 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-06-24 01:17:07,651 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-06-24 01:17:07,655 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-06-24 01:17:07,696 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-06-24 01:17:07,699 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-06-24 01:17:07,699 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-06-24 01:17:07,703 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c
datanode3_1  | 2022-06-24 01:17:07,708 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-06-24 01:17:07,717 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-06-24 01:17:07,717 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-06-24 01:17:07,718 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-06-24 01:17:07,718 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-06-24 01:17:07,718 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-06-24 01:17:07,718 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-06-24 01:17:07,718 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-06-24 01:17:07,718 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-06-24 01:17:07,760 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-06-24 01:17:07,761 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-06-24 01:17:07,782 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-06-24 01:17:07,782 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-06-24 01:17:07,796 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-06-24 01:17:07,796 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-06-24 01:17:07,802 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-06-24 01:17:07,802 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-06-24 01:17:07,803 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-06-24 01:17:07,803 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-06-24 01:17:07,804 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-06-24 01:17:07,804 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-06-24 01:17:07,808 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-06-24 01:17:07,810 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-06-24 01:17:07,811 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-06-24 01:17:07,831 [pool-23-thread-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: start as a follower, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-06-24 01:17:07,836 [pool-23-thread-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-06-24 01:17:07,836 [pool-23-thread-1] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:07,837 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C3AF98EA0F8C,id=f7360d38-a163-48e1-bebb-4404a3285b4b
datanode3_1  | 2022-06-24 01:17:07,838 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=f58ed7fb-82ba-4210-bda3-c3af98ea0f8c
datanode3_1  | 2022-06-24 01:17:09,298 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=f58ed7fb-82ba-4210-bda3-c3af98ea0f8c.
datanode3_1  | 2022-06-24 01:17:09,301 [grpc-default-executor-1] INFO leader.FollowerInfo: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23: nextIndex: updateUnconditionally 1 -> 0
datanode3_1  | 2022-06-24 01:17:12,983 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5147070290ns, electionTimeout:5112ms
datanode3_1  | 2022-06-24 01:17:12,984 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:38,670 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t6. Peer's state: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C:t6, leader=null, voted=null, raftlog=f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-06-24 01:17:43,869 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5212723240ns, electionTimeout:5200ms
datanode1_1  | 2022-06-24 01:17:43,870 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: shutdown f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState
datanode1_1  | 2022-06-24 01:17:43,870 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
datanode1_1  | 2022-06-24 01:17:43,870 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-06-24 01:17:43,870 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3
datanode1_1  | 2022-06-24 01:17:43,874 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO impl.LeaderElection: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3 ELECTION round 0: submit vote requests at term 7 for -1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-06-24 01:17:43,917 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: receive requestVote(ELECTION, f7360d38-a163-48e1-bebb-4404a3285b4b, group-C3AF98EA0F8C, 7, (t:0, i:0))
datanode1_1  | 2022-06-24 01:17:43,918 [grpc-default-executor-2] INFO impl.VoteContext: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-CANDIDATE: reject ELECTION from f7360d38-a163-48e1-bebb-4404a3285b4b: already has voted for f015cc2c-a406-4fd0-a15c-edabddeafb23 at current term 7
datanode1_1  | 2022-06-24 01:17:43,918 [grpc-default-executor-2] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C replies to ELECTION vote request: f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t7. Peer's state: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C:t7, leader=null, voted=f015cc2c-a406-4fd0-a15c-edabddeafb23, raftlog=f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-06-24 01:17:43,920 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO impl.LeaderElection: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode1_1  | 2022-06-24 01:17:43,923 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO impl.LeaderElection:   Response 0: f015cc2c-a406-4fd0-a15c-edabddeafb23<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:OK-t7
datanode1_1  | 2022-06-24 01:17:43,929 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO impl.LeaderElection: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3 ELECTION round 0: result PASSED
datanode1_1  | 2022-06-24 01:17:43,929 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: shutdown f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3
datanode1_1  | 2022-06-24 01:17:43,930 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: changes role from CANDIDATE to LEADER at term 7 for changeToLeader
datanode1_1  | 2022-06-24 01:17:43,930 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C3AF98EA0F8C with new leaderId: f015cc2c-a406-4fd0-a15c-edabddeafb23
datanode1_1  | 2022-06-24 01:17:43,943 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: change Leader from null to f015cc2c-a406-4fd0-a15c-edabddeafb23 at term 7 for becomeLeader, leader elected after 34874ms
datanode1_1  | 2022-06-24 01:17:43,946 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-06-24 01:17:43,946 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-06-24 01:17:43,946 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-06-24 01:17:43,947 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-06-24 01:17:43,947 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-06-24 01:17:43,947 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-06-24 01:17:43,947 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-06-24 01:17:43,948 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-06-24 01:17:44,047 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2022-06-24 01:17:44,051 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:52Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-06-24 01:16:47,366 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-06-24 01:16:54,802 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-06-24 01:16:56,606 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-06-24 01:16:56,775 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-06-24 01:16:56,778 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-06-24 01:16:56,778 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-06-24 01:16:56,796 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-06-24 01:16:57,032 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om1_1        | 2022-06-24 01:16:58,115 [main] INFO reflections.Reflections: Reflections took 867 ms to scan 1 urls, producing 113 keys and 336 values [using 2 cores]
om1_1        | 2022-06-24 01:16:59,559 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-06-24 01:16:59,563 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-06-24 01:16:59,563 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-06-24 01:17:01,953 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-06-24 01:17:02,125 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-06-24 01:17:05,726 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2022-06-24 01:17:06,381 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2022-06-24 01:17:06,432 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-811320438653.crt.
om1_1        | 2022-06-24 01:17:06,448 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/907725775105.crt.
om1_1        | 2022-06-24 01:17:06,702 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-06-24 01:17:07,922 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-06-24 01:17:07,944 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-06-24 01:17:09,439 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om1_1        | 2022-06-24 01:17:09,506 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2022-06-24 01:17:09,510 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2022-06-24 01:17:10,220 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om1_1        | 2022-06-24 01:17:10,734 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-06-24 01:17:10,741 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2022-06-24 01:17:10,796 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2022-06-24 01:17:11,211 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2022-06-24 01:17:11,261 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-06-24 01:17:11,448 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om1:9872, om3:9872, om2:9872
om1_1        | 2022-06-24 01:17:11,487 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2022-06-24 01:17:12,451 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2022-06-24 01:17:12,712 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2022-06-24 01:17:12,727 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
datanode3_1  | 2022-06-24 01:17:12,984 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-06-24 01:17:12,984 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-06-24 01:17:12,985 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection3
datanode3_1  | 2022-06-24 01:17:12,991 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection3] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-06-24 01:17:13,060 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection3] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection3: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-06-24 01:17:13,060 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection3] INFO impl.LeaderElection:   Response 0: f7360d38-a163-48e1-bebb-4404a3285b4b<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:OK-t1
datanode3_1  | 2022-06-24 01:17:13,060 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection3] INFO impl.LeaderElection:   Response 1: f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t1
datanode3_1  | 2022-06-24 01:17:13,060 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection3] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection3 ELECTION round 0: result REJECTED
datanode3_1  | 2022-06-24 01:17:13,061 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode3_1  | 2022-06-24 01:17:13,061 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection3] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection3
datanode3_1  | 2022-06-24 01:17:13,062 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection3] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:18,147 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5085356884ns, electionTimeout:5084ms
datanode3_1  | 2022-06-24 01:17:18,147 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:18,148 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode3_1  | 2022-06-24 01:17:18,148 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-06-24 01:17:18,148 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection4
datanode3_1  | 2022-06-24 01:17:18,151 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection4] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection4 ELECTION round 0: submit vote requests at term 2 for -1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-06-24 01:17:18,231 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection4] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection4: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-06-24 01:17:18,232 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection4] INFO impl.LeaderElection:   Response 0: f7360d38-a163-48e1-bebb-4404a3285b4b<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:OK-t2
datanode3_1  | 2022-06-24 01:17:18,232 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection4] INFO impl.LeaderElection:   Response 1: f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t2
datanode3_1  | 2022-06-24 01:17:18,232 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection4] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection4 ELECTION round 0: result REJECTED
datanode3_1  | 2022-06-24 01:17:18,232 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection4] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode3_1  | 2022-06-24 01:17:18,232 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection4] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection4
datanode3_1  | 2022-06-24 01:17:18,233 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection4] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:19,342 [grpc-default-executor-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: receive requestVote(ELECTION, f015cc2c-a406-4fd0-a15c-edabddeafb23, group-C3AF98EA0F8C, 2, (t:0, i:0))
datanode3_1  | 2022-06-24 01:17:19,344 [grpc-default-executor-1] INFO impl.VoteContext: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FOLLOWER: reject ELECTION from f015cc2c-a406-4fd0-a15c-edabddeafb23: already has voted for f7360d38-a163-48e1-bebb-4404a3285b4b at current term 2
datanode3_1  | 2022-06-24 01:17:19,347 [grpc-default-executor-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C replies to ELECTION vote request: f015cc2c-a406-4fd0-a15c-edabddeafb23<-f7360d38-a163-48e1-bebb-4404a3285b4b#0:FAIL-t2. Peer's state: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C:t2, leader=null, voted=f7360d38-a163-48e1-bebb-4404a3285b4b, raftlog=f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode1_1  | 2022-06-24 01:17:44,056 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2022-06-24 01:17:44,078 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2022-06-24 01:17:44,080 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-06-24 01:17:44,080 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-06-24 01:17:44,090 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2022-06-24 01:17:44,090 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-06-24 01:17:44,097 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2022-06-24 01:17:44,098 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2022-06-24 01:17:44,098 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-06-24 01:17:44,098 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-06-24 01:17:44,100 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO impl.RoleInfo: f015cc2c-a406-4fd0-a15c-edabddeafb23: start f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderStateImpl
datanode1_1  | 2022-06-24 01:17:44,103 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-06-24 01:17:44,108 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c/current/log_inprogress_0
datanode1_1  | 2022-06-24 01:17:44,129 [f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C-LeaderElection3] INFO server.RaftServer$Division: f015cc2c-a406-4fd0-a15c-edabddeafb23@group-C3AF98EA0F8C: set configuration 0: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-06-24 01:17:51,305 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:903548285013.
om1_1        | 2022-06-24 01:17:12,732 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2022-06-24 01:17:12,732 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-06-24 01:17:12,732 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-06-24 01:17:12,737 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2022-06-24 01:17:12,768 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-06-24 01:17:12,769 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2022-06-24 01:17:12,771 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-06-24 01:17:12,818 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om1_1        | 2022-06-24 01:17:12,818 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om1_1        | 2022-06-24 01:17:15,309 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2022-06-24 01:17:15,314 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om1_1        | 2022-06-24 01:17:15,315 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om1_1        | 2022-06-24 01:17:15,315 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-06-24 01:17:15,317 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-06-24 01:17:15,494 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-06-24 01:17:15,550 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@48e7e2ca[Not completed]
om1_1        | 2022-06-24 01:17:15,559 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2022-06-24 01:17:15,598 [pool-27-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2022-06-24 01:17:15,619 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2022-06-24 01:17:15,626 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2022-06-24 01:17:15,627 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2022-06-24 01:17:15,627 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-06-24 01:17:15,627 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-06-24 01:17:15,627 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2022-06-24 01:17:15,645 [pool-27-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2022-06-24 01:17:15,658 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-06-24 01:17:15,684 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2022-06-24 01:17:15,689 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1        | 2022-06-24 01:17:15,694 [main] INFO om.OzoneManager: Creating RPC Server
om1_1        | 2022-06-24 01:17:15,699 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2022-06-24 01:17:15,747 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om1
om1_1        | 2022-06-24 01:17:15,875 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2022-06-24 01:17:15,889 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2022-06-24 01:17:15,898 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2022-06-24 01:17:15,958 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2022-06-24 01:17:15,960 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-06-24 01:17:15,962 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om1_1        | 2022-06-24 01:17:16,091 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-06-24 01:17:16,290 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2022-06-24 01:17:16,290 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2022-06-24 01:17:16,322 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2022-06-24 01:17:16,326 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-06-24 01:17:16,329 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2022-06-24 01:17:16,338 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-06-24 01:17:16,338 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2022-06-24 01:17:16,344 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2022-06-24 01:17:16,348 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2022-06-24 01:17:16,353 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2022-06-24 01:17:16,353 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2022-06-24 01:17:16,452 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2022-06-24 01:17:16,453 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om1_1        | 2022-06-24 01:17:16,483 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2022-06-24 01:17:16,530 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
kdc_1        | Jun 24 01:24:05 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.114: ISSUE: authtime 1656033287, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:24:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033847, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:24:09 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033847, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:24:26 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033866, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:24:29 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033866, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:24:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:24:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:24:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033891, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:24:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033891, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:25:00 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033900, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:25:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033900, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:25:09 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033909, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:25:12 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033909, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:25:17 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033917, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:25:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033917, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:25:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033917, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:25:29 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656033929, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:25:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:25:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:25:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656033929, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:26:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:26:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:26:48 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656034008, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:26:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656034008, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:27:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:27:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:28:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:28:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:29:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656034145, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:29:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656034145, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:29:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:29:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:30:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:30:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:31:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:31:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
om1_1        | 2022-06-24 01:17:16,530 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2022-06-24 01:17:16,540 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2022-06-24 01:17:16,541 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2022-06-24 01:17:16,541 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2022-06-24 01:17:16,548 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2022-06-24 01:17:16,549 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2022-06-24 01:17:16,549 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2022-06-24 01:17:17,107 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-06-24 01:17:17,119 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om1_1        | 2022-06-24 01:17:17,151 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om1_1        | 2022-06-24 01:17:17,160 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om1_1        | 2022-06-24 01:17:17,160 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om1_1        | 2022-06-24 01:17:18,567 [main] INFO reflections.Reflections: Reflections took 2508 ms to scan 8 urls, producing 23 keys and 512 values [using 2 cores]
om1_1        | 2022-06-24 01:17:19,651 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2022-06-24 01:17:19,672 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2022-06-24 01:17:23,146 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2022-06-24 01:17:23,194 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2022-06-24 01:17:23,194 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2022-06-24 01:17:23,414 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2022-06-24 01:17:23,435 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2022-06-24 01:17:23,441 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-06-24 01:17:23,449 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2022-06-24 01:17:23,450 [om1-impl-thread1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-06-24 01:17:23,473 [om1-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2022-06-24 01:17:23,493 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2022-06-24 01:17:23,788 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2022-06-24 01:17:23,807 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$449/0x00000008405cac40@43b5274e] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2022-06-24 01:17:23,809 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2022-06-24 01:17:23,809 [Listener at om1/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-06-24 01:17:23,811 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2022-06-24 01:17:23,820 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-06-24 01:17:23,827 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1        | 2022-06-24 01:17:23,843 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2022-06-24 01:17:24,017 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2022-06-24 01:17:24,017 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2022-06-24 01:17:24,017 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om1_1        | 2022-06-24 01:17:24,207 [Listener at om1/9862] INFO util.log: Logging initialized @45778ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2022-06-24 01:17:24,708 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2022-06-24 01:17:24,748 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2022-06-24 01:17:24,754 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2022-06-24 01:17:24,759 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2022-06-24 01:17:24,761 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2022-06-24 01:17:24,770 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2022-06-24 01:17:24,897 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2022-06-24 01:17:24,899 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om1_1        | 2022-06-24 01:17:25,023 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2022-06-24 01:17:25,025 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2022-06-24 01:17:25,029 [Listener at om1/9862] INFO server.session: node0 Scavenging every 660000ms
om1_1        | 2022-06-24 01:17:25,093 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-06-24 01:17:25,106 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@344c2157{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2022-06-24 01:17:25,107 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@8704186{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2022-06-24 01:17:25,508 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-06-24 01:17:25,548 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5edd76b8{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-3470552989267760670/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2022-06-24 01:17:25,564 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@14719b71{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2022-06-24 01:17:25,565 [Listener at om1/9862] INFO server.Server: Started @47135ms
om1_1        | 2022-06-24 01:17:25,567 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2022-06-24 01:17:25,571 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2022-06-24 01:17:25,575 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2022-06-24 01:17:25,576 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2022-06-24 01:17:25,764 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om1_1        | 2022-06-24 01:17:25,765 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2022-06-24 01:17:26,041 [Listener at om1/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om1_1        | 2022-06-24 01:17:26,102 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3bcb3510] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2022-06-24 01:17:28,522 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-06-24 01:17:28,533 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: accept ELECTION from om2: our priority 0 <= candidate's priority 0
om1_1        | 2022-06-24 01:17:28,535 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:om2
om1_1        | 2022-06-24 01:17:28,536 [grpc-default-executor-0] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-06-24 01:17:28,537 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState was interrupted
om1_1        | 2022-06-24 01:17:28,539 [grpc-default-executor-0] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-06-24 01:17:28,613 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:OK-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om2, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-06-24 01:17:28,870 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41137
om1_1        | 2022-06-24 01:17:28,892 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:17:29,387 [om1-server-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om2 at term 1 for appendEntries, leader elected after 13498ms
om1_1        | 2022-06-24 01:17:29,606 [om1-server-thread2] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2022-06-24 01:17:29,639 [om1-server-thread2] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2022-06-24 01:17:29,957 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2022-06-24 01:17:30,256 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-06-24 01:17:30,257 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: reject ELECTION from om3: already has voted for om2 at current term 1
om1_1        | 2022-06-24 01:17:30,257 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=om2, voted=om2, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2022-06-24 01:17:31,385 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49146
om1_1        | 2022-06-24 01:17:31,437 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:17:32,719 [om1@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1        | [id: "om1"
om1_1        | address: "om1:9872"
om1_1        | , id: "om3"
om1_1        | address: "om3:9872"
om1_1        | , id: "om2"
om1_1        | address: "om2:9872"
om1_1        | ]
om1_1        | 2022-06-24 01:17:46,355 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49198
om1_1        | 2022-06-24 01:17:46,376 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:17:47,349 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om1_1        | 2022-06-24 01:17:47,469 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om1_1        | 2022-06-24 01:17:59,831 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49252
om1_1        | 2022-06-24 01:17:59,849 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:18:00,537 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49256
om1_1        | 2022-06-24 01:18:00,554 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:18:05,756 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49272
datanode3_1  | 2022-06-24 01:17:23,281 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5048233142ns, electionTimeout:5047ms
datanode3_1  | 2022-06-24 01:17:23,281 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:23,281 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode3_1  | 2022-06-24 01:17:23,282 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-06-24 01:17:23,282 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection5
datanode3_1  | 2022-06-24 01:17:23,284 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection5] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection5 ELECTION round 0: submit vote requests at term 3 for -1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-06-24 01:17:23,303 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection5] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection5: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-06-24 01:17:23,304 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection5] INFO impl.LeaderElection:   Response 0: f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t3
datanode3_1  | 2022-06-24 01:17:23,304 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection5] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection5 ELECTION round 0: result REJECTED
datanode3_1  | 2022-06-24 01:17:23,304 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection5] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode3_1  | 2022-06-24 01:17:23,304 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection5] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection5
datanode3_1  | 2022-06-24 01:17:23,304 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection5] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:23,561 [grpc-default-executor-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: receive requestVote(ELECTION, 171701ce-d9aa-46d7-a310-34f3f137a6a3, group-C3AF98EA0F8C, 3, (t:0, i:0))
datanode3_1  | 2022-06-24 01:17:23,564 [grpc-default-executor-1] INFO impl.VoteContext: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FOLLOWER: reject ELECTION from 171701ce-d9aa-46d7-a310-34f3f137a6a3: already has voted for f7360d38-a163-48e1-bebb-4404a3285b4b at current term 3
datanode3_1  | 2022-06-24 01:17:23,565 [grpc-default-executor-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C replies to ELECTION vote request: 171701ce-d9aa-46d7-a310-34f3f137a6a3<-f7360d38-a163-48e1-bebb-4404a3285b4b#0:FAIL-t3. Peer's state: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C:t3, leader=null, voted=f7360d38-a163-48e1-bebb-4404a3285b4b, raftlog=f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-06-24 01:17:28,423 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5119322681ns, electionTimeout:5062ms
datanode3_1  | 2022-06-24 01:17:28,424 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:28,424 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode3_1  | 2022-06-24 01:17:28,424 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-06-24 01:17:28,424 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection6
datanode3_1  | 2022-06-24 01:17:28,430 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection6] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection6 ELECTION round 0: submit vote requests at term 4 for -1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-06-24 01:17:28,466 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection6] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection6: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-06-24 01:17:28,473 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection6] INFO impl.LeaderElection:   Response 0: f7360d38-a163-48e1-bebb-4404a3285b4b<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:OK-t4
datanode3_1  | 2022-06-24 01:17:28,473 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection6] INFO impl.LeaderElection:   Response 1: f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t4
datanode3_1  | 2022-06-24 01:17:28,473 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection6] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection6 ELECTION round 0: result REJECTED
datanode3_1  | 2022-06-24 01:17:28,486 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection6] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode3_1  | 2022-06-24 01:17:28,486 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection6] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection6
datanode3_1  | 2022-06-24 01:17:28,486 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection6] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:33,569 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5082755147ns, electionTimeout:5082ms
datanode3_1  | 2022-06-24 01:17:33,570 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:33,570 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
datanode3_1  | 2022-06-24 01:17:33,570 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-06-24 01:17:33,570 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection7
datanode3_1  | 2022-06-24 01:17:33,578 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection7] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection7 ELECTION round 0: submit vote requests at term 5 for -1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-06-24 01:17:33,601 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection7] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection7: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-06-24 01:17:33,602 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection7] INFO impl.LeaderElection:   Response 0: f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t5
datanode3_1  | 2022-06-24 01:17:33,602 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection7] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection7 ELECTION round 0: result REJECTED
datanode3_1  | 2022-06-24 01:17:33,602 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection7] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
datanode3_1  | 2022-06-24 01:17:33,602 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection7] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection7
datanode3_1  | 2022-06-24 01:17:33,602 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection7] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:38,639 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5036551763ns, electionTimeout:5024ms
datanode3_1  | 2022-06-24 01:17:38,639 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:38,639 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
datanode3_1  | 2022-06-24 01:17:38,639 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-06-24 01:17:38,639 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection8
datanode3_1  | 2022-06-24 01:17:38,643 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection8] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection8 ELECTION round 0: submit vote requests at term 6 for -1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-06-24 01:17:38,674 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection8] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection8: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-06-24 01:17:38,674 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection8] INFO impl.LeaderElection:   Response 0: f7360d38-a163-48e1-bebb-4404a3285b4b<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:OK-t6
datanode3_1  | 2022-06-24 01:17:38,675 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection8] INFO impl.LeaderElection:   Response 1: f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t6
datanode3_1  | 2022-06-24 01:17:38,679 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection8] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection8 ELECTION round 0: result REJECTED
datanode3_1  | 2022-06-24 01:17:38,679 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection8] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from CANDIDATE to FOLLOWER at term 6 for REJECTED
datanode3_1  | 2022-06-24 01:17:38,679 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection8] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection8
datanode3_1  | 2022-06-24 01:17:38,680 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection8] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:43,873 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.FollowerState: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5193519222ns, electionTimeout:5188ms
datanode3_1  | 2022-06-24 01:17:43,874 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:43,874 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
datanode3_1  | 2022-06-24 01:17:43,875 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
kdc_1        | Jun 24 01:32:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:32:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:33:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:33:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:34:25 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656034465, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:34:29 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656034465, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:34:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:34:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:35:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:35:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:35:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656034539, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:35:45 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656034539, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:36:06 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656034566, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:36:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656034566, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 24 01:36:15 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656034575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 24 01:36:15 kdc krb5kdc[9](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656034575, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
kdc_1        | Jun 24 01:36:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 24 01:36:32 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
om1_1        | 2022-06-24 01:18:05,783 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:18:06,436 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49276
om1_1        | 2022-06-24 01:18:06,440 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:18:06,511 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om1_1        | 2022-06-24 01:18:11,204 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49290
om1_1        | 2022-06-24 01:18:11,228 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:18:19,411 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49316
om1_1        | 2022-06-24 01:18:19,432 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:18:25,603 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49356
om1_1        | 2022-06-24 01:18:25,622 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:18:26,236 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49360
om1_1        | 2022-06-24 01:18:26,243 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:18:26,305 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om1_1        | 2022-06-24 01:18:30,970 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49366
om1_1        | 2022-06-24 01:18:31,000 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:18:35,994 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49382
om1_1        | 2022-06-24 01:18:36,020 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:18:50,554 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49424
om1_1        | 2022-06-24 01:18:50,573 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:18:51,241 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:42768-source for user:testuser
om1_1        | 2022-06-24 01:18:55,239 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49458
om1_1        | 2022-06-24 01:18:55,280 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:18:55,940 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:42768-target for user:testuser
om1_1        | 2022-06-24 01:18:59,656 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49472
om1_1        | 2022-06-24 01:18:59,669 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:19:00,282 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 42768-source
om1_1        | 2022-06-24 01:19:04,084 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49486
om1_1        | 2022-06-24 01:19:04,104 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:19:13,296 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49528
om1_1        | 2022-06-24 01:19:13,319 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:19:14,220 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 42768-source
om1_1        | 2022-06-24 01:19:19,255 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49542
om1_1        | 2022-06-24 01:19:19,276 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:19:20,081 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 42768-target
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-06-24 01:16:07,903 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:52Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-06-24 01:16:07,960 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-06-24 01:16:15,192 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-06-24 01:16:17,659 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-06-24 01:16:18,131 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-06-24 01:16:18,134 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-06-24 01:16:18,138 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-06-24 01:16:19,527 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-06-24 01:16:19,530 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-06-24 01:16:19,553 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-06-24 01:16:20,085 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-06-24 01:16:22,324 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2022-06-24 01:16:26,250 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2022-06-24 01:16:26,250 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2022-06-24 01:16:26,268 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2022-06-24 01:16:29,705 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2022-06-24 01:16:30,052 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2022-06-24 01:16:30,055 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2022-06-24 01:16:30,077 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2022-06-24 01:16:30,082 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-06-24 01:16:30,089 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-06-24 01:16:30,095 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-06-24 01:16:30,096 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-06-24 01:16:30,115 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:53b8a25c-b7d5-4020-bf2c-829236b7c472,clusterId:CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86,subject:om2
om2_1        | 2022-06-24 01:16:31,007 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2022-06-24 01:16:32,988 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86;layoutVersion=3
om2_1        | 2022-06-24 01:16:33,186 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-06-24 01:16:43,600 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
datanode3_1  | 2022-06-24 01:17:43,875 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection9
datanode3_1  | 2022-06-24 01:17:43,884 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection9] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection9 ELECTION round 0: submit vote requests at term 7 for -1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-06-24 01:17:43,920 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection9] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection9: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-06-24 01:17:43,921 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection9] INFO impl.LeaderElection:   Response 0: f7360d38-a163-48e1-bebb-4404a3285b4b<-171701ce-d9aa-46d7-a310-34f3f137a6a3#0:FAIL-t7
datanode3_1  | 2022-06-24 01:17:43,921 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection9] INFO impl.LeaderElection:   Response 1: f7360d38-a163-48e1-bebb-4404a3285b4b<-f015cc2c-a406-4fd0-a15c-edabddeafb23#0:FAIL-t7
datanode3_1  | 2022-06-24 01:17:43,921 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection9] INFO impl.LeaderElection: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection9 ELECTION round 0: result REJECTED
datanode3_1  | 2022-06-24 01:17:43,921 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection9] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: changes role from CANDIDATE to FOLLOWER at term 7 for REJECTED
datanode3_1  | 2022-06-24 01:17:43,921 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection9] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: shutdown f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection9
datanode3_1  | 2022-06-24 01:17:43,921 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-LeaderElection9] INFO impl.RoleInfo: f7360d38-a163-48e1-bebb-4404a3285b4b: start f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FollowerState
datanode3_1  | 2022-06-24 01:17:43,952 [grpc-default-executor-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: receive requestVote(ELECTION, f015cc2c-a406-4fd0-a15c-edabddeafb23, group-C3AF98EA0F8C, 7, (t:0, i:0))
datanode3_1  | 2022-06-24 01:17:43,953 [grpc-default-executor-1] INFO impl.VoteContext: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-FOLLOWER: reject ELECTION from f015cc2c-a406-4fd0-a15c-edabddeafb23: already has voted for f7360d38-a163-48e1-bebb-4404a3285b4b at current term 7
datanode3_1  | 2022-06-24 01:17:43,953 [grpc-default-executor-1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C replies to ELECTION vote request: f015cc2c-a406-4fd0-a15c-edabddeafb23<-f7360d38-a163-48e1-bebb-4404a3285b4b#0:FAIL-t7. Peer's state: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C:t7, leader=null, voted=f7360d38-a163-48e1-bebb-4404a3285b4b, raftlog=f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-SegmentedRaftLog:OPENED:c-1, conf=-1: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode3_1  | 2022-06-24 01:17:44,157 [f7360d38-a163-48e1-bebb-4404a3285b4b-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C3AF98EA0F8C with new leaderId: f015cc2c-a406-4fd0-a15c-edabddeafb23
datanode3_1  | 2022-06-24 01:17:44,157 [f7360d38-a163-48e1-bebb-4404a3285b4b-server-thread1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: change Leader from null to f015cc2c-a406-4fd0-a15c-edabddeafb23 at term 7 for appendEntries, leader elected after 36517ms
datanode3_1  | 2022-06-24 01:17:44,228 [f7360d38-a163-48e1-bebb-4404a3285b4b-server-thread1] INFO server.RaftServer$Division: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C: set configuration 0: [171701ce-d9aa-46d7-a310-34f3f137a6a3|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, f015cc2c-a406-4fd0-a15c-edabddeafb23|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, f7360d38-a163-48e1-bebb-4404a3285b4b|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-24 01:17:44,229 [f7360d38-a163-48e1-bebb-4404a3285b4b-server-thread1] INFO segmented.SegmentedRaftLogWorker: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-06-24 01:17:44,231 [f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f7360d38-a163-48e1-bebb-4404a3285b4b@group-C3AF98EA0F8C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f58ed7fb-82ba-4210-bda3-c3af98ea0f8c/current/log_inprogress_0
datanode3_1  | 2022-06-24 01:17:50,970 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:903548285013.
datanode3_1  | 2022-06-24 01:18:09,302 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4,entriesCount=1,lastEntry=(t:1, i:0)
datanode3_1  | 2022-06-24 01:18:50,945 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=243,entriesCount=1,lastEntry=(t:1, i:1)
datanode3_1  | 2022-06-24 01:18:51,021 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=244,entriesCount=1,lastEntry=(t:1, i:2)
datanode3_1  | 2022-06-24 01:18:52,266 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=246,entriesCount=1,lastEntry=(t:1, i:3)
datanode3_1  | 2022-06-24 01:18:52,314 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=249,entriesCount=1,lastEntry=(t:1, i:4)
datanode3_1  | 2022-06-24 01:19:13,814 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=471,entriesCount=1,lastEntry=(t:1, i:5)
datanode3_1  | 2022-06-24 01:19:13,824 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=472,entriesCount=1,lastEntry=(t:1, i:6)
datanode3_1  | 2022-06-24 01:19:13,852 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=474,entriesCount=1,lastEntry=(t:1, i:7)
datanode3_1  | 2022-06-24 01:19:13,860 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=475,entriesCount=1,lastEntry=(t:1, i:8)
datanode3_1  | 2022-06-24 01:22:06,002 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=615,entriesCount=1,lastEntry=(t:1, i:9)
datanode3_1  | 2022-06-24 01:22:06,003 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=616,entriesCount=1,lastEntry=(t:1, i:10)
datanode3_1  | 2022-06-24 01:22:06,010 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=617,entriesCount=1,lastEntry=(t:1, i:11)
datanode3_1  | 2022-06-24 01:22:06,039 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=621,entriesCount=1,lastEntry=(t:1, i:12)
datanode3_1  | 2022-06-24 01:24:10,359 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=817,entriesCount=1,lastEntry=(t:1, i:13)
datanode3_1  | 2022-06-24 01:24:10,374 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=818,entriesCount=1,lastEntry=(t:1, i:14)
datanode3_1  | 2022-06-24 01:24:10,383 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=819,entriesCount=1,lastEntry=(t:1, i:15)
datanode3_1  | 2022-06-24 01:24:10,385 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=820,entriesCount=1,lastEntry=(t:1, i:16)
datanode3_1  | 2022-06-24 01:25:15,512 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1087,entriesCount=1,lastEntry=(t:1, i:17)
datanode3_1  | 2022-06-24 01:25:15,539 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1088,entriesCount=1,lastEntry=(t:1, i:18)
datanode3_1  | 2022-06-24 01:25:15,549 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1090,entriesCount=1,lastEntry=(t:1, i:19)
datanode3_1  | 2022-06-24 01:25:15,557 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1091,entriesCount=1,lastEntry=(t:1, i:20)
datanode3_1  | 2022-06-24 01:25:18,667 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1327,entriesCount=1,lastEntry=(t:1, i:21)
datanode3_1  | 2022-06-24 01:25:18,668 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1328,entriesCount=1,lastEntry=(t:1, i:22)
datanode3_1  | 2022-06-24 01:25:18,683 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1329,entriesCount=1,lastEntry=(t:1, i:23)
datanode3_1  | 2022-06-24 01:25:18,697 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1330,entriesCount=1,lastEntry=(t:1, i:24)
datanode3_1  | 2022-06-24 01:25:22,944 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1506,entriesCount=1,lastEntry=(t:1, i:25)
datanode3_1  | 2022-06-24 01:25:22,953 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1507,entriesCount=1,lastEntry=(t:1, i:26)
datanode3_1  | 2022-06-24 01:25:22,954 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1508,entriesCount=1,lastEntry=(t:1, i:27)
datanode3_1  | 2022-06-24 01:25:22,967 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1509,entriesCount=1,lastEntry=(t:1, i:28)
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-06-24 01:16:07,748 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:52Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-06-24 01:16:07,840 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-06-24 01:16:15,068 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-06-24 01:16:16,925 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-06-24 01:16:17,504 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-06-24 01:16:17,518 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-06-24 01:16:17,521 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-06-24 01:16:18,801 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-06-24 01:16:18,801 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-06-24 01:16:18,861 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-06-24 01:16:19,665 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-06-24 01:16:22,646 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2022-06-24 01:16:25,687 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2022-06-24 01:16:25,688 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2022-06-24 01:16:25,696 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2022-06-24 01:16:33,463 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2022-06-24 01:16:33,632 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2022-06-24 01:16:33,635 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2022-06-24 01:16:33,650 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2022-06-24 01:16:33,653 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-06-24 01:16:33,660 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-06-24 01:16:33,663 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-06-24 01:16:33,667 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-06-24 01:16:33,669 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:53b8a25c-b7d5-4020-bf2c-829236b7c472,clusterId:CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86,subject:om3
om3_1        | 2022-06-24 01:16:34,558 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2022-06-24 01:16:36,165 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86;layoutVersion=3
om3_1        | 2022-06-24 01:16:36,355 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-06-24 01:16:46,779 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:52Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-06-24 01:16:46,832 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-06-24 01:16:53,755 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-06-24 01:16:56,428 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-06-24 01:16:56,650 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-06-24 01:16:56,651 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-06-24 01:16:56,658 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-06-24 01:16:56,695 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-06-24 01:16:56,888 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om3_1        | 2022-06-24 01:16:58,034 [main] INFO reflections.Reflections: Reflections took 857 ms to scan 1 urls, producing 113 keys and 336 values [using 2 cores]
om3_1        | 2022-06-24 01:16:59,073 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-06-24 01:16:59,073 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-06-24 01:16:59,074 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-06-24 01:17:00,941 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-06-24 01:17:01,217 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-06-24 01:17:05,385 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2022-06-24 01:17:05,913 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2022-06-24 01:17:05,930 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-811320438653.crt.
om3_1        | 2022-06-24 01:17:05,948 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/906767789945.crt.
om3_1        | 2022-06-24 01:17:06,217 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-06-24 01:17:07,231 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-06-24 01:17:07,270 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-06-24 01:17:09,085 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om3_1        | 2022-06-24 01:17:09,124 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2022-06-24 01:17:09,124 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2022-06-24 01:17:09,592 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om3_1        | 2022-06-24 01:17:10,139 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-06-24 01:17:10,140 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2022-06-24 01:17:10,194 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2022-06-24 01:17:10,745 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2022-06-24 01:17:10,795 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-06-24 01:17:10,914 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om3:9872, om1:9872, om2:9872
om3_1        | 2022-06-24 01:17:11,002 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2022-06-24 01:17:12,364 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2022-06-24 01:17:12,862 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2022-06-24 01:17:12,868 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | 2022-06-24 01:25:33,490 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1761,entriesCount=1,lastEntry=(t:1, i:29)
datanode3_1  | 2022-06-24 01:25:33,496 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1762,entriesCount=1,lastEntry=(t:1, i:30)
datanode3_1  | 2022-06-24 01:25:33,503 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1763,entriesCount=1,lastEntry=(t:1, i:31)
datanode3_1  | 2022-06-24 01:25:33,511 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1764,entriesCount=1,lastEntry=(t:1, i:32)
datanode3_1  | 2022-06-24 01:25:35,567 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1959,entriesCount=1,lastEntry=(t:1, i:33)
datanode3_1  | 2022-06-24 01:25:35,581 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1960,entriesCount=1,lastEntry=(t:1, i:34)
datanode3_1  | 2022-06-24 01:25:35,582 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1961,entriesCount=1,lastEntry=(t:1, i:35)
datanode3_1  | 2022-06-24 01:25:35,605 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1963,entriesCount=1,lastEntry=(t:1, i:36)
datanode3_1  | 2022-06-24 01:25:38,829 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2194,entriesCount=1,lastEntry=(t:1, i:37)
datanode3_1  | 2022-06-24 01:25:38,903 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2195,entriesCount=1,lastEntry=(t:1, i:38)
datanode3_1  | 2022-06-24 01:25:39,027 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2196,entriesCount=1,lastEntry=(t:1, i:39)
datanode3_1  | 2022-06-24 01:25:39,035 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2197,entriesCount=1,lastEntry=(t:1, i:40)
datanode3_1  | 2022-06-24 01:25:40,920 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2341,entriesCount=1,lastEntry=(t:1, i:41)
datanode3_1  | 2022-06-24 01:25:40,923 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2342,entriesCount=1,lastEntry=(t:1, i:42)
datanode3_1  | 2022-06-24 01:25:41,042 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2343,entriesCount=1,lastEntry=(t:1, i:43)
datanode3_1  | 2022-06-24 01:25:41,061 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2344,entriesCount=1,lastEntry=(t:1, i:44)
datanode3_1  | 2022-06-24 01:25:43,332 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2530,entriesCount=1,lastEntry=(t:1, i:45)
datanode3_1  | 2022-06-24 01:25:43,344 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2531,entriesCount=1,lastEntry=(t:1, i:46)
datanode3_1  | 2022-06-24 01:25:43,372 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2533,entriesCount=1,lastEntry=(t:1, i:47)
datanode3_1  | 2022-06-24 01:25:43,381 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2535,entriesCount=1,lastEntry=(t:1, i:48)
datanode3_1  | 2022-06-24 01:25:47,849 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2744,entriesCount=1,lastEntry=(t:1, i:49)
datanode3_1  | 2022-06-24 01:25:48,263 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2746,entriesCount=1,lastEntry=(t:1, i:50)
datanode3_1  | 2022-06-24 01:25:48,360 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2747,entriesCount=1,lastEntry=(t:1, i:51)
datanode3_1  | 2022-06-24 01:25:48,625 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2765,entriesCount=1,lastEntry=(t:1, i:52)
datanode3_1  | 2022-06-24 01:25:48,648 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2767,entriesCount=1,lastEntry=(t:1, i:53)
datanode3_1  | 2022-06-24 01:25:48,816 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2782,entriesCount=1,lastEntry=(t:1, i:54)
datanode3_1  | 2022-06-24 01:25:48,867 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2788,entriesCount=1,lastEntry=(t:1, i:55)
datanode3_1  | 2022-06-24 01:25:48,882 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2790,entriesCount=1,lastEntry=(t:1, i:56)
datanode3_1  | 2022-06-24 01:26:37,889 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2984,entriesCount=1,lastEntry=(t:1, i:57)
datanode3_1  | 2022-06-24 01:26:37,895 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2985,entriesCount=1,lastEntry=(t:1, i:58)
datanode3_1  | 2022-06-24 01:26:37,907 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2986,entriesCount=1,lastEntry=(t:1, i:59)
datanode3_1  | 2022-06-24 01:26:38,056 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2987,entriesCount=1,lastEntry=(t:1, i:60)
datanode3_1  | 2022-06-24 01:26:38,068 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2989,entriesCount=1,lastEntry=(t:1, i:61)
om3_1        | 2022-06-24 01:17:12,870 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2022-06-24 01:17:12,871 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-06-24 01:17:12,871 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-06-24 01:17:12,910 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2022-06-24 01:17:12,949 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-06-24 01:17:12,950 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2022-06-24 01:17:12,958 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2022-06-24 01:17:13,080 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om3_1        | 2022-06-24 01:17:13,083 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om3_1        | 2022-06-24 01:17:15,476 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2022-06-24 01:17:15,480 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om3_1        | 2022-06-24 01:17:15,491 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om3_1        | 2022-06-24 01:17:15,498 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-06-24 01:17:15,500 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-06-24 01:17:15,517 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-06-24 01:17:15,636 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@71a2a9a0[Not completed]
om3_1        | 2022-06-24 01:17:15,637 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2022-06-24 01:17:15,721 [pool-27-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2022-06-24 01:17:15,723 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2022-06-24 01:17:15,737 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2022-06-24 01:17:15,738 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2022-06-24 01:17:15,738 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-06-24 01:17:15,739 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-06-24 01:17:15,740 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2022-06-24 01:17:15,740 [main] INFO om.OzoneManager: Creating RPC Server
om3_1        | 2022-06-24 01:17:15,768 [pool-27-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2022-06-24 01:17:15,783 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-06-24 01:17:15,788 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2022-06-24 01:17:15,797 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1        | 2022-06-24 01:17:15,812 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2022-06-24 01:17:15,867 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om3
om3_1        | 2022-06-24 01:17:15,963 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2022-06-24 01:17:15,966 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2022-06-24 01:17:15,974 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2022-06-24 01:17:16,015 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2022-06-24 01:17:16,029 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-06-24 01:17:16,035 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om3_1        | 2022-06-24 01:17:16,246 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2022-06-24 01:14:47,810 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1        | 2022-06-24 01:14:47,819 [main] INFO s3.Gateway: S3Gateway login successful.
s3g_1        | 2022-06-24 01:14:48,060 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2022-06-24 01:14:48,067 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2022-06-24 01:14:48,067 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2022-06-24 01:14:48,217 [main] INFO util.log: Logging initialized @5190ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2022-06-24 01:14:48,755 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2022-06-24 01:14:48,796 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2022-06-24 01:14:48,797 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2022-06-24 01:14:48,797 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2022-06-24 01:14:48,798 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2022-06-24 01:14:48,813 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2022-06-24 01:14:49,124 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.2.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:52Z
s3g_1        | STARTUP_MSG:   java = 11.0.14.1
s3g_1        | ************************************************************/
s3g_1        | 2022-06-24 01:14:49,145 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2022-06-24 01:14:49,230 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2022-06-24 01:14:49,628 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 2022-06-24 01:14:50,053 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 2022-06-24 01:14:50,053 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1        | 2022-06-24 01:14:50,265 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2022-06-24 01:14:50,267 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
s3g_1        | 2022-06-24 01:14:50,453 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2022-06-24 01:14:50,453 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2022-06-24 01:14:50,471 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1        | 2022-06-24 01:14:50,533 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2022-06-24 01:14:50,570 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f69d591{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2022-06-24 01:14:50,580 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4a8a60bc{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2022-06-24 01:14:57,614 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Jun 24, 2022 1:14:59 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2022-06-24 01:14:59,434 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5fa5c8cf{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-1760203211596433735/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2022-06-24 01:14:59,457 [main] INFO server.AbstractConnector: Started ServerConnector@7a138fc5{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2022-06-24 01:14:59,457 [main] INFO server.Server: Started @16431ms
s3g_1        | 2022-06-24 01:14:59,471 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2022-06-24 01:14:59,471 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2022-06-24 01:14:59,473 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1        | 2022-06-24 01:24:04,433 [qtp848097505-20] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
s3g_1        | 2022-06-24 01:24:04,447 [qtp848097505-20] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
s3g_1        | 2022-06-24 01:24:06,112 [qtp848097505-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5909566742, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:24:06,172 [qtp848097505-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5909566742
s3g_1        | 2022-06-24 01:24:13,228 [qtp848097505-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5553790426, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:24:13,249 [qtp848097505-18] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5553790426
s3g_1        | 2022-06-24 01:24:14,102 [qtp848097505-25] WARN impl.MetricsSystemImpl: S3Gateway metrics system already initialized!
s3g_1        | 2022-06-24 01:24:14,441 [qtp848097505-25] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 2022-06-24 01:24:32,809 [qtp848097505-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6250892700, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:24:32,826 [qtp848097505-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6250892700
s3g_1        | 2022-06-24 01:24:33,333 [qtp848097505-22] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-yojsherreq, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:24:33,356 [qtp848097505-22] INFO endpoint.BucketEndpoint: Location is /ozone-test-yojsherreq
s3g_1        | 2022-06-24 01:24:43,089 [qtp848097505-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-pnijeaeuam, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:24:43,100 [qtp848097505-21] INFO endpoint.BucketEndpoint: Location is /bucket-pnijeaeuam
s3g_1        | 2022-06-24 01:24:57,555 [qtp848097505-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4733637939, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:24:57,569 [qtp848097505-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-4733637939
s3g_1        | 2022-06-24 01:24:58,156 [qtp848097505-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1730767704, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:24:58,176 [qtp848097505-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1730767704
s3g_1        | 2022-06-24 01:24:58,749 [qtp848097505-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2065079189, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:24:58,767 [qtp848097505-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2065079189
s3g_1        | 2022-06-24 01:24:59,342 [qtp848097505-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2065079189, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:24:59,359 [qtp848097505-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2065079189
s3g_1        | 2022-06-24 01:25:06,869 [qtp848097505-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3364067888, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:25:06,926 [qtp848097505-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-3364067888
s3g_1        | 2022-06-24 01:25:07,614 [qtp848097505-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4560648265, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:25:07,628 [qtp848097505-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-4560648265
s3g_1        | 2022-06-24 01:25:15,360 [qtp848097505-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2933990824, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:25:15,379 [qtp848097505-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2933990824
s3g_1        | 2022-06-24 01:25:23,214 [qtp848097505-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8597145003, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:25:23,225 [qtp848097505-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-8597145003
s3g_1        | 2022-06-24 01:25:29,281 [qtp848097505-21] ERROR signature.AuthorizationV4HeaderParser: AWS access id shouldn't be empty. credential:/20220624/us-west-1/s3/aws4_request
s3g_1        | Jun 24, 2022 1:25:29 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1        | MultiException stack 1 of 1
s3g_1        | javax.ws.rs.WebApplicationException: The authorization header you provided is invalid.
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.wrapOS3Exception(OzoneClientProducer.java:140)
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:101)
datanode3_1  | 2022-06-24 01:26:38,080 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2991,entriesCount=1,lastEntry=(t:1, i:62)
datanode3_1  | 2022-06-24 01:26:42,832 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3009,entriesCount=1,lastEntry=(t:1, i:63)
datanode3_1  | 2022-06-24 01:26:42,861 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3010,entriesCount=1,lastEntry=(t:1, i:64)
datanode3_1  | 2022-06-24 01:26:42,862 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3011,entriesCount=1,lastEntry=(t:1, i:65)
datanode3_1  | 2022-06-24 01:26:42,918 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3012,entriesCount=1,lastEntry=(t:1, i:66)
datanode3_1  | 2022-06-24 01:26:43,006 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3020,entriesCount=1,lastEntry=(t:1, i:67)
datanode3_1  | 2022-06-24 01:26:43,007 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3021,entriesCount=1,lastEntry=(t:1, i:68)
datanode3_1  | 2022-06-24 01:26:50,776 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3048,entriesCount=1,lastEntry=(t:1, i:69)
datanode3_1  | 2022-06-24 01:26:50,776 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3049,entriesCount=1,lastEntry=(t:1, i:70)
datanode3_1  | 2022-06-24 01:26:50,789 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3050,entriesCount=1,lastEntry=(t:1, i:71)
datanode3_1  | 2022-06-24 01:26:50,808 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3051,entriesCount=1,lastEntry=(t:1, i:72)
datanode3_1  | 2022-06-24 01:26:59,051 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3293,entriesCount=1,lastEntry=(t:1, i:73)
om3_1        | 2022-06-24 01:17:16,321 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2022-06-24 01:17:16,331 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2022-06-24 01:17:16,383 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2022-06-24 01:17:16,419 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2022-06-24 01:17:16,420 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2022-06-24 01:17:16,421 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-06-24 01:17:16,443 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2022-06-24 01:17:16,445 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2022-06-24 01:17:16,457 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2022-06-24 01:17:16,463 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1        | 2022-06-24 01:17:16,466 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2022-06-24 01:17:16,585 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2022-06-24 01:17:16,600 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om3_1        | 2022-06-24 01:17:16,601 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2022-06-24 01:17:16,780 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2022-06-24 01:19:26,285 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49564
om1_1        | 2022-06-24 01:19:26,330 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:19:27,557 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 42768-target
om1_1        | 2022-06-24 01:19:33,041 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49580
om1_1        | 2022-06-24 01:19:33,072 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:19:34,617 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 42768-target
om1_1        | 2022-06-24 01:19:39,665 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49618
om1_1        | 2022-06-24 01:19:39,699 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:19:46,204 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49638
om1_1        | 2022-06-24 01:19:46,228 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:19:53,487 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49654
om1_1        | 2022-06-24 01:19:53,533 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:19:59,295 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49672
om1_1        | 2022-06-24 01:19:59,311 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:20:05,885 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49686
om1_1        | 2022-06-24 01:20:05,921 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:20:12,566 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49724
om1_1        | 2022-06-24 01:20:12,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:20:13,282 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 42768-target
om1_1        | 2022-06-24 01:20:20,008 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49746
om1_1        | 2022-06-24 01:20:20,091 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:20:26,865 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49764
om1_1        | 2022-06-24 01:20:26,905 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:20:28,331 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 42768-target
om1_1        | 2022-06-24 01:20:34,499 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49780
om1_1        | 2022-06-24 01:20:34,539 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:20:35,654 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 42768-source
om1_1        | 2022-06-24 01:20:41,496 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49818
om1_1        | 2022-06-24 01:20:41,514 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:20:51,625 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49852
om1_1        | 2022-06-24 01:20:51,650 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:21:02,534 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49884
om1_1        | 2022-06-24 01:21:02,555 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:21:11,427 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49926
om1_1        | 2022-06-24 01:21:11,443 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:21:17,840 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49944
om1_1        | 2022-06-24 01:21:17,860 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:21:22,531 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49958
om1_1        | 2022-06-24 01:21:22,542 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:21:26,896 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49972
om1_1        | 2022-06-24 01:21:26,913 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:21:31,058 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49978
om1_1        | 2022-06-24 01:21:31,070 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode3_1  | 2022-06-24 01:26:59,053 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3294,entriesCount=1,lastEntry=(t:1, i:74)
datanode3_1  | 2022-06-24 01:26:59,068 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3295,entriesCount=1,lastEntry=(t:1, i:75)
datanode3_1  | 2022-06-24 01:26:59,080 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3297,entriesCount=1,lastEntry=(t:1, i:76)
datanode3_1  | 2022-06-24 01:27:09,079 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3466,entriesCount=1,lastEntry=(t:1, i:77)
datanode3_1  | 2022-06-24 01:27:09,080 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3467,entriesCount=1,lastEntry=(t:1, i:78)
datanode3_1  | 2022-06-24 01:27:09,089 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3468,entriesCount=1,lastEntry=(t:1, i:79)
datanode3_1  | 2022-06-24 01:27:09,096 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3469,entriesCount=1,lastEntry=(t:1, i:80)
datanode3_1  | 2022-06-24 01:27:18,602 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3639,entriesCount=1,lastEntry=(t:1, i:81)
datanode3_1  | 2022-06-24 01:27:18,602 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3640,entriesCount=1,lastEntry=(t:1, i:82)
datanode3_1  | 2022-06-24 01:27:18,612 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3641,entriesCount=1,lastEntry=(t:1, i:83)
datanode3_1  | 2022-06-24 01:27:18,672 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3642,entriesCount=1,lastEntry=(t:1, i:84)
datanode3_1  | 2022-06-24 01:27:18,696 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3645,entriesCount=1,lastEntry=(t:1, i:85)
datanode3_1  | 2022-06-24 01:27:18,715 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3647,entriesCount=1,lastEntry=(t:1, i:86)
datanode3_1  | 2022-06-24 01:27:24,854 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3857,entriesCount=1,lastEntry=(t:1, i:87)
datanode3_1  | 2022-06-24 01:27:24,954 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3858,entriesCount=1,lastEntry=(t:1, i:88)
datanode3_1  | 2022-06-24 01:27:25,014 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3859,entriesCount=1,lastEntry=(t:1, i:89)
datanode3_1  | 2022-06-24 01:27:25,032 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3860,entriesCount=1,lastEntry=(t:1, i:90)
datanode3_1  | 2022-06-24 01:27:25,045 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3862,entriesCount=1,lastEntry=(t:1, i:91)
datanode3_1  | 2022-06-24 01:27:25,077 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3866,entriesCount=1,lastEntry=(t:1, i:92)
datanode3_1  | 2022-06-24 01:27:25,106 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3869,entriesCount=1,lastEntry=(t:1, i:93)
datanode3_1  | 2022-06-24 01:27:25,119 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3873,entriesCount=1,lastEntry=(t:1, i:94)
datanode3_1  | 2022-06-24 01:27:27,361 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3942,entriesCount=1,lastEntry=(t:1, i:95)
datanode3_1  | 2022-06-24 01:27:27,429 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3943,entriesCount=1,lastEntry=(t:1, i:96)
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:52Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-06-24 01:16:43,678 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-06-24 01:16:50,256 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-06-24 01:16:52,594 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-06-24 01:16:53,032 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-06-24 01:16:53,035 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-06-24 01:16:53,035 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-06-24 01:16:53,124 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-06-24 01:16:53,372 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om2_1        | 2022-06-24 01:16:54,749 [main] INFO reflections.Reflections: Reflections took 1149 ms to scan 1 urls, producing 113 keys and 336 values [using 2 cores]
om2_1        | 2022-06-24 01:16:56,270 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-06-24 01:16:56,270 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-06-24 01:16:56,273 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-06-24 01:16:58,028 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-06-24 01:16:58,222 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-06-24 01:17:02,573 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2022-06-24 01:17:03,011 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2022-06-24 01:17:03,024 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-811320438653.crt.
om2_1        | 2022-06-24 01:17:03,040 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/903548285013.crt.
om2_1        | 2022-06-24 01:17:03,249 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-06-24 01:17:04,324 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-06-24 01:17:04,352 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-06-24 01:17:07,141 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om2_1        | 2022-06-24 01:17:07,253 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2022-06-24 01:17:07,253 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2022-06-24 01:17:08,361 [main] INFO om.OzoneManager: Created Volume s3v With Owner root required for S3Gateway operations.
om2_1        | 2022-06-24 01:17:09,030 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-06-24 01:17:09,055 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2022-06-24 01:17:09,162 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2022-06-24 01:17:09,786 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2022-06-24 01:17:09,885 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-06-24 01:17:10,118 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om2:9872, om1:9872, om3:9872
om2_1        | 2022-06-24 01:17:10,280 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2022-06-24 01:17:11,114 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2022-06-24 01:17:11,465 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2022-06-24 01:17:11,469 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2022-06-24 01:14:45,540 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:52Z
recon_1      | STARTUP_MSG:   java = 11.0.14.1
recon_1      | ************************************************************/
recon_1      | 2022-06-24 01:14:45,582 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2022-06-24 01:14:47,859 [main] INFO reflections.Reflections: Reflections took 207 ms to scan 1 urls, producing 13 keys and 35 values 
recon_1      | 2022-06-24 01:14:50,309 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2022-06-24 01:14:50,426 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2022-06-24 01:14:51,014 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
recon_1      | 2022-06-24 01:14:51,025 [main] INFO recon.ReconServer: Recon login successful.
recon_1      | 2022-06-24 01:14:51,025 [main] INFO recon.ReconServer: Initializing secure Recon.
recon_1      | 2022-06-24 01:14:52,740 [main] ERROR client.ReconCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
recon_1      | 2022-06-24 01:14:52,741 [main] INFO client.ReconCertificateClient: Certificate client init case: 0
recon_1      | 2022-06-24 01:14:52,742 [main] INFO client.ReconCertificateClient: Creating keypair for client as keypair and certificate not found.
recon_1      | 2022-06-24 01:14:55,174 [main] INFO recon.ReconServer: Init response: GETCERT
recon_1      | 2022-06-24 01:14:55,218 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.115,host:recon
recon_1      | 2022-06-24 01:14:55,219 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
recon_1      | 2022-06-24 01:14:55,233 [main] ERROR client.ReconCertificateClient: Invalid domain recon
recon_1      | 2022-06-24 01:14:55,423 [main] INFO recon.ReconServer: Creating CSR for Recon.
recon_1      | 2022-06-24 01:14:58,392 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:15:00,394 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:15:02,395 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:15:04,397 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:15:06,399 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:15:08,400 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:15:10,402 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:15:12,405 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:15:16,407 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:53b8a25c-b7d5-4020-bf2c-829236b7c472 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
om2_1        | 2022-06-24 01:17:11,471 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2022-06-24 01:17:11,472 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-06-24 01:17:11,472 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-06-24 01:17:11,474 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2022-06-24 01:17:11,477 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-06-24 01:17:11,484 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2022-06-24 01:17:11,485 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-06-24 01:17:11,559 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om2_1        | 2022-06-24 01:17:11,563 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om2_1        | 2022-06-24 01:17:13,633 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2022-06-24 01:17:13,647 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om2_1        | 2022-06-24 01:17:13,650 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om2_1        | 2022-06-24 01:17:13,651 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-06-24 01:17:13,654 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-06-24 01:17:13,672 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-06-24 01:17:13,734 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@189fe8af[Not completed]
om2_1        | 2022-06-24 01:17:13,734 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2022-06-24 01:17:13,829 [pool-27-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2022-06-24 01:17:13,896 [main] INFO om.OzoneManager: Creating RPC Server
om2_1        | 2022-06-24 01:17:13,898 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2022-06-24 01:17:13,926 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2022-06-24 01:17:13,926 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2022-06-24 01:17:13,926 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-06-24 01:17:13,926 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-06-24 01:17:13,927 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2022-06-24 01:17:13,944 [pool-27-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2022-06-24 01:17:13,960 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-06-24 01:17:13,972 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2022-06-24 01:17:13,984 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2022-06-24 01:17:13,986 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2022-06-24 01:17:14,051 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om2
om2_1        | 2022-06-24 01:17:14,167 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2022-06-24 01:17:14,172 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2022-06-24 01:17:14,174 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2022-06-24 01:17:14,206 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2022-06-24 01:17:14,207 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-06-24 01:17:14,209 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om2_1        | 2022-06-24 01:17:14,414 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-06-24 01:17:14,492 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2022-06-24 01:17:14,504 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2022-06-24 01:17:14,546 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2022-06-24 01:17:14,581 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-06-24 01:17:14,582 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2022-06-24 01:17:14,604 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-06-24 01:17:14,615 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2022-06-24 01:17:14,616 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2022-06-24 01:17:14,626 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2022-06-24 01:17:14,647 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2022-06-24 01:17:14,648 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2022-06-24 01:17:14,777 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2022-06-24 01:17:14,787 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om2_1        | 2022-06-24 01:17:14,795 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2022-06-24 01:17:14,846 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2022-06-24 01:17:14,846 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2022-06-24 01:17:14,908 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2022-06-24 01:17:14,927 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2022-06-24 01:17:14,928 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2022-06-24 01:17:14,930 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2022-06-24 01:17:14,966 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2022-06-24 01:17:14,966 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2022-06-24 01:17:15,292 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-06-24 01:17:15,303 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om2_1        | 2022-06-24 01:17:15,303 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om2_1        | 2022-06-24 01:17:15,304 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om2_1        | 2022-06-24 01:17:15,304 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om2_1        | 2022-06-24 01:17:16,043 [main] INFO reflections.Reflections: Reflections took 1846 ms to scan 8 urls, producing 23 keys and 512 values [using 2 cores]
om2_1        | 2022-06-24 01:17:17,146 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2022-06-24 01:17:17,219 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2022-06-24 01:17:21,416 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2022-06-24 01:17:21,481 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2022-06-24 01:17:21,481 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2022-06-24 01:17:21,694 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2022-06-24 01:17:21,694 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2022-06-24 01:17:21,696 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-06-24 01:17:21,703 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2022-06-24 01:17:21,705 [om2-impl-thread1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-06-24 01:17:21,732 [om2-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
datanode3_1  | 2022-06-24 01:27:27,730 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3968,entriesCount=1,lastEntry=(t:1, i:97)
datanode3_1  | 2022-06-24 01:27:27,770 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3972,entriesCount=1,lastEntry=(t:1, i:98)
datanode3_1  | 2022-06-24 01:27:27,821 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3977,entriesCount=1,lastEntry=(t:1, i:99)
datanode3_1  | 2022-06-24 01:27:27,871 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3983,entriesCount=1,lastEntry=(t:1, i:100)
datanode3_1  | 2022-06-24 01:27:27,891 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3985,entriesCount=1,lastEntry=(t:1, i:101)
datanode3_1  | 2022-06-24 01:27:27,892 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3986,entriesCount=1,lastEntry=(t:1, i:102)
datanode3_1  | 2022-06-24 01:27:29,029 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4029,entriesCount=1,lastEntry=(t:1, i:103)
datanode3_1  | 2022-06-24 01:27:29,040 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4030,entriesCount=1,lastEntry=(t:1, i:104)
datanode3_1  | 2022-06-24 01:27:29,057 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4031,entriesCount=1,lastEntry=(t:1, i:105)
datanode3_1  | 2022-06-24 01:27:29,062 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4033,entriesCount=1,lastEntry=(t:1, i:106)
datanode3_1  | 2022-06-24 01:27:38,220 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4207,entriesCount=1,lastEntry=(t:1, i:107)
datanode3_1  | 2022-06-24 01:27:38,450 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4209,entriesCount=1,lastEntry=(t:1, i:108)
datanode3_1  | 2022-06-24 01:27:38,495 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4210,entriesCount=1,lastEntry=(t:1, i:109)
datanode3_1  | 2022-06-24 01:27:38,498 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4211,entriesCount=1,lastEntry=(t:1, i:110)
datanode3_1  | 2022-06-24 01:27:38,513 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4213,entriesCount=1,lastEntry=(t:1, i:111)
datanode3_1  | 2022-06-24 01:27:38,706 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4220,entriesCount=1,lastEntry=(t:1, i:112)
datanode3_1  | 2022-06-24 01:27:38,734 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4223,entriesCount=1,lastEntry=(t:1, i:113)
datanode3_1  | 2022-06-24 01:27:38,770 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4228,entriesCount=1,lastEntry=(t:1, i:114)
datanode3_1  | 2022-06-24 01:27:42,851 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4473,entriesCount=1,lastEntry=(t:1, i:115)
datanode3_1  | 2022-06-24 01:27:42,959 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4474,entriesCount=1,lastEntry=(t:1, i:116)
datanode3_1  | 2022-06-24 01:27:43,086 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4486,entriesCount=1,lastEntry=(t:1, i:117)
datanode3_1  | 2022-06-24 01:27:43,151 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4493,entriesCount=1,lastEntry=(t:1, i:118)
datanode3_1  | 2022-06-24 01:27:43,176 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4495,entriesCount=1,lastEntry=(t:1, i:119)
datanode3_1  | 2022-06-24 01:27:43,204 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4499,entriesCount=1,lastEntry=(t:1, i:120)
datanode3_1  | 2022-06-24 01:27:43,213 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4500,entriesCount=1,lastEntry=(t:1, i:121)
datanode3_1  | 2022-06-24 01:27:43,216 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4501,entriesCount=1,lastEntry=(t:1, i:122)
datanode3_1  | 2022-06-24 01:27:55,403 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4558,entriesCount=1,lastEntry=(t:1, i:123)
datanode3_1  | 2022-06-24 01:27:55,403 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4559,entriesCount=1,lastEntry=(t:1, i:124)
datanode3_1  | 2022-06-24 01:27:55,416 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4560,entriesCount=1,lastEntry=(t:1, i:125)
datanode3_1  | 2022-06-24 01:27:55,416 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4561,entriesCount=1,lastEntry=(t:1, i:126)
datanode3_1  | 2022-06-24 01:27:57,501 [java.util.concurrent.ThreadPoolExecutor$Worker@5f2202a1[State = -1, empty queue]] WARN server.GrpcLogAppender: f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11->f015cc2c-a406-4fd0-a15c-edabddeafb23-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4640,entriesCount=1,lastEntry=(t:1, i:127)
datanode3_1  | 2022-06-24 01:29:57,901 [null-request--thread6] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-FA455E8DB533->f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11, cid=154, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-FA455E8DB533->f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11, cid=154, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 154 and log index 129 is not yet replicated to ALL_COMMITTED, logIndex=129, commits[f7360d38-a163-48e1-bebb-4404a3285b4b:c138, 171701ce-d9aa-46d7-a310-34f3f137a6a3:c138, f015cc2c-a406-4fd0-a15c-edabddeafb23:c127]
datanode3_1  | 2022-06-24 01:30:58,897 [null-request--thread6] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-52909E10B9BD->f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11, cid=158, seq=0, Watch-ALL_COMMITTED(133), Message:<EMPTY>, reply=RaftClientReply:client-52909E10B9BD->f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11, cid=158, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 158 and log index 133 is not yet replicated to ALL_COMMITTED, logIndex=133, commits[f7360d38-a163-48e1-bebb-4404a3285b4b:c142, 171701ce-d9aa-46d7-a310-34f3f137a6a3:c142, f015cc2c-a406-4fd0-a15c-edabddeafb23:c127]
datanode3_1  | 2022-06-24 01:32:25,898 [null-request--thread6] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-F3038FD16D2E->f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11, cid=173, seq=0, Watch-ALL_COMMITTED(136), Message:<EMPTY>, reply=RaftClientReply:client-F3038FD16D2E->f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11, cid=173, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 173 and log index 136 is not yet replicated to ALL_COMMITTED, logIndex=136, commits[f7360d38-a163-48e1-bebb-4404a3285b4b:c146, 171701ce-d9aa-46d7-a310-34f3f137a6a3:c146, f015cc2c-a406-4fd0-a15c-edabddeafb23:c127]
datanode3_1  | 2022-06-24 01:33:26,897 [null-request--thread6] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-207956328C73->f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11, cid=178, seq=0, Watch-ALL_COMMITTED(140), Message:<EMPTY>, reply=RaftClientReply:client-207956328C73->f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11, cid=178, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 178 and log index 140 is not yet replicated to ALL_COMMITTED, logIndex=140, commits[f7360d38-a163-48e1-bebb-4404a3285b4b:c150, 171701ce-d9aa-46d7-a310-34f3f137a6a3:c150, f015cc2c-a406-4fd0-a15c-edabddeafb23:c127]
datanode3_1  | 2022-06-24 01:34:26,897 [null-request--thread6] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-98649773B771->f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11, cid=183, seq=0, Watch-ALL_COMMITTED(144), Message:<EMPTY>, reply=RaftClientReply:client-98649773B771->f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11, cid=183, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 183 and log index 144 is not yet replicated to ALL_COMMITTED, logIndex=144, commits[f7360d38-a163-48e1-bebb-4404a3285b4b:c154, 171701ce-d9aa-46d7-a310-34f3f137a6a3:c154, f015cc2c-a406-4fd0-a15c-edabddeafb23:c127]
datanode3_1  | 2022-06-24 01:35:29,897 [null-request--thread6] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-D635EFD7BBFD->f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11, cid=188, seq=0, Watch-ALL_COMMITTED(148), Message:<EMPTY>, reply=RaftClientReply:client-D635EFD7BBFD->f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11, cid=188, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 188 and log index 148 is not yet replicated to ALL_COMMITTED, logIndex=148, commits[f7360d38-a163-48e1-bebb-4404a3285b4b:c158, 171701ce-d9aa-46d7-a310-34f3f137a6a3:c158, f015cc2c-a406-4fd0-a15c-edabddeafb23:c127]
datanode3_1  | 2022-06-24 01:36:35,897 [null-request--thread7] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-E916952B451F->f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11, cid=193, seq=0, Watch-ALL_COMMITTED(153), Message:<EMPTY>, reply=RaftClientReply:client-E916952B451F->f7360d38-a163-48e1-bebb-4404a3285b4b@group-14B5EFD07C11, cid=193, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 193 and log index 153 is not yet replicated to ALL_COMMITTED, logIndex=153, commits[f7360d38-a163-48e1-bebb-4404a3285b4b:c158, 171701ce-d9aa-46d7-a310-34f3f137a6a3:c158, f015cc2c-a406-4fd0-a15c-edabddeafb23:c127]
om3_1        | 2022-06-24 01:17:16,789 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2022-06-24 01:17:16,864 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2022-06-24 01:17:16,865 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2022-06-24 01:17:16,871 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2022-06-24 01:17:16,883 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2022-06-24 01:17:16,902 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2022-06-24 01:17:16,916 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2022-06-24 01:17:17,589 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2022-06-24 01:17:17,590 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om3_1        | 2022-06-24 01:17:17,603 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om3_1        | 2022-06-24 01:17:17,604 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om3_1        | 2022-06-24 01:17:17,609 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om3_1        | 2022-06-24 01:17:18,071 [main] INFO reflections.Reflections: Reflections took 2062 ms to scan 8 urls, producing 23 keys and 512 values [using 2 cores]
om3_1        | 2022-06-24 01:17:19,282 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2022-06-24 01:17:19,369 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2022-06-24 01:17:23,043 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2022-06-24 01:17:23,102 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2022-06-24 01:17:23,102 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2022-06-24 01:17:23,294 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2022-06-24 01:17:23,299 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1        | 2022-06-24 01:17:23,319 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-06-24 01:17:23,321 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2022-06-24 01:17:23,324 [om3-impl-thread1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-06-24 01:17:23,365 [om3-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2022-06-24 01:17:23,382 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2022-06-24 01:17:23,715 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2022-06-24 01:17:23,719 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2022-06-24 01:17:23,722 [Listener at om3/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-06-24 01:17:23,725 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2022-06-24 01:17:23,725 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-06-24 01:17:23,729 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$449/0x00000008405cac40@704588fc] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2022-06-24 01:17:23,739 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1        | 2022-06-24 01:17:23,730 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2022-06-24 01:17:23,957 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2022-06-24 01:17:23,957 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2022-06-24 01:17:23,957 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2022-06-24 01:17:24,178 [Listener at om3/9862] INFO util.log: Logging initialized @46808ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2022-06-24 01:17:24,615 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2022-06-24 01:17:24,634 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2022-06-24 01:17:24,648 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2022-06-24 01:17:24,649 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2022-06-24 01:17:24,651 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2022-06-24 01:17:24,654 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2022-06-24 01:17:24,774 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2022-06-24 01:17:24,780 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om3_1        | 2022-06-24 01:17:24,893 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2022-06-24 01:17:24,893 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2022-06-24 01:17:24,912 [Listener at om3/9862] INFO server.session: node0 Scavenging every 600000ms
om3_1        | 2022-06-24 01:17:24,998 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-06-24 01:17:25,003 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@670ef436{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1        | 2022-06-24 01:17:25,007 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@67288f31{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2022-06-24 01:21:35,659 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49994
om1_1        | 2022-06-24 01:21:35,683 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:21:40,391 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50032
om1_1        | 2022-06-24 01:21:40,413 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:21:44,876 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50052
om1_1        | 2022-06-24 01:21:44,895 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:21:48,872 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50060
om1_1        | 2022-06-24 01:21:48,895 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:21:53,522 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50076
om1_1        | 2022-06-24 01:21:53,544 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:21:57,995 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50094
om1_1        | 2022-06-24 01:21:58,019 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:22:02,117 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50100
om1_1        | 2022-06-24 01:22:02,139 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:22:06,751 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50114
om1_1        | 2022-06-24 01:22:06,762 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:22:11,513 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50152
om1_1        | 2022-06-24 01:22:11,531 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:22:12,163 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 42768-target
om1_1        | 2022-06-24 01:22:15,705 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50166
om1_1        | 2022-06-24 01:22:15,723 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:22:16,381 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:42768-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-24 01:22:20,032 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50172
om1_1        | 2022-06-24 01:22:20,052 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:22:20,627 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 42768-target
om1_1        | 2022-06-24 01:22:24,240 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50188
om1_1        | 2022-06-24 01:22:24,259 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:22:24,905 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:42768-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-24 01:22:28,342 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50202
om1_1        | 2022-06-24 01:22:28,364 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:22:32,969 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50218
om1_1        | 2022-06-24 01:22:32,980 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:22:37,403 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50248
om1_1        | 2022-06-24 01:22:37,422 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:22:41,894 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50262
om1_1        | 2022-06-24 01:22:41,912 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:22:46,308 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50282
om1_1        | 2022-06-24 01:22:46,336 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:22:46,935 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 42768-target
om1_1        | 2022-06-24 01:22:50,672 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50298
om1_1        | 2022-06-24 01:22:50,699 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:22:51,349 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 42768-target
om1_1        | 2022-06-24 01:22:55,082 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50308
om1_1        | 2022-06-24 01:22:55,099 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:22:55,752 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 42768-target
om1_1        | 2022-06-24 01:22:59,198 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50322
om1_1        | 2022-06-24 01:22:59,213 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:23:03,398 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50336
om1_1        | 2022-06-24 01:23:03,413 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:23:03,973 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 42768-target
om1_1        | 2022-06-24 01:23:07,837 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50366
om1_1        | 2022-06-24 01:23:07,856 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:23:16,840 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50392
om1_1        | 2022-06-24 01:23:16,879 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:23:23,293 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50410
om1_1        | 2022-06-24 01:23:23,313 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:23:27,438 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50424
om1_1        | 2022-06-24 01:23:27,454 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:23:32,012 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50432
om1_1        | 2022-06-24 01:23:32,030 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:24:00,836 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50716
om1_1        | 2022-06-24 01:24:00,856 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:24:05,553 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:40523
om1_1        | 2022-06-24 01:24:05,565 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:24:06,161 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5909566742 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:24:09,948 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50764
om1_1        | 2022-06-24 01:24:09,966 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:24:13,252 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5553790426 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:24:29,529 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50814
om1_1        | 2022-06-24 01:24:29,543 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:24:32,832 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6250892700 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:24:33,352 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-yojsherreq of layout LEGACY in volume: s3v
recon_1      | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1      | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
recon_1      | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:15:18,413 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:15:20,415 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:15:22,947 [main] INFO recon.ReconServer: Successfully stored SCM signed certificate, case:GETCERT.
recon_1      | 2022-06-24 01:15:23,488 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-06-24 01:15:25,070 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2022-06-24 01:15:25,611 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-06-24 01:15:25,633 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2022-06-24 01:15:25,634 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2022-06-24 01:15:28,200 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1        | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1        | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1        | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1        | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1        | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1        | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1        | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1        | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:874)
s3g_1        | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1        | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1        | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:127)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:69)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:103)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:46)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:53)
s3g_1        | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:129)
s3g_1        | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
s3g_1        | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:46)
s3g_1        | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
s3g_1        | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
s3g_1        | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
s3g_1        | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
om1_1        | 2022-06-24 01:24:43,114 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-pnijeaeuam of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:24:54,422 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50910
om1_1        | 2022-06-24 01:24:54,441 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:24:57,583 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4733637939 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:24:58,174 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1730767704 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:24:58,766 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2065079189 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:24:59,354 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-2065079189 in volume:s3v
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-24 01:25:03,647 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50946
om1_1        | 2022-06-24 01:25:03,663 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:25:06,935 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3364067888 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:25:07,629 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4560648265 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:25:08,837 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-2464099455 in volume:s3v
om1_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2496)
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2466)
om1_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-24 01:25:12,219 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:50992
om1_1        | 2022-06-24 01:25:12,232 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:25:15,374 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2933990824 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:25:19,970 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51012
om1_1        | 2022-06-24 01:25:19,988 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:25:23,239 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8597145003 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:25:27,447 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51040
om1_1        | 2022-06-24 01:25:27,460 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:25:32,824 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51058
om1_1        | 2022-06-24 01:25:32,850 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:25:36,058 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0116139998 of layout LEGACY in volume: s3v
recon_1      | 2022-06-24 01:15:28,201 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2022-06-24 01:15:28,202 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2022-06-24 01:15:28,231 [main] INFO util.log: Logging initialized @46019ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2022-06-24 01:15:28,533 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2022-06-24 01:15:28,550 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2022-06-24 01:15:28,556 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2022-06-24 01:15:28,556 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2022-06-24 01:15:28,556 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2022-06-24 01:15:28,568 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2022-06-24 01:15:28,784 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2022-06-24 01:15:29,412 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2022-06-24 01:15:29,424 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2022-06-24 01:15:29,448 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1      | 2022-06-24 01:15:29,477 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2022-06-24 01:15:30,904 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-06-24 01:15:31,470 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-06-24 01:15:31,654 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2022-06-24 01:15:31,660 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2022-06-24 01:15:31,947 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-06-24 01:15:32,360 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
recon_1      | 2022-06-24 01:15:32,525 [main] INFO reflections.Reflections: Reflections took 155 ms to scan 3 urls, producing 109 keys and 243 values 
recon_1      | 2022-06-24 01:15:32,697 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2022-06-24 01:15:32,856 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2022-06-24 01:15:32,882 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2022-06-24 01:15:32,912 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2022-06-24 01:15:33,003 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1      | 2022-06-24 01:15:33,100 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2022-06-24 01:15:33,117 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2022-06-24 01:15:33,290 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 2022-06-24 01:15:33,493 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2022-06-24 01:15:33,493 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2022-06-24 01:15:33,637 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2022-06-24 01:15:33,664 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2022-06-24 01:15:33,664 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2022-06-24 01:15:34,433 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2022-06-24 01:15:34,447 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
recon_1      | 2022-06-24 01:15:34,539 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2022-06-24 01:25:53,908 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-0116139998/ozone-test-2761194856/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om1_1        | 2022-06-24 01:25:53,909 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2761194856/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om1_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-2761194856/multipartKey2. Entity too small.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:531)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-24 01:25:55,240 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1        | partName: "etag1"
om1_1        | , partNumber: 2
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-06-24 01:25:55,245 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-24 01:25:55,920 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1        | partName: "etag1"
om1_1        | , partNumber: 1
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-06-24 01:25:55,922 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-24 01:26:01,382 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3-967b04a5-b8d6-47fb-b25e-4684f48c8038-108529841242505252-1
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:508)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-24 01:26:02,002 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3-967b04a5-b8d6-47fb-b25e-4684f48c8038-108529841242505252-2
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:508)
om2_1        | 2022-06-24 01:17:21,743 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2022-06-24 01:17:21,974 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2022-06-24 01:17:21,990 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$449/0x00000008405cac40@79a3499] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2022-06-24 01:17:21,992 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2022-06-24 01:17:21,998 [Listener at om2/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-06-24 01:17:21,999 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2022-06-24 01:17:21,999 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-06-24 01:17:22,011 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1        | 2022-06-24 01:17:22,021 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2022-06-24 01:17:22,351 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2022-06-24 01:17:22,352 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2022-06-24 01:17:22,352 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2022-06-24 01:17:22,538 [Listener at om2/9862] INFO util.log: Logging initialized @48212ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2022-06-24 01:17:23,130 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2022-06-24 01:17:23,197 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2022-06-24 01:17:23,208 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2022-06-24 01:17:23,210 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2022-06-24 01:17:23,210 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2022-06-24 01:17:23,220 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2022-06-24 01:17:23,476 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2022-06-24 01:17:23,478 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om2_1        | 2022-06-24 01:17:23,741 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2022-06-24 01:17:23,744 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2022-06-24 01:17:23,746 [Listener at om2/9862] INFO server.session: node0 Scavenging every 600000ms
om2_1        | 2022-06-24 01:17:23,848 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-06-24 01:17:23,857 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1d3433c7{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2022-06-24 01:17:23,860 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@28feec4f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2022-06-24 01:17:24,301 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-06-24 01:17:24,357 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1230a38d{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-9765462038875419023/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2022-06-24 01:17:24,415 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@3122e792{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2022-06-24 01:17:24,416 [Listener at om2/9862] INFO server.Server: Started @50090ms
om2_1        | 2022-06-24 01:17:24,441 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2022-06-24 01:17:24,441 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2022-06-24 01:17:24,443 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2022-06-24 01:17:24,458 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2022-06-24 01:17:24,458 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2022-06-24 01:17:24,745 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om2_1        | 2022-06-24 01:17:25,021 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44843
om2_1        | 2022-06-24 01:17:25,064 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:17:25,493 [Listener at om2/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om2_1        | 2022-06-24 01:17:25,542 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@415542ba] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2022-06-24 01:17:26,848 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5143555897ns, electionTimeout:5114ms
om2_1        | 2022-06-24 01:17:26,849 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-06-24 01:17:26,850 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2022-06-24 01:17:26,852 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2022-06-24 01:17:26,853 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1        | 2022-06-24 01:17:26,870 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-06-24 01:17:28,750 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION PASSED received 1 response(s) and 0 exception(s):
om2_1        | 2022-06-24 01:17:28,752 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:OK-t1
om2_1        | 2022-06-24 01:17:28,752 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result PASSED
om2_1        | 2022-06-24 01:17:28,753 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1        | 2022-06-24 01:17:28,753 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om2_1        | 2022-06-24 01:17:28,753 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om2 at term 1 for becomeLeader, leader elected after 14581ms
om2_1        | 2022-06-24 01:17:28,765 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om2_1        | 2022-06-24 01:17:28,773 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om2_1        | 2022-06-24 01:17:28,777 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-06-24 01:17:28,784 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om2_1        | 2022-06-24 01:17:28,787 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om2_1        | 2022-06-24 01:17:28,789 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om2_1        | 2022-06-24 01:17:28,802 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om2_1        | 2022-06-24 01:17:28,809 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om2_1        | 2022-06-24 01:17:28,848 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om2_1        | 2022-06-24 01:17:28,860 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-06-24 01:17:28,863 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om2_1        | 2022-06-24 01:17:28,888 [om2@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om2_1        | 2022-06-24 01:17:28,890 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-06-24 01:17:28,890 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-06-24 01:17:28,901 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om2_1        | 2022-06-24 01:17:28,919 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-06-24 01:17:28,919 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om2_1        | 2022-06-24 01:17:28,920 [om2@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om2_1        | 2022-06-24 01:17:28,920 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-06-24 01:17:28,920 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-06-24 01:17:28,925 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderStateImpl
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-24 01:26:02,623 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3
om1_1        | 2022-06-24 01:26:02,625 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om1_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3 because parts are in Invalid order.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:474)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-24 01:26:05,977 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-4622559934/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-0116139998
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-0116139998key: ozone-test-4622559934/multipartKey5
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-24 01:26:06,593 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-0116139998, Key:ozone-test-4161686202/multipartKey. 
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:758)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:282)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-24 01:26:50,938 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51444
om1_1        | 2022-06-24 01:26:50,956 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:26:54,139 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7363313379 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:26:54,731 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-22045 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:29:11,144 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:51854
om1_1        | 2022-06-24 01:29:11,178 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:29:15,620 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5999345803 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:34:29,645 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52668
om1_1        | 2022-06-24 01:34:29,693 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:34:33,140 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5973959837 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:35:38,024 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-5973959837, Key:ozone-test-6031795731/multidelete/key=value/f4.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
recon_1      | 2022-06-24 01:15:34,551 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2022-06-24 01:15:34,553 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1      | 2022-06-24 01:15:34,607 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-06-24 01:15:34,624 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@549fe529{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 2022-06-24 01:15:34,631 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5e781b4f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2022-06-24 01:15:35,575 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-06-24 01:15:35,579 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-06-24 01:15:38,747 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@508edcd7{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-6844482485666366340/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1      | 2022-06-24 01:15:38,756 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@56f569e{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1      | 2022-06-24 01:15:38,757 [Listener at 0.0.0.0/9891] INFO server.Server: Started @56545ms
recon_1      | 2022-06-24 01:15:38,760 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1      | 2022-06-24 01:15:38,760 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1      | 2022-06-24 01:15:38,762 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1      | 2022-06-24 01:15:38,762 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1      | 2022-06-24 01:15:38,774 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1      | 2022-06-24 01:15:38,781 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1      | 2022-06-24 01:15:38,782 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1      | 2022-06-24 01:15:38,782 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-06-24 01:15:38,783 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1      | 2022-06-24 01:15:38,784 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1      | 2022-06-24 01:15:39,155 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1      | 2022-06-24 01:15:39,164 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-06-24 01:15:39,166 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1      | 2022-06-24 01:15:39,170 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1      | 2022-06-24 01:15:39,175 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1      | 2022-06-24 01:15:39,288 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1      | 2022-06-24 01:15:39,288 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1      | 2022-06-24 01:15:39,300 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-06-24 01:15:39,301 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 8 milliseconds.
recon_1      | 2022-06-24 01:15:39,307 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1      | 2022-06-24 01:15:39,307 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1      | 2022-06-24 01:15:58,784 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:15:58,785 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:15:59,066 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:15:59,072 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:01,076 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 3 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:01,079 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 4 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:01,080 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:03,082 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 6 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:03,083 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 7 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:03,084 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:05,086 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 9 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:05,087 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 10 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:05,088 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 2022-06-24 01:17:25,387 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-06-24 01:17:25,429 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2296c3d4{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-6383112523063311210/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2022-06-24 01:17:25,480 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@66b27bd6{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2022-06-24 01:17:25,480 [Listener at om3/9862] INFO server.Server: Started @48111ms
om3_1        | 2022-06-24 01:17:25,505 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2022-06-24 01:17:25,505 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2022-06-24 01:17:25,507 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1        | 2022-06-24 01:17:25,513 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2022-06-24 01:17:25,597 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2022-06-24 01:17:25,768 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om3_1        | 2022-06-24 01:17:25,928 [Listener at om3/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om3_1        | 2022-06-24 01:17:25,977 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@223cd181] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2022-06-24 01:17:26,185 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33637
om3_1        | 2022-06-24 01:17:26,190 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-06-24 01:17:28,385 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5061315620ns, electionTimeout:5039ms
om3_1        | 2022-06-24 01:17:28,386 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-06-24 01:17:28,389 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2022-06-24 01:17:28,398 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2022-06-24 01:17:28,398 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1        | 2022-06-24 01:17:28,434 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-06-24 01:17:28,621 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:139)
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:126)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseCredentials(AuthorizationV4HeaderParser.java:171)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseSignature(AuthorizationV4HeaderParser.java:91)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor.parseSignature(AWSSignatureProcessor.java:70)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor$Proxy$_$$_WeldClientProxy.parseSignature(Unknown Source)
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:80)
s3g_1        | 	... 114 more
s3g_1        | 
s3g_1        | 
s3g_1        | 2022-06-24 01:25:36,014 [qtp848097505-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0116139998, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:25:36,040 [qtp848097505-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-0116139998
s3g_1        | 2022-06-24 01:26:06,594 [qtp848097505-20] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-06-24 01:26:36,599 [qtp848097505-20] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-06-24 01:26:37,398 [qtp848097505-25] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-06-24 01:26:54,120 [qtp848097505-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-7363313379, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:26:54,131 [qtp848097505-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-7363313379
s3g_1        | 2022-06-24 01:26:54,719 [qtp848097505-25] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-22045, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:26:54,734 [qtp848097505-25] INFO endpoint.BucketEndpoint: Location is /destbucket-22045
s3g_1        | 2022-06-24 01:29:02,990 [qtp848097505-25] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-06-24 01:29:03,730 [qtp848097505-25] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-06-24 01:29:05,128 [qtp848097505-24] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-06-24 01:29:15,578 [qtp848097505-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5999345803, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:29:15,597 [qtp848097505-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5999345803
s3g_1        | 2022-06-24 01:29:57,545 [qtp848097505-20] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #154 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
recon_1      | 2022-06-24 01:16:07,089 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 12 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:07,090 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 13 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:07,091 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:09,099 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 15 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:09,100 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 16 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:09,101 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:11,102 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 18 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:11,104 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 19 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:11,105 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 20 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:13,106 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 21 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:13,107 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 22 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:13,108 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 23 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:15,111 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 24 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:15,112 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 25 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:15,114 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 26 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:17,117 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 27 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:17,119 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 28 failover attempts. Trying to failover immediately.
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-24 01:35:45,130 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52896
om1_1        | 2022-06-24 01:35:45,170 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:35:49,981 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0161962971 of layout LEGACY in volume: s3v
om1_1        | 2022-06-24 01:36:11,545 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53022
om1_1        | 2022-06-24 01:36:11,572 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-24 01:36:15,792 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7609276061 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:17:29,026 [om2@group-562213E44849-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2022-06-24 01:17:29,160 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2022-06-24 01:17:29,355 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2022-06-24 01:17:29,841 [om2@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1        | [id: "om1"
om2_1        | address: "om1:9872"
om2_1        | , id: "om3"
om2_1        | address: "om3:9872"
om2_1        | , id: "om2"
om2_1        | address: "om2:9872"
om2_1        | ]
om2_1        | 2022-06-24 01:17:30,424 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-06-24 01:17:30,436 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-LEADER: reject ELECTION from om3: already has voted for om2 at current term 1
om2_1        | 2022-06-24 01:17:30,448 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=om2, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c0, conf=0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2022-06-24 01:17:31,473 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43548
om2_1        | 2022-06-24 01:17:31,484 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:17:46,413 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43600
om2_1        | 2022-06-24 01:17:46,431 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:17:47,123 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om2_1        | 2022-06-24 01:17:47,379 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om2_1        | 2022-06-24 01:17:59,886 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43654
om2_1        | 2022-06-24 01:17:59,892 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:18:00,578 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43658
om2_1        | 2022-06-24 01:18:00,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:18:05,818 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43674
om2_1        | 2022-06-24 01:18:05,826 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:18:06,473 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43678
om2_1        | 2022-06-24 01:18:06,480 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:18:06,501 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om2_1        | 2022-06-24 01:18:11,270 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43692
om2_1        | 2022-06-24 01:18:11,275 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:18:19,464 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43718
om2_1        | 2022-06-24 01:18:19,474 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:18:25,656 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43758
om2_1        | 2022-06-24 01:18:25,669 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:18:26,263 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43762
om2_1        | 2022-06-24 01:18:26,273 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:18:26,285 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om2_1        | 2022-06-24 01:18:31,034 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43768
om2_1        | 2022-06-24 01:18:31,036 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:18:31,189 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46469
om2_1        | 2022-06-24 01:18:31,205 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:18:36,053 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43784
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:392)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:552)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
om3_1        | 2022-06-24 01:17:28,631 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om3 at current term 1
om3_1        | 2022-06-24 01:17:28,692 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-06-24 01:17:29,333 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for appendEntries
om3_1        | 2022-06-24 01:17:29,353 [om3-server-thread1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om3_1        | 2022-06-24 01:17:29,362 [om3-server-thread1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-06-24 01:17:29,364 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om2 at term 1 for appendEntries, leader elected after 13397ms
om3_1        | 2022-06-24 01:17:29,488 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2022-06-24 01:17:29,681 [om3-server-thread1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2022-06-24 01:17:30,447 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: ELECTION REJECTED received 1 response(s) and 0 exception(s):
om3_1        | 2022-06-24 01:17:30,447 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:FAIL-t1
om3_1        | 2022-06-24 01:17:30,453 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om3_1        | 2022-06-24 01:17:30,532 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2022-06-24 01:17:33,358 [om3@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1        | [id: "om1"
om3_1        | address: "om1:9872"
om3_1        | , id: "om3"
om3_1        | address: "om3:9872"
om3_1        | , id: "om2"
om3_1        | address: "om2:9872"
om3_1        | ]
om3_1        | 2022-06-24 01:17:47,382 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om3_1        | 2022-06-24 01:17:47,541 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om3_1        | 2022-06-24 01:18:06,510 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om3_1        | 2022-06-24 01:18:26,294 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om3_1        | 2022-06-24 01:18:51,242 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:42768-source for user:testuser
om3_1        | 2022-06-24 01:18:55,947 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:42768-target for user:testuser
om3_1        | 2022-06-24 01:19:00,274 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 42768-source
om3_1        | 2022-06-24 01:19:14,212 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 42768-source
om3_1        | 2022-06-24 01:19:20,065 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 42768-target
recon_1      | 2022-06-24 01:16:17,122 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 29 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:19,129 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 30 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:19,130 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 31 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:19,131 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 32 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:21,133 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 33 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:21,136 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 34 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:21,136 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 35 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:23,138 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 36 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:23,141 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 37 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:23,142 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 38 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:25,144 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 39 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:25,145 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 40 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:25,146 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 41 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:27,147 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 42 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:27,148 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 43 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:27,149 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 44 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:29,150 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 45 failover attempts. Trying to failover immediately.
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.copyObject(ObjectEndpoint.java:901)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:196)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om3_1        | 2022-06-24 01:19:27,574 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 42768-target
om3_1        | 2022-06-24 01:19:34,629 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 42768-target
om3_1        | 2022-06-24 01:20:13,285 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 42768-target
om3_1        | 2022-06-24 01:20:28,324 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 42768-target
om3_1        | 2022-06-24 01:20:35,649 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 42768-source
om3_1        | 2022-06-24 01:22:12,176 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 42768-target
om3_1        | 2022-06-24 01:22:16,382 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:42768-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-24 01:22:20,624 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 42768-target
om3_1        | 2022-06-24 01:22:24,903 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:42768-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-24 01:22:46,923 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 42768-target
om3_1        | 2022-06-24 01:22:51,356 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 42768-target
om3_1        | 2022-06-24 01:22:55,733 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 42768-target
om3_1        | 2022-06-24 01:23:03,977 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 42768-target
om3_1        | 2022-06-24 01:24:06,163 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5909566742 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:24:13,244 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5553790426 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:24:32,838 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6250892700 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:24:33,350 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-yojsherreq of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:24:43,145 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-pnijeaeuam of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:24:57,574 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4733637939 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:24:58,172 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1730767704 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:24:58,760 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2065079189 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:24:59,360 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-2065079189 in volume:s3v
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-24 01:25:06,912 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3364067888 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:25:07,639 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4560648265 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:25:08,840 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-2464099455 in volume:s3v
om3_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2496)
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2466)
om3_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om2_1        | 2022-06-24 01:18:36,059 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:18:50,612 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43826
om2_1        | 2022-06-24 01:18:50,615 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:18:51,235 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:42768-source for user:testuser
om2_1        | 2022-06-24 01:18:55,322 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43860
om2_1        | 2022-06-24 01:18:55,327 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:18:55,935 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:42768-target for user:testuser
om2_1        | 2022-06-24 01:18:59,710 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43874
om2_1        | 2022-06-24 01:18:59,728 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:19:00,266 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 42768-source
om2_1        | 2022-06-24 01:19:04,147 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43888
om2_1        | 2022-06-24 01:19:04,155 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:19:13,379 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43930
om2_1        | 2022-06-24 01:19:13,391 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:19:14,198 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 42768-source
om2_1        | 2022-06-24 01:19:19,311 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43944
om2_1        | 2022-06-24 01:19:19,319 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:19:20,045 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 42768-target
om2_1        | 2022-06-24 01:19:26,389 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43966
om2_1        | 2022-06-24 01:19:26,395 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:19:27,534 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 42768-target
om2_1        | 2022-06-24 01:19:31,287 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39787
om2_1        | 2022-06-24 01:19:31,310 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:19:33,132 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:43982
om2_1        | 2022-06-24 01:19:33,145 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:19:34,607 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 42768-target
om2_1        | 2022-06-24 01:19:39,761 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44020
om2_1        | 2022-06-24 01:19:39,765 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:19:46,274 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44040
om2_1        | 2022-06-24 01:19:46,281 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:19:53,614 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44056
om2_1        | 2022-06-24 01:19:53,619 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:19:59,355 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44074
om2_1        | 2022-06-24 01:19:59,365 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:20:05,954 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44088
om2_1        | 2022-06-24 01:20:05,958 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:20:12,629 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44126
om2_1        | 2022-06-24 01:20:12,634 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:20:13,267 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 42768-target
om2_1        | 2022-06-24 01:20:20,159 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44148
om2_1        | 2022-06-24 01:20:20,161 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:20:26,988 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44166
om2_1        | 2022-06-24 01:20:26,997 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:20:28,313 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 42768-target
om2_1        | 2022-06-24 01:20:31,384 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40679
om2_1        | 2022-06-24 01:20:31,408 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:20:34,581 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44182
om2_1        | 2022-06-24 01:20:34,604 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:20:35,633 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 42768-source
om2_1        | 2022-06-24 01:20:41,542 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44220
om2_1        | 2022-06-24 01:20:41,546 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:20:51,721 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44254
om2_1        | 2022-06-24 01:20:51,740 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:21:02,605 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44286
om2_1        | 2022-06-24 01:21:02,614 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:21:11,491 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44328
om2_1        | 2022-06-24 01:21:11,499 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:21:17,896 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44346
om2_1        | 2022-06-24 01:21:17,907 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:21:22,584 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44360
om2_1        | 2022-06-24 01:21:22,591 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:21:26,937 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44374
om2_1        | 2022-06-24 01:21:26,943 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:21:31,107 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44380
om2_1        | 2022-06-24 01:21:31,113 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:21:31,462 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33403
om2_1        | 2022-06-24 01:21:31,472 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:21:35,718 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44396
om2_1        | 2022-06-24 01:21:35,727 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:21:40,453 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44434
om2_1        | 2022-06-24 01:21:40,457 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:21:44,925 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44454
om2_1        | 2022-06-24 01:21:44,941 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:21:48,928 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44462
om2_1        | 2022-06-24 01:21:48,935 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:21:53,586 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44478
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-24 01:25:15,377 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2933990824 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:25:23,234 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8597145003 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:25:36,033 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0116139998 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:25:53,914 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-0116139998/ozone-test-2761194856/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om3_1        | 2022-06-24 01:25:53,916 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2761194856/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om3_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-2761194856/multipartKey2. Entity too small.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:531)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-24 01:25:55,216 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om3_1        | partName: "etag1"
om3_1        | , partNumber: 2
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-06-24 01:25:55,217 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-24 01:25:55,921 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om3_1        | partName: "etag1"
om3_1        | , partNumber: 1
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-06-24 01:25:55,923 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-24 01:26:01,385 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3-967b04a5-b8d6-47fb-b25e-4684f48c8038-108529841242505252-1
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:508)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 2022-06-24 01:21:53,590 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:21:58,047 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44496
om2_1        | 2022-06-24 01:21:58,051 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:02,182 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44510
om2_1        | 2022-06-24 01:22:02,187 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:06,801 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44516
om2_1        | 2022-06-24 01:22:06,807 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:11,566 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44554
om2_1        | 2022-06-24 01:22:11,571 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:12,153 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 42768-target
om2_1        | 2022-06-24 01:22:15,749 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44568
om2_1        | 2022-06-24 01:22:15,753 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:16,357 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:42768-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-24 01:22:20,075 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44582
om2_1        | 2022-06-24 01:22:20,077 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:20,608 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 42768-target
om2_1        | 2022-06-24 01:22:24,298 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44590
om2_1        | 2022-06-24 01:22:24,303 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:24,896 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:42768-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-24 01:22:28,403 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44604
om2_1        | 2022-06-24 01:22:28,411 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:31,525 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42787
om2_1        | 2022-06-24 01:22:31,530 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:33,010 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44620
om2_1        | 2022-06-24 01:22:33,014 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:33,517 [IPC Server handler 16 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket Volume:42768-target Bucket:unreadable-link 
om2_1        | 2022-06-24 01:22:37,448 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44650
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #154 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
recon_1      | 2022-06-24 01:16:29,151 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 46 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:29,152 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 47 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:31,154 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 48 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:31,155 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 49 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:31,156 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 50 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:33,158 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 51 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:33,159 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 52 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:33,160 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 53 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:35,161 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 54 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:35,163 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 55 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:35,163 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 56 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:37,167 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 57 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:37,168 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 58 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:37,169 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 59 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:39,171 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 60 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:39,172 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 61 failover attempts. Trying to failover immediately.
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-24 01:26:02,004 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3-967b04a5-b8d6-47fb-b25e-4684f48c8038-108529841242505252-2
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:508)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-24 01:26:02,626 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3
om3_1        | 2022-06-24 01:26:02,628 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om3_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3 because parts are in Invalid order.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:474)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-24 01:26:05,984 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-4622559934/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-0116139998
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-0116139998key: ozone-test-4622559934/multipartKey5
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-24 01:26:06,589 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-0116139998, Key:ozone-test-4161686202/multipartKey. 
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:758)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:282)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-24 01:26:54,133 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7363313379 of layout LEGACY in volume: s3v
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-06-24 01:29:57,571 [qtp848097505-20] INFO scm.XceiverClientRatis: Could not commit index 129 on pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]] to all the nodes. Server f015cc2c-a406-4fd0-a15c-edabddeafb23 has failed. Committed by majority.
s3g_1        | 2022-06-24 01:29:57,571 [qtp848097505-20] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200047 bcsId: 129 on Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]]. Failed nodes: [f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-06-24 01:30:58,656 [qtp848097505-21] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #158 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:392)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:552)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.copyObject(ObjectEndpoint.java:901)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:196)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
recon_1      | 2022-06-24 01:16:39,172 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 62 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:41,174 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 63 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:41,176 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 64 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:41,178 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 65 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:43,179 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 66 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:43,185 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 67 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:43,187 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 68 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:45,189 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 69 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:45,190 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 70 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:45,191 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 71 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:47,192 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 72 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:47,193 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 73 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:47,194 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 74 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:49,195 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 75 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:49,196 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 76 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:49,197 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 77 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:50,076 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43912
recon_1      | 2022-06-24 01:16:50,094 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:16:51,198 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 78 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:51,201 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 79 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:51,204 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 80 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:51,332 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50362
recon_1      | 2022-06-24 01:16:51,372 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:16:53,095 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57944
recon_1      | 2022-06-24 01:16:53,131 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:16:53,208 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 81 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:53,209 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 82 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:53,210 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 83 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:53,393 [IPC Server handler 2 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f7360d38-a163-48e1-bebb-4404a3285b4b
recon_1      | 2022-06-24 01:16:53,495 [IPC Server handler 2 on default port 9891] INFO node.SCMNodeManager: Registered Data node : f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 896230875764, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:16:53,812 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node f7360d38-a163-48e1-bebb-4404a3285b4b to Node DB.
recon_1      | 2022-06-24 01:16:53,846 [IPC Server handler 82 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f015cc2c-a406-4fd0-a15c-edabddeafb23
recon_1      | 2022-06-24 01:16:53,874 [IPC Server handler 82 on default port 9891] INFO node.SCMNodeManager: Registered Data node : f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 894868778582, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:16:53,875 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node f015cc2c-a406-4fd0-a15c-edabddeafb23 to Node DB.
recon_1      | 2022-06-24 01:16:55,082 [IPC Server handler 39 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-06-24 01:16:55,218 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 84 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:55,229 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 85 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:55,232 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 86 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:55,458 [IPC Server handler 2 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-06-24 01:16:55,569 [IPC Server handler 82 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/171701ce-d9aa-46d7-a310-34f3f137a6a3
recon_1      | 2022-06-24 01:16:55,569 [IPC Server handler 82 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 897348533486, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:16:55,575 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 171701ce-d9aa-46d7-a310-34f3f137a6a3 to Node DB.
recon_1      | 2022-06-24 01:16:56,930 [IPC Server handler 56 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-06-24 01:16:56,950 [IPC Server handler 49 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #158 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
recon_1      | 2022-06-24 01:16:57,237 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 87 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:57,238 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 88 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:57,238 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 89 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:58,436 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=fae297c5-ae4f-43a4-9b48-cbad1b5e890a. Trying to get from SCM.
recon_1      | 2022-06-24 01:16:58,732 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: fae297c5-ae4f-43a4-9b48-cbad1b5e890a, Nodes: f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:55.529Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-06-24 01:16:58,854 [IPC Server handler 56 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-06-24 01:16:58,937 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fae297c5-ae4f-43a4-9b48-cbad1b5e890a, Nodes: f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:55.529Z[UTC]].
recon_1      | 2022-06-24 01:16:59,240 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 90 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:59,241 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 91 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:16:59,243 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 92 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:16:59,461 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11. Trying to get from SCM.
recon_1      | 2022-06-24 01:16:59,480 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-06-24 01:16:59,482 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]].
recon_1      | 2022-06-24 01:16:59,483 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11 reported by f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 896230875764, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:17:00,620 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=0eb29a31-b4b1-466e-a46a-1ca046e16e6e. Trying to get from SCM.
recon_1      | 2022-06-24 01:17:00,627 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 0eb29a31-b4b1-466e-a46a-1ca046e16e6e, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:56.870Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-06-24 01:17:00,632 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 0eb29a31-b4b1-466e-a46a-1ca046e16e6e, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:56.870Z[UTC]].
recon_1      | 2022-06-24 01:17:00,636 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=0eb29a31-b4b1-466e-a46a-1ca046e16e6e reported by 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 897348533486, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:17:00,643 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 0eb29a31-b4b1-466e-a46a-1ca046e16e6e, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:171701ce-d9aa-46d7-a310-34f3f137a6a3, CreationTimestamp2022-06-24T01:16:56.870Z[UTC]] moved to OPEN state
recon_1      | 2022-06-24 01:17:01,245 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 93 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:01,246 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 94 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:01,247 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 95 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:17:01,728 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11 reported by 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 897348533486, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:17:03,248 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 96 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:03,250 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 97 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:03,250 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 98 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:17:04,486 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11 reported by f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 896230875764, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:17:05,252 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 99 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:05,254 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 100 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:05,255 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 101 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1        | 2022-06-24 01:22:37,454 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:41,936 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44664
om2_1        | 2022-06-24 01:22:41,942 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:42,424 [IPC Server handler 14 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket Volume:42768-source Bucket:unreadable-bucket Key:
om2_1        | 2022-06-24 01:22:46,374 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44684
om2_1        | 2022-06-24 01:22:46,388 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:46,912 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 42768-target
om2_1        | 2022-06-24 01:22:50,728 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44700
om2_1        | 2022-06-24 01:22:50,734 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:51,342 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 42768-target
om2_1        | 2022-06-24 01:22:55,130 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44710
om2_1        | 2022-06-24 01:22:55,135 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:22:55,724 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 42768-target
om2_1        | 2022-06-24 01:22:59,246 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44724
om2_1        | 2022-06-24 01:22:59,252 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:23:03,451 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44738
om2_1        | 2022-06-24 01:23:03,460 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:23:03,966 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 42768-target
om2_1        | 2022-06-24 01:23:07,901 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44768
om2_1        | 2022-06-24 01:23:07,915 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:23:16,923 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44794
om2_1        | 2022-06-24 01:23:16,935 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:23:23,350 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44812
om2_1        | 2022-06-24 01:23:23,359 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:23:27,489 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44826
om2_1        | 2022-06-24 01:23:27,495 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:23:31,573 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41129
om2_1        | 2022-06-24 01:23:31,582 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:23:32,066 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44834
om2_1        | 2022-06-24 01:23:32,071 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:24:00,883 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45118
om2_1        | 2022-06-24 01:24:00,885 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:24:05,589 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:45299
om2_1        | 2022-06-24 01:24:05,591 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:24:06,017 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:06,145 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:06,159 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5909566742 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:24:09,988 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45166
om2_1        | 2022-06-24 01:24:09,994 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:24:13,225 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:13,231 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-06-24 01:15:04,549 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:51Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-06-24 01:15:04,556 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-06-24 01:15:04,646 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-06-24 01:15:04,669 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-06-24 01:15:04,669 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-06-24 01:15:04,700 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-06-24 01:15:04,700 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-06-24 01:15:04,848 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-06-24 01:15:04,848 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-06-24 01:15:04,880 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2022-06-24 01:15:07,057 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-06-24 01:15:09,059 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-06-24 01:15:11,061 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-06-24 01:15:13,064 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-06-24 01:15:15,071 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-06-24 01:15:17,247 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:53b8a25c-b7d5-4020-bf2c-829236b7c472 is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-06-24 01:15:19,249 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-06-24 01:15:21,360 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm2.org_1   | 2022-06-24 01:15:21,889 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm2.org_1   | 2022-06-24 01:15:21,889 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2022-06-24 01:15:21,890 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm2.org_1   | 2022-06-24 01:15:22,200 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2022-06-24 01:15:22,228 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2022-06-24 01:15:22,229 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2022-06-24 01:15:22,232 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:7294e591-5fc1-4a75-ab0a-c1d51b5556d2,clusterId:CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86,subject:scm-sub@scm2.org
scm2.org_1   | 2022-06-24 01:15:24,393 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm2.org_1   | 2022-06-24 01:15:24,415 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86, SCMID 7294e591-5fc1-4a75-ab0a-c1d51b5556d2
scm2.org_1   | 2022-06-24 01:15:24,415 [main] INFO server.StorageContainerManager: Primary SCM Node ID 53b8a25c-b7d5-4020-bf2c-829236b7c472
scm2.org_1   | 2022-06-24 01:15:24,463 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-06-24 01:15:27,974 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-06-24 01:14:52,103 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:51Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-06-24 01:14:52,165 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-06-24 01:14:52,771 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-06-24 01:14:53,105 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-06-24 01:14:53,180 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-06-24 01:14:53,590 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-06-24 01:14:53,591 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-06-24 01:14:53,721 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2022-06-24 01:14:55,527 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2022-06-24 01:14:55,527 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2022-06-24 01:14:55,545 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2022-06-24 01:14:59,145 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2022-06-24 01:14:59,975 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-06-24 01:14:59,979 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-06-24 01:15:00,154 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-06-24 01:15:00,154 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-06-24 01:15:00,155 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:53b8a25c-b7d5-4020-bf2c-829236b7c472,clusterId:CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86,subject:scm-sub@scm1.org
scm1.org_1   | 2022-06-24 01:15:00,248 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2022-06-24 01:15:00,363 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-06-24 01:15:00,541 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-06-24 01:15:00,544 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-06-24 01:15:00,545 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-06-24 01:15:00,551 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-06-24 01:15:00,551 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-06-24 01:15:00,553 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-06-24 01:15:00,554 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-06-24 01:15:00,555 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-06-24 01:15:00,587 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-06-24 01:15:00,614 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2022-06-24 01:15:00,623 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2022-06-24 01:15:01,084 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-06-24 01:15:01,092 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm1.org_1   | 2022-06-24 01:15:01,093 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2022-06-24 01:15:01,095 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-06-24 01:15:01,095 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-06-24 01:15:01,105 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-06-24 01:15:01,118 [main] INFO server.RaftServer: 53b8a25c-b7d5-4020-bf2c-829236b7c472: addNew group-E1C8A5D19D86:[53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|priority:0] returns group-E1C8A5D19D86:java.util.concurrent.CompletableFuture@795f5d51[Not completed]
scm1.org_1   | 2022-06-24 01:15:01,172 [pool-2-thread-1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472: new RaftServerImpl for group-E1C8A5D19D86:[53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-06-24 01:15:01,199 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-06-24 01:15:01,199 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-06-24 01:15:01,200 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-06-24 01:15:01,200 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-06-24 01:15:01,200 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-06-24 01:15:01,200 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-06-24 01:15:01,208 [pool-2-thread-1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: ConfigurationManager, init=-1: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-06-24 01:15:01,209 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-06-24 01:15:01,218 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-06-24 01:15:01,222 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2022-06-24 01:24:13,239 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5553790426 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:24:13,843 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:13,849 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:13,869 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:17,984 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:18,609 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:18,614 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:18,620 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:20,452 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:21,044 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:21,049 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:21,055 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:21,070 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:21,698 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:21,702 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:21,707 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:21,710 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:22,270 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:22,275 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:22,279 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:22,285 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:22,887 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:22,893 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:22,901 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:25,458 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:26,063 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:26,067 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:26,072 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:26,077 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:29,580 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45216
om2_1        | 2022-06-24 01:24:29,584 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:24:31,610 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33341
om2_1        | 2022-06-24 01:24:31,615 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:24:32,806 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:32,811 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:32,824 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6250892700 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:24:33,329 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:33,335 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:33,346 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-yojsherreq of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:24:33,372 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:33,379 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:33,382 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:35,473 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:35,520 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
scm1.org_1   | 2022-06-24 01:15:01,224 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86 does not exist. Creating ...
scm1.org_1   | 2022-06-24 01:15:01,258 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/in_use.lock acquired by nodename 86@scm1.org
scm1.org_1   | 2022-06-24 01:15:01,281 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86 has been successfully formatted.
scm1.org_1   | 2022-06-24 01:15:01,286 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-06-24 01:15:01,291 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-06-24 01:15:01,317 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-06-24 01:15:01,318 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-06-24 01:15:01,324 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2022-06-24 01:15:01,345 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-06-24 01:15:01,547 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-06-24 01:15:01,555 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-06-24 01:15:01,555 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-06-24 01:15:01,581 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86
scm1.org_1   | 2022-06-24 01:15:01,585 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-06-24 01:15:01,587 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-06-24 01:15:01,588 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-06-24 01:15:01,591 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-06-24 01:15:01,592 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-06-24 01:15:01,595 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-06-24 01:15:01,595 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-06-24 01:15:01,595 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-06-24 01:15:01,617 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-06-24 01:15:01,618 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2022-06-24 01:15:01,618 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-06-24 01:15:01,630 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-06-24 01:15:01,630 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-06-24 01:15:01,655 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-06-24 01:15:01,656 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-06-24 01:15:01,656 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-06-24 01:15:01,657 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-06-24 01:15:01,658 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-06-24 01:15:01,662 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-06-24 01:15:01,769 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-06-24 01:15:01,773 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2022-06-24 01:15:01,774 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2022-06-24 01:15:01,775 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2022-06-24 01:15:01,776 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2022-06-24 01:15:01,777 [53b8a25c-b7d5-4020-bf2c-829236b7c472-impl-thread1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: start as a follower, conf=-1: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-06-24 01:15:01,780 [53b8a25c-b7d5-4020-bf2c-829236b7c472-impl-thread1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2022-06-24 01:15:01,781 [53b8a25c-b7d5-4020-bf2c-829236b7c472-impl-thread1] INFO impl.RoleInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472: start 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState
scm1.org_1   | 2022-06-24 01:15:01,789 [53b8a25c-b7d5-4020-bf2c-829236b7c472-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E1C8A5D19D86,id=53b8a25c-b7d5-4020-bf2c-829236b7c472
scm1.org_1   | 2022-06-24 01:15:01,792 [main] INFO server.RaftServer: 53b8a25c-b7d5-4020-bf2c-829236b7c472: start RPC server
scm1.org_1   | 2022-06-24 01:15:01,860 [main] INFO server.GrpcService: 53b8a25c-b7d5-4020-bf2c-829236b7c472: GrpcService started, listening on 9894
scm1.org_1   | 2022-06-24 01:15:01,877 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$354/0x000000084031f040@869d87c] INFO util.JvmPauseMonitor: JvmPauseMonitor-53b8a25c-b7d5-4020-bf2c-829236b7c472: Started
scm1.org_1   | 2022-06-24 01:15:06,912 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState] INFO impl.FollowerState: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5131646346ns, electionTimeout:5112ms
scm1.org_1   | 2022-06-24 01:15:06,914 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState] INFO impl.RoleInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472: shutdown 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState
scm1.org_1   | 2022-06-24 01:15:06,914 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:51Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-06-24 01:15:28,009 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-06-24 01:15:28,209 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-06-24 01:15:28,296 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-06-24 01:15:28,333 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-06-24 01:15:28,434 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-06-24 01:15:28,439 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-06-24 01:15:29,755 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2022-06-24 01:15:30,126 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2022-06-24 01:15:30,134 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/833676156658.crt.
scm2.org_1   | 2022-06-24 01:15:30,159 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm2.org_1   | 2022-06-24 01:15:30,540 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-06-24 01:15:30,541 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-06-24 01:15:30,619 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-06-24 01:15:31,067 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-06-24 01:15:31,656 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2022-06-24 01:15:31,656 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm2.org_1   | 2022-06-24 01:15:31,919 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2022-06-24 01:15:31,975 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:7294e591-5fc1-4a75-ab0a-c1d51b5556d2
scm2.org_1   | 2022-06-24 01:15:32,291 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2022-06-24 01:15:32,520 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm2.org_1   | 2022-06-24 01:15:32,527 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-06-24 01:15:32,528 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm2.org_1   | 2022-06-24 01:15:32,528 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-06-24 01:15:32,529 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-06-24 01:15:32,530 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm2.org_1   | 2022-06-24 01:15:32,531 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-06-24 01:15:32,532 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm2.org_1   | 2022-06-24 01:15:32,532 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2022-06-24 01:15:32,575 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm2.org_1   | 2022-06-24 01:15:32,588 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm2.org_1   | 2022-06-24 01:15:34,052 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm2.org_1   | 2022-06-24 01:15:34,054 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm2.org_1   | 2022-06-24 01:15:34,070 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm2.org_1   | 2022-06-24 01:15:34,070 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-06-24 01:15:34,070 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-06-24 01:15:34,088 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-06-24 01:15:34,122 [main] INFO server.RaftServer: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2: addNew group-E1C8A5D19D86:[] returns group-E1C8A5D19D86:java.util.concurrent.CompletableFuture@39832280[Not completed]
scm1.org_1   | 2022-06-24 01:15:06,917 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-06-24 01:15:06,917 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState] INFO impl.RoleInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472: start 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1
scm1.org_1   | 2022-06-24 01:15:06,924 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO impl.LeaderElection: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-06-24 01:15:06,925 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO impl.LeaderElection: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2022-06-24 01:15:06,925 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO impl.RoleInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472: shutdown 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1
scm1.org_1   | 2022-06-24 01:15:06,925 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm1.org_1   | 2022-06-24 01:15:06,926 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: change Leader from null to 53b8a25c-b7d5-4020-bf2c-829236b7c472 at term 1 for becomeLeader, leader elected after 5640ms
scm1.org_1   | 2022-06-24 01:15:06,930 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-06-24 01:15:06,934 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-06-24 01:15:06,935 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-06-24 01:15:06,940 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-06-24 01:15:06,940 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-06-24 01:15:06,940 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-06-24 01:15:06,947 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-06-24 01:15:06,950 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-06-24 01:15:06,952 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO impl.RoleInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472: start 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderStateImpl
scm1.org_1   | 2022-06-24 01:15:06,971 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2022-06-24 01:15:07,002 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: set configuration 0: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-06-24 01:15:07,031 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/current/log_inprogress_0
scm1.org_1   | 2022-06-24 01:15:07,889 [main] INFO server.RaftServer: 53b8a25c-b7d5-4020-bf2c-829236b7c472: close
scm1.org_1   | 2022-06-24 01:15:07,890 [main] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: shutdown
scm1.org_1   | 2022-06-24 01:15:07,892 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E1C8A5D19D86,id=53b8a25c-b7d5-4020-bf2c-829236b7c472
scm1.org_1   | 2022-06-24 01:15:07,892 [main] INFO impl.RoleInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472: shutdown 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderStateImpl
scm1.org_1   | 2022-06-24 01:15:07,897 [main] INFO impl.PendingRequests: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-PendingRequests: sendNotLeaderResponses
scm1.org_1   | 2022-06-24 01:15:07,898 [main] INFO impl.StateMachineUpdater: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2022-06-24 01:15:07,901 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO impl.StateMachineUpdater: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2022-06-24 01:15:07,901 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO impl.StateMachineUpdater: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2022-06-24 01:15:07,907 [main] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: closes. applyIndex: 0
scm1.org_1   | 2022-06-24 01:15:07,908 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm1.org_1   | 2022-06-24 01:15:07,909 [main] INFO segmented.SegmentedRaftLogWorker: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker close()
scm1.org_1   | 2022-06-24 01:15:07,911 [main] INFO server.GrpcService: 53b8a25c-b7d5-4020-bf2c-829236b7c472: shutdown server with port 9894 now
scm1.org_1   | 2022-06-24 01:15:07,924 [main] INFO server.GrpcService: 53b8a25c-b7d5-4020-bf2c-829236b7c472: shutdown server with port 9894 successfully
scm1.org_1   | 2022-06-24 01:15:07,924 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$354/0x000000084031f040@869d87c] INFO util.JvmPauseMonitor: JvmPauseMonitor-53b8a25c-b7d5-4020-bf2c-829236b7c472: Stopped
scm1.org_1   | 2022-06-24 01:15:07,925 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-06-24 01:15:07,928 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86; layoutVersion=4; scmId=53b8a25c-b7d5-4020-bf2c-829236b7c472
scm1.org_1   | 2022-06-24 01:15:07,947 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm1.org_1   | ************************************************************/
recon_1      | 2022-06-24 01:17:06,171 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11 reported by f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 896230875764, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:17:06,561 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11 reported by 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 897348533486, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:17:06,912 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43968
recon_1      | 2022-06-24 01:17:07,080 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:17:07,081 [IPC Server handler 59 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-06-24 01:17:07,084 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11 reported by f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 894868778582, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:17:07,084 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]] moved to OPEN state
recon_1      | 2022-06-24 01:17:07,256 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 102 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:07,258 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 103 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:07,258 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 104 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:17:07,764 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=f58ed7fb-82ba-4210-bda3-c3af98ea0f8c. Trying to get from SCM.
recon_1      | 2022-06-24 01:17:07,807 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: f58ed7fb-82ba-4210-bda3-c3af98ea0f8c, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:57.105Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-06-24 01:17:07,808 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f58ed7fb-82ba-4210-bda3-c3af98ea0f8c, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:57.105Z[UTC]].
om2_1        | 2022-06-24 01:24:35,523 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:35,528 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:37,978 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,054 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,059 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,110 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,266 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,307 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,313 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,346 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,439 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,444 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,452 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,508 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,590 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,595 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,602 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:38,632 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:39,592 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,476 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,535 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,541 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,562 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,632 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,639 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,645 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,697 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,703 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,707 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,722 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,848 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,854 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,859 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:40,874 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:41,597 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:42,992 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,042 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,045 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,049 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,084 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,091 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,098 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-pnijeaeuam of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:24:43,143 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,158 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,170 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,189 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,193 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,222 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,236 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,283 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,289 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:43,293 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,486 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,514 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,521 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,529 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,556 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,558 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,561 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,579 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,581 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,583 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,638 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,842 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,851 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,856 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,876 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,914 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,917 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,926 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,980 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,983 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:45,989 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:46,037 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:46,051 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:46,060 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:46,084 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:46,087 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:46,090 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:46,104 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:46,110 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:46,113 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:46,261 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:47,335 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:47,379 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:47,382 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:47,387 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:47,418 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:47,421 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:47,423 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
recon_1      | 2022-06-24 01:17:07,810 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f58ed7fb-82ba-4210-bda3-c3af98ea0f8c reported by f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 896230875764, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:17:08,406 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f58ed7fb-82ba-4210-bda3-c3af98ea0f8c reported by 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 897348533486, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:17:09,047 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f58ed7fb-82ba-4210-bda3-c3af98ea0f8c reported by f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 894868778582, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:17:09,260 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 105 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:09,261 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 106 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:09,262 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 107 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:17:11,263 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 108 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:11,264 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 109 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:11,265 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 110 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:17:13,266 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 111 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:13,267 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 112 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:13,268 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 113 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:17:15,271 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 114 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:15,272 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 115 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:15,273 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 116 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:17:17,274 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 117 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:25,991 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
om3_1        | 2022-06-24 01:26:54,734 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-22045 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:29:15,597 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5999345803 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:34:33,142 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5973959837 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:35:38,025 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-5973959837, Key:ozone-test-6031795731/multidelete/key=value/f4.
scm2.org_1   | 2022-06-24 01:15:34,210 [pool-16-thread-1] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2: new RaftServerImpl for group-E1C8A5D19D86:[] with SCMStateMachine:uninitialized
scm2.org_1   | 2022-06-24 01:15:34,226 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2022-06-24 01:15:34,226 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm2.org_1   | 2022-06-24 01:15:34,226 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm2.org_1   | 2022-06-24 01:15:34,226 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-06-24 01:15:34,226 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-06-24 01:15:34,226 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2022-06-24 01:15:34,253 [pool-16-thread-1] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2022-06-24 01:15:34,254 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-06-24 01:15:34,266 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2022-06-24 01:15:34,274 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm2.org_1   | 2022-06-24 01:15:34,276 [pool-16-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86 does not exist. Creating ...
scm2.org_1   | 2022-06-24 01:15:34,312 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/in_use.lock acquired by nodename 7@scm2.org
scm2.org_1   | 2022-06-24 01:15:34,348 [pool-16-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86 has been successfully formatted.
scm2.org_1   | 2022-06-24 01:15:34,357 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm2.org_1   | 2022-06-24 01:15:34,363 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2022-06-24 01:15:34,374 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm2.org_1   | 2022-06-24 01:15:34,383 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-06-24 01:15:34,385 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm2.org_1   | 2022-06-24 01:15:34,621 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-06-24 01:15:34,649 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2022-06-24 01:15:34,650 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2022-06-24 01:15:34,654 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86
scm2.org_1   | 2022-06-24 01:15:34,660 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2022-06-24 01:15:34,660 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2022-06-24 01:15:34,668 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-06-24 01:15:34,669 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm2.org_1   | 2022-06-24 01:15:34,669 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2022-06-24 01:15:34,670 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2022-06-24 01:15:34,670 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2022-06-24 01:15:34,670 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2022-06-24 01:15:34,711 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2022-06-24 01:15:34,716 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm2.org_1   | 2022-06-24 01:15:34,717 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2022-06-24 01:15:34,731 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-06-24 01:15:34,731 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-06-24 01:15:34,740 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2022-06-24 01:15:34,741 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2022-06-24 01:15:34,742 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2022-06-24 01:15:34,743 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2022-06-24 01:15:34,749 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2022-06-24 01:15:34,755 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2022-06-24 01:15:34,877 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2022-06-24 01:15:34,877 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm2.org_1   | 2022-06-24 01:15:34,878 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm2.org_1   | 2022-06-24 01:15:34,878 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm2.org_1   | 2022-06-24 01:15:34,882 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm2.org_1   | 2022-06-24 01:15:34,892 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2022-06-24 01:15:34,894 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2022-06-24 01:15:34,895 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2022-06-24 01:15:35,462 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 118 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:26,497 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44038
recon_1      | 2022-06-24 01:17:26,564 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:17:26,567 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f58ed7fb-82ba-4210-bda3-c3af98ea0f8c reported by f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 894868778582, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:17:26,569 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=d398541e-69bc-4b5f-864d-ad98d1005d0c. Trying to get from SCM.
recon_1      | 2022-06-24 01:17:26,648 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: d398541e-69bc-4b5f-864d-ad98d1005d0c, Nodes: f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:f015cc2c-a406-4fd0-a15c-edabddeafb23, CreationTimestamp2022-06-24T01:16:54.502Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-06-24 01:17:26,650 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d398541e-69bc-4b5f-864d-ad98d1005d0c, Nodes: f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:f015cc2c-a406-4fd0-a15c-edabddeafb23, CreationTimestamp2022-06-24T01:16:54.502Z[UTC]].
recon_1      | 2022-06-24 01:17:26,678 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 119 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-24 01:17:29,586 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-24 01:35:49,980 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0161962971 of layout LEGACY in volume: s3v
om3_1        | 2022-06-24 01:36:15,799 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7609276061 of layout LEGACY in volume: s3v
s3g_1        | 2022-06-24 01:30:58,661 [qtp848097505-21] INFO scm.XceiverClientRatis: Could not commit index 133 on pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]] to all the nodes. Server f015cc2c-a406-4fd0-a15c-edabddeafb23 has failed. Committed by majority.
s3g_1        | 2022-06-24 01:30:58,662 [qtp848097505-21] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200048 bcsId: 133 on Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]]. Failed nodes: [f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-06-24 01:32:24,986 [qtp848097505-25] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #173 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:392)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:552)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:254)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
scm2.org_1   | 2022-06-24 01:15:35,794 [main] INFO reflections.Reflections: Reflections took 244 ms to scan 3 urls, producing 109 keys and 243 values 
scm2.org_1   | 2022-06-24 01:15:36,156 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm2.org_1   | 2022-06-24 01:15:36,156 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2022-06-24 01:15:36,175 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm2.org_1   | 2022-06-24 01:15:36,178 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2022-06-24 01:15:36,401 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2022-06-24 01:15:36,499 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2022-06-24 01:15:36,525 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2022-06-24 01:15:36,644 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2022-06-24 01:15:36,647 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm2.org_1   | 2022-06-24 01:15:36,658 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2022-06-24 01:15:36,666 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm2.org_1   | 2022-06-24 01:15:36,711 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2022-06-24 01:15:36,711 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm2.org_1   | 2022-06-24 01:15:36,738 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm2.org_1   | 2022-06-24 01:15:36,743 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm2.org_1   | 2022-06-24 01:15:36,908 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2022-06-24 01:15:36,971 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2022-06-24 01:15:37,072 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm2.org_1   | 2022-06-24 01:15:37,079 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2022-06-24 01:15:37,163 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm2.org_1   | 2022-06-24 01:15:37,164 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-06-24 01:15:37,172 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:15:37,174 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-06-24 01:15:37,276 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm2.org_1   | 2022-06-24 01:15:37,402 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-06-24 01:15:37,573 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm2.org_1   | 2022-06-24 01:15:38,952 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-06-24 01:15:38,970 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-06-24 01:15:38,971 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2022-06-24 01:15:39,080 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-06-24 01:15:39,098 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-06-24 01:15:39,108 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2022-06-24 01:15:39,217 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-06-24 01:15:39,233 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-06-24 01:15:39,236 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm2.org_1   | 2022-06-24 01:15:39,438 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm2.org_1   | 2022-06-24 01:15:39,439 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm2.org_1   | Container Balancer status:
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        false
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                                                Value
scm2.org_1   | Threshold                                          10
scm2.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm2.org_1   | Max Size to Move per Iteration                     500GB
scm2.org_1   | Max Size Entering Target per Iteration             26GB
scm2.org_1   | Max Size Leaving Source per Iteration              26GB
scm2.org_1   | 
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-06-24 01:15:09,550 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 120 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-24 01:17:31,159 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:51Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-06-24 01:15:09,571 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-06-24 01:15:09,624 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-06-24 01:15:09,684 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-06-24 01:15:09,697 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-06-24 01:15:09,749 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-06-24 01:15:09,749 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-06-24 01:15:10,265 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm1.org_1   | 2022-06-24 01:15:10,396 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2022-06-24 01:15:10,399 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/811320438653.crt.
scm1.org_1   | 2022-06-24 01:15:10,402 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2022-06-24 01:15:10,534 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2022-06-24 01:15:10,539 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2022-06-24 01:15:10,584 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-06-24 01:15:10,784 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-06-24 01:15:11,136 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm1.org_1   | 2022-06-24 01:15:11,136 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm1.org_1   | 2022-06-24 01:15:11,253 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-06-24 01:15:11,293 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:53b8a25c-b7d5-4020-bf2c-829236b7c472
scm1.org_1   | 2022-06-24 01:15:11,446 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-06-24 01:15:11,585 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-06-24 01:15:11,589 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-06-24 01:15:11,590 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-06-24 01:15:11,590 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-06-24 01:15:11,591 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-06-24 01:15:11,592 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-06-24 01:15:11,596 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-06-24 01:15:11,602 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-06-24 01:15:11,602 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-06-24 01:15:11,627 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2022-06-24 01:15:11,628 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2022-06-24 01:15:12,622 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-06-24 01:15:12,624 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm1.org_1   | 2022-06-24 01:15:12,625 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2022-06-24 01:15:12,625 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-06-24 01:15:12,625 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-06-24 01:15:12,628 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-06-24 01:15:12,636 [53b8a25c-b7d5-4020-bf2c-829236b7c472-impl-thread1] INFO server.RaftServer: 53b8a25c-b7d5-4020-bf2c-829236b7c472: found a subdirectory /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86
scm1.org_1   | 2022-06-24 01:15:12,642 [main] INFO server.RaftServer: 53b8a25c-b7d5-4020-bf2c-829236b7c472: addNew group-E1C8A5D19D86:[] returns group-E1C8A5D19D86:java.util.concurrent.CompletableFuture@26e8ff8c[Not completed]
scm1.org_1   | 2022-06-24 01:15:12,681 [pool-16-thread-1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472: new RaftServerImpl for group-E1C8A5D19D86:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-06-24 01:15:12,682 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-06-24 01:15:12,699 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-06-24 01:15:12,701 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-06-24 01:15:12,702 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-06-24 01:15:12,702 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-06-24 01:15:12,702 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-06-24 01:15:12,709 [pool-16-thread-1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-06-24 01:15:12,710 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-06-24 01:15:12,713 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2022-06-24 01:24:47,435 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:47,437 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:47,439 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:47,515 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:50,615 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:50,662 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:50,665 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:50,670 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:54,464 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45316
om2_1        | 2022-06-24 01:24:54,470 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:24:57,550 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:57,557 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:57,564 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4733637939 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:24:58,152 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:58,158 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:58,175 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1730767704 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:24:58,748 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:58,750 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:58,759 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2065079189 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:24:59,340 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:59,343 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:24:59,351 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-2065079189 in volume:s3v
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-24 01:24:59,932 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:03,696 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45348
om2_1        | 2022-06-24 01:25:03,703 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:25:06,867 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:06,891 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:06,901 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3364067888 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:25:07,613 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:07,615 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:07,624 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4560648265 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:25:08,234 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:08,237 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:08,823 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:08,826 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:08,832 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-2464099455 in volume:s3v
om2_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2496)
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2466)
om2_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-24 01:25:12,255 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45394
om2_1        | 2022-06-24 01:25:12,259 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:25:15,348 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:15,362 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:15,369 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2933990824 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:25:15,945 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:15,947 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:16,535 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:16,540 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:20,014 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45414
om2_1        | 2022-06-24 01:25:20,019 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:25:23,211 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:23,216 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:23,224 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8597145003 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:25:23,811 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:23,818 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:23,822 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:27,485 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45442
om2_1        | 2022-06-24 01:25:27,487 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:25:31,653 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37565
om2_1        | 2022-06-24 01:25:31,660 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:25:32,881 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45460
om2_1        | 2022-06-24 01:25:32,885 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:25:36,010 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:38181
om2_1        | 2022-06-24 01:25:36,011 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:25:36,012 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:36,016 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:36,037 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0116139998 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:25:36,736 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:36,739 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:36,742 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:37,616 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
recon_1      | 2022-06-24 01:17:31,651 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f58ed7fb-82ba-4210-bda3-c3af98ea0f8c reported by f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 894868778582, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:17:37,774 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50518
recon_1      | 2022-06-24 01:17:37,845 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:17:38,420 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58100
recon_1      | 2022-06-24 01:17:38,498 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:17:44,023 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44112
recon_1      | 2022-06-24 01:17:44,080 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:17:44,081 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=f58ed7fb-82ba-4210-bda3-c3af98ea0f8c reported by f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 894868778582, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-24 01:17:44,083 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f58ed7fb-82ba-4210-bda3-c3af98ea0f8c, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:f015cc2c-a406-4fd0-a15c-edabddeafb23, CreationTimestamp2022-06-24T01:16:57.105Z[UTC]] moved to OPEN state
recon_1      | 2022-06-24 01:17:51,548 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50586
recon_1      | 2022-06-24 01:17:51,721 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:17:51,754 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-06-24 01:17:51,867 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58168
recon_1      | 2022-06-24 01:17:51,913 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:17:52,001 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1      | 2022-06-24 01:18:21,549 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50682
recon_1      | 2022-06-24 01:18:21,579 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:18:21,836 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58266
recon_1      | 2022-06-24 01:18:21,885 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:18:22,079 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44258
recon_1      | 2022-06-24 01:18:22,146 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:18:31,167 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:18:31,167 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:18:31,246 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
scm3.org_1   | Sleeping for 5 seconds
scm3.org_1   | Waiting for the service scm2.org:9894
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-06-24 01:15:43,640 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:51Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-06-24 01:15:43,656 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-06-24 01:15:43,869 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-06-24 01:15:43,953 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-06-24 01:15:43,959 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-06-24 01:15:44,099 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-06-24 01:15:44,100 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-06-24 01:15:44,453 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-06-24 01:15:44,453 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-06-24 01:15:44,615 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2022-06-24 01:15:45,423 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2022-06-24 01:15:46,198 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm3.org_1   | 2022-06-24 01:15:46,200 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2022-06-24 01:15:46,202 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm3.org_1   | 2022-06-24 01:15:47,030 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm3.org_1   | 2022-06-24 01:15:47,131 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2022-06-24 01:15:47,132 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2022-06-24 01:15:47,138 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:b14cb6be-fcb2-48c3-9740-35fdb02d7d2d,clusterId:CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86,subject:scm-sub@scm3.org
scm3.org_1   | 2022-06-24 01:15:48,241 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2022-06-24 01:15:48,262 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-082d7a2f-1407-4624-8d8e-e1c8a5d19d86, SCMID b14cb6be-fcb2-48c3-9740-35fdb02d7d2d
scm3.org_1   | 2022-06-24 01:15:48,262 [main] INFO server.StorageContainerManager: Primary SCM Node ID 53b8a25c-b7d5-4020-bf2c-829236b7c472
scm3.org_1   | 2022-06-24 01:15:48,318 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-06-24 01:15:50,426 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/gson-2.8.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/110dca5ec74722109cf1bb890db0ba15b5557cb3 ; compiled by 'runner' on 2022-06-24T00:51Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-06-24 01:15:50,438 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-06-24 01:15:50,514 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-06-24 01:15:50,582 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-06-24 01:15:50,592 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-06-24 01:15:50,625 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-06-24 01:15:50,625 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-06-24 01:15:51,019 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2022-06-24 01:15:51,132 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/858575419197.crt.
scm3.org_1   | 2022-06-24 01:15:51,135 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2022-06-24 01:15:51,139 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2022-06-24 01:15:51,242 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-06-24 01:15:51,242 [main] INFO server.StorageContainerManager: SCM login successful.
om2_1        | 2022-06-24 01:25:37,619 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:37,622 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:37,644 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:38,195 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:38,841 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
scm1.org_1   | 2022-06-24 01:15:12,713 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-06-24 01:15:12,723 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/in_use.lock acquired by nodename 6@scm1.org
scm1.org_1   | 2022-06-24 01:15:12,730 [pool-16-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=53b8a25c-b7d5-4020-bf2c-829236b7c472} from /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/current/raft-meta
scm1.org_1   | 2022-06-24 01:15:12,775 [pool-16-thread-1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: set configuration 0: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-06-24 01:15:12,776 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-06-24 01:15:12,777 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-06-24 01:15:12,784 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-06-24 01:15:12,784 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-06-24 01:15:12,785 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2022-06-24 01:15:12,857 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-06-24 01:15:12,864 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-06-24 01:15:12,864 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-06-24 01:15:12,869 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86
scm1.org_1   | 2022-06-24 01:15:12,869 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-06-24 01:15:12,869 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-06-24 01:15:12,870 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-06-24 01:15:12,871 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-06-24 01:15:12,871 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-06-24 01:15:12,871 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-06-24 01:15:12,872 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-06-24 01:15:12,872 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-06-24 01:15:12,879 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-06-24 01:15:12,879 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2022-06-24 01:15:12,880 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-06-24 01:15:12,899 [pool-16-thread-1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: set configuration 0: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-06-24 01:15:12,900 [pool-16-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/current/log_inprogress_0
scm1.org_1   | 2022-06-24 01:15:12,902 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-06-24 01:15:12,902 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-06-24 01:15:12,971 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-06-24 01:15:12,972 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-06-24 01:15:12,977 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-06-24 01:15:12,977 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-06-24 01:15:12,979 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-06-24 01:15:12,979 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-06-24 01:15:13,026 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-06-24 01:15:13,027 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2022-06-24 01:15:13,028 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2022-06-24 01:15:13,029 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2022-06-24 01:15:13,033 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2022-06-24 01:15:13,035 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2022-06-24 01:15:13,035 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2022-06-24 01:15:13,036 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2022-06-24 01:15:13,210 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm1.org_1   | 2022-06-24 01:15:13,311 [main] INFO reflections.Reflections: Reflections took 77 ms to scan 3 urls, producing 109 keys and 243 values 
scm1.org_1   | 2022-06-24 01:15:13,393 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm1.org_1   | 2022-06-24 01:15:13,393 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm1.org_1   | 2022-06-24 01:15:13,396 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2022-06-24 01:15:13,398 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2022-06-24 01:15:13,444 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2022-06-24 01:15:13,455 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2022-06-24 01:15:13,463 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #173 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-06-24 01:32:25,000 [qtp848097505-25] INFO scm.XceiverClientRatis: Could not commit index 136 on pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]] to all the nodes. Server f015cc2c-a406-4fd0-a15c-edabddeafb23 has failed. Committed by majority.
s3g_1        | 2022-06-24 01:32:25,000 [qtp848097505-25] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200053 bcsId: 136 on Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]]. Failed nodes: [f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-06-24 01:33:25,916 [qtp848097505-24] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #178 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:392)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:552)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:254)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm1.org_1   | 2022-06-24 01:15:13,536 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm1.org_1   | 2022-06-24 01:15:13,537 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm1.org_1   | 2022-06-24 01:15:13,545 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm1.org_1   | 2022-06-24 01:15:13,549 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm1.org_1   | 2022-06-24 01:15:13,555 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm1.org_1   | 2022-06-24 01:15:13,555 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm1.org_1   | 2022-06-24 01:15:13,562 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm1.org_1   | 2022-06-24 01:15:13,562 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm1.org_1   | 2022-06-24 01:15:13,598 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2022-06-24 01:15:13,621 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2022-06-24 01:15:13,654 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2022-06-24 01:15:13,654 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2022-06-24 01:15:13,683 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-06-24 01:15:13,686 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm1.org_1   | 2022-06-24 01:15:13,690 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:15:13,693 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-06-24 01:15:13,736 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-06-24 01:15:13,746 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-06-24 01:15:13,747 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 811320438653 on primary SCM
scm1.org_1   | 2022-06-24 01:15:13,755 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm1.org_1   | 2022-06-24 01:15:13,797 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-06-24 01:15:13,832 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2022-06-24 01:15:14,707 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-06-24 01:15:14,740 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-06-24 01:15:14,743 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm1.org_1   | 2022-06-24 01:15:14,789 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-06-24 01:15:14,794 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-06-24 01:15:14,797 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2022-06-24 01:15:14,832 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-06-24 01:15:14,841 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-06-24 01:15:14,843 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm1.org_1   | 2022-06-24 01:15:14,970 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm1.org_1   | 2022-06-24 01:15:14,970 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | Container Balancer status:
scm1.org_1   | Key                            Value
scm1.org_1   | Running                        false
scm1.org_1   | Container Balancer Configuration values:
scm1.org_1   | Key                                                Value
scm1.org_1   | Threshold                                          10
scm1.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm1.org_1   | Max Size to Move per Iteration                     500GB
scm1.org_1   | Max Size Entering Target per Iteration             26GB
scm1.org_1   | Max Size Leaving Source per Iteration              26GB
scm1.org_1   | 
scm1.org_1   | 2022-06-24 01:15:14,970 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-06-24 01:15:14,970 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm1.org_1   | 2022-06-24 01:15:14,976 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm1.org_1   | 2022-06-24 01:15:14,977 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm1.org_1   | 2022-06-24 01:15:14,979 [53b8a25c-b7d5-4020-bf2c-829236b7c472-impl-thread1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: start as a follower, conf=0: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-06-24 01:15:14,980 [53b8a25c-b7d5-4020-bf2c-829236b7c472-impl-thread1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm1.org_1   | 2022-06-24 01:15:14,981 [53b8a25c-b7d5-4020-bf2c-829236b7c472-impl-thread1] INFO impl.RoleInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472: start 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState
scm1.org_1   | 2022-06-24 01:15:15,000 [53b8a25c-b7d5-4020-bf2c-829236b7c472-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E1C8A5D19D86,id=53b8a25c-b7d5-4020-bf2c-829236b7c472
scm1.org_1   | 2022-06-24 01:15:15,008 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 53b8a25c-b7d5-4020-bf2c-829236b7c472: start RPC server
scm1.org_1   | 2022-06-24 01:15:15,071 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 53b8a25c-b7d5-4020-bf2c-829236b7c472: GrpcService started, listening on 9894
scm1.org_1   | 2022-06-24 01:15:15,073 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-06-24 01:15:15,075 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$476/0x000000084055f040@f14d079] INFO util.JvmPauseMonitor: JvmPauseMonitor-53b8a25c-b7d5-4020-bf2c-829236b7c472: Started
scm1.org_1   | 2022-06-24 01:15:15,075 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2022-06-24 01:15:39,443 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-06-24 01:15:39,445 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm2.org_1   | 2022-06-24 01:15:39,454 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2022-06-24 01:15:39,463 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2022-06-24 01:15:39,465 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-impl-thread1] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: start with initializing state, conf=-1: [], old=null
scm2.org_1   | 2022-06-24 01:15:39,465 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-impl-thread1] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: changes role from      null to FOLLOWER at term 0 for startInitializing
scm2.org_1   | 2022-06-24 01:15:39,467 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E1C8A5D19D86,id=7294e591-5fc1-4a75-ab0a-c1d51b5556d2
scm2.org_1   | 2022-06-24 01:15:39,470 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2: start RPC server
scm2.org_1   | 2022-06-24 01:15:39,534 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2: GrpcService started, listening on 9894
scm2.org_1   | 2022-06-24 01:15:39,543 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$462/0x0000000840529840@38320819] INFO util.JvmPauseMonitor: JvmPauseMonitor-7294e591-5fc1-4a75-ab0a-c1d51b5556d2: Started
scm3.org_1   | 2022-06-24 01:15:51,269 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-06-24 01:15:51,425 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-06-24 01:15:39,551 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2022-06-24 01:15:40,702 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: receive installSnapshot: 53b8a25c-b7d5-4020-bf2c-829236b7c472->7294e591-5fc1-4a75-ab0a-c1d51b5556d2#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2022-06-24 01:15:40,723 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2022-06-24 01:15:40,723 [grpc-default-executor-0] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: change Leader from null to 53b8a25c-b7d5-4020-bf2c-829236b7c472 at term 2 for installSnapshot, leader elected after 6367ms
scm2.org_1   | 2022-06-24 01:15:40,726 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: Received notification to install snapshot at index 0
scm2.org_1   | 2022-06-24 01:15:40,727 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm2.org_1   | 2022-06-24 01:15:40,971 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "53b8a25c-b7d5-4020-bf2c-829236b7c472"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-06-24 01:15:40,980 [grpc-default-executor-0] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: set configuration 1: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-24 01:15:40,986 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: reply installSnapshot: 53b8a25c-b7d5-4020-bf2c-829236b7c472<-7294e591-5fc1-4a75-ab0a-c1d51b5556d2#0:FAIL-t0,ALREADY_INSTALLED
scm2.org_1   | 2022-06-24 01:15:41,014 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2: Completed INSTALL_SNAPSHOT, lastRequest: 53b8a25c-b7d5-4020-bf2c-829236b7c472->7294e591-5fc1-4a75-ab0a-c1d51b5556d2#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2022-06-24 01:15:41,081 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread1] INFO impl.RoleInfo: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2: start 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-FollowerState
scm2.org_1   | 2022-06-24 01:15:41,082 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread1] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2022-06-24 01:15:41,088 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread1] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: inconsistency entries. Reply:53b8a25c-b7d5-4020-bf2c-829236b7c472<-7294e591-5fc1-4a75-ab0a-c1d51b5556d2#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-06-24 01:15:41,108 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread1] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2022-06-24 01:15:41,108 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread1] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: inconsistency entries. Reply:53b8a25c-b7d5-4020-bf2c-829236b7c472<-7294e591-5fc1-4a75-ab0a-c1d51b5556d2#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-06-24 01:15:41,116 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread1] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: set configuration 0: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-24 01:15:41,118 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread1] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: set configuration 1: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-24 01:15:41,122 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread1] INFO segmented.SegmentedRaftLogWorker: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-SegmentedRaftLogWorker: Starting segment from index:0
scm2.org_1   | 2022-06-24 01:15:41,180 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread1] INFO segmented.SegmentedRaftLogWorker: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm2.org_1   | 2022-06-24 01:15:41,246 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread2] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: set configuration 0: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-24 01:15:41,247 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread2] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: set configuration 1: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-24 01:15:41,500 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/current/log_inprogress_0
scm2.org_1   | 2022-06-24 01:15:41,510 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/current/log_inprogress_0 to /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/current/log_0-0
scm2.org_1   | 2022-06-24 01:15:41,565 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/current/log_inprogress_1
scm2.org_1   | 2022-06-24 01:15:41,587 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:15:41,593 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2022-06-24 01:15:41,594 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-06-24 01:15:41,595 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2022-06-24 01:15:41,599 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread2] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: set configuration 7: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-06-24 01:15:41,604 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-06-24 01:15:41,607 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm2.org_1   | 2022-06-24 01:15:41,634 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread2] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: set configuration 9: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-24 01:15:41,858 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-E1C8A5D19D86:[7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-06-24 01:15:41,862 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2022-06-24 01:15:41,898 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm2.org_1   | 2022-06-24 01:15:41,898 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm2.org_1   | 2022-06-24 01:15:41,904 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:15:41,912 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm2.org_1   | 2022-06-24 01:15:41,914 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm2.org_1   | 2022-06-24 01:15:42,048 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:15:42,256 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2022-06-24 01:15:42,322 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2022-06-24 01:15:42,323 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2022-06-24 01:15:43,084 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2022-06-24 01:15:43,085 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-06-24 01:15:43,085 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2022-06-24 01:15:43,132 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2022-06-24 01:15:43,133 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2022-06-24 01:15:43,133 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-06-24 01:15:43,134 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2022-06-24 01:15:43,148 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2022-06-24 01:15:43,156 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-06-24 01:15:43,156 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2022-06-24 01:15:43,157 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2022-06-24 01:15:43,306 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-06-24 01:15:43,315 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-06-24 01:15:43,317 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2022-06-24 01:15:43,658 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 811320438653 on Scm Bootstrap Node 7294e591-5fc1-4a75-ab0a-c1d51b5556d2
scm2.org_1   | 2022-06-24 01:15:43,661 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 7294e591-5fc1-4a75-ab0a-c1d51b5556d2
scm2.org_1   | 2022-06-24 01:15:43,725 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3a1eb893] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm2.org_1   | 2022-06-24 01:15:43,780 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2022-06-24 01:15:43,780 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm2.org_1   | 2022-06-24 01:15:43,786 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2022-06-24 01:15:43,841 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @19089ms to org.eclipse.jetty.util.log.Slf4jLog
scm2.org_1   | 2022-06-24 01:15:44,042 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2022-06-24 01:15:44,055 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2022-06-24 01:15:44,062 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm2.org_1   | 2022-06-24 01:15:44,067 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2022-06-24 01:15:44,068 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm2.org_1   | 2022-06-24 01:15:44,071 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm2.org_1   | 2022-06-24 01:15:44,156 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2022-06-24 01:15:44,157 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm2.org_1   | 2022-06-24 01:15:44,270 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2022-06-24 01:15:44,273 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2022-06-24 01:15:44,275 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
om2_1        | 2022-06-24 01:25:38,844 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:38,846 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:38,868 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:39,026 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:39,679 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:39,682 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:39,685 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:40,277 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:40,284 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:40,289 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:40,318 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:41,290 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:41,293 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:41,298 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:41,972 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:41,977 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:41,980 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:42,698 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:42,700 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:42,704 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:42,722 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:43,206 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:43,884 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:43,887 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:43,890 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:43,913 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:44,318 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:45,153 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:45,157 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:45,159 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:45,893 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:45,895 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:45,908 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:45,926 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:46,251 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:46,951 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:46,953 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:46,957 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:46,972 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:47,064 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:47,695 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:47,698 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:47,700 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:48,302 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:48,305 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:48,307 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:48,321 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:49,302 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:49,304 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:49,306 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:49,939 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:49,942 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:49,945 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:49,960 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:50,043 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:50,720 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:50,722 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:50,724 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:50,744 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:53,218 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:53,890 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:53,893 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:53,896 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:53,903 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-0116139998/ozone-test-2761194856/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1        | 2022-06-24 01:25:53,907 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2761194856/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om2_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-2761194856/multipartKey2. Entity too small.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:531)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-24 01:25:54,500 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:54,502 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:54,506 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
scm1.org_1   | 2022-06-24 01:15:15,083 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2022-06-24 01:15:15,083 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2022-06-24 01:15:15,211 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2022-06-24 01:15:15,231 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2022-06-24 01:15:15,231 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2022-06-24 01:15:15,488 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2022-06-24 01:15:15,490 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-06-24 01:15:15,491 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm1.org_1   | 2022-06-24 01:15:15,516 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm1.org_1   | 2022-06-24 01:15:15,517 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm1.org_1   | 2022-06-24 01:15:15,517 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-06-24 01:15:15,518 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm1.org_1   | 2022-06-24 01:15:15,533 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2022-06-24 01:15:15,537 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-06-24 01:15:15,537 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2022-06-24 01:15:15,538 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2022-06-24 01:15:15,664 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5abf9a76] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2022-06-24 01:15:15,684 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2022-06-24 01:15:15,684 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2022-06-24 01:15:15,686 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | 2022-06-24 01:15:15,756 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @7313ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2022-06-24 01:15:15,927 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39341
scm1.org_1   | 2022-06-24 01:15:16,002 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:15:16,142 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm1.org_1   | 2022-06-24 01:15:16,173 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm1.org_1   | 2022-06-24 01:15:16,182 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2022-06-24 01:15:16,187 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm1.org_1   | 2022-06-24 01:15:16,187 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2022-06-24 01:15:16,207 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm1.org_1   | 2022-06-24 01:15:16,285 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm1.org_1   | 2022-06-24 01:15:16,286 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm1.org_1   | 2022-06-24 01:15:16,383 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.25.0.115:39341
scm1.org_1   | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:53b8a25c-b7d5-4020-bf2c-829236b7c472 is not the leader. Could not determine the leader node.
scm1.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-06-24 01:15:16,334 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55136
scm1.org_1   | 2022-06-24 01:15:16,421 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm1.org_1   | 2022-06-24 01:15:16,421 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm1.org_1   | 2022-06-24 01:15:16,422 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm1.org_1   | 2022-06-24 01:15:16,428 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:15:16,454 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-06-24 01:15:16,456 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2d9cc10{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:18:51,540 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50794
recon_1      | 2022-06-24 01:18:51,626 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:18:51,831 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58370
recon_1      | 2022-06-24 01:18:51,840 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:18:52,064 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44360
recon_1      | 2022-06-24 01:18:52,083 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:19:06,946 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58438
recon_1      | 2022-06-24 01:19:06,993 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50856
recon_1      | 2022-06-24 01:19:07,000 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44428
recon_1      | 2022-06-24 01:19:07,004 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:19:07,006 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-06-24 01:19:07,100 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:19:07,101 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:19:07,156 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-06-24 01:19:31,247 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:19:31,248 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:19:31,358 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
scm3.org_1   | 2022-06-24 01:15:51,847 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm3.org_1   | 2022-06-24 01:15:51,849 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm3.org_1   | 2022-06-24 01:15:51,970 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2022-06-24 01:15:52,014 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:b14cb6be-fcb2-48c3-9740-35fdb02d7d2d
scm3.org_1   | 2022-06-24 01:15:52,204 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm3.org_1   | 2022-06-24 01:15:52,393 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm3.org_1   | 2022-06-24 01:15:52,395 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-06-24 01:15:52,395 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm3.org_1   | 2022-06-24 01:15:52,398 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-06-24 01:15:52,399 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-06-24 01:15:52,400 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm3.org_1   | 2022-06-24 01:15:52,408 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-06-24 01:15:52,411 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2022-06-24 01:15:52,412 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2022-06-24 01:15:52,471 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm3.org_1   | 2022-06-24 01:15:52,476 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm3.org_1   | 2022-06-24 01:15:53,263 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2022-06-24 01:15:53,267 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm3.org_1   | 2022-06-24 01:15:53,271 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm3.org_1   | 2022-06-24 01:15:53,271 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-06-24 01:15:53,271 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-06-24 01:15:53,279 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-06-24 01:15:53,290 [main] INFO server.RaftServer: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: addNew group-E1C8A5D19D86:[] returns group-E1C8A5D19D86:java.util.concurrent.CompletableFuture@39832280[Not completed]
scm3.org_1   | 2022-06-24 01:15:53,333 [pool-16-thread-1] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: new RaftServerImpl for group-E1C8A5D19D86:[] with SCMStateMachine:uninitialized
scm3.org_1   | 2022-06-24 01:15:53,337 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | 2022-06-24 01:15:53,338 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2022-06-24 01:15:53,338 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm3.org_1   | 2022-06-24 01:15:53,338 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-06-24 01:15:53,338 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-06-24 01:15:53,338 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2022-06-24 01:15:53,350 [pool-16-thread-1] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2022-06-24 01:15:53,351 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-06-24 01:15:53,361 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm3.org_1   | 2022-06-24 01:15:53,364 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2022-06-24 01:15:53,366 [pool-16-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86 does not exist. Creating ...
scm3.org_1   | 2022-06-24 01:15:53,389 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/in_use.lock acquired by nodename 7@scm3.org
scm3.org_1   | 2022-06-24 01:15:53,416 [pool-16-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86 has been successfully formatted.
scm3.org_1   | 2022-06-24 01:15:53,421 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm3.org_1   | 2022-06-24 01:15:53,422 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2022-06-24 01:15:53,440 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2022-06-24 01:15:53,440 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-06-24 01:15:53,442 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm3.org_1   | 2022-06-24 01:15:53,658 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-06-24 01:15:53,681 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2022-06-24 01:15:53,681 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm3.org_1   | 2022-06-24 01:15:53,706 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86
scm3.org_1   | 2022-06-24 01:15:53,717 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2022-06-24 01:15:53,717 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm3.org_1   | 2022-06-24 01:15:53,718 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-06-24 01:15:53,719 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm3.org_1   | 2022-06-24 01:15:53,719 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2022-06-24 01:15:53,720 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm3.org_1   | 2022-06-24 01:15:53,720 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2022-06-24 01:15:53,720 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm3.org_1   | 2022-06-24 01:15:53,754 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm3.org_1   | 2022-06-24 01:15:53,758 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #178 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-06-24 01:33:25,919 [qtp848097505-24] INFO scm.XceiverClientRatis: Could not commit index 140 on pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]] to all the nodes. Server f015cc2c-a406-4fd0-a15c-edabddeafb23 has failed. Committed by majority.
s3g_1        | 2022-06-24 01:33:25,920 [qtp848097505-24] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200054 bcsId: 140 on Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]]. Failed nodes: [f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-06-24 01:34:26,529 [qtp848097505-18] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #183 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:392)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:552)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:254)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
scm2.org_1   | 2022-06-24 01:15:44,289 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-06-24 01:15:44,368 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5d8b5cf6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2022-06-24 01:15:44,369 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@20bc417f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2022-06-24 01:15:44,632 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-06-24 01:15:44,652 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@67d99612{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-5424908743415115452/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm2.org_1   | 2022-06-24 01:15:44,699 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@51e513b7{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm2.org_1   | 2022-06-24 01:15:44,707 [Listener at 0.0.0.0/9860] INFO server.Server: Started @19955ms
scm2.org_1   | 2022-06-24 01:15:44,724 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2022-06-24 01:15:44,724 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2022-06-24 01:15:44,726 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm2.org_1   | 2022-06-24 01:15:48,046 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:16:03,689 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread2] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: set configuration 13: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, b14cb6be-fcb2-48c3-9740-35fdb02d7d2d|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-06-24 01:16:03,802 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2-server-thread2] INFO server.RaftServer$Division: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86: set configuration 15: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, b14cb6be-fcb2-48c3-9740-35fdb02d7d2d|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-24 01:16:23,922 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:16:25,372 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:16:26,558 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:16:32,799 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$462/0x0000000840529840@38320819] WARN util.JvmPauseMonitor: JvmPauseMonitor-7294e591-5fc1-4a75-ab0a-c1d51b5556d2: Detected pause in JVM or host machine (eg GC): pause of approximately 131915015ns.
scm2.org_1   | GC pool 'ParNew' had collection(s): count=1 time=141ms
scm2.org_1   | 2022-06-24 01:16:32,806 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:16:35,845 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:16:36,809 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:16:49,699 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45108
scm2.org_1   | 2022-06-24 01:16:49,817 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:16:51,329 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51964
scm2.org_1   | 2022-06-24 01:16:51,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:16:53,117 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55306
scm2.org_1   | 2022-06-24 01:16:53,142 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:16:53,947 [IPC Server handler 8 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f015cc2c-a406-4fd0-a15c-edabddeafb23
scm2.org_1   | 2022-06-24 01:16:53,999 [IPC Server handler 8 on default port 9861] INFO node.SCMNodeManager: Registered Data node : f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 894868778582, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-06-24 01:16:54,068 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-06-24 01:16:54,112 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm2.org_1   | 2022-06-24 01:16:54,987 [IPC Server handler 24 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f7360d38-a163-48e1-bebb-4404a3285b4b
scm2.org_1   | 2022-06-24 01:16:54,989 [IPC Server handler 24 on default port 9861] INFO node.SCMNodeManager: Registered Data node : f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 896230875764, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-06-24 01:16:54,990 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-06-24 01:16:54,990 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2022-06-24 01:15:16,456 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@582ce329{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | 2022-06-24 01:15:16,620 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-06-24 01:15:16,640 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@a43a21e{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-12871421319668614846/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2022-06-24 01:15:16,666 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@7fdf32a4{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm1.org_1   | 2022-06-24 01:15:16,666 [Listener at 0.0.0.0/9860] INFO server.Server: Started @8223ms
scm1.org_1   | 2022-06-24 01:15:16,669 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm1.org_1   | 2022-06-24 01:15:16,669 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm1.org_1   | 2022-06-24 01:15:16,670 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2022-06-24 01:15:17,187 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:41890
scm1.org_1   | 2022-06-24 01:15:17,210 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:15:20,127 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState] INFO impl.FollowerState: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5146806462ns, electionTimeout:5126ms
scm1.org_1   | 2022-06-24 01:15:20,128 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState] INFO impl.RoleInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472: shutdown 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState
scm1.org_1   | 2022-06-24 01:15:20,129 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm1.org_1   | 2022-06-24 01:15:20,132 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-06-24 01:15:20,132 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-FollowerState] INFO impl.RoleInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472: start 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1
scm1.org_1   | 2022-06-24 01:15:20,145 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO impl.LeaderElection: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-06-24 01:15:20,146 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO impl.LeaderElection: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm1.org_1   | 2022-06-24 01:15:20,146 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO impl.RoleInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472: shutdown 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1
scm1.org_1   | 2022-06-24 01:15:20,146 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm1.org_1   | 2022-06-24 01:15:20,146 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm1.org_1   | 2022-06-24 01:15:20,147 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm1.org_1   | 2022-06-24 01:15:20,148 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: change Leader from null to 53b8a25c-b7d5-4020-bf2c-829236b7c472 at term 2 for becomeLeader, leader elected after 7371ms
scm1.org_1   | 2022-06-24 01:15:20,154 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-06-24 01:15:20,158 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-06-24 01:15:20,158 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-06-24 01:15:20,163 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-06-24 01:15:20,163 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-06-24 01:15:20,164 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-06-24 01:15:20,169 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-06-24 01:15:20,171 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-06-24 01:15:20,172 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO impl.RoleInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472: start 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderStateImpl
scm1.org_1   | 2022-06-24 01:15:20,179 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm1.org_1   | 2022-06-24 01:15:20,183 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/current/log_inprogress_0 to /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/current/log_0-0
scm1.org_1   | 2022-06-24 01:15:20,193 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderElection1] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: set configuration 1: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-06-24 01:15:20,200 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/current/log_inprogress_1
scm1.org_1   | 2022-06-24 01:15:20,205 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm2.org_1   | 2022-06-24 01:16:55,434 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d398541e-69bc-4b5f-864d-ad98d1005d0c, Nodes: f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:54.502Z[UTC]].
scm2.org_1   | 2022-06-24 01:16:55,439 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:16:55,699 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fae297c5-ae4f-43a4-9b48-cbad1b5e890a, Nodes: f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:55.529Z[UTC]].
scm2.org_1   | 2022-06-24 01:16:55,699 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:16:56,844 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/171701ce-d9aa-46d7-a310-34f3f137a6a3
scm2.org_1   | 2022-06-24 01:16:56,846 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 897348533486, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-06-24 01:16:56,847 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-06-24 01:16:56,854 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm2.org_1   | 2022-06-24 01:16:56,854 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2022-06-24 01:16:56,854 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2022-06-24 01:16:56,855 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-06-24 01:16:56,863 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2022-06-24 01:16:56,864 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-06-24 01:16:56,923 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 0eb29a31-b4b1-466e-a46a-1ca046e16e6e, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:56.870Z[UTC]].
scm2.org_1   | 2022-06-24 01:16:56,924 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:16:57,104 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]].
scm2.org_1   | 2022-06-24 01:16:57,105 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:16:57,192 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f58ed7fb-82ba-4210-bda3-c3af98ea0f8c, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:57.105Z[UTC]].
scm2.org_1   | 2022-06-24 01:16:57,194 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:15:53,758 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2022-06-24 01:15:53,777 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-06-24 01:15:53,777 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-06-24 01:15:53,781 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm3.org_1   | 2022-06-24 01:15:53,782 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm3.org_1   | 2022-06-24 01:15:53,783 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm3.org_1   | 2022-06-24 01:15:53,784 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2022-06-24 01:15:53,786 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2022-06-24 01:15:53,786 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | 2022-06-24 01:15:53,862 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2022-06-24 01:15:53,867 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm3.org_1   | 2022-06-24 01:15:53,868 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm3.org_1   | 2022-06-24 01:15:53,868 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm3.org_1   | 2022-06-24 01:15:53,869 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm3.org_1   | 2022-06-24 01:15:53,872 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2022-06-24 01:15:53,872 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2022-06-24 01:15:53,872 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm3.org_1   | 2022-06-24 01:15:54,169 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm3.org_1   | 2022-06-24 01:15:54,405 [main] INFO reflections.Reflections: Reflections took 175 ms to scan 3 urls, producing 109 keys and 243 values 
scm3.org_1   | 2022-06-24 01:15:54,571 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm3.org_1   | 2022-06-24 01:15:54,572 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2022-06-24 01:15:54,578 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2022-06-24 01:15:54,584 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm3.org_1   | 2022-06-24 01:15:54,701 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | 2022-06-24 01:15:54,730 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2022-06-24 01:15:54,752 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2022-06-24 01:15:54,837 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm3.org_1   | 2022-06-24 01:15:54,841 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2022-06-24 01:15:54,857 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2022-06-24 01:15:54,861 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm3.org_1   | 2022-06-24 01:15:54,862 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm3.org_1   | 2022-06-24 01:15:54,862 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm3.org_1   | 2022-06-24 01:15:54,871 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm3.org_1   | 2022-06-24 01:15:54,871 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm3.org_1   | 2022-06-24 01:15:54,949 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm3.org_1   | 2022-06-24 01:15:54,977 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm3.org_1   | 2022-06-24 01:15:55,041 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2022-06-24 01:15:55,041 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-06-24 01:15:55,086 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-06-24 01:15:55,122 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2022-06-24 01:15:55,138 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:15:55,148 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-06-24 01:15:55,214 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | 2022-06-24 01:15:55,272 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-06-24 01:15:55,370 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm3.org_1   | 2022-06-24 01:15:56,772 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-06-24 01:15:56,783 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-06-24 01:15:56,803 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm3.org_1   | 2022-06-24 01:15:56,934 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-06-24 01:15:56,945 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-06-24 01:15:56,952 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2022-06-24 01:15:57,038 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-06-24 01:15:57,062 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-06-24 01:16:58,442 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fae297c5-ae4f-43a4-9b48-cbad1b5e890a, Nodes: f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:55.529Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-06-24 01:16:58,759 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:16:59,463 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-06-24 01:17:00,634 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 0eb29a31-b4b1-466e-a46a-1ca046e16e6e, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:171701ce-d9aa-46d7-a310-34f3f137a6a3, CreationTimestamp2022-06-24T01:16:56.870Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-06-24 01:17:00,733 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:17:01,650 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-06-24 01:17:04,490 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-06-24 01:17:06,152 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-06-24 01:17:06,622 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-06-24 01:17:07,248 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45182
scm2.org_1   | 2022-06-24 01:17:07,376 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:17:07,381 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-06-24 01:17:07,592 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-24 01:17:07,711 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm2.org_1   | 2022-06-24 01:17:07,712 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm2.org_1   | 2022-06-24 01:17:07,712 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm2.org_1   | 2022-06-24 01:17:07,712 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm2.org_1   | 2022-06-24 01:17:07,712 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-06-24 01:17:07,712 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm2.org_1   | 2022-06-24 01:17:26,474 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45236
scm2.org_1   | 2022-06-24 01:17:26,532 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:17:26,534 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d398541e-69bc-4b5f-864d-ad98d1005d0c, Nodes: f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:f015cc2c-a406-4fd0-a15c-edabddeafb23, CreationTimestamp2022-06-24T01:16:54.502Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-06-24 01:17:37,753 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52124
scm2.org_1   | 2022-06-24 01:17:37,851 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:17:38,455 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55464
scm2.org_1   | 2022-06-24 01:17:38,503 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:17:43,992 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45308
scm1.org_1   | 2022-06-24 01:15:20,206 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm1.org_1   | 2022-06-24 01:15:20,212 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:15:20,213 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2022-06-24 01:15:20,213 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-06-24 01:15:20,213 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2022-06-24 01:15:20,221 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-06-24 01:15:20,222 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2022-06-24 01:15:22,483 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:33752
scm1.org_1   | 2022-06-24 01:15:22,473 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: b8e61944-0481-44df-afbc-8577cf39f240
scm1.org_1   | 2022-06-24 01:15:22,494 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:15:22,494 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2
scm1.org_1   | 2022-06-24 01:15:22,741 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:15:22,743 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2022-06-24 01:15:22,743 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm1.org_1   | 2022-06-24 01:15:24,262 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:15:36,697 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55458
scm1.org_1   | 2022-06-24 01:15:36,759 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:15:38,864 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43251
scm1.org_1   | 2022-06-24 01:15:38,886 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:15:39,844 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:42250
scm1.org_1   | 2022-06-24 01:15:39,866 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:15:39,869 [IPC Server handler 0 on default port 9863] INFO ha.SCMRatisServerImpl: 53b8a25c-b7d5-4020-bf2c-829236b7c472: Submitting SetConfiguration request to Ratis server with new SCM peers list: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-06-24 01:15:39,870 [IPC Server handler 0 on default port 9863] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: receive setConfiguration SetConfigurationRequest:client-2B9AC5ACC6C6->53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86, cid=1, seq=0, RW, null, peers:[53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-06-24 01:15:39,870 [IPC Server handler 0 on default port 9863] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-2B9AC5ACC6C6->53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86, cid=1, seq=0, RW, null, peers:[53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-06-24 01:15:39,886 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-06-24 01:15:39,886 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-06-24 01:15:39,886 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-06-24 01:15:39,891 [IPC Server handler 0 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-06-24 01:15:39,897 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-06-24 01:15:39,898 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-06-24 01:15:39,908 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->7294e591-5fc1-4a75-ab0a-c1d51b5556d2-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->7294e591-5fc1-4a75-ab0a-c1d51b5556d2-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2022-06-24 01:15:39,918 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->7294e591-5fc1-4a75-ab0a-c1d51b5556d2-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->7294e591-5fc1-4a75-ab0a-c1d51b5556d2-GrpcLogAppender: send 53b8a25c-b7d5-4020-bf2c-829236b7c472->7294e591-5fc1-4a75-ab0a-c1d51b5556d2#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2022-06-24 01:15:41,012 [grpc-default-executor-1] INFO server.GrpcLogAppender: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->7294e591-5fc1-4a75-ab0a-c1d51b5556d2-InstallSnapshotResponseHandler: received the first reply 53b8a25c-b7d5-4020-bf2c-829236b7c472<-7294e591-5fc1-4a75-ab0a-c1d51b5556d2#0:FAIL-t0,ALREADY_INSTALLED
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
om2_1        | 2022-06-24 01:25:55,200 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:55,202 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:55,205 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:55,212 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om2_1        | partName: "etag1"
om2_1        | , partNumber: 2
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-06-24 01:25:55,213 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-24 01:25:55,903 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:55,906 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:55,908 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:55,918 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1        | partName: "etag1"
om2_1        | , partNumber: 1
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-06-24 01:25:55,924 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-24 01:25:56,580 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:56,584 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:56,589 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:56,604 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:56,947 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:57,753 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:57,756 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:57,761 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:57,775 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:58,189 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:58,990 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:58,992 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:58,995 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:25:59,017 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:00,728 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:01,357 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:01,361 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:01,364 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:01,375 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3-967b04a5-b8d6-47fb-b25e-4684f48c8038-108529841242505252-1
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:508)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-24 01:26:01,980 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:01,983 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:01,985 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:01,993 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3-967b04a5-b8d6-47fb-b25e-4684f48c8038-108529841242505252-2
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:508)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-24 01:26:02,606 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:02,609 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:02,611 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:02,618 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-0116139998/ozone-test-0539870890/multipartKey3
om2_1        | 2022-06-24 01:26:02,618 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0539870890/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-0116139998
om2_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-0116139998 key: ozone-test-0539870890/multipartKey3 because parts are in Invalid order.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:474)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
scm2.org_1   | 2022-06-24 01:17:44,006 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:17:44,007 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f58ed7fb-82ba-4210-bda3-c3af98ea0f8c, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:f015cc2c-a406-4fd0-a15c-edabddeafb23, CreationTimestamp2022-06-24T01:16:57.105Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-06-24 01:17:47,945 [7294e591-5fc1-4a75-ab0a-c1d51b5556d2@group-E1C8A5D19D86-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm2.org_1   | 2022-06-24 01:17:51,731 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52188
scm2.org_1   | 2022-06-24 01:17:51,788 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:17:51,914 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55526
scm2.org_1   | 2022-06-24 01:17:52,030 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:18:21,553 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52284
scm2.org_1   | 2022-06-24 01:18:21,581 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:18:21,811 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55628
scm2.org_1   | 2022-06-24 01:18:21,862 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:18:22,093 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45454
scm2.org_1   | 2022-06-24 01:18:22,146 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:18:51,565 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52390
scm2.org_1   | 2022-06-24 01:18:51,628 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:18:51,841 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55734
scm2.org_1   | 2022-06-24 01:18:51,866 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:18:52,078 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45562
scm2.org_1   | 2022-06-24 01:18:52,084 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:19:06,901 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55796
scm2.org_1   | 2022-06-24 01:19:06,902 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52454
scm2.org_1   | 2022-06-24 01:19:06,990 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:19:07,027 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45632
scm2.org_1   | 2022-06-24 01:19:07,029 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:19:07,126 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:19:37,002 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52560
scm2.org_1   | 2022-06-24 01:19:37,056 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45718
scm2.org_1   | 2022-06-24 01:19:37,099 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:19:37,151 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:19:37,154 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55882
scm2.org_1   | 2022-06-24 01:19:37,246 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:20:06,952 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52664
scm2.org_1   | 2022-06-24 01:20:06,984 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55994
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #183 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-06-24 01:34:26,535 [qtp848097505-18] INFO scm.XceiverClientRatis: Could not commit index 144 on pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]] to all the nodes. Server f015cc2c-a406-4fd0-a15c-edabddeafb23 has failed. Committed by majority.
s3g_1        | 2022-06-24 01:34:26,536 [qtp848097505-18] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200055 bcsId: 144 on Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]]. Failed nodes: [f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-06-24 01:34:33,128 [qtp848097505-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5973959837, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:34:33,149 [qtp848097505-23] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5973959837
s3g_1        | 2022-06-24 01:35:28,992 [qtp848097505-20] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #188 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:392)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:552)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:254)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
scm3.org_1   | 2022-06-24 01:15:57,063 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm3.org_1   | 2022-06-24 01:15:57,296 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm3.org_1   | 2022-06-24 01:15:57,301 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | Container Balancer status:
scm3.org_1   | Key                            Value
scm3.org_1   | Running                        false
scm3.org_1   | Container Balancer Configuration values:
scm3.org_1   | Key                                                Value
scm3.org_1   | Threshold                                          10
scm3.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm3.org_1   | Max Size to Move per Iteration                     500GB
scm3.org_1   | Max Size Entering Target per Iteration             26GB
scm3.org_1   | Max Size Leaving Source per Iteration              26GB
scm3.org_1   | 
scm3.org_1   | 2022-06-24 01:15:57,301 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-06-24 01:15:57,303 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm3.org_1   | 2022-06-24 01:15:57,319 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2022-06-24 01:15:57,329 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm3.org_1   | 2022-06-24 01:15:57,332 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-impl-thread1] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: start with initializing state, conf=-1: [], old=null
scm3.org_1   | 2022-06-24 01:15:57,336 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-impl-thread1] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2022-06-24 01:15:57,343 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E1C8A5D19D86,id=b14cb6be-fcb2-48c3-9740-35fdb02d7d2d
scm3.org_1   | 2022-06-24 01:15:57,371 [Listener at 0.0.0.0/9860] INFO server.RaftServer: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: start RPC server
scm3.org_1   | 2022-06-24 01:15:57,566 [Listener at 0.0.0.0/9860] INFO server.GrpcService: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: GrpcService started, listening on 9894
scm3.org_1   | 2022-06-24 01:15:57,585 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$459/0x000000084052ac40@38320819] INFO util.JvmPauseMonitor: JvmPauseMonitor-b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: Started
scm3.org_1   | 2022-06-24 01:15:57,600 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2022-06-24 01:16:01,086 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: receive installSnapshot: 53b8a25c-b7d5-4020-bf2c-829236b7c472->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2022-06-24 01:16:01,135 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm3.org_1   | 2022-06-24 01:16:01,136 [grpc-default-executor-0] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: change Leader from null to 53b8a25c-b7d5-4020-bf2c-829236b7c472 at term 2 for installSnapshot, leader elected after 7714ms
scm3.org_1   | 2022-06-24 01:16:01,156 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: Received notification to install snapshot at index 0
scm3.org_1   | 2022-06-24 01:16:01,158 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm3.org_1   | 2022-06-24 01:16:02,226 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "7294e591-5fc1-4a75-ab0a-c1d51b5556d2"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "53b8a25c-b7d5-4020-bf2c-829236b7c472"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-06-24 01:16:02,236 [grpc-default-executor-0] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: set configuration 9: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-06-24 01:16:02,261 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: reply installSnapshot: 53b8a25c-b7d5-4020-bf2c-829236b7c472<-b14cb6be-fcb2-48c3-9740-35fdb02d7d2d#0:FAIL-t0,ALREADY_INSTALLED
scm3.org_1   | 2022-06-24 01:16:02,318 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: Completed INSTALL_SNAPSHOT, lastRequest: 53b8a25c-b7d5-4020-bf2c-829236b7c472->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2022-06-24 01:16:02,582 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread1] INFO impl.RoleInfo: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: start b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-FollowerState
scm3.org_1   | 2022-06-24 01:16:02,600 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread1] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm3.org_1   | 2022-06-24 01:16:02,612 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread1] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: inconsistency entries. Reply:53b8a25c-b7d5-4020-bf2c-829236b7c472<-b14cb6be-fcb2-48c3-9740-35fdb02d7d2d#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-06-24 01:16:02,685 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread2] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm3.org_1   | 2022-06-24 01:16:02,686 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread2] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: inconsistency entries. Reply:53b8a25c-b7d5-4020-bf2c-829236b7c472<-b14cb6be-fcb2-48c3-9740-35fdb02d7d2d#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:19:36,974 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50958
recon_1      | 2022-06-24 01:19:37,085 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:19:37,120 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58520
recon_1      | 2022-06-24 01:19:37,165 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44522
recon_1      | 2022-06-24 01:19:37,223 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:19:37,240 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:20:06,923 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51052
recon_1      | 2022-06-24 01:20:06,952 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58628
recon_1      | 2022-06-24 01:20:07,042 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44624
scm1.org_1   | 2022-06-24 01:15:41,029 [grpc-default-executor-1] INFO server.GrpcLogAppender: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->7294e591-5fc1-4a75-ab0a-c1d51b5556d2-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2022-06-24 01:15:41,032 [grpc-default-executor-1] INFO leader.FollowerInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->7294e591-5fc1-4a75-ab0a-c1d51b5556d2: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-06-24 01:15:41,032 [grpc-default-executor-1] INFO leader.FollowerInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->7294e591-5fc1-4a75-ab0a-c1d51b5556d2: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-06-24 01:15:41,033 [grpc-default-executor-1] INFO leader.FollowerInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->7294e591-5fc1-4a75-ab0a-c1d51b5556d2: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2022-06-24 01:15:41,033 [grpc-default-executor-1] INFO leader.FollowerInfo: Follower 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->7294e591-5fc1-4a75-ab0a-c1d51b5556d2 acknowledged installing snapshot
scm1.org_1   | 2022-06-24 01:15:41,033 [grpc-default-executor-1] INFO leader.FollowerInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->7294e591-5fc1-4a75-ab0a-c1d51b5556d2: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2022-06-24 01:15:41,110 [grpc-default-executor-1] INFO leader.FollowerInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->7294e591-5fc1-4a75-ab0a-c1d51b5556d2: nextIndex: updateUnconditionally 7 -> 0
scm1.org_1   | 2022-06-24 01:15:41,118 [grpc-default-executor-1] INFO leader.FollowerInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->7294e591-5fc1-4a75-ab0a-c1d51b5556d2: nextIndex: updateUnconditionally 7 -> 0
scm1.org_1   | 2022-06-24 01:15:41,600 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderStateImpl] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: set configuration 7: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-06-24 01:15:41,623 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderStateImpl] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: set configuration 9: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-06-24 01:15:41,685 [IPC Server handler 0 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 7294e591-5fc1-4a75-ab0a-c1d51b5556d2.
scm1.org_1   | 2022-06-24 01:15:43,501 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:34094
scm1.org_1   | 2022-06-24 01:15:43,504 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:15:45,299 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:53220
scm1.org_1   | 2022-06-24 01:15:45,334 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:15:47,449 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:51212
scm1.org_1   | 2022-06-24 01:15:47,459 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:15:47,463 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d
scm1.org_1   | 2022-06-24 01:15:48,049 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:15:49,101 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55668
scm1.org_1   | 2022-06-24 01:15:49,147 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:15:59,407 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:53416
scm1.org_1   | 2022-06-24 01:15:59,551 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:15:59,561 [IPC Server handler 50 on default port 9863] INFO ha.SCMRatisServerImpl: 53b8a25c-b7d5-4020-bf2c-829236b7c472: Submitting SetConfiguration request to Ratis server with new SCM peers list: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, b14cb6be-fcb2-48c3-9740-35fdb02d7d2d|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-06-24 01:15:59,566 [IPC Server handler 50 on default port 9863] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: receive setConfiguration SetConfigurationRequest:client-2B9AC5ACC6C6->53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86, cid=2, seq=0, RW, null, peers:[7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, b14cb6be-fcb2-48c3-9740-35fdb02d7d2d|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-06-24 01:15:59,573 [IPC Server handler 50 on default port 9863] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-2B9AC5ACC6C6->53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86, cid=2, seq=0, RW, null, peers:[7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, b14cb6be-fcb2-48c3-9740-35fdb02d7d2d|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-06-24 01:15:59,580 [IPC Server handler 50 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-06-24 01:15:59,583 [IPC Server handler 50 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-06-24 01:15:59,586 [IPC Server handler 50 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-06-24 01:15:59,588 [IPC Server handler 50 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-06-24 01:15:59,592 [IPC Server handler 50 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-06-24 01:15:59,600 [IPC Server handler 50 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-06-24 01:15:59,613 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2022-06-24 01:15:59,619 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-GrpcLogAppender: send 53b8a25c-b7d5-4020-bf2c-829236b7c472->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2022-06-24 01:16:02,377 [grpc-default-executor-2] INFO server.GrpcLogAppender: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-InstallSnapshotResponseHandler: received the first reply 53b8a25c-b7d5-4020-bf2c-829236b7c472<-b14cb6be-fcb2-48c3-9740-35fdb02d7d2d#0:FAIL-t0,ALREADY_INSTALLED
scm1.org_1   | 2022-06-24 01:16:02,377 [grpc-default-executor-2] INFO server.GrpcLogAppender: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2022-06-24 01:16:02,386 [grpc-default-executor-2] INFO leader.FollowerInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-06-24 01:16:02,491 [grpc-default-executor-2] INFO leader.FollowerInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-06-24 01:16:02,491 [grpc-default-executor-2] INFO leader.FollowerInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2022-06-24 01:16:02,491 [grpc-default-executor-2] INFO leader.FollowerInfo: Follower 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d acknowledged installing snapshot
scm1.org_1   | 2022-06-24 01:16:02,492 [grpc-default-executor-2] INFO leader.FollowerInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2022-06-24 01:16:02,658 [grpc-default-executor-2] INFO leader.FollowerInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2022-06-24 01:16:02,696 [grpc-default-executor-2] INFO leader.FollowerInfo: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86->b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2022-06-24 01:16:03,660 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderStateImpl] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: set configuration 13: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|priority:0, b14cb6be-fcb2-48c3-9740-35fdb02d7d2d|rpc:scm3.org:9894|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-06-24 01:16:03,761 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-LeaderStateImpl] INFO server.RaftServer$Division: 53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86: set configuration 15: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|priority:0, b14cb6be-fcb2-48c3-9740-35fdb02d7d2d|rpc:scm3.org:9894|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-06-24 01:16:03,824 [IPC Server handler 50 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d.
scm1.org_1   | 2022-06-24 01:16:04,260 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55824
scm1.org_1   | 2022-06-24 01:16:04,520 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:16:10,288 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:51412
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #188 timeout 180s
scm3.org_1   | 2022-06-24 01:16:02,720 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread2] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: set configuration 0: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-06-24 01:16:02,721 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread2] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: set configuration 1: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-24 01:20:07,010 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45828
scm2.org_1   | 2022-06-24 01:20:07,035 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:20:07,099 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:20:07,123 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:20:37,011 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52752
scm2.org_1   | 2022-06-24 01:20:37,019 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56092
scm2.org_1   | 2022-06-24 01:20:37,056 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:20:37,096 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:20:37,119 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45924
scm2.org_1   | 2022-06-24 01:20:37,152 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:20:37,170 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-06-24 01:21:06,867 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52856
scm2.org_1   | 2022-06-24 01:21:06,878 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56194
scm2.org_1   | 2022-06-24 01:21:06,912 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:21:06,947 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:21:07,005 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46026
scm2.org_1   | 2022-06-24 01:21:07,035 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:21:36,930 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52966
scm2.org_1   | 2022-06-24 01:21:36,933 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56302
scm2.org_1   | 2022-06-24 01:21:36,947 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:21:36,961 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:21:36,996 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46134
scm2.org_1   | 2022-06-24 01:21:37,027 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:22:06,895 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56414
scm2.org_1   | 2022-06-24 01:22:06,934 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:22:06,964 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53090
scm2.org_1   | 2022-06-24 01:22:06,992 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:22:07,022 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46256
scm2.org_1   | 2022-06-24 01:22:07,027 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:22:36,870 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56518
scm2.org_1   | 2022-06-24 01:22:36,917 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53196
scm2.org_1   | 2022-06-24 01:22:36,947 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46360
scm2.org_1   | 2022-06-24 01:22:36,949 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:22:36,955 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:22:36,966 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:23:06,890 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53312
scm2.org_1   | 2022-06-24 01:23:06,938 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56642
scm2.org_1   | 2022-06-24 01:23:06,965 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:16:02,721 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread2] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: set configuration 7: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-06-24 01:16:02,725 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread2] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: set configuration 9: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-06-24 01:16:02,734 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread2] INFO segmented.SegmentedRaftLogWorker: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-SegmentedRaftLogWorker: Starting segment from index:0
scm3.org_1   | 2022-06-24 01:16:02,875 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread2] INFO segmented.SegmentedRaftLogWorker: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm3.org_1   | 2022-06-24 01:16:02,948 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread1] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: set configuration 0: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-06-24 01:16:02,948 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread1] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: set configuration 1: [53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-06-24 01:16:02,949 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread1] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: set configuration 7: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-06-24 01:16:02,949 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread1] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: set configuration 9: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-06-24 01:16:03,646 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/current/log_inprogress_0
scm3.org_1   | 2022-06-24 01:16:03,718 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/current/log_inprogress_0 to /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/current/log_0-0
scm3.org_1   | 2022-06-24 01:16:03,725 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread1] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: set configuration 13: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, b14cb6be-fcb2-48c3-9740-35fdb02d7d2d|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-06-24 01:16:03,799 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/082d7a2f-1407-4624-8d8e-e1c8a5d19d86/current/log_inprogress_1
scm3.org_1   | 2022-06-24 01:16:03,834 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d-server-thread1] INFO server.RaftServer$Division: b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86: set configuration 15: [7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, b14cb6be-fcb2-48c3-9740-35fdb02d7d2d|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-06-24 01:16:03,939 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:03,958 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm3.org_1   | 2022-06-24 01:16:03,963 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-06-24 01:16:03,967 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2022-06-24 01:16:04,008 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm3.org_1   | 2022-06-24 01:16:04,261 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-06-24 01:16:04,501 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-E1C8A5D19D86:[7294e591-5fc1-4a75-ab0a-c1d51b5556d2|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, b14cb6be-fcb2-48c3-9740-35fdb02d7d2d|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 53b8a25c-b7d5-4020-bf2c-829236b7c472|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-06-24 01:16:04,501 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2022-06-24 01:16:04,700 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2022-06-24 01:16:04,700 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm3.org_1   | 2022-06-24 01:16:04,771 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$459/0x000000084052ac40@38320819] WARN util.JvmPauseMonitor: JvmPauseMonitor-b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: Detected pause in JVM or host machine (eg GC): pause of approximately 109925922ns. No GCs detected.
scm3.org_1   | 2022-06-24 01:16:05,237 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:05,255 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2022-06-24 01:16:05,255 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2022-06-24 01:16:05,477 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-06-24 01:35:28,999 [qtp848097505-20] INFO scm.XceiverClientRatis: Could not commit index 148 on pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]] to all the nodes. Server f015cc2c-a406-4fd0-a15c-edabddeafb23 has failed. Committed by majority.
s3g_1        | 2022-06-24 01:35:29,000 [qtp848097505-20] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200056 bcsId: 148 on Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]]. Failed nodes: [f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-06-24 01:35:49,955 [qtp848097505-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0161962971, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:35:49,973 [qtp848097505-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-0161962971
s3g_1        | 2022-06-24 01:36:15,772 [qtp848097505-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-7609276061, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-24 01:36:15,782 [qtp848097505-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-7609276061
s3g_1        | 2022-06-24 01:36:35,504 [qtp848097505-25] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #193 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:392)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:552)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:254)
scm3.org_1   | 2022-06-24 01:16:05,544 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:05,855 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2022-06-24 01:16:06,027 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm3.org_1   | 2022-06-24 01:16:06,031 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm3.org_1   | 2022-06-24 01:16:08,020 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2022-06-24 01:16:08,031 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-06-24 01:16:08,091 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   | 2022-06-24 01:16:08,432 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   | 2022-06-24 01:16:08,433 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2022-06-24 01:16:08,436 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-06-24 01:16:08,437 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2022-06-24 01:16:08,555 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2022-06-24 01:16:08,562 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-06-24 01:16:08,562 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2022-06-24 01:16:08,562 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2022-06-24 01:16:08,881 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-06-24 01:16:08,881 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-06-24 01:16:08,909 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2022-06-24 01:16:10,499 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 811320438653 on Scm Bootstrap Node b14cb6be-fcb2-48c3-9740-35fdb02d7d2d
scm3.org_1   | 2022-06-24 01:16:10,556 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node b14cb6be-fcb2-48c3-9740-35fdb02d7d2d
scm3.org_1   | 2022-06-24 01:16:10,676 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7cb15360] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2022-06-24 01:16:10,768 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm3.org_1   | 2022-06-24 01:16:10,771 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2022-06-24 01:16:10,798 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2022-06-24 01:16:11,024 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @22271ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2022-06-24 01:16:11,785 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2022-06-24 01:16:11,826 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2022-06-24 01:16:11,839 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2022-06-24 01:16:11,850 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2022-06-24 01:16:11,853 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2022-06-24 01:16:11,868 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2022-06-24 01:16:12,168 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$459/0x000000084052ac40@38320819] WARN util.JvmPauseMonitor: JvmPauseMonitor-b14cb6be-fcb2-48c3-9740-35fdb02d7d2d: Detected pause in JVM or host machine (eg GC): pause of approximately 152439773ns.
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=148ms
scm3.org_1   | 2022-06-24 01:16:12,360 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2022-06-24 01:16:12,368 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm3.org_1   | 2022-06-24 01:16:12,649 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2022-06-24 01:16:12,649 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2022-06-24 01:16:12,694 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm3.org_1   | 2022-06-24 01:16:12,776 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-06-24 01:16:12,798 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@614da024{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2022-06-24 01:16:12,805 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@a72bb34{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2022-06-24 01:16:13,640 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-06-24 01:16:13,690 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1254e9a7{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-1863715403170746046/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2022-06-24 01:16:13,820 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@60483dcf{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2022-06-24 01:16:13,826 [Listener at 0.0.0.0/9860] INFO server.Server: Started @25071ms
scm3.org_1   | 2022-06-24 01:16:13,849 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2022-06-24 01:16:13,850 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2022-06-24 01:16:13,854 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm2.org_1   | 2022-06-24 01:23:06,989 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46478
scm2.org_1   | 2022-06-24 01:23:06,997 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:23:07,033 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:23:36,902 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53418
scm2.org_1   | 2022-06-24 01:23:37,019 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46580
scm2.org_1   | 2022-06-24 01:23:37,028 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:23:37,044 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:23:37,059 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56736
scm2.org_1   | 2022-06-24 01:23:37,095 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:24:06,889 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57022
scm2.org_1   | 2022-06-24 01:24:06,902 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53702
scm2.org_1   | 2022-06-24 01:24:06,954 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46864
scm2.org_1   | 2022-06-24 01:24:06,983 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:24:07,001 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:24:07,005 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:24:36,931 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57130
scm2.org_1   | 2022-06-24 01:24:36,938 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:24:36,959 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53812
scm2.org_1   | 2022-06-24 01:24:36,971 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46974
scm2.org_1   | 2022-06-24 01:24:36,982 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:24:36,998 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:25:06,895 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53922
scm2.org_1   | 2022-06-24 01:25:06,912 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57250
scm2.org_1   | 2022-06-24 01:25:06,981 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47088
scm2.org_1   | 2022-06-24 01:25:06,987 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:25:07,019 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:25:07,033 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:25:36,908 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54036
scm2.org_1   | 2022-06-24 01:25:36,915 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57364
scm2.org_1   | 2022-06-24 01:25:36,964 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47202
scm2.org_1   | 2022-06-24 01:25:36,982 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:25:36,998 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:25:37,010 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:25:37,171 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-06-24 01:26:06,880 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57520
scm2.org_1   | 2022-06-24 01:26:06,948 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47362
scm2.org_1   | 2022-06-24 01:26:06,970 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:26:06,987 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-24 01:26:03,223 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:03,228 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:03,236 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:03,858 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:03,860 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:03,862 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:03,910 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:04,724 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:04,726 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:04,729 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:05,360 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:05,365 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:05,370 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:05,961 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:05,964 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:05,966 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:05,973 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-4622559934/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-0116139998
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-0116139998key: ozone-test-4622559934/multipartKey5
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm1.org_1   | 2022-06-24 01:16:10,356 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:16:22,038 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:49888
scm1.org_1   | 2022-06-24 01:16:22,150 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:16:22,316 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:34388
scm1.org_1   | 2022-06-24 01:16:22,444 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:16:23,701 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47608
scm1.org_1   | 2022-06-24 01:16:23,744 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:16:23,749 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 2b7ec0a4d217, UUID: f015cc2c-a406-4fd0-a15c-edabddeafb23
scm1.org_1   | 2022-06-24 01:16:23,902 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:16:24,985 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41742
scm1.org_1   | 2022-06-24 01:16:24,991 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59748
scm1.org_1   | 2022-06-24 01:16:25,071 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:16:25,075 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:16:25,086 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn becb59e2a5e3, UUID: f7360d38-a163-48e1-bebb-4404a3285b4b
scm1.org_1   | 2022-06-24 01:16:25,337 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:16:26,063 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55060
scm1.org_1   | 2022-06-24 01:16:26,203 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:16:26,212 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 9b9d0279a7ce, UUID: 171701ce-d9aa-46d7-a310-34f3f137a6a3
scm1.org_1   | 2022-06-24 01:16:26,531 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:16:32,102 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:55546
scm1.org_1   | 2022-06-24 01:16:32,161 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:16:32,310 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: 588e7f30-729b-46d1-8c35-e97490c01702
scm1.org_1   | 2022-06-24 01:16:32,640 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:16:34,300 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47634
scm1.org_1   | 2022-06-24 01:16:34,353 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:16:35,463 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41766
scm1.org_1   | 2022-06-24 01:16:35,537 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:36084
scm1.org_1   | 2022-06-24 01:16:35,542 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:16:35,584 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:16:35,644 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: c4fbe2fb-ec20-4bd0-af91-927ca0a414dc
scm1.org_1   | 2022-06-24 01:16:35,835 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:16:36,602 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:35126
scm1.org_1   | 2022-06-24 01:16:36,610 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:16:36,611 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: 38903242-b2d6-42bb-8ac0-98aa1ebd05fa
scm1.org_1   | 2022-06-24 01:16:36,788 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:16:37,259 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55090
scm1.org_1   | 2022-06-24 01:16:37,296 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:16:40,390 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55904
scm1.org_1   | 2022-06-24 01:16:40,560 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:16:49,658 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52708
scm1.org_1   | 2022-06-24 01:16:49,771 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:16:51,370 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40854
scm1.org_1   | 2022-06-24 01:16:51,411 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:16:53,108 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50602
scm1.org_1   | 2022-06-24 01:16:53,319 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:16:54,264 [IPC Server handler 30 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f015cc2c-a406-4fd0-a15c-edabddeafb23
scm1.org_1   | 2022-06-24 01:16:54,304 [IPC Server handler 30 on default port 9861] INFO node.SCMNodeManager: Registered Data node : f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 894868778582, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-06-24 01:16:54,468 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-06-24 01:16:54,575 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d398541e-69bc-4b5f-864d-ad98d1005d0c to datanode:f015cc2c-a406-4fd0-a15c-edabddeafb23
scm1.org_1   | 2022-06-24 01:16:54,616 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2022-06-24 01:16:55,011 [IPC Server handler 66 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f7360d38-a163-48e1-bebb-4404a3285b4b
scm1.org_1   | 2022-06-24 01:16:55,043 [IPC Server handler 66 on default port 9861] INFO node.SCMNodeManager: Registered Data node : f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 896230875764, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-06-24 01:16:55,067 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
om2_1        | 2022-06-24 01:26:06,573 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:06,575 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:06,579 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:06,585 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-0116139998, Key:ozone-test-4161686202/multipartKey. 
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:758)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:282)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-24 01:26:07,283 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:07,286 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:07,288 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:07,986 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:07,990 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:07,993 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:08,010 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:08,305 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:08,996 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:08,999 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:09,000 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:09,021 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:10,768 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:11,394 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:11,397 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:11,406 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:12,087 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:12,090 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:12,093 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:12,763 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:12,765 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:12,767 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:13,384 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:13,386 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:13,388 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,175 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,178 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,181 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,270 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,273 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,280 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,291 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,336 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,346 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,352 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,373 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,399 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,406 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,411 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:14,451 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:15,504 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:15,524 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:15,527 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:15,627 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:15,636 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:15,654 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,286 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,290 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,291 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,310 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,312 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,314 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,327 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,328 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,331 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,334 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,337 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,338 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,387 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,390 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:16,393 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:17,633 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:17,635 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:17,638 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:17,654 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:18,484 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:18,486 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:18,495 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:20,780 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:21,401 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:21,409 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:21,413 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:22,059 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:22,065 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:22,068 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:22,089 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:22,095 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:22,098 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:22,111 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
scm2.org_1   | 2022-06-24 01:26:07,020 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54198
scm2.org_1   | 2022-06-24 01:26:07,034 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:26:36,942 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57668
scm2.org_1   | 2022-06-24 01:26:36,968 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54342
scm2.org_1   | 2022-06-24 01:26:36,997 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47508
scm2.org_1   | 2022-06-24 01:26:36,999 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:26:37,028 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:26:37,029 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:27:06,891 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57792
scm2.org_1   | 2022-06-24 01:27:06,902 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54470
scm2.org_1   | 2022-06-24 01:27:06,961 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:27:06,983 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:27:06,992 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47632
scm2.org_1   | 2022-06-24 01:27:07,021 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:27:36,898 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54538
scm2.org_1   | 2022-06-24 01:27:36,899 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57864
scm2.org_1   | 2022-06-24 01:27:36,930 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:27:36,973 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47696
scm2.org_1   | 2022-06-24 01:27:36,976 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:27:36,992 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:28:06,901 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57944
scm2.org_1   | 2022-06-24 01:28:06,906 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54620
scm2.org_1   | 2022-06-24 01:28:06,947 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:28:06,981 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:28:06,996 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47784
scm2.org_1   | 2022-06-24 01:28:07,013 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:28:36,888 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58014
scm2.org_1   | 2022-06-24 01:28:36,910 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:28:36,915 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54686
scm2.org_1   | 2022-06-24 01:28:36,952 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47852
scm2.org_1   | 2022-06-24 01:28:36,962 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:28:36,983 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:29:06,902 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58118
scm2.org_1   | 2022-06-24 01:29:06,913 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54790
scm2.org_1   | 2022-06-24 01:29:06,929 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:29:06,939 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:29:06,986 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47958
scm1.org_1   | 2022-06-24 01:16:55,067 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2022-06-24 01:16:55,158 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d398541e-69bc-4b5f-864d-ad98d1005d0c, Nodes: f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:54.502Z[UTC]].
scm1.org_1   | 2022-06-24 01:16:55,192 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:16:55,529 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fae297c5-ae4f-43a4-9b48-cbad1b5e890a to datanode:f7360d38-a163-48e1-bebb-4404a3285b4b
scm1.org_1   | 2022-06-24 01:16:55,661 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fae297c5-ae4f-43a4-9b48-cbad1b5e890a, Nodes: f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:55.529Z[UTC]].
scm1.org_1   | 2022-06-24 01:16:55,676 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:16:56,864 [IPC Server handler 45 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/171701ce-d9aa-46d7-a310-34f3f137a6a3
scm1.org_1   | 2022-06-24 01:16:56,868 [IPC Server handler 45 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 897348533486, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-06-24 01:16:56,869 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-06-24 01:16:56,870 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=0eb29a31-b4b1-466e-a46a-1ca046e16e6e to datanode:171701ce-d9aa-46d7-a310-34f3f137a6a3
scm1.org_1   | 2022-06-24 01:16:56,886 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2022-06-24 01:16:56,891 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2022-06-24 01:16:56,891 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2022-06-24 01:16:56,891 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-06-24 01:16:56,891 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2022-06-24 01:16:56,891 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-06-24 01:16:56,908 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 0eb29a31-b4b1-466e-a46a-1ca046e16e6e, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:56.870Z[UTC]].
scm1.org_1   | 2022-06-24 01:16:56,914 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:16:56,966 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11 to datanode:171701ce-d9aa-46d7-a310-34f3f137a6a3
scm1.org_1   | 2022-06-24 01:16:57,032 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11 to datanode:f015cc2c-a406-4fd0-a15c-edabddeafb23
scm1.org_1   | 2022-06-24 01:16:57,033 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11 to datanode:f7360d38-a163-48e1-bebb-4404a3285b4b
scm1.org_1   | 2022-06-24 01:16:57,076 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]].
scm1.org_1   | 2022-06-24 01:16:57,084 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:16:57,105 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f58ed7fb-82ba-4210-bda3-c3af98ea0f8c to datanode:171701ce-d9aa-46d7-a310-34f3f137a6a3
scm1.org_1   | 2022-06-24 01:16:57,115 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f58ed7fb-82ba-4210-bda3-c3af98ea0f8c to datanode:f015cc2c-a406-4fd0-a15c-edabddeafb23
om2_1        | 2022-06-24 01:26:22,114 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:22,126 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:22,222 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:22,539 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:23,227 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:23,229 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:23,231 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:23,839 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:23,841 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:23,843 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:23,852 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:24,723 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:24,726 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:24,730 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:25,786 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:26,377 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:26,379 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:26,382 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:27,002 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:27,004 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:27,009 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:27,021 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:27,026 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:27,030 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:27,038 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:27,040 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:27,042 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:27,086 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:28,290 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:28,933 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:28,935 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:28,937 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:28,950 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:28,952 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:28,955 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:28,968 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:28,969 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:28,971 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:28,997 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:30,794 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:31,456 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:31,458 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:31,460 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:31,704 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45155
scm1.org_1   | 2022-06-24 01:16:57,115 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f58ed7fb-82ba-4210-bda3-c3af98ea0f8c to datanode:f7360d38-a163-48e1-bebb-4404a3285b4b
scm1.org_1   | 2022-06-24 01:16:57,149 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f58ed7fb-82ba-4210-bda3-c3af98ea0f8c, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:57.105Z[UTC]].
scm1.org_1   | 2022-06-24 01:16:57,157 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:16:57,169 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=f58ed7fb-82ba-4210-bda3-c3af98ea0f8c contains same datanodes as previous pipelines: PipelineID=68c11d03-dba9-4490-9bc6-14b5efd07c11 nodeIds: 171701ce-d9aa-46d7-a310-34f3f137a6a3, f015cc2c-a406-4fd0-a15c-edabddeafb23, f7360d38-a163-48e1-bebb-4404a3285b4b
scm1.org_1   | 2022-06-24 01:16:58,579 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fae297c5-ae4f-43a4-9b48-cbad1b5e890a, Nodes: f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:55.529Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-06-24 01:16:58,596 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37233
scm1.org_1   | 2022-06-24 01:16:58,606 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:16:58,627 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:16:58,783 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-06-24 01:16:59,491 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-06-24 01:16:59,524 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:50012
scm1.org_1   | 2022-06-24 01:16:59,606 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:17:00,683 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 0eb29a31-b4b1-466e-a46a-1ca046e16e6e, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:171701ce-d9aa-46d7-a310-34f3f137a6a3, CreationTimestamp2022-06-24T01:16:56.870Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-06-24 01:17:00,711 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:17:00,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-06-24 01:17:01,730 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-06-24 01:17:02,398 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:34522
scm1.org_1   | 2022-06-24 01:17:02,469 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:17:02,797 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59880
scm1.org_1   | 2022-06-24 01:17:02,846 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:17:04,527 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-06-24 01:17:06,223 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-06-24 01:17:06,603 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-06-24 01:17:07,453 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52782
scm1.org_1   | 2022-06-24 01:17:07,499 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:29:07,021 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:29:36,914 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54900
scm2.org_1   | 2022-06-24 01:29:36,919 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58224
scm2.org_1   | 2022-06-24 01:29:36,958 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48060
scm2.org_1   | 2022-06-24 01:29:36,959 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:29:36,971 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:29:37,009 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:30:06,871 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58300
scm2.org_1   | 2022-06-24 01:30:06,890 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:30:06,905 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54972
scm2.org_1   | 2022-06-24 01:30:06,958 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:30:06,972 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48138
scm2.org_1   | 2022-06-24 01:30:07,001 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:30:36,896 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55046
scm2.org_1   | 2022-06-24 01:30:36,916 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58370
scm2.org_1   | 2022-06-24 01:30:36,951 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:30:36,956 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:30:36,979 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48214
scm2.org_1   | 2022-06-24 01:30:36,998 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:30:37,171 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-06-24 01:31:06,889 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58446
scm2.org_1   | 2022-06-24 01:31:06,900 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55126
scm2.org_1   | 2022-06-24 01:31:06,917 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:31:06,945 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:31:06,986 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48290
scm2.org_1   | 2022-06-24 01:31:07,011 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:31:36,908 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58522
scm2.org_1   | 2022-06-24 01:31:36,933 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55196
scm2.org_1   | 2022-06-24 01:31:36,958 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48362
scm2.org_1   | 2022-06-24 01:31:36,966 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:31:36,987 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:31:37,018 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:32:06,878 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58600
scm2.org_1   | 2022-06-24 01:32:06,903 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:32:06,931 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55276
scm2.org_1   | 2022-06-24 01:32:06,970 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:32:06,982 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48440
scm2.org_1   | 2022-06-24 01:32:07,005 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:32:36,902 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55346
scm2.org_1   | 2022-06-24 01:32:36,905 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58674
scm2.org_1   | 2022-06-24 01:32:36,914 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:32:36,955 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:32:36,981 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48514
scm2.org_1   | 2022-06-24 01:32:36,993 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:33:06,879 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58752
scm2.org_1   | 2022-06-24 01:33:06,900 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55424
scm2.org_1   | 2022-06-24 01:33:06,912 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:33:06,947 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48588
scm2.org_1   | 2022-06-24 01:33:06,962 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:33:06,996 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:33:36,862 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58822
scm2.org_1   | 2022-06-24 01:33:36,898 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:33:36,913 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55498
scm2.org_1   | 2022-06-24 01:33:36,961 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:33:36,968 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48664
scm2.org_1   | 2022-06-24 01:33:36,980 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:34:06,894 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58898
scm2.org_1   | 2022-06-24 01:34:06,910 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55574
scm2.org_1   | 2022-06-24 01:34:06,960 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48740
scm2.org_1   | 2022-06-24 01:34:06,961 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:34:06,973 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:34:07,012 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:34:36,864 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58990
scm2.org_1   | 2022-06-24 01:34:36,899 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55666
scm2.org_1   | 2022-06-24 01:34:36,905 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:34:36,946 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:34:36,966 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48830
scm2.org_1   | 2022-06-24 01:34:37,008 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:35:06,880 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55740
scm2.org_1   | 2022-06-24 01:35:06,893 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59064
scm2.org_1   | 2022-06-24 01:35:06,904 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:35:06,914 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor28.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #193 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
scm1.org_1   | 2022-06-24 01:17:07,523 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-06-24 01:17:07,580 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-24 01:17:07,586 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm1.org_1   | 2022-06-24 01:17:07,608 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 2022-06-24 01:17:07,608 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm1.org_1   | 2022-06-24 01:17:07,608 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm1.org_1   | 2022-06-24 01:17:07,608 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-06-24 01:17:07,620 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm1.org_1   | 2022-06-24 01:17:07,620 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
scm1.org_1   | 2022-06-24 01:17:07,620 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
scm1.org_1   | 2022-06-24 01:17:07,620 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm1.org_1   | 2022-06-24 01:17:07,630 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
scm1.org_1   | 2022-06-24 01:17:10,790 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:55688
scm1.org_1   | 2022-06-24 01:17:10,796 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:17:11,951 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:36222
scm1.org_1   | 2022-06-24 01:17:11,965 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:17:12,105 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:35264
scm1.org_1   | 2022-06-24 01:17:12,121 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:17:14,974 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56038
scm1.org_1   | 2022-06-24 01:17:15,080 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:17:26,520 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52840
scm1.org_1   | 2022-06-24 01:17:26,574 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:17:26,580 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d398541e-69bc-4b5f-864d-ad98d1005d0c, Nodes: f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:f015cc2c-a406-4fd0-a15c-edabddeafb23, CreationTimestamp2022-06-24T01:16:54.502Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-06-24 01:17:26,638 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40583
scm1.org_1   | 2022-06-24 01:17:26,645 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:17:37,763 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41006
scm1.org_1   | 2022-06-24 01:17:37,829 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:17:38,467 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50762
scm1.org_1   | 2022-06-24 01:17:38,503 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:17:44,018 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52908
scm1.org_1   | 2022-06-24 01:17:44,033 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:17:44,040 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f58ed7fb-82ba-4210-bda3-c3af98ea0f8c, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:f015cc2c-a406-4fd0-a15c-edabddeafb23, CreationTimestamp2022-06-24T01:16:57.105Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-06-24 01:17:47,731 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:50184
scm1.org_1   | 2022-06-24 01:17:47,746 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:17:47,819 [IPC Server handler 73 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm1.org_1   | 2022-06-24 01:17:47,937 [53b8a25c-b7d5-4020-bf2c-829236b7c472@group-E1C8A5D19D86-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm1.org_1   | 2022-06-24 01:17:47,976 [IPC Server handler 73 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
scm1.org_1   | 2022-06-24 01:17:51,048 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42044
scm1.org_1   | 2022-06-24 01:17:51,056 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:17:51,268 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55354
scm1.org_1   | 2022-06-24 01:17:51,283 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:17:51,398 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47918
scm1.org_1   | 2022-06-24 01:17:51,400 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-24 01:17:51,566 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41068
scm1.org_1   | 2022-06-24 01:17:51,791 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:17:51,809 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42865
scm1.org_1   | 2022-06-24 01:17:51,859 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:17:51,932 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50822
scm1.org_1   | 2022-06-24 01:17:52,032 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:18:00,613 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:50242
scm1.org_1   | 2022-06-24 01:18:00,625 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:18:11,928 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:50276
scm1.org_1   | 2022-06-24 01:18:11,934 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | 2022-06-24 01:16:23,919 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:25,348 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:26,577 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:32,709 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:35,868 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:36,833 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:49,806 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54966
scm3.org_1   | 2022-06-24 01:16:49,843 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:16:51,220 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42880
scm3.org_1   | 2022-06-24 01:16:51,264 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:16:53,115 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36280
scm3.org_1   | 2022-06-24 01:16:53,185 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:16:53,850 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f015cc2c-a406-4fd0-a15c-edabddeafb23
scm3.org_1   | 2022-06-24 01:16:53,909 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 894868778582, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-06-24 01:16:53,968 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-06-24 01:16:54,012 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2022-06-24 01:16:54,986 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f7360d38-a163-48e1-bebb-4404a3285b4b
scm3.org_1   | 2022-06-24 01:16:54,986 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 896230875764, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-06-24 01:16:54,987 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-06-24 01:16:54,987 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm3.org_1   | 2022-06-24 01:16:55,586 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d398541e-69bc-4b5f-864d-ad98d1005d0c, Nodes: f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:54.502Z[UTC]].
scm3.org_1   | 2022-06-24 01:16:55,691 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:55,764 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fae297c5-ae4f-43a4-9b48-cbad1b5e890a, Nodes: f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:55.529Z[UTC]].
scm3.org_1   | 2022-06-24 01:16:55,770 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:56,842 [IPC Server handler 69 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/171701ce-d9aa-46d7-a310-34f3f137a6a3
scm3.org_1   | 2022-06-24 01:16:56,846 [IPC Server handler 69 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 897348533486, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-06-24 01:16:56,852 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-06-24 01:16:56,853 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm3.org_1   | 2022-06-24 01:16:56,853 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm3.org_1   | 2022-06-24 01:16:56,853 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm3.org_1   | 2022-06-24 01:16:56,854 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-06-24 01:16:56,854 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2022-06-24 01:35:06,954 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48908
scm2.org_1   | 2022-06-24 01:35:06,972 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:35:36,882 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59142
scm2.org_1   | 2022-06-24 01:35:36,971 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55818
scm2.org_1   | 2022-06-24 01:35:36,980 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48984
om2_1        | 2022-06-24 01:26:31,711 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:26:32,078 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:32,080 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:32,084 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:32,097 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:33,176 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:33,181 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:33,184 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:33,691 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:34,303 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:34,308 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:34,313 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:34,950 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:34,953 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:34,954 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:36,546 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:36,548 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:36,551 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:36,566 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:36,570 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:36,572 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:36,586 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:37,350 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:37,354 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:37,356 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:37,374 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:37,377 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:37,379 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:37,388 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:37,987 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:37,989 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:37,992 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:38,008 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:38,014 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:38,017 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:38,025 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:38,027 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:38,029 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:38,080 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:41,186 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:41,847 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:41,849 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:41,851 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:41,868 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:41,870 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
recon_1      | 2022-06-24 01:20:07,042 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:20:07,058 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:20:07,126 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:20:31,371 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:20:31,371 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:20:31,443 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-06-24 01:36:35,513 [qtp848097505-25] INFO scm.XceiverClientRatis: Could not commit index 153 on pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]] to all the nodes. Server f015cc2c-a406-4fd0-a15c-edabddeafb23 has failed. Committed by majority.
s3g_1        | 2022-06-24 01:36:35,514 [qtp848097505-25] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200057 bcsId: 153 on Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]]. Failed nodes: [f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
scm1.org_1   | 2022-06-24 01:18:21,526 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41166
scm1.org_1   | 2022-06-24 01:18:21,532 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:18:21,867 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50922
scm1.org_1   | 2022-06-24 01:18:21,888 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:18:22,102 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53054
scm1.org_1   | 2022-06-24 01:18:22,153 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:18:22,178 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:50328
scm1.org_1   | 2022-06-24 01:18:22,189 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:18:22,241 [IPC Server handler 7 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm1.org_1   | 2022-06-24 01:18:36,691 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:40168
scm1.org_1   | 2022-06-24 01:18:36,693 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:18:51,564 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41274
scm1.org_1   | 2022-06-24 01:18:51,645 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:16:56,855 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-06-24 01:16:56,923 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 0eb29a31-b4b1-466e-a46a-1ca046e16e6e, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:56.870Z[UTC]].
scm3.org_1   | 2022-06-24 01:16:56,924 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:57,095 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]].
scm3.org_1   | 2022-06-24 01:16:57,095 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:57,195 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f58ed7fb-82ba-4210-bda3-c3af98ea0f8c, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-24T01:16:57.105Z[UTC]].
scm3.org_1   | 2022-06-24 01:16:57,196 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:58,429 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fae297c5-ae4f-43a4-9b48-cbad1b5e890a, Nodes: f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:55.529Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-06-24 01:16:58,657 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:16:59,462 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-06-24 01:17:00,658 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 0eb29a31-b4b1-466e-a46a-1ca046e16e6e, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:171701ce-d9aa-46d7-a310-34f3f137a6a3, CreationTimestamp2022-06-24T01:16:56.870Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-06-24 01:17:00,773 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:17:01,620 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-06-24 01:17:04,489 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-06-24 01:17:06,176 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-06-24 01:17:06,561 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-06-24 01:17:07,301 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55032
scm3.org_1   | 2022-06-24 01:17:07,376 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:35:36,988 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:35:37,002 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:35:37,013 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:35:37,171 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-06-24 01:36:06,880 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59282
scm2.org_1   | 2022-06-24 01:36:06,896 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55958
scm2.org_1   | 2022-06-24 01:36:06,917 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:36:06,947 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:36:07,018 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49124
scm2.org_1   | 2022-06-24 01:36:07,036 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:36:36,954 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59362
scm2.org_1   | 2022-06-24 01:36:37,017 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:36:37,029 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56042
scm2.org_1   | 2022-06-24 01:36:37,033 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49204
scm2.org_1   | 2022-06-24 01:36:37,040 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-24 01:36:37,043 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-24 01:26:41,872 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:41,879 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:41,883 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:41,886 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:41,925 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:41,995 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:42,639 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:42,641 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:42,643 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:42,659 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:42,663 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:42,666 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:42,682 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:42,687 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:42,692 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:42,718 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:43,689 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:44,353 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:44,356 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:44,358 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:44,950 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:44,954 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:44,957 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:44,968 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:46,041 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:46,045 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:46,048 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:46,669 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:46,677 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:46,683 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:47,333 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:47,335 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:47,340 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:50,996 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45856
om2_1        | 2022-06-24 01:26:51,007 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:26:54,105 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:54,121 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:54,129 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7363313379 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:26:54,717 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:54,721 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:54,728 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-22045 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:26:55,328 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:55,331 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:55,333 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:56,201 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
scm1.org_1   | 2022-06-24 01:18:51,871 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51028
scm1.org_1   | 2022-06-24 01:18:51,890 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:18:52,079 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53162
scm1.org_1   | 2022-06-24 01:18:52,087 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:19:04,776 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:50472
scm1.org_1   | 2022-06-24 01:19:04,782 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:19:06,904 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51100
scm1.org_1   | 2022-06-24 01:19:07,008 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:19:07,020 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53224
scm1.org_1   | 2022-06-24 01:19:07,083 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41346
scm1.org_1   | 2022-06-24 01:19:07,123 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42101
scm1.org_1   | 2022-06-24 01:19:07,127 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:19:07,144 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:19:07,179 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:19:37,066 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41442
scm1.org_1   | 2022-06-24 01:19:37,160 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:19:37,173 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53322
scm1.org_1   | 2022-06-24 01:19:37,193 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51186
scm1.org_1   | 2022-06-24 01:19:37,206 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:19:37,273 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:20:07,064 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41546
scm1.org_1   | 2022-06-24 01:20:07,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51286
scm1.org_1   | 2022-06-24 01:20:07,085 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:20:07,098 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53420
scm1.org_1   | 2022-06-24 01:20:07,128 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:20:07,132 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:20:13,685 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-06-24 01:20:36,904 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41634
scm1.org_1   | 2022-06-24 01:20:36,920 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51378
scm1.org_1   | 2022-06-24 01:20:36,931 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53516
scm1.org_1   | 2022-06-24 01:20:36,982 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:20:37,042 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:20:37,118 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:20:39,486 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43025
scm1.org_1   | 2022-06-24 01:20:39,492 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:20:42,260 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:50804
scm1.org_1   | 2022-06-24 01:20:42,274 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:20:52,605 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:40638
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:20:36,998 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51150
recon_1      | 2022-06-24 01:20:37,057 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58728
recon_1      | 2022-06-24 01:20:37,108 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-06-24 01:17:07,383 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 68c11d03-dba9-4490-9bc6-14b5efd07c11, Nodes: 171701ce-d9aa-46d7-a310-34f3f137a6a3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f7360d38-a163-48e1-bebb-4404a3285b4b{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:f7360d38-a163-48e1-bebb-4404a3285b4b, CreationTimestamp2022-06-24T01:16:56.966Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-06-24 01:17:07,643 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-24 01:17:07,755 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm3.org_1   | 2022-06-24 01:17:07,759 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm3.org_1   | 2022-06-24 01:17:07,761 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm3.org_1   | 2022-06-24 01:17:07,765 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm3.org_1   | 2022-06-24 01:17:07,765 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-06-24 01:17:07,766 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2022-06-24 01:17:26,495 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55092
scm3.org_1   | 2022-06-24 01:17:26,565 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:17:26,571 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d398541e-69bc-4b5f-864d-ad98d1005d0c, Nodes: f015cc2c-a406-4fd0-a15c-edabddeafb23{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:f015cc2c-a406-4fd0-a15c-edabddeafb23, CreationTimestamp2022-06-24T01:16:54.502Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-06-24 01:17:37,754 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43036
scm3.org_1   | 2022-06-24 01:17:37,837 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:17:38,450 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36430
scm3.org_1   | 2022-06-24 01:17:38,497 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:17:44,037 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55158
scm3.org_1   | 2022-06-24 01:17:44,085 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:17:47,965 [b14cb6be-fcb2-48c3-9740-35fdb02d7d2d@group-E1C8A5D19D86-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm3.org_1   | 2022-06-24 01:17:51,501 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43098
scm3.org_1   | 2022-06-24 01:17:51,552 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:17:51,943 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36496
scm3.org_1   | 2022-06-24 01:17:52,029 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:18:21,528 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43200
scm3.org_1   | 2022-06-24 01:18:21,574 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:18:21,849 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36596
scm3.org_1   | 2022-06-24 01:18:21,880 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:18:22,075 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55312
scm3.org_1   | 2022-06-24 01:18:22,145 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:18:51,566 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43306
scm3.org_1   | 2022-06-24 01:18:51,631 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:18:51,859 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36704
scm3.org_1   | 2022-06-24 01:18:51,869 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:18:52,057 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55418
om2_1        | 2022-06-24 01:26:56,810 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:56,812 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:56,814 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:56,816 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:57,413 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:57,415 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:57,417 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:57,418 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:57,420 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:57,439 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:26:57,447 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:27:31,754 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44963
om2_1        | 2022-06-24 01:27:31,757 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:27:58,368 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:43123
om2_1        | 2022-06-24 01:27:58,377 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:27:58,378 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:27:58,383 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:27:58,393 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:27:58,395 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:27:58,398 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:27:58,433 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:27:58,453 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:28:31,789 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35505
om2_1        | 2022-06-24 01:28:31,808 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:28:59,624 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:44075
om2_1        | 2022-06-24 01:28:59,634 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:28:59,635 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:28:59,639 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:28:59,642 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:28:59,644 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:28:59,645 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:28:59,691 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:28:59,729 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:28:59,949 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:28:59,964 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:00,741 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:00,743 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:00,745 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:00,749 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:01,418 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:01,420 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:01,423 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:01,425 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
scm3.org_1   | 2022-06-24 01:18:52,075 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:19:06,972 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43372
scm3.org_1   | 2022-06-24 01:19:06,982 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55482
scm3.org_1   | 2022-06-24 01:19:07,000 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:19:07,030 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36766
scm3.org_1   | 2022-06-24 01:19:07,064 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:19:07,111 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:19:36,937 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36850
scm3.org_1   | 2022-06-24 01:19:36,963 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43466
scm3.org_1   | 2022-06-24 01:19:37,019 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:19:37,051 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55572
scm3.org_1   | 2022-06-24 01:19:37,105 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:19:37,182 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:20:06,955 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36962
scm3.org_1   | 2022-06-24 01:20:06,986 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43564
scm3.org_1   | 2022-06-24 01:20:07,024 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:20:07,036 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:20:07,097 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55678
scm3.org_1   | 2022-06-24 01:20:07,136 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:20:36,901 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37062
scm3.org_1   | 2022-06-24 01:20:36,974 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43668
scm3.org_1   | 2022-06-24 01:20:37,025 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55774
scm3.org_1   | 2022-06-24 01:20:37,043 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:20:37,095 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:20:37,113 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:20:55,092 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-06-24 01:21:06,889 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37168
scm3.org_1   | 2022-06-24 01:21:06,911 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43766
scm3.org_1   | 2022-06-24 01:21:06,960 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:21:06,980 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:21:07,013 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55880
scm3.org_1   | 2022-06-24 01:21:07,039 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:21:36,959 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37276
scm3.org_1   | 2022-06-24 01:21:36,981 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43882
scm3.org_1   | 2022-06-24 01:21:36,987 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:21:36,990 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55988
scm3.org_1   | 2022-06-24 01:21:37,015 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:21:37,023 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-06-24 01:20:37,124 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:20:37,129 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44720
recon_1      | 2022-06-24 01:20:37,197 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:20:39,381 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 62 milliseconds to process 0 existing database records.
recon_1      | 2022-06-24 01:20:39,406 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 26 milliseconds for processing 2 containers.
recon_1      | 2022-06-24 01:20:39,508 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-06-24 01:20:39,521 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 85 milliseconds.
recon_1      | 2022-06-24 01:21:06,888 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58832
recon_1      | 2022-06-24 01:21:06,889 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51266
recon_1      | 2022-06-24 01:21:06,926 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:21:06,971 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:21:07,004 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44830
recon_1      | 2022-06-24 01:21:07,031 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:21:31,449 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:21:31,450 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:21:31,510 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:21:36,895 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51364
recon_1      | 2022-06-24 01:21:36,896 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58934
recon_1      | 2022-06-24 01:21:36,909 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:21:36,918 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:21:36,938 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44932
recon_1      | 2022-06-24 01:21:36,947 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:22:06,870 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59056
recon_1      | 2022-06-24 01:22:06,898 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:22:06,906 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51492
recon_1      | 2022-06-24 01:22:06,938 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:22:06,951 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45052
scm1.org_1   | 2022-06-24 01:20:52,614 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:21:04,000 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:50870
scm1.org_1   | 2022-06-24 01:21:04,007 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:21:06,869 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41744
scm1.org_1   | 2022-06-24 01:21:06,891 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51486
scm1.org_1   | 2022-06-24 01:21:06,911 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:21:06,971 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:21:06,999 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53622
scm1.org_1   | 2022-06-24 01:21:07,033 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:21:12,084 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:40712
scm1.org_1   | 2022-06-24 01:21:12,090 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:21:36,979 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41846
scm1.org_1   | 2022-06-24 01:21:36,981 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51590
scm1.org_1   | 2022-06-24 01:21:36,996 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:21:37,026 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:21:37,034 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53728
scm1.org_1   | 2022-06-24 01:21:37,045 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:22:06,873 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51710
scm1.org_1   | 2022-06-24 01:22:06,946 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41972
scm1.org_1   | 2022-06-24 01:22:06,958 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:22:06,990 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53848
scm1.org_1   | 2022-06-24 01:22:06,995 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:22:07,016 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:22:22,148 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:51168
scm1.org_1   | 2022-06-24 01:22:22,170 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:22:36,900 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51816
scm1.org_1   | 2022-06-24 01:22:36,961 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:22:36,982 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42084
scm1.org_1   | 2022-06-24 01:22:37,016 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:22:37,029 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53960
scm1.org_1   | 2022-06-24 01:22:37,053 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:23:06,952 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51936
scm1.org_1   | 2022-06-24 01:23:06,971 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:23:07,033 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42188
scm1.org_1   | 2022-06-24 01:23:07,042 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54072
scm1.org_1   | 2022-06-24 01:23:07,052 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:23:07,052 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:23:08,514 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:51360
scm1.org_1   | 2022-06-24 01:23:08,521 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:23:17,495 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:41178
scm1.org_1   | 2022-06-24 01:23:17,502 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:23:36,903 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52040
scm1.org_1   | 2022-06-24 01:23:36,961 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42300
scm1.org_1   | 2022-06-24 01:23:36,982 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54174
scm1.org_1   | 2022-06-24 01:23:37,033 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:23:37,037 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:23:37,092 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:24:06,929 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52326
scm1.org_1   | 2022-06-24 01:24:06,977 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42586
scm1.org_1   | 2022-06-24 01:24:06,997 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54460
scm1.org_1   | 2022-06-24 01:24:07,026 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:24:07,048 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:24:07,059 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:24:13,897 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:51754
scm1.org_1   | 2022-06-24 01:24:13,904 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:24:33,395 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:51814
scm1.org_1   | 2022-06-24 01:24:33,400 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:24:36,881 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52434
scm1.org_1   | 2022-06-24 01:24:36,895 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:24:36,908 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42694
scm1.org_1   | 2022-06-24 01:24:36,955 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:24:36,981 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54568
scm1.org_1   | 2022-06-24 01:24:37,007 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:24:45,614 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:41670
scm1.org_1   | 2022-06-24 01:24:45,621 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:25:06,901 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42802
scm1.org_1   | 2022-06-24 01:25:06,984 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54682
scm1.org_1   | 2022-06-24 01:25:06,997 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:25:07,023 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52546
scm1.org_1   | 2022-06-24 01:25:07,037 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:25:07,059 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:25:13,688 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 3 milliseconds for processing 2 containers.
scm1.org_1   | 2022-06-24 01:25:22,125 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52006
scm1.org_1   | 2022-06-24 01:25:22,127 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:25:36,938 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42926
scm1.org_1   | 2022-06-24 01:25:36,952 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52658
scm1.org_1   | 2022-06-24 01:25:36,985 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54802
scm1.org_1   | 2022-06-24 01:25:36,996 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:25:37,017 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:25:37,022 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:25:37,665 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52074
scm1.org_1   | 2022-06-24 01:25:37,674 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:25:39,537 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43709
scm1.org_1   | 2022-06-24 01:25:39,539 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:25:40,304 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:41894
scm1.org_1   | 2022-06-24 01:25:40,308 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:26:03,897 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:41994
scm1.org_1   | 2022-06-24 01:26:03,899 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:26:06,985 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52818
scm1.org_1   | 2022-06-24 01:26:06,995 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43094
scm1.org_1   | 2022-06-24 01:26:07,003 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54954
scm1.org_1   | 2022-06-24 01:26:07,010 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:26:07,014 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:26:07,023 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:26:16,365 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42080
scm1.org_1   | 2022-06-24 01:26:16,370 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:26:36,955 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43224
scm1.org_1   | 2022-06-24 01:26:36,990 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:26:36,997 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52966
scm1.org_1   | 2022-06-24 01:26:37,015 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:26:37,028 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55102
scm1.org_1   | 2022-06-24 01:26:37,049 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:26:55,342 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52450
scm1.org_1   | 2022-06-24 01:26:55,344 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:26:57,432 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42266
scm1.org_1   | 2022-06-24 01:26:57,433 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:27:06,890 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53088
scm1.org_1   | 2022-06-24 01:27:06,911 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43354
scm1.org_1   | 2022-06-24 01:27:06,956 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55226
scm1.org_1   | 2022-06-24 01:27:06,965 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:27:06,972 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:27:07,005 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:27:22,144 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52526
scm1.org_1   | 2022-06-24 01:27:22,148 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:27:36,907 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53156
scm1.org_1   | 2022-06-24 01:27:36,918 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43412
scm1.org_1   | 2022-06-24 01:27:36,938 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:27:36,969 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55298
scm1.org_1   | 2022-06-24 01:27:36,979 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:27:36,992 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:27:58,417 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42416
scm1.org_1   | 2022-06-24 01:27:58,419 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:27:58,465 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52618
scm1.org_1   | 2022-06-24 01:27:58,478 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:28:06,903 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53242
scm1.org_1   | 2022-06-24 01:28:06,915 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43504
scm1.org_1   | 2022-06-24 01:28:06,944 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:28:06,977 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55384
scm1.org_1   | 2022-06-24 01:28:06,983 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:28:07,005 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:28:36,861 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53308
scm1.org_1   | 2022-06-24 01:28:36,882 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:28:36,936 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43570
scm1.org_1   | 2022-06-24 01:28:36,966 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:28:36,991 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55446
scm1.org_1   | 2022-06-24 01:28:36,996 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:28:59,665 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42568
scm1.org_1   | 2022-06-24 01:28:59,673 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:28:59,739 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52770
scm1.org_1   | 2022-06-24 01:28:59,748 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:29:06,889 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53414
scm1.org_1   | 2022-06-24 01:29:06,916 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43674
scm1.org_1   | 2022-06-24 01:29:06,925 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:29:06,980 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:29:06,994 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55550
scm1.org_1   | 2022-06-24 01:29:07,024 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:29:16,343 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:52852
scm1.org_1   | 2022-06-24 01:29:16,350 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:29:17,891 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42660
scm1.org_1   | 2022-06-24 01:29:17,894 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:29:36,883 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53520
recon_1      | 2022-06-24 01:22:07,013 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:22:31,511 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:22:31,511 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:22:31,556 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:22:36,874 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59162
recon_1      | 2022-06-24 01:22:36,949 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51594
recon_1      | 2022-06-24 01:22:36,970 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:22:36,980 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:22:37,009 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45156
recon_1      | 2022-06-24 01:22:37,048 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:23:06,871 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59278
recon_1      | 2022-06-24 01:23:06,888 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51716
recon_1      | 2022-06-24 01:23:06,940 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:23:06,961 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45280
recon_1      | 2022-06-24 01:23:06,974 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:23:07,028 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:23:31,562 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:23:31,562 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:23:31,596 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
scm1.org_1   | 2022-06-24 01:29:36,917 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:29:36,988 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55656
scm1.org_1   | 2022-06-24 01:29:36,993 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43786
scm1.org_1   | 2022-06-24 01:29:37,001 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:29:37,012 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:29:58,012 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42776
scm1.org_1   | 2022-06-24 01:29:58,020 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:30:06,903 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53596
scm1.org_1   | 2022-06-24 01:30:06,906 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43860
scm1.org_1   | 2022-06-24 01:30:06,927 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:30:06,944 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55740
scm1.org_1   | 2022-06-24 01:30:06,955 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:30:06,993 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:30:13,689 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm1.org_1   | 2022-06-24 01:30:22,148 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53034
scm1.org_1   | 2022-06-24 01:30:22,151 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:30:36,894 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43930
scm1.org_1   | 2022-06-24 01:30:36,917 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53668
scm1.org_1   | 2022-06-24 01:30:36,939 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55806
scm1.org_1   | 2022-06-24 01:30:36,951 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:30:36,959 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:30:36,994 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:30:39,558 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44311
scm1.org_1   | 2022-06-24 01:30:39,564 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:30:58,990 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:42926
scm1.org_1   | 2022-06-24 01:30:58,996 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:31:06,878 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44008
scm1.org_1   | 2022-06-24 01:31:06,894 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53748
scm1.org_1   | 2022-06-24 01:31:06,920 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:31:06,942 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:31:06,963 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55884
scm1.org_1   | 2022-06-24 01:31:06,993 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:31:22,142 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53184
scm1.org_1   | 2022-06-24 01:31:22,154 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:31:36,883 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53820
scm1.org_1   | 2022-06-24 01:31:36,972 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55962
scm1.org_1   | 2022-06-24 01:31:36,985 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44086
scm1.org_1   | 2022-06-24 01:31:37,013 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:23:36,900 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51816
recon_1      | 2022-06-24 01:23:36,981 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:23:36,997 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45378
recon_1      | 2022-06-24 01:23:37,023 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:23:37,060 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59382
recon_1      | 2022-06-24 01:23:37,096 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:24:06,884 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59664
recon_1      | 2022-06-24 01:24:06,981 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52104
recon_1      | 2022-06-24 01:24:06,989 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:24:07,010 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45668
recon_1      | 2022-06-24 01:24:07,042 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:24:07,068 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:24:31,599 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:24:31,599 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:24:31,624 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-24 01:29:01,427 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:01,435 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:01,442 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:01,549 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:01,580 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:02,337 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:02,339 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:02,341 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:02,344 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:02,987 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:02,989 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:03,718 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:03,721 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:03,725 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:03,727 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:04,425 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:04,428 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:05,114 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:05,120 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:05,122 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:05,124 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:05,125 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:11,261 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46256
om2_1        | 2022-06-24 01:29:11,271 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:29:15,571 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:36373
om2_1        | 2022-06-24 01:29:15,575 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:29:15,575 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:15,580 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:15,589 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5999345803 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:29:16,324 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:16,326 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:16,329 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:16,517 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:17,190 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:17,193 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:17,194 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:17,197 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:17,877 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:17,879 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:17,881 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:17,902 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:18,637 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:18,639 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:18,642 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
scm3.org_1   | 2022-06-24 01:22:06,910 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37384
scm3.org_1   | 2022-06-24 01:22:06,928 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44002
scm3.org_1   | 2022-06-24 01:22:06,948 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:22:06,981 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:22:06,986 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56106
scm3.org_1   | 2022-06-24 01:22:07,018 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:22:36,867 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37492
scm3.org_1   | 2022-06-24 01:22:36,954 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:22:36,957 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44106
scm3.org_1   | 2022-06-24 01:22:36,997 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:22:37,007 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56210
scm3.org_1   | 2022-06-24 01:22:37,051 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:23:06,894 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44228
scm3.org_1   | 2022-06-24 01:23:06,953 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37612
scm3.org_1   | 2022-06-24 01:23:06,966 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:23:06,992 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56328
scm3.org_1   | 2022-06-24 01:23:07,001 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:23:07,023 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:23:36,959 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44326
scm3.org_1   | 2022-06-24 01:23:36,976 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56434
scm3.org_1   | 2022-06-24 01:23:37,014 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:23:37,018 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:23:37,044 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37710
scm3.org_1   | 2022-06-24 01:23:37,054 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:24:06,916 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38000
scm3.org_1   | 2022-06-24 01:24:06,964 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44612
scm3.org_1   | 2022-06-24 01:24:06,996 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56718
scm3.org_1   | 2022-06-24 01:24:07,017 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:24:07,039 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:24:07,047 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:24:36,899 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38104
scm3.org_1   | 2022-06-24 01:24:36,902 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:24:36,945 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44720
scm3.org_1   | 2022-06-24 01:24:36,966 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:24:36,975 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56828
scm3.org_1   | 2022-06-24 01:24:37,009 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:25:06,893 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44834
scm3.org_1   | 2022-06-24 01:25:06,975 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56942
scm1.org_1   | 2022-06-24 01:31:37,019 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:31:37,032 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:32:06,882 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53902
scm1.org_1   | 2022-06-24 01:32:06,914 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44158
scm1.org_1   | 2022-06-24 01:32:06,915 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:32:06,964 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56034
scm1.org_1   | 2022-06-24 01:32:06,970 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:32:06,999 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:32:28,885 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53344
scm1.org_1   | 2022-06-24 01:32:28,893 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:32:36,880 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44230
scm1.org_1   | 2022-06-24 01:32:36,900 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:32:36,911 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53968
scm1.org_1   | 2022-06-24 01:32:36,948 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56106
scm1.org_1   | 2022-06-24 01:32:36,961 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:32:36,973 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:33:06,904 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54046
scm1.org_1   | 2022-06-24 01:33:06,912 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:33:06,936 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44314
scm1.org_1   | 2022-06-24 01:33:06,954 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56184
scm1.org_1   | 2022-06-24 01:33:06,957 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:33:06,995 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:33:35,393 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53504
scm1.org_1   | 2022-06-24 01:33:35,395 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:33:36,866 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54120
scm1.org_1   | 2022-06-24 01:33:36,900 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:33:36,908 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44380
scm1.org_1   | 2022-06-24 01:33:36,952 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56260
scm1.org_1   | 2022-06-24 01:33:36,953 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:33:36,973 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:34:06,903 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44456
scm1.org_1   | 2022-06-24 01:34:06,912 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54194
scm1.org_1   | 2022-06-24 01:34:06,948 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:34:06,962 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56332
scm1.org_1   | 2022-06-24 01:34:06,975 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:34:07,005 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:34:22,148 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53624
scm1.org_1   | 2022-06-24 01:34:22,157 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om2_1        | 2022-06-24 01:29:19,273 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:19,276 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:19,278 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:20,031 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:20,034 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:20,036 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:20,717 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:20,720 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:20,722 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:21,472 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:21,475 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:21,478 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:21,593 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:22,296 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:22,299 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:22,301 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:22,303 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:23,011 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:23,013 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:23,015 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:23,660 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:23,662 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:23,664 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:23,670 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:24,277 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:24,279 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:24,280 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:24,288 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:24,897 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:24,899 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:24,901 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:31,848 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38329
om2_1        | 2022-06-24 01:29:31,851 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:29:57,953 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:33669
om2_1        | 2022-06-24 01:29:57,956 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:29:57,959 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:29:57,975 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:30:25,801 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:45095
om2_1        | 2022-06-24 01:30:25,808 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:30:25,809 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:30:25,814 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:30:25,835 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:30:31,877 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40047
om2_1        | 2022-06-24 01:30:31,887 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:24:36,862 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59776
recon_1      | 2022-06-24 01:24:36,872 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:24:36,907 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52210
recon_1      | 2022-06-24 01:24:36,955 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:24:36,972 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45772
recon_1      | 2022-06-24 01:24:36,997 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:25:06,894 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52324
recon_1      | 2022-06-24 01:25:06,913 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59884
recon_1      | 2022-06-24 01:25:06,977 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45886
recon_1      | 2022-06-24 01:25:06,992 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:25:07,006 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:25:07,030 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:25:31,634 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:25:31,635 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:25:31,677 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
scm3.org_1   | 2022-06-24 01:25:06,991 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:25:07,037 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:25:07,046 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38214
scm3.org_1   | 2022-06-24 01:25:07,065 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:25:36,913 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38332
scm3.org_1   | 2022-06-24 01:25:36,917 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44948
scm3.org_1   | 2022-06-24 01:25:36,933 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:25:36,961 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:25:36,972 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57050
scm3.org_1   | 2022-06-24 01:25:36,986 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:25:55,092 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-06-24 01:26:06,893 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45106
scm3.org_1   | 2022-06-24 01:26:06,944 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38494
scm3.org_1   | 2022-06-24 01:26:06,949 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57210
scm3.org_1   | 2022-06-24 01:26:06,968 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:26:06,979 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:26:06,989 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:26:36,886 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38634
scm3.org_1   | 2022-06-24 01:26:36,937 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:26:36,959 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45254
scm3.org_1   | 2022-06-24 01:26:36,968 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57358
scm3.org_1   | 2022-06-24 01:26:37,000 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:26:37,055 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:27:06,897 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38766
scm3.org_1   | 2022-06-24 01:27:06,907 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45378
scm3.org_1   | 2022-06-24 01:27:06,939 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:27:06,955 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57486
scm3.org_1   | 2022-06-24 01:27:06,961 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:27:07,016 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:27:36,914 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38834
scm3.org_1   | 2022-06-24 01:27:36,922 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45450
scm3.org_1   | 2022-06-24 01:27:36,951 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:27:36,977 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:27:36,984 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57554
scm3.org_1   | 2022-06-24 01:27:36,996 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:28:06,895 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38918
scm3.org_1   | 2022-06-24 01:28:06,916 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45538
scm3.org_1   | 2022-06-24 01:28:06,939 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57640
scm3.org_1   | 2022-06-24 01:28:06,950 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:28:06,973 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:28:07,005 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:28:36,890 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38982
scm3.org_1   | 2022-06-24 01:28:36,916 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:28:36,956 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57702
scm3.org_1   | 2022-06-24 01:28:36,961 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45604
scm3.org_1   | 2022-06-24 01:28:36,972 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:28:36,984 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:29:06,897 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45706
scm3.org_1   | 2022-06-24 01:29:06,907 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39084
scm3.org_1   | 2022-06-24 01:29:06,917 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:29:06,956 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:29:06,963 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57806
scm3.org_1   | 2022-06-24 01:29:07,001 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:29:36,942 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39194
scm3.org_1   | 2022-06-24 01:29:36,963 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45810
scm3.org_1   | 2022-06-24 01:29:36,964 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:29:36,977 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:29:36,987 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57914
scm3.org_1   | 2022-06-24 01:29:37,026 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:30:06,876 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39274
scm3.org_1   | 2022-06-24 01:30:06,899 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45890
scm3.org_1   | 2022-06-24 01:30:06,925 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:30:06,963 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:30:06,977 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57988
scm3.org_1   | 2022-06-24 01:30:06,997 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:30:36,895 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45962
scm3.org_1   | 2022-06-24 01:30:36,903 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39344
scm3.org_1   | 2022-06-24 01:30:36,939 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:30:36,959 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:30:36,987 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58064
scm3.org_1   | 2022-06-24 01:30:37,009 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:30:55,093 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-06-24 01:31:06,875 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46038
scm3.org_1   | 2022-06-24 01:31:06,925 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39422
scm3.org_1   | 2022-06-24 01:31:06,944 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:31:06,948 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:25:36,881 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52438
recon_1      | 2022-06-24 01:25:36,899 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60002
recon_1      | 2022-06-24 01:25:36,901 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:25:36,935 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:25:36,959 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46000
recon_1      | 2022-06-24 01:25:36,966 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:25:39,407 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1      | 2022-06-24 01:25:39,411 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds for processing 2 containers.
recon_1      | 2022-06-24 01:25:39,543 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-06-24 01:25:39,546 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 17 milliseconds.
recon_1      | 2022-06-24 01:26:06,892 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52594
om2_1        | 2022-06-24 01:30:58,920 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:43367
om2_1        | 2022-06-24 01:30:58,923 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:30:58,924 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:30:58,953 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:31:26,424 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:43827
om2_1        | 2022-06-24 01:31:26,430 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:31:26,431 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:31:26,435 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:31:26,448 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:31:31,915 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40169
om2_1        | 2022-06-24 01:31:31,917 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:32:25,925 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:37419
om2_1        | 2022-06-24 01:32:25,928 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:32:25,929 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:32:28,843 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:32:28,847 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:32:28,864 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:32:31,950 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39351
om2_1        | 2022-06-24 01:32:31,963 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:33:26,920 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:37999
om2_1        | 2022-06-24 01:33:26,927 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:33:26,928 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:33:31,991 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41923
om2_1        | 2022-06-24 01:33:31,999 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:33:35,355 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:33:35,357 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:33:35,368 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:25,036 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:44759
om2_1        | 2022-06-24 01:34:25,040 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:34:25,041 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:25,045 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:26,903 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:29,752 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47070
om2_1        | 2022-06-24 01:34:29,759 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:34:32,020 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45891
om2_1        | 2022-06-24 01:34:32,023 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:34:33,110 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:33,130 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:33,137 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5973959837 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:34:33,777 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:33,780 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
recon_1      | 2022-06-24 01:26:06,899 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:26:06,935 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60168
recon_1      | 2022-06-24 01:26:06,952 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46160
recon_1      | 2022-06-24 01:26:06,974 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:26:06,986 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:26:31,678 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:26:31,679 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:26:31,729 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:26:36,942 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60304
scm3.org_1   | 2022-06-24 01:31:06,995 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58144
scm3.org_1   | 2022-06-24 01:31:07,015 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:31:36,914 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39490
scm3.org_1   | 2022-06-24 01:31:36,975 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46112
scm3.org_1   | 2022-06-24 01:31:36,977 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58210
scm3.org_1   | 2022-06-24 01:31:36,993 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:31:37,000 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:31:37,018 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:32:06,916 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46192
scm3.org_1   | 2022-06-24 01:32:06,928 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39568
scm3.org_1   | 2022-06-24 01:32:06,969 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:32:06,975 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:32:06,992 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58294
scm3.org_1   | 2022-06-24 01:32:07,005 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:32:36,876 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46264
scm3.org_1   | 2022-06-24 01:32:36,895 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:32:36,910 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39642
scm3.org_1   | 2022-06-24 01:32:36,956 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:32:36,970 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58364
scm3.org_1   | 2022-06-24 01:32:36,989 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:33:06,908 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39720
scm3.org_1   | 2022-06-24 01:33:06,916 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:33:06,933 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46340
scm3.org_1   | 2022-06-24 01:33:06,957 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:33:06,960 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58444
scm3.org_1   | 2022-06-24 01:33:06,995 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:33:36,908 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39790
scm3.org_1   | 2022-06-24 01:33:36,917 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:33:36,935 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46410
scm3.org_1   | 2022-06-24 01:33:36,954 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:33:36,968 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58510
scm3.org_1   | 2022-06-24 01:33:36,979 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:34:06,876 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39872
scm3.org_1   | 2022-06-24 01:34:06,895 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46486
scm3.org_1   | 2022-06-24 01:34:06,946 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:34:06,949 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:34:06,953 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58590
scm1.org_1   | 2022-06-24 01:34:33,813 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53660
scm1.org_1   | 2022-06-24 01:34:33,819 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:34:36,873 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54288
scm1.org_1   | 2022-06-24 01:34:36,903 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44556
scm1.org_1   | 2022-06-24 01:34:36,917 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:34:36,944 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:34:36,964 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56426
scm1.org_1   | 2022-06-24 01:34:36,992 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:35:06,879 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44630
scm1.org_1   | 2022-06-24 01:35:06,904 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:35:06,920 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54368
scm1.org_1   | 2022-06-24 01:35:06,945 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:35:06,977 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56502
scm1.org_1   | 2022-06-24 01:35:06,985 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:35:13,689 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm1.org_1   | 2022-06-24 01:35:22,149 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53794
scm1.org_1   | 2022-06-24 01:35:22,154 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:35:36,200 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53824
scm1.org_1   | 2022-06-24 01:35:36,207 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:35:36,916 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54438
scm1.org_1   | 2022-06-24 01:35:36,973 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44700
scm1.org_1   | 2022-06-24 01:35:36,980 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:35:37,007 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:35:37,009 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56578
scm1.org_1   | 2022-06-24 01:35:37,031 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:35:39,587 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46639
scm1.org_1   | 2022-06-24 01:35:39,589 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:35:50,672 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53894
scm1.org_1   | 2022-06-24 01:35:50,674 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:35:53,991 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43716
scm1.org_1   | 2022-06-24 01:35:53,993 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-24 01:36:06,894 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54580
scm1.org_1   | 2022-06-24 01:36:06,922 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:36:06,957 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44842
scm1.org_1   | 2022-06-24 01:36:06,958 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56718
scm1.org_1   | 2022-06-24 01:36:06,963 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:36:07,001 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:36:22,159 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:54022
recon_1      | 2022-06-24 01:26:36,946 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52744
recon_1      | 2022-06-24 01:26:36,979 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:26:36,990 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46302
recon_1      | 2022-06-24 01:26:37,023 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:26:37,057 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:27:06,892 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60430
recon_1      | 2022-06-24 01:27:06,900 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52866
recon_1      | 2022-06-24 01:27:06,954 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46430
recon_1      | 2022-06-24 01:27:06,963 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:27:06,973 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:27:06,995 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:27:31,737 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:27:31,737 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:27:31,770 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
scm1.org_1   | 2022-06-24 01:36:22,173 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-24 01:36:36,885 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54664
scm1.org_1   | 2022-06-24 01:36:36,903 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44922
scm1.org_1   | 2022-06-24 01:36:36,905 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:36:36,936 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56798
scm1.org_1   | 2022-06-24 01:36:36,951 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-24 01:36:36,956 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:34:07,004 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:34:36,877 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39966
scm3.org_1   | 2022-06-24 01:34:36,904 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46578
scm3.org_1   | 2022-06-24 01:34:36,918 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:34:36,944 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:34:36,992 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58686
scm3.org_1   | 2022-06-24 01:34:37,012 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:35:06,892 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40042
scm3.org_1   | 2022-06-24 01:35:06,915 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:35:06,919 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46656
scm3.org_1   | 2022-06-24 01:35:06,943 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58758
scm3.org_1   | 2022-06-24 01:35:06,961 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:35:06,973 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:35:36,881 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40116
scm3.org_1   | 2022-06-24 01:35:36,961 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46730
scm3.org_1   | 2022-06-24 01:35:36,965 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58834
scm3.org_1   | 2022-06-24 01:35:36,975 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:35:36,989 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:35:37,018 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:35:55,093 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-06-24 01:36:06,882 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40256
scm3.org_1   | 2022-06-24 01:36:06,922 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:36:06,939 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46874
scm3.org_1   | 2022-06-24 01:36:06,953 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:36:06,960 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58978
scm3.org_1   | 2022-06-24 01:36:06,998 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:36:36,899 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40338
scm3.org_1   | 2022-06-24 01:36:36,904 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46954
scm3.org_1   | 2022-06-24 01:36:36,918 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:36:36,977 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59058
scm3.org_1   | 2022-06-24 01:36:36,991 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-24 01:36:36,998 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:27:36,905 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52928
recon_1      | 2022-06-24 01:27:36,918 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60506
recon_1      | 2022-06-24 01:27:36,933 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:27:36,972 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46498
recon_1      | 2022-06-24 01:27:36,976 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:27:36,999 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:28:06,900 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60588
recon_1      | 2022-06-24 01:28:06,913 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53022
recon_1      | 2022-06-24 01:28:06,944 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:28:06,973 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:28:06,978 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46582
recon_1      | 2022-06-24 01:28:07,010 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:28:31,771 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:28:31,771 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:28:31,825 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
om2_1        | 2022-06-24 01:34:33,783 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:33,981 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:34,733 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:34,735 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:34,738 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:34,805 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:35,628 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:35,630 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:34:35,638 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:29,916 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:42137
om2_1        | 2022-06-24 01:35:29,925 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:35:29,926 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:32,052 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39733
om2_1        | 2022-06-24 01:35:32,060 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:35:36,154 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:36,160 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:36,172 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:36,324 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:37,228 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:37,230 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:37,231 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:37,235 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:37,935 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:37,938 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:37,939 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:37,953 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:37,977 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:37,998 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-5973959837, Key:ozone-test-6031795731/multidelete/key=value/f4.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-24 01:35:38,750 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:38,752 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:38,754 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:38,756 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:45,237 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47298
om2_1        | 2022-06-24 01:35:45,247 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:35:49,946 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:44151
om2_1        | 2022-06-24 01:35:49,952 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:35:49,953 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:28:36,874 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60652
recon_1      | 2022-06-24 01:28:36,903 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:28:36,924 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53088
recon_1      | 2022-06-24 01:28:36,935 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46654
recon_1      | 2022-06-24 01:28:36,964 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:28:36,983 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:29:06,894 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53194
recon_1      | 2022-06-24 01:29:06,906 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60756
recon_1      | 2022-06-24 01:29:06,909 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:29:06,953 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46756
recon_1      | 2022-06-24 01:29:06,954 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:29:07,012 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:29:31,827 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:29:31,828 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:29:31,862 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
om2_1        | 2022-06-24 01:35:49,956 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:49,967 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0161962971 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:35:50,648 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:50,651 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:50,653 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:50,961 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:51,737 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:51,739 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:51,741 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:51,743 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:52,435 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:52,437 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:52,439 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:52,471 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:53,256 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:53,258 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:53,259 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:53,263 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:53,976 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:53,978 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:53,980 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:53,999 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:54,858 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:54,860 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:54,861 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:54,869 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:55,616 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:55,618 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:55,620 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:55,629 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:56,414 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:56,416 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:56,418 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:56,428 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:57,193 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:57,195 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:57,197 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:57,876 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:57,878 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:57,879 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:57,886 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:58,643 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:58,645 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:58,647 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:58,653 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:59,496 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:59,503 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:59,506 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:35:59,516 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:00,318 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:00,320 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:00,322 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:00,330 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:01,102 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:01,104 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:01,106 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:01,114 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:01,854 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:01,855 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:01,858 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:01,866 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:02,600 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:29:36,864 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60866
recon_1      | 2022-06-24 01:29:36,874 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:29:36,894 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53298
recon_1      | 2022-06-24 01:29:36,952 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46864
recon_1      | 2022-06-24 01:29:36,974 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:29:37,021 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:30:06,873 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60938
recon_1      | 2022-06-24 01:30:06,901 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53378
recon_1      | 2022-06-24 01:30:06,916 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:30:06,957 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:30:06,978 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46940
recon_1      | 2022-06-24 01:30:06,996 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:30:31,864 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:30:31,864 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:30:31,899 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
om2_1        | 2022-06-24 01:36:02,602 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:02,604 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:02,611 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:03,288 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:03,290 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:03,291 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:03,299 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:03,939 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:03,941 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:03,942 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:04,547 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:04,552 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:04,554 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:05,309 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:05,311 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:05,314 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:11,611 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47424
om2_1        | 2022-06-24 01:36:11,621 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:36:15,741 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:35767
om2_1        | 2022-06-24 01:36:15,746 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:36:15,747 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:15,774 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
om2_1        | 2022-06-24 01:36:15,780 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7609276061 of layout LEGACY in volume: s3v
om2_1        | 2022-06-24 01:36:32,082 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39741
om2_1        | 2022-06-24 01:36:32,089 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-24 01:36:35,928 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:33861
om2_1        | 2022-06-24 01:36:35,944 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:30:36,850 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:32782
recon_1      | 2022-06-24 01:30:36,895 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53450
recon_1      | 2022-06-24 01:30:36,914 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:30:36,949 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:30:36,956 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47010
recon_1      | 2022-06-24 01:30:36,992 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:30:39,412 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds to process 0 existing database records.
recon_1      | 2022-06-24 01:30:39,417 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 4 milliseconds for processing 2 containers.
recon_1      | 2022-06-24 01:30:39,567 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-06-24 01:30:39,572 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 22 milliseconds.
recon_1      | 2022-06-24 01:31:06,858 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:32860
recon_1      | 2022-06-24 01:31:06,876 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53528
recon_1      | 2022-06-24 01:31:06,891 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:31:06,916 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:31:06,970 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47088
recon_1      | 2022-06-24 01:31:07,003 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:31:31,901 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:31:31,901 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
om2_1        | 2022-06-24 01:36:35,945 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: d920e98258bd62bbc38744e84593ce222b766530a4463f33f8390b78088a072c
recon_1      | 2022-06-24 01:31:31,936 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:31:36,877 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:32932
recon_1      | 2022-06-24 01:31:36,920 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53594
recon_1      | 2022-06-24 01:31:36,959 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47160
recon_1      | 2022-06-24 01:31:36,974 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:31:36,986 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:31:36,991 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:32:06,855 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33006
recon_1      | 2022-06-24 01:32:06,926 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53674
recon_1      | 2022-06-24 01:32:06,932 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:32:06,971 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:32:06,974 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47238
recon_1      | 2022-06-24 01:32:07,014 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:32:31,937 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:32:31,937 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:32:31,978 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:32:36,848 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33080
recon_1      | 2022-06-24 01:32:36,878 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53748
recon_1      | 2022-06-24 01:32:36,886 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:32:36,900 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:32:36,944 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47310
recon_1      | 2022-06-24 01:32:36,981 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:33:06,870 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33158
recon_1      | 2022-06-24 01:33:06,899 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53822
recon_1      | 2022-06-24 01:33:06,910 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:33:06,948 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47390
recon_1      | 2022-06-24 01:33:06,957 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:33:07,001 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:33:31,979 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:33:31,979 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:33:32,010 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor55.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:33:36,861 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33232
recon_1      | 2022-06-24 01:33:36,898 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:33:36,909 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53900
recon_1      | 2022-06-24 01:33:36,942 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47460
recon_1      | 2022-06-24 01:33:36,945 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:33:36,968 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:34:06,891 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33304
recon_1      | 2022-06-24 01:34:06,926 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53976
recon_1      | 2022-06-24 01:34:06,946 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47536
recon_1      | 2022-06-24 01:34:06,968 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:34:06,971 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:34:07,000 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:34:32,010 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:34:32,011 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:34:32,039 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor55.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:34:36,874 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33400
recon_1      | 2022-06-24 01:34:36,898 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54068
recon_1      | 2022-06-24 01:34:36,917 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:34:36,941 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:34:36,970 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47632
recon_1      | 2022-06-24 01:34:37,000 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:35:06,851 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33474
recon_1      | 2022-06-24 01:35:06,888 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:35:06,893 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54146
recon_1      | 2022-06-24 01:35:06,958 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:35:06,981 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47710
recon_1      | 2022-06-24 01:35:07,004 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:35:32,040 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:35:32,040 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:35:32,071 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor55.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:35:36,855 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33548
recon_1      | 2022-06-24 01:35:36,873 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:35:36,904 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54220
recon_1      | 2022-06-24 01:35:36,947 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:35:36,961 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47778
recon_1      | 2022-06-24 01:35:37,009 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:35:39,419 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds to process 0 existing database records.
recon_1      | 2022-06-24 01:35:39,422 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds for processing 2 containers.
recon_1      | 2022-06-24 01:35:39,593 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-06-24 01:35:39,603 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 27 milliseconds.
recon_1      | 2022-06-24 01:36:06,849 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33694
recon_1      | 2022-06-24 01:36:06,856 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:36:06,902 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54362
recon_1      | 2022-06-24 01:36:06,947 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:36:07,003 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:47922
recon_1      | 2022-06-24 01:36:07,016 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:36:32,072 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-24 01:36:32,072 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-24 01:36:32,103 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor55.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-24 01:36:36,940 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33768
recon_1      | 2022-06-24 01:36:36,952 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:36:37,005 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48002
recon_1      | 2022-06-24 01:36:37,010 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54438
recon_1      | 2022-06-24 01:36:37,014 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-24 01:36:37,014 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
