Attaching to ozonesecure-ha_recon_1, ozonesecure-ha_s3g_1, ozonesecure-ha_scm3.org_1, ozonesecure-ha_om1_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_datanode2_1, ozonesecure-ha_om2_1, ozonesecure-ha_om3_1, ozonesecure-ha_kdc_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_kms_1, ozonesecure-ha_datanode3_1
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2022-06-28 01:18:12,588 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = 3648fb418109/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
datanode1_1  | STARTUP_MSG:   java = 11.0.14.1
datanode1_1  | ************************************************************/
datanode1_1  | 2022-06-28 01:18:12,668 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2022-06-28 01:18:13,066 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2022-06-28 01:18:13,796 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2022-06-28 01:18:14,719 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2022-06-28 01:18:14,726 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2022-06-28 01:18:15,474 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:3648fb418109 ip:172.25.0.102
datanode1_1  | 2022-06-28 01:18:18,723 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2022-06-28 01:18:19,625 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2022-06-28 01:18:19,625 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2022-06-28 01:18:21,437 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2022-06-28 01:18:21,443 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2022-06-28 01:18:21,443 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2022-06-28 01:18:21,448 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2022-06-28 01:18:29,000 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2022-06-28 01:18:29,097 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:3648fb418109
datanode1_1  | 2022-06-28 01:18:29,107 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2022-06-28 01:18:29,129 [main] ERROR client.DNCertificateClient: Invalid domain 3648fb418109
datanode1_1  | 2022-06-28 01:18:29,130 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@3648fb418109
datanode1_1  | 2022-06-28 01:18:33,651 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2022-06-28 01:18:33,752 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2022-06-28 01:18:33,785 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/1007988787146.crt.
datanode1_1  | 2022-06-28 01:18:33,793 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-916105677270.crt.
datanode1_1  | 2022-06-28 01:18:33,793 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2022-06-28 01:18:33,897 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode1_1  | 2022-06-28 01:18:35,062 [main] INFO reflections.Reflections: Reflections took 860 ms to scan 2 urls, producing 89 keys and 195 values 
datanode1_1  | 2022-06-28 01:18:35,601 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode1_1  | 2022-06-28 01:18:36,717 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2022-06-28 01:18:36,834 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode1_1  | 2022-06-28 01:18:36,853 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2022-06-28 01:18:36,879 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2022-06-28 01:18:37,093 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2022-06-28 01:18:37,207 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-06-28 01:18:37,225 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2022-06-28 01:18:37,239 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2022-06-28 01:18:37,239 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2022-06-28 01:18:37,240 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2022-06-28 01:18:37,447 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2022-06-28 01:18:37,459 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2022-06-28 01:18:42,105 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode1_1  | 2022-06-28 01:18:43,807 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-06-28 01:18:44,187 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2022-06-28 01:18:44,953 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2022-06-28 01:18:44,971 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2022-06-28 01:18:44,972 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2022-06-28 01:18:44,980 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2022-06-28 01:18:44,988 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-06-28 01:18:45,048 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2022-06-28 01:18:45,076 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-06-28 01:18:45,262 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode1_1  | 2022-06-28 01:18:45,263 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode1_1  | 2022-06-28 01:18:50,647 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2022-06-28 01:18:50,663 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode1_1  | 2022-06-28 01:18:50,669 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode1_1  | 2022-06-28 01:18:50,670 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-06-28 01:18:50,682 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-06-28 01:18:50,694 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-06-28 01:18:51,117 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode1_1  | 2022-06-28 01:18:52,089 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode1_1  | 2022-06-28 01:18:52,097 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode1_1  | 2022-06-28 01:18:52,553 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2022-06-28 01:18:52,553 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2022-06-28 01:18:52,553 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2022-06-28 01:18:52,814 [main] INFO util.log: Logging initialized @51233ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2022-06-28 01:18:53,858 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2022-06-28 01:18:53,932 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2022-06-28 01:18:53,951 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2022-06-28 01:18:53,951 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2022-06-28 01:18:53,954 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2022-06-28 01:18:53,965 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2022-06-28 01:18:54,191 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2022-06-28 01:18:54,206 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode1_1  | 2022-06-28 01:18:54,378 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2022-06-28 01:18:54,396 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2022-06-28 01:18:54,401 [main] INFO server.session: node0 Scavenging every 660000ms
datanode1_1  | 2022-06-28 01:18:54,606 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-06-28 01:18:54,628 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@238cac6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2022-06-28 01:18:54,633 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@373c367{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2022-06-28 01:18:55,261 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-06-28 01:18:55,335 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@12939937{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-12257514003882164574/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2022-06-28 01:18:55,395 [main] INFO server.AbstractConnector: Started ServerConnector@d8f65a1{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2022-06-28 01:18:55,397 [main] INFO server.Server: Started @53816ms
datanode1_1  | 2022-06-28 01:18:55,406 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2022-06-28 01:18:55,406 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2022-06-28 01:18:55,410 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2022-06-28 01:18:55,435 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode1_1  | 2022-06-28 01:18:55,672 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2bf95f67] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2022-06-28 01:18:56,051 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2022-06-28 01:18:56,096 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode1_1  | 2022-06-28 01:18:59,061 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b/DS-2bf68c1f-1268-4045-9646-8bbbb3ef9835/container.db for volume DS-2bf68c1f-1268-4045-9646-8bbbb3ef9835
datanode1_1  | 2022-06-28 01:18:59,130 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b/DS-2bf68c1f-1268-4045-9646-8bbbb3ef9835/container.db for volume DS-2bf68c1f-1268-4045-9646-8bbbb3ef9835
datanode1_1  | 2022-06-28 01:18:59,138 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2022-06-28 01:18:59,155 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2022-06-28 01:19:00,215 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 3f49ce74-6987-463e-a960-954ebbba5f61
datanode1_1  | 2022-06-28 01:19:00,472 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.RaftServer: 3f49ce74-6987-463e-a960-954ebbba5f61: start RPC server
datanode1_1  | 2022-06-28 01:19:00,496 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 3f49ce74-6987-463e-a960-954ebbba5f61: GrpcService started, listening on 9856
datanode1_1  | 2022-06-28 01:19:00,505 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 3f49ce74-6987-463e-a960-954ebbba5f61: GrpcService started, listening on 9857
datanode1_1  | 2022-06-28 01:19:00,507 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 3f49ce74-6987-463e-a960-954ebbba5f61: GrpcService started, listening on 9858
datanode1_1  | 2022-06-28 01:19:00,535 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3f49ce74-6987-463e-a960-954ebbba5f61 is started using port 9858 for RATIS
datanode1_1  | 2022-06-28 01:19:00,543 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3f49ce74-6987-463e-a960-954ebbba5f61 is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2022-06-28 01:19:00,543 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3f49ce74-6987-463e-a960-954ebbba5f61 is started using port 9856 for RATIS_SERVER
datanode1_1  | 2022-06-28 01:19:00,548 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$388/0x00000008405de040@3ba06bb8] INFO util.JvmPauseMonitor: JvmPauseMonitor-3f49ce74-6987-463e-a960-954ebbba5f61: Started
datanode1_1  | 2022-06-28 01:19:00,631 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-06-28 01:19:00,635 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-06-28 01:19:04,956 [Command processor thread] INFO server.RaftServer: 3f49ce74-6987-463e-a960-954ebbba5f61: addNew group-A67715D36AB1:[9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-A67715D36AB1:java.util.concurrent.CompletableFuture@5b6bf9c8[Not completed]
datanode1_1  | 2022-06-28 01:19:05,126 [pool-23-thread-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61: new RaftServerImpl for group-A67715D36AB1:[9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-06-28 01:19:05,146 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-06-28 01:19:05,147 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-06-28 01:19:05,148 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-06-28 01:19:05,157 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-06-28 01:19:05,157 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-06-28 01:19:05,172 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-06-28 01:19:05,199 [pool-23-thread-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1: ConfigurationManager, init=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-06-28 01:19:05,204 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-06-28 01:19:05,228 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-06-28 01:19:05,230 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-06-28 01:19:05,236 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 does not exist. Creating ...
datanode1_1  | 2022-06-28 01:19:05,271 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1/in_use.lock acquired by nodename 9@3648fb418109
datanode1_1  | 2022-06-28 01:19:05,299 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 has been successfully formatted.
datanode1_1  | 2022-06-28 01:19:05,360 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-A67715D36AB1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-06-28 01:19:05,363 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-06-28 01:19:05,388 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-06-28 01:19:05,508 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-06-28 01:19:05,509 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-06-28 01:19:05,510 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-06-28 01:19:05,606 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-06-28 01:19:05,656 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-06-28 01:19:05,660 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-06-28 01:19:05,742 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1
datanode1_1  | 2022-06-28 01:19:05,746 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-06-28 01:19:05,747 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-06-28 01:19:05,754 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-06-28 01:19:05,756 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-06-28 01:19:05,757 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-06-28 01:19:05,775 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-06-28 01:19:05,784 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-06-28 01:19:05,785 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-06-28 01:19:05,853 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-06-28 01:19:05,860 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-06-28 01:19:05,878 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-06-28 01:19:05,902 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2022-06-28 01:18:11,158 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = 65eb9f967bad/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
datanode2_1  | STARTUP_MSG:   java = 11.0.14.1
datanode2_1  | ************************************************************/
datanode2_1  | 2022-06-28 01:18:11,212 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2022-06-28 01:18:11,512 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2022-06-28 01:18:12,132 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2022-06-28 01:18:13,085 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2022-06-28 01:18:13,085 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2022-06-28 01:18:14,085 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:65eb9f967bad ip:172.25.0.103
datanode2_1  | 2022-06-28 01:18:17,961 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2022-06-28 01:18:19,054 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2022-06-28 01:18:19,054 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2022-06-28 01:18:20,776 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2022-06-28 01:18:20,783 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2022-06-28 01:18:20,784 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2022-06-28 01:18:20,793 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2022-06-28 01:18:25,395 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2022-06-28 01:18:25,451 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:65eb9f967bad
datanode2_1  | 2022-06-28 01:18:25,464 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2022-06-28 01:18:25,474 [main] ERROR client.DNCertificateClient: Invalid domain 65eb9f967bad
datanode2_1  | 2022-06-28 01:18:25,475 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@65eb9f967bad
datanode2_1  | 2022-06-28 01:18:30,403 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2022-06-28 01:18:30,507 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2022-06-28 01:18:30,509 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/1004767615899.crt.
datanode2_1  | 2022-06-28 01:18:30,516 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-916105677270.crt.
datanode2_1  | 2022-06-28 01:18:30,522 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2022-06-28 01:18:30,615 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode2_1  | 2022-06-28 01:18:31,671 [main] INFO reflections.Reflections: Reflections took 808 ms to scan 2 urls, producing 89 keys and 195 values 
datanode2_1  | 2022-06-28 01:18:32,114 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode2_1  | 2022-06-28 01:18:33,266 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2022-06-28 01:18:33,358 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode2_1  | 2022-06-28 01:18:33,395 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2022-06-28 01:18:33,404 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2022-06-28 01:18:33,671 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2022-06-28 01:18:33,827 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-06-28 01:18:33,833 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2022-06-28 01:18:33,847 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2022-06-28 01:18:33,848 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2022-06-28 01:18:33,849 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode2_1  | 2022-06-28 01:18:34,121 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2022-06-28 01:18:34,156 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2022-06-28 01:18:39,096 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode2_1  | 2022-06-28 01:18:40,263 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-06-28 01:18:40,623 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2022-06-28 01:18:41,565 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2022-06-28 01:18:41,565 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2022-06-28 01:18:41,583 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2022-06-28 01:18:41,604 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2022-06-28 01:18:41,620 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-06-28 01:18:41,624 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2022-06-28 01:18:41,634 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-06-28 01:18:41,875 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode2_1  | 2022-06-28 01:18:41,912 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode2_1  | 2022-06-28 01:18:48,637 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2022-06-28 01:18:48,682 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode1_1  | 2022-06-28 01:19:05,902 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-06-28 01:19:05,922 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-06-28 01:18:48,684 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode2_1  | 2022-06-28 01:18:48,687 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-06-28 01:18:48,687 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-06-28 01:18:48,697 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-06-28 01:18:49,362 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode2_1  | 2022-06-28 01:18:50,639 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-06-28 01:18:50,689 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-06-28 01:18:50,954 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2022-06-28 01:18:50,954 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2022-06-28 01:18:50,954 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2022-06-28 01:18:51,096 [main] INFO util.log: Logging initialized @50363ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2022-06-28 01:18:51,767 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2022-06-28 01:18:51,801 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2022-06-28 01:18:51,802 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2022-06-28 01:18:51,802 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2022-06-28 01:18:51,802 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2022-06-28 01:18:51,866 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2022-06-28 01:18:52,099 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2022-06-28 01:18:52,110 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode2_1  | 2022-06-28 01:18:52,339 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2022-06-28 01:18:52,339 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2022-06-28 01:18:52,348 [main] INFO server.session: node0 Scavenging every 660000ms
datanode2_1  | 2022-06-28 01:18:52,490 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-06-28 01:18:52,509 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@44aaa987{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2022-06-28 01:18:52,516 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@f359e65{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2022-06-28 01:18:53,577 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-06-28 01:18:53,682 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7ebf5bf{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-3939919881725502559/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2022-06-28 01:18:53,748 [main] INFO server.AbstractConnector: Started ServerConnector@729a98e9{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2022-06-28 01:18:53,754 [main] INFO server.Server: Started @53021ms
datanode2_1  | 2022-06-28 01:18:53,757 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2022-06-28 01:18:53,757 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2022-06-28 01:18:53,770 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2022-06-28 01:18:53,811 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode2_1  | 2022-06-28 01:18:53,959 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b0c4ee9] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2022-06-28 01:18:54,579 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2022-06-28 01:18:54,642 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode2_1  | 2022-06-28 01:18:58,946 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b/DS-f22107e1-9cf9-4576-9115-a5bfe1a591dc/container.db for volume DS-f22107e1-9cf9-4576-9115-a5bfe1a591dc
datanode2_1  | 2022-06-28 01:18:59,013 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b/DS-f22107e1-9cf9-4576-9115-a5bfe1a591dc/container.db for volume DS-f22107e1-9cf9-4576-9115-a5bfe1a591dc
datanode2_1  | 2022-06-28 01:18:59,024 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2022-06-28 01:18:59,030 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2022-06-28 01:18:59,555 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
datanode2_1  | 2022-06-28 01:18:59,762 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start RPC server
datanode2_1  | 2022-06-28 01:18:59,785 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: GrpcService started, listening on 9856
datanode2_1  | 2022-06-28 01:18:59,788 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: GrpcService started, listening on 9857
datanode2_1  | 2022-06-28 01:18:59,805 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: GrpcService started, listening on 9858
datanode2_1  | 2022-06-28 01:18:59,871 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa is started using port 9858 for RATIS
datanode2_1  | 2022-06-28 01:18:59,874 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2022-06-28 01:18:59,874 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa is started using port 9856 for RATIS_SERVER
datanode1_1  | 2022-06-28 01:19:05,951 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-06-28 01:19:05,958 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-06-28 01:19:05,959 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-06-28 01:19:05,962 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-06-28 01:19:05,979 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-06-28 01:19:06,177 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-06-28 01:19:06,193 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-06-28 01:19:06,207 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-06-28 01:19:06,210 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-06-28 01:19:06,211 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-06-28 01:19:06,214 [pool-23-thread-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1: start as a follower, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-06-28 01:19:06,214 [pool-23-thread-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-06-28 01:19:06,215 [pool-23-thread-1] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-FollowerState
datanode1_1  | 2022-06-28 01:19:06,242 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A67715D36AB1,id=3f49ce74-6987-463e-a960-954ebbba5f61
datanode1_1  | 2022-06-28 01:19:06,363 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=51a7f1ac-dc16-43e5-8dfa-a67715d36ab1
datanode1_1  | 2022-06-28 01:19:11,295 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-FollowerState] INFO impl.FollowerState: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5080689754ns, electionTimeout:5051ms
datanode1_1  | 2022-06-28 01:19:11,296 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-FollowerState
datanode1_1  | 2022-06-28 01:19:11,297 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-FollowerState] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-06-28 01:19:11,300 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-06-28 01:19:11,301 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1
datanode1_1  | 2022-06-28 01:19:11,321 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-06-28 01:19:12,312 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode1_1  | 2022-06-28 01:19:12,314 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO impl.LeaderElection:   Response 0: 3f49ce74-6987-463e-a960-954ebbba5f61<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:OK-t1
datanode1_1  | 2022-06-28 01:19:12,319 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1 ELECTION round 0: result PASSED
datanode1_1  | 2022-06-28 01:19:12,320 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1
datanode1_1  | 2022-06-28 01:19:12,323 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2022-06-28 01:19:12,324 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A67715D36AB1 with new leaderId: 3f49ce74-6987-463e-a960-954ebbba5f61
datanode1_1  | 2022-06-28 01:19:12,331 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1: change Leader from null to 3f49ce74-6987-463e-a960-954ebbba5f61 at term 1 for becomeLeader, leader elected after 6960ms
datanode1_1  | 2022-06-28 01:19:12,393 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-06-28 01:19:12,482 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-06-28 01:19:12,520 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-06-28 01:19:12,594 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-06-28 01:19:12,620 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-06-28 01:19:12,630 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-06-28 01:19:12,760 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-06-28 01:19:12,775 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-06-28 01:19:12,908 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2022-06-28 01:19:12,909 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-06-28 01:19:12,909 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2022-06-28 01:19:13,105 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2022-06-28 01:19:13,152 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-06-28 01:19:13,152 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-06-28 01:19:13,154 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2022-06-28 01:19:13,154 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-06-28 01:19:13,154 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2022-06-28 01:19:13,176 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2022-06-28 01:19:13,176 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-06-28 01:19:13,179 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-06-28 01:19:13,192 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderStateImpl
datanode1_1  | 2022-06-28 01:19:13,320 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-06-28 01:19:13,561 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-LeaderElection1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1: set configuration 0: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-06-28 01:19:13,891 [3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1/current/log_inprogress_0
datanode1_1  | 2022-06-28 01:19:16,168 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=51a7f1ac-dc16-43e5-8dfa-a67715d36ab1.
datanode1_1  | 2022-06-28 01:19:16,169 [Command processor thread] INFO server.RaftServer: 3f49ce74-6987-463e-a960-954ebbba5f61: addNew group-805995535EAC:[3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-805995535EAC:java.util.concurrent.CompletableFuture@19ccd456[Not completed]
datanode1_1  | 2022-06-28 01:19:16,172 [pool-23-thread-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61: new RaftServerImpl for group-805995535EAC:[3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-06-28 01:19:16,176 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-06-28 01:19:16,178 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-06-28 01:19:16,181 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-06-28 01:19:16,183 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-06-28 01:19:16,183 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-06-28 01:19:16,183 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-06-28 01:19:16,184 [pool-23-thread-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC: ConfigurationManager, init=-1: [3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-06-28 01:19:16,184 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-06-28 01:19:16,188 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-06-28 01:19:16,188 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-06-28 01:19:16,191 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e0166ad2-3c82-41e4-a01f-805995535eac does not exist. Creating ...
datanode1_1  | 2022-06-28 01:19:16,194 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e0166ad2-3c82-41e4-a01f-805995535eac/in_use.lock acquired by nodename 9@3648fb418109
datanode1_1  | 2022-06-28 01:19:16,197 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e0166ad2-3c82-41e4-a01f-805995535eac has been successfully formatted.
datanode1_1  | 2022-06-28 01:19:16,206 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-805995535EAC: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-06-28 01:19:16,207 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-06-28 01:19:16,208 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-06-28 01:19:16,209 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-06-28 01:19:16,209 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-06-28 01:19:16,211 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-06-28 01:19:16,212 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-06-28 01:19:16,232 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2022-06-28 01:18:12,058 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = 472cd7b1c4f7/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
datanode3_1  | STARTUP_MSG:   java = 11.0.14.1
datanode3_1  | ************************************************************/
datanode3_1  | 2022-06-28 01:18:12,143 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2022-06-28 01:18:12,470 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2022-06-28 01:18:13,239 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2022-06-28 01:18:14,216 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2022-06-28 01:18:14,216 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2022-06-28 01:18:14,900 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:472cd7b1c4f7 ip:172.25.0.104
datanode3_1  | 2022-06-28 01:18:18,605 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2022-06-28 01:18:19,325 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2022-06-28 01:18:19,325 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2022-06-28 01:18:21,213 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2022-06-28 01:18:21,223 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2022-06-28 01:18:21,227 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2022-06-28 01:18:21,239 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2022-06-28 01:18:26,237 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2022-06-28 01:18:26,407 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:472cd7b1c4f7
datanode3_1  | 2022-06-28 01:18:26,408 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2022-06-28 01:18:26,441 [main] ERROR client.DNCertificateClient: Invalid domain 472cd7b1c4f7
datanode3_1  | 2022-06-28 01:18:26,446 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@472cd7b1c4f7
datanode3_1  | 2022-06-28 01:18:31,009 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2022-06-28 01:18:31,073 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/1005480937391.crt.
datanode3_1  | 2022-06-28 01:18:31,108 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2022-06-28 01:18:31,117 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-916105677270.crt.
datanode3_1  | 2022-06-28 01:18:31,139 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2022-06-28 01:18:31,220 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode3_1  | 2022-06-28 01:18:32,096 [main] INFO reflections.Reflections: Reflections took 652 ms to scan 2 urls, producing 89 keys and 195 values 
datanode3_1  | 2022-06-28 01:18:32,560 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode3_1  | 2022-06-28 01:18:33,745 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2022-06-28 01:18:33,846 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89311358976
datanode3_1  | 2022-06-28 01:18:33,880 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2022-06-28 01:18:33,924 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2022-06-28 01:18:34,241 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2022-06-28 01:18:34,400 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-06-28 01:18:34,412 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2022-06-28 01:18:34,415 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2022-06-28 01:18:34,418 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2022-06-28 01:18:34,418 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2022-06-28 01:18:34,640 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2022-06-28 01:18:34,667 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2022-06-28 01:18:39,865 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode3_1  | 2022-06-28 01:18:40,814 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-06-28 01:18:41,367 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2022-06-28 01:18:42,210 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2022-06-28 01:18:42,236 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2022-06-28 01:18:42,240 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2022-06-28 01:18:42,252 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2022-06-28 01:18:42,257 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-06-28 01:18:42,258 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2022-06-28 01:18:42,286 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-06-28 01:18:42,471 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode3_1  | 2022-06-28 01:18:42,489 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode3_1  | 2022-06-28 01:18:48,746 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
datanode1_1  | 2022-06-28 01:19:16,249 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-06-28 01:19:16,256 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e0166ad2-3c82-41e4-a01f-805995535eac
datanode1_1  | 2022-06-28 01:19:16,256 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-06-28 01:19:16,256 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-06-28 01:19:16,259 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-06-28 01:19:16,260 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-06-28 01:19:16,262 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-06-28 01:19:16,262 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-06-28 01:19:16,263 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-06-28 01:19:16,266 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-06-28 01:19:16,267 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-06-28 01:19:16,272 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-06-28 01:19:16,274 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-06-28 01:19:16,275 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-06-28 01:19:16,279 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-06-28 01:19:16,281 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-06-28 01:19:16,317 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-06-28 01:19:16,318 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-06-28 01:19:16,318 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-06-28 01:19:16,318 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-06-28 01:19:16,318 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-06-28 01:19:16,319 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-06-28 01:19:16,322 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-06-28 01:19:16,323 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-06-28 01:19:16,334 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-06-28 01:19:16,336 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-06-28 01:19:16,337 [pool-23-thread-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC: start as a follower, conf=-1: [3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-06-28 01:19:16,337 [pool-23-thread-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-06-28 01:19:16,342 [pool-23-thread-1] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-FollowerState
datanode1_1  | 2022-06-28 01:19:16,343 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-805995535EAC,id=3f49ce74-6987-463e-a960-954ebbba5f61
datanode1_1  | 2022-06-28 01:19:16,371 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=e0166ad2-3c82-41e4-a01f-805995535eac
datanode1_1  | 2022-06-28 01:19:16,371 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=e0166ad2-3c82-41e4-a01f-805995535eac.
datanode1_1  | 2022-06-28 01:19:16,372 [Command processor thread] INFO server.RaftServer: 3f49ce74-6987-463e-a960-954ebbba5f61: addNew group-FD99B4920D70:[9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] returns group-FD99B4920D70:java.util.concurrent.CompletableFuture@18c18aaf[Not completed]
datanode1_1  | 2022-06-28 01:19:16,375 [pool-23-thread-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61: new RaftServerImpl for group-FD99B4920D70:[9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-06-28 01:19:16,377 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-06-28 01:19:16,377 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-06-28 01:19:16,378 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-06-28 01:19:16,378 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-06-28 01:19:16,378 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-06-28 01:19:16,378 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-06-28 01:19:16,378 [pool-23-thread-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: ConfigurationManager, init=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-06-28 01:19:16,379 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-06-28 01:18:48,772 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode3_1  | 2022-06-28 01:18:48,787 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode3_1  | 2022-06-28 01:18:48,795 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-06-28 01:18:48,800 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-06-28 01:18:48,824 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-06-28 01:18:49,600 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode3_1  | 2022-06-28 01:18:50,767 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-06-28 01:18:50,778 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-06-28 01:18:51,130 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2022-06-28 01:18:51,135 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2022-06-28 01:18:51,139 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2022-06-28 01:18:51,504 [main] INFO util.log: Logging initialized @49647ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2022-06-28 01:18:52,110 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2022-06-28 01:18:52,164 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2022-06-28 01:18:52,168 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2022-06-28 01:18:52,176 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2022-06-28 01:18:52,178 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2022-06-28 01:18:52,194 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2022-06-28 01:18:52,417 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2022-06-28 01:18:52,430 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode3_1  | 2022-06-28 01:18:52,719 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2022-06-28 01:18:52,719 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2022-06-28 01:18:52,725 [main] INFO server.session: node0 Scavenging every 660000ms
datanode3_1  | 2022-06-28 01:18:52,991 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-06-28 01:18:53,027 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@9d4d221{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2022-06-28 01:18:53,049 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@294aaa6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2022-06-28 01:18:53,971 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-06-28 01:18:54,045 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4a577b99{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-18317866136520882751/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2022-06-28 01:18:54,132 [main] INFO server.AbstractConnector: Started ServerConnector@362109d0{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2022-06-28 01:18:54,132 [main] INFO server.Server: Started @52303ms
datanode3_1  | 2022-06-28 01:18:54,147 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2022-06-28 01:18:54,147 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2022-06-28 01:18:54,154 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2022-06-28 01:18:54,193 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode3_1  | 2022-06-28 01:18:54,408 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b2d38e9] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2022-06-28 01:18:55,012 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2022-06-28 01:18:55,025 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode3_1  | 2022-06-28 01:18:58,969 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b/DS-1de78de8-7a3a-4708-b85d-37c862305b7c/container.db for volume DS-1de78de8-7a3a-4708-b85d-37c862305b7c
datanode3_1  | 2022-06-28 01:18:59,028 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b/DS-1de78de8-7a3a-4708-b85d-37c862305b7c/container.db for volume DS-1de78de8-7a3a-4708-b85d-37c862305b7c
datanode3_1  | 2022-06-28 01:18:59,036 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2022-06-28 01:18:59,060 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2022-06-28 01:18:59,997 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
datanode3_1  | 2022-06-28 01:19:00,186 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start RPC server
datanode3_1  | 2022-06-28 01:19:00,198 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: GrpcService started, listening on 9856
datanode3_1  | 2022-06-28 01:19:00,216 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: GrpcService started, listening on 9857
datanode3_1  | 2022-06-28 01:19:00,218 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: GrpcService started, listening on 9858
datanode3_1  | 2022-06-28 01:19:00,275 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda is started using port 9858 for RATIS
datanode3_1  | 2022-06-28 01:19:00,277 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2022-06-28 01:19:00,278 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda is started using port 9856 for RATIS_SERVER
datanode3_1  | 2022-06-28 01:19:00,286 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$389/0x00000008405da440@18250960] INFO util.JvmPauseMonitor: JvmPauseMonitor-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: Started
datanode3_1  | 2022-06-28 01:19:00,367 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-06-28 01:19:00,367 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-06-28 01:19:10,810 [grpc-default-executor-0] INFO server.RaftServer: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: addNew group-A67715D36AB1:[9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1] returns group-A67715D36AB1:java.util.concurrent.CompletableFuture@454911e3[Not completed]
datanode3_1  | 2022-06-28 01:19:10,883 [pool-23-thread-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: new RaftServerImpl for group-A67715D36AB1:[9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-06-28 01:19:10,951 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-06-28 01:19:10,953 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-06-28 01:19:10,953 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-06-28 01:19:10,953 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-06-28 01:19:10,953 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-06-28 01:19:10,953 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-06-28 01:19:11,016 [pool-23-thread-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1: ConfigurationManager, init=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-06-28 01:19:11,016 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-06-28 01:19:11,025 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-06-28 01:19:11,028 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-06-28 01:19:11,038 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 does not exist. Creating ...
datanode3_1  | 2022-06-28 01:19:11,063 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1/in_use.lock acquired by nodename 7@472cd7b1c4f7
datanode3_1  | 2022-06-28 01:19:11,097 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 has been successfully formatted.
datanode3_1  | 2022-06-28 01:19:11,187 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-A67715D36AB1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-06-28 01:19:11,196 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-06-28 01:19:11,218 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-06-28 01:19:11,327 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-06-28 01:19:11,327 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-06-28 01:19:11,328 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-06-28 01:19:11,385 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-06-28 01:19:11,425 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-06-28 01:19:11,429 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-06-28 01:19:11,463 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1
datanode3_1  | 2022-06-28 01:19:11,466 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-06-28 01:19:11,468 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-06-28 01:19:11,469 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-06-28 01:19:11,474 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-06-28 01:19:11,475 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-06-28 01:19:11,480 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-06-28 01:19:11,480 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-06-28 01:19:11,480 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-06-28 01:19:11,510 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-06-28 01:18:59,877 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$388/0x00000008405de840@20274e49] INFO util.JvmPauseMonitor: JvmPauseMonitor-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: Started
datanode2_1  | 2022-06-28 01:18:59,978 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-06-28 01:18:59,978 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-06-28 01:19:13,734 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: Failed requestVote 3f49ce74-6987-463e-a960-954ebbba5f61->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0
datanode2_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: group-A67715D36AB1 not found.
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:148)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:347)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:356)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:351)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:603)
datanode2_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode2_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:382)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:340)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:866)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode2_1  | 2022-06-28 01:19:14,203 [grpc-default-executor-1] INFO server.RaftServer: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: addNew group-A67715D36AB1:[9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1] returns group-A67715D36AB1:java.util.concurrent.CompletableFuture@2ba6a30[Not completed]
datanode2_1  | 2022-06-28 01:19:14,355 [pool-23-thread-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: new RaftServerImpl for group-A67715D36AB1:[9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-06-28 01:19:14,369 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-06-28 01:19:14,372 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-06-28 01:19:14,385 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-06-28 01:19:14,391 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-06-28 01:19:14,393 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-06-28 01:19:14,394 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-06-28 01:19:14,427 [pool-23-thread-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-A67715D36AB1: ConfigurationManager, init=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-06-28 01:19:14,428 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-06-28 01:19:14,453 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-06-28 01:19:14,454 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-06-28 01:19:14,460 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 does not exist. Creating ...
datanode2_1  | 2022-06-28 01:19:14,514 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1/in_use.lock acquired by nodename 6@65eb9f967bad
datanode2_1  | 2022-06-28 01:19:14,603 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 has been successfully formatted.
datanode2_1  | 2022-06-28 01:19:14,717 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-A67715D36AB1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-06-28 01:19:14,718 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-06-28 01:19:14,811 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-06-28 01:19:14,959 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-06-28 01:19:14,971 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-06-28 01:19:14,996 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-06-28 01:19:15,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-06-28 01:19:15,170 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-06-28 01:19:15,198 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
kdc_1        | Jun 28 01:16:36 kdc krb5kdc[7](info): Loaded
kdc_1        | Jun 28 01:16:36 kdc krb5kdc[7](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Jun 28 01:16:36 kdc krb5kdc[7](info): setting up network...
kdc_1        | Jun 28 01:16:36 kdc krb5kdc[7](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Jun 28 01:16:36 kdc krb5kdc[7](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Jun 28 01:16:36 kdc krb5kdc[7](info): set up 4 sockets
kdc_1        | Jun 28 01:16:36 kdc krb5kdc[7](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Jun 28 01:16:41 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379001, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:16:49 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.114: ISSUE: authtime 1656379009, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:16:53 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.115: ISSUE: authtime 1656379013, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:16:55 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379015, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:17:06 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1656379026, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:17:11 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1656379031, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:17:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1656379013, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:17:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379015, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:17:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1656379026, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:17:29 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379049, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:17:33 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1656379053, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:17:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379049, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:17:43 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379063, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:17:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1656379053, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:17:47 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1656379067, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:17:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1656379067, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:17:52 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379063, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:17:54 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1656379074, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:17:56 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379076, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:18:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1656379074, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:18:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379076, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:18:16 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379096, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:18:18 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1656379098, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:18:19 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1656379099, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:18:19 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1656379099, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:18:22 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1656379102, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:18:23 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1656379103, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:18:24 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1656379104, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:18:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1656379102, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:18:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1656379103, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:18:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1656379104, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:18:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1656379098, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:18:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1656379099, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:18:32 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1656379099, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:18:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379096, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:18:53 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379133, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:18:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1656379098, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
datanode1_1  | 2022-06-28 01:19:16,379 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-06-28 01:19:16,379 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-06-28 01:19:16,380 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70 does not exist. Creating ...
datanode1_1  | 2022-06-28 01:19:16,440 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70/in_use.lock acquired by nodename 9@3648fb418109
datanode1_1  | 2022-06-28 01:19:16,460 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70 has been successfully formatted.
datanode1_1  | 2022-06-28 01:19:16,525 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-FD99B4920D70: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-06-28 01:19:16,528 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-06-28 01:19:16,531 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-06-28 01:19:16,543 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-06-28 01:19:16,556 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-06-28 01:19:16,557 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-06-28 01:19:16,557 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-06-28 01:19:16,562 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-06-28 01:19:16,587 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-06-28 01:19:16,588 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70
datanode1_1  | 2022-06-28 01:19:16,589 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-06-28 01:19:16,597 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-06-28 01:19:16,598 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-06-28 01:19:16,599 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-06-28 01:19:16,603 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-06-28 01:19:16,604 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-06-28 01:19:16,606 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-06-28 01:19:16,606 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-06-28 01:19:16,615 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-06-28 01:19:16,617 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-06-28 01:19:16,624 [grpc-default-executor-1] INFO leader.FollowerInfo: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: nextIndex: updateUnconditionally 1 -> 0
datanode1_1  | 2022-06-28 01:19:16,627 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
kdc_1        | Jun 28 01:18:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1656379099, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Jun 28 01:18:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1656379099, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Jun 28 01:19:00 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1656379140, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:19:00 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1656379140, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:19:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1656379140, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:19:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1656379140, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:19:04 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1656379144, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:19:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1656379144, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:19:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379133, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:19:24 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379164, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:19:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1656379013, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:19:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379164, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:19:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:19:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:19:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:19:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:19:42 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:19:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:20:07 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2022-06-28 01:19:15,231 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-A67715D36AB1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1
datanode2_1  | 2022-06-28 01:19:15,244 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-06-28 01:19:15,253 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-06-28 01:19:15,254 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-06-28 01:19:15,260 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-06-28 01:19:15,264 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-06-28 01:19:15,265 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-06-28 01:19:15,272 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-06-28 01:19:15,278 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-06-28 01:19:15,334 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-06-28 01:19:15,336 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-06-28 01:19:15,337 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-06-28 01:19:15,369 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-A67715D36AB1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-06-28 01:19:15,392 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-A67715D36AB1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-06-28 01:19:15,426 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-06-28 01:19:15,434 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-06-28 01:19:15,435 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-06-28 01:19:15,439 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-06-28 01:19:15,452 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-06-28 01:19:15,460 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-06-28 01:19:15,726 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-06-28 01:19:15,735 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-06-28 01:19:15,744 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-06-28 01:19:15,748 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-06-28 01:19:15,753 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-06-28 01:19:15,784 [pool-23-thread-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-A67715D36AB1: start as a follower, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-06-28 01:19:15,786 [pool-23-thread-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-A67715D36AB1: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-06-28 01:19:15,788 [pool-23-thread-1] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-A67715D36AB1-FollowerState
datanode2_1  | 2022-06-28 01:19:15,836 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A67715D36AB1,id=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
datanode2_1  | 2022-06-28 01:19:16,451 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A67715D36AB1 with new leaderId: 3f49ce74-6987-463e-a960-954ebbba5f61
datanode2_1  | 2022-06-28 01:19:16,463 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-server-thread1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-A67715D36AB1: change Leader from null to 3f49ce74-6987-463e-a960-954ebbba5f61 at term 1 for appendEntries, leader elected after 1732ms
datanode2_1  | 2022-06-28 01:19:16,469 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-server-thread1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-A67715D36AB1: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode2_1  | 2022-06-28 01:19:16,560 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-server-thread1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-A67715D36AB1: inconsistency entries. Reply:3f49ce74-6987-463e-a960-954ebbba5f61<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#4:FAIL-t0,INCONSISTENCY,nextIndex=0,followerCommit=-1
datanode2_1  | 2022-06-28 01:19:16,652 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-server-thread1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-A67715D36AB1: set configuration 0: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-06-28 01:19:16,692 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-server-thread1] INFO segmented.SegmentedRaftLogWorker: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-A67715D36AB1-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-06-28 01:19:17,202 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-A67715D36AB1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-A67715D36AB1-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1/current/log_inprogress_0
datanode2_1  | 2022-06-28 01:19:17,786 [grpc-default-executor-1] INFO server.RaftServer: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: addNew group-FD99B4920D70:[9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0] returns group-FD99B4920D70:java.util.concurrent.CompletableFuture@3440671f[Not completed]
datanode1_1  | 2022-06-28 01:19:16,628 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-06-28 01:19:16,630 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-06-28 01:19:16,630 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-06-28 01:19:16,631 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-06-28 01:19:16,631 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-06-28 01:19:16,632 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-06-28 01:19:16,632 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-06-28 01:19:16,638 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-06-28 01:19:16,639 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-06-28 01:19:16,658 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-06-28 01:19:16,658 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-06-28 01:19:16,658 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-06-28 01:19:16,658 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-06-28 01:19:16,659 [pool-23-thread-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: start as a follower, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:19:16,659 [pool-23-thread-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-06-28 01:19:16,659 [pool-23-thread-1] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:16,669 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FD99B4920D70,id=3f49ce74-6987-463e-a960-954ebbba5f61
datanode1_1  | 2022-06-28 01:19:16,674 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70
datanode1_1  | 2022-06-28 01:19:17,925 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70.
datanode1_1  | 2022-06-28 01:19:21,446 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-FollowerState] INFO impl.FollowerState: 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5104000067ns, electionTimeout:5099ms
datanode1_1  | 2022-06-28 01:19:21,447 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-FollowerState
datanode1_1  | 2022-06-28 01:19:21,447 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-FollowerState] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-06-28 01:19:21,448 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-06-28 01:19:21,448 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2
datanode1_1  | 2022-06-28 01:19:21,452 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-06-28 01:19:21,454 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2022-06-28 01:19:21,454 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2
datanode1_1  | 2022-06-28 01:19:21,454 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2022-06-28 01:19:21,454 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-805995535EAC with new leaderId: 3f49ce74-6987-463e-a960-954ebbba5f61
datanode1_1  | 2022-06-28 01:19:21,456 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC: change Leader from null to 3f49ce74-6987-463e-a960-954ebbba5f61 at term 1 for becomeLeader, leader elected after 5247ms
datanode1_1  | 2022-06-28 01:19:21,456 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-06-28 01:19:21,467 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-06-28 01:19:21,469 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-06-28 01:19:21,483 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-06-28 01:19:21,484 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-06-28 01:19:21,484 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-06-28 01:19:21,484 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-06-28 01:19:21,484 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-06-28 01:19:21,485 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderStateImpl
datanode1_1  | 2022-06-28 01:19:21,485 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-06-28 01:19:21,496 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e0166ad2-3c82-41e4-a01f-805995535eac/current/log_inprogress_0
datanode1_1  | 2022-06-28 01:19:21,497 [3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC-LeaderElection2] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-805995535EAC: set configuration 0: [3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-06-28 01:19:21,760 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5100139193ns, electionTimeout:5014ms
datanode1_1  | 2022-06-28 01:19:21,762 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:21,763 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-06-28 01:19:21,763 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-06-28 01:19:21,763 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection3
datanode1_1  | 2022-06-28 01:19:21,771 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection3] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:19:21,807 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection3] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode1_1  | 2022-06-28 01:19:21,808 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection3] INFO impl.LeaderElection:   Response 0: 3f49ce74-6987-463e-a960-954ebbba5f61<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t1
datanode1_1  | 2022-06-28 01:19:21,808 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection3] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection3 ELECTION round 0: result REJECTED
datanode3_1  | 2022-06-28 01:19:11,515 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-06-28 01:19:11,517 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-06-28 01:19:11,550 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-06-28 01:19:11,550 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
kdc_1        | Jun 28 01:20:13 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:20:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:20:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:20:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:20:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:20:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:20:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:20:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:21:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:21:05 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:21:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:21:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:21:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:21:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:21:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:21:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:21:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:21:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-06-28 01:18:12,708 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-06-28 01:18:12,781 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-06-28 01:18:20,328 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-06-28 01:18:22,498 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-06-28 01:18:23,128 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-06-28 01:18:23,131 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-06-28 01:18:23,132 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-06-28 01:18:24,509 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-06-28 01:18:24,510 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-06-28 01:18:24,557 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-06-28 01:18:25,425 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-06-28 01:18:28,224 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2022-06-28 01:18:30,924 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2022-06-28 01:18:30,932 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2022-06-28 01:18:30,937 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2022-06-28 01:18:33,122 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2022-06-28 01:18:33,344 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2022-06-28 01:18:33,351 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2022-06-28 01:18:33,366 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2022-06-28 01:18:33,377 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-06-28 01:18:33,378 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-06-28 01:18:33,381 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-06-28 01:18:33,386 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-06-28 01:18:33,397 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:45e35def-6cad-44ae-bb26-f31c46277acf,clusterId:CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b,subject:om1
om1_1        | 2022-06-28 01:18:34,614 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2022-06-28 01:18:36,226 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
kdc_1        | Jun 28 01:21:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:21:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:21:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:21:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:22:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:22:01 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379321, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:22:05 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379321, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:22:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379321, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:22:11 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379331, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:22:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379331, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:22:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379331, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:22:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379331, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:22:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379331, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:22:37 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379357, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:22:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:22:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:22:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379357, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:22:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379357, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2022-06-28 01:19:17,789 [pool-23-thread-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: new RaftServerImpl for group-FD99B4920D70:[9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-06-28 01:19:17,792 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-06-28 01:19:17,793 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-06-28 01:19:17,793 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-06-28 01:19:17,797 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-06-28 01:19:17,798 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-06-28 01:19:17,798 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-06-28 01:19:17,798 [pool-23-thread-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: ConfigurationManager, init=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-06-28 01:19:17,798 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-06-28 01:19:17,799 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-06-28 01:19:17,799 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-06-28 01:19:17,800 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70 does not exist. Creating ...
datanode2_1  | 2022-06-28 01:19:17,806 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70/in_use.lock acquired by nodename 6@65eb9f967bad
datanode2_1  | 2022-06-28 01:19:17,807 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70 has been successfully formatted.
datanode2_1  | 2022-06-28 01:19:17,809 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-FD99B4920D70: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-06-28 01:19:17,811 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-06-28 01:19:17,817 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-06-28 01:19:17,817 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-06-28 01:19:17,817 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-06-28 01:19:17,817 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-06-28 01:19:17,818 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-06-28 01:19:17,818 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-06-28 01:19:17,818 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-06-28 01:19:17,819 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70
datanode2_1  | 2022-06-28 01:19:17,819 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-06-28 01:19:17,819 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-06-28 01:19:17,821 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-06-28 01:19:17,823 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-06-28 01:19:17,824 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-06-28 01:19:17,824 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-06-28 01:19:17,824 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-06-28 01:19:17,825 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-06-28 01:19:17,825 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-06-28 01:19:17,829 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-06-28 01:19:17,868 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-06-28 01:19:17,872 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-06-28 01:19:17,872 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-06-28 01:19:17,873 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-06-28 01:19:17,873 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-06-28 01:19:17,874 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-06-28 01:19:17,874 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-06-28 01:19:17,874 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-06-28 01:19:17,874 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-06-28 01:19:17,875 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-06-28 01:19:17,891 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-06-28 01:19:17,892 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-06-28 01:19:17,892 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-06-28 01:19:17,899 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-06-28 01:19:11,567 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-06-28 01:19:11,568 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-06-28 01:19:11,569 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-06-28 01:19:11,570 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-06-28 01:19:11,585 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-06-28 01:19:11,591 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-06-28 01:19:11,845 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-06-28 01:19:11,875 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-06-28 01:19:11,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-06-28 01:19:11,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-06-28 01:19:11,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-06-28 01:19:11,877 [pool-23-thread-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1: start as a follower, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-06-28 01:19:11,880 [pool-23-thread-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-06-28 01:19:11,895 [pool-23-thread-1] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1-FollowerState
datanode3_1  | 2022-06-28 01:19:11,908 [grpc-default-executor-0] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1: receive requestVote(ELECTION, 3f49ce74-6987-463e-a960-954ebbba5f61, group-A67715D36AB1, 1, (t:0, i:0))
datanode3_1  | 2022-06-28 01:19:11,943 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A67715D36AB1,id=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
datanode3_1  | 2022-06-28 01:19:11,949 [grpc-default-executor-0] INFO impl.VoteContext: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1-FOLLOWER: accept ELECTION from 3f49ce74-6987-463e-a960-954ebbba5f61: our priority 0 <= candidate's priority 1
datanode3_1  | 2022-06-28 01:19:11,952 [grpc-default-executor-0] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:3f49ce74-6987-463e-a960-954ebbba5f61
datanode3_1  | 2022-06-28 01:19:11,959 [grpc-default-executor-0] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1-FollowerState
datanode3_1  | 2022-06-28 01:19:11,983 [grpc-default-executor-0] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1-FollowerState
datanode3_1  | 2022-06-28 01:19:11,984 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1-FollowerState] INFO impl.FollowerState: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1-FollowerState was interrupted
datanode3_1  | 2022-06-28 01:19:12,061 [grpc-default-executor-0] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1 replies to ELECTION vote request: 3f49ce74-6987-463e-a960-954ebbba5f61<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:OK-t1. Peer's state: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1:t1, leader=null, voted=3f49ce74-6987-463e-a960-954ebbba5f61, raftlog=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-06-28 01:19:13,707 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A67715D36AB1 with new leaderId: 3f49ce74-6987-463e-a960-954ebbba5f61
datanode3_1  | 2022-06-28 01:19:13,718 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda-server-thread1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1: change Leader from null to 3f49ce74-6987-463e-a960-954ebbba5f61 at term 1 for appendEntries, leader elected after 2512ms
datanode3_1  | 2022-06-28 01:19:13,898 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda-server-thread1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1: set configuration 0: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-06-28 01:19:13,952 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda-server-thread1] INFO segmented.SegmentedRaftLogWorker: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-06-28 01:19:14,441 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-A67715D36AB1-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/51a7f1ac-dc16-43e5-8dfa-a67715d36ab1/current/log_inprogress_0
datanode3_1  | 2022-06-28 01:19:17,280 [grpc-default-executor-1] INFO server.RaftServer: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: addNew group-FD99B4920D70:[9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0] returns group-FD99B4920D70:java.util.concurrent.CompletableFuture@5763e214[Not completed]
datanode3_1  | 2022-06-28 01:19:17,282 [pool-23-thread-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: new RaftServerImpl for group-FD99B4920D70:[9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-06-28 01:19:17,287 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-06-28 01:19:17,291 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-06-28 01:19:17,291 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-06-28 01:19:17,291 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-06-28 01:19:17,291 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-06-28 01:19:17,292 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-06-28 01:19:17,292 [pool-23-thread-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: ConfigurationManager, init=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-06-28 01:19:17,292 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-06-28 01:19:17,294 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-06-28 01:19:17,294 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-06-28 01:19:17,295 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70 does not exist. Creating ...
datanode3_1  | 2022-06-28 01:19:17,300 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70/in_use.lock acquired by nodename 7@472cd7b1c4f7
datanode3_1  | 2022-06-28 01:19:17,302 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70 has been successfully formatted.
datanode3_1  | 2022-06-28 01:19:17,302 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-FD99B4920D70: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-06-28 01:19:17,302 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-06-28 01:19:17,303 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-06-28 01:19:17,303 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-06-28 01:19:17,303 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-06-28 01:19:17,303 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-06-28 01:19:17,303 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-06-28 01:19:17,304 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-06-28 01:19:17,304 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-06-28 01:19:17,304 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70
datanode3_1  | 2022-06-28 01:19:17,304 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-06-28 01:19:17,304 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-06-28 01:19:17,304 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-06-28 01:19:17,304 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-06-28 01:19:17,304 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-06-28 01:19:17,334 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-06-28 01:19:17,334 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-06-28 01:19:17,334 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-06-28 01:19:17,335 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-06-28 01:19:17,340 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-06-28 01:19:17,346 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-06-28 01:19:17,355 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-06-28 01:19:17,356 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-06-28 01:19:17,360 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-06-28 01:19:17,360 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-06-28 01:19:17,362 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-06-28 01:19:17,366 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-06-28 01:19:21,808 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection3] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode1_1  | 2022-06-28 01:19:21,809 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection3] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection3
datanode1_1  | 2022-06-28 01:19:21,809 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection3] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:26,842 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5033105237ns, electionTimeout:5015ms
datanode1_1  | 2022-06-28 01:19:26,843 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:26,843 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode1_1  | 2022-06-28 01:19:26,844 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-06-28 01:19:26,844 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection4
datanode1_1  | 2022-06-28 01:19:26,849 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection4] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection4 ELECTION round 0: submit vote requests at term 2 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:19:26,865 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection4] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection4: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode1_1  | 2022-06-28 01:19:26,865 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection4] INFO impl.LeaderElection:   Response 0: 3f49ce74-6987-463e-a960-954ebbba5f61<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t2
datanode1_1  | 2022-06-28 01:19:26,865 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection4] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection4 ELECTION round 0: result REJECTED
datanode1_1  | 2022-06-28 01:19:26,865 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection4] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode1_1  | 2022-06-28 01:19:26,865 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection4] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection4
datanode1_1  | 2022-06-28 01:19:26,866 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection4] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:28,036 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: receive requestVote(ELECTION, 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, group-FD99B4920D70, 2, (t:0, i:0))
datanode1_1  | 2022-06-28 01:19:28,048 [grpc-default-executor-1] INFO impl.VoteContext: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FOLLOWER: reject ELECTION from 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: already has voted for 3f49ce74-6987-463e-a960-954ebbba5f61 at current term 2
datanode1_1  | 2022-06-28 01:19:28,075 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70 replies to ELECTION vote request: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-3f49ce74-6987-463e-a960-954ebbba5f61#0:FAIL-t2. Peer's state: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70:t2, leader=null, voted=3f49ce74-6987-463e-a960-954ebbba5f61, raftlog=3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:19:31,944 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5078101031ns, electionTimeout:5045ms
datanode1_1  | 2022-06-28 01:19:31,944 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:31,944 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode1_1  | 2022-06-28 01:19:31,946 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-06-28 01:19:31,946 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection5
datanode1_1  | 2022-06-28 01:19:31,950 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection5] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection5 ELECTION round 0: submit vote requests at term 3 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:19:31,986 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection5] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection5: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode1_1  | 2022-06-28 01:19:31,986 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection5] INFO impl.LeaderElection:   Response 0: 3f49ce74-6987-463e-a960-954ebbba5f61<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:OK-t3
datanode3_1  | 2022-06-28 01:19:17,367 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-06-28 01:19:17,376 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-06-28 01:19:17,378 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-06-28 01:19:17,392 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-06-28 01:19:17,395 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-06-28 01:19:17,396 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-06-28 01:19:17,396 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-06-28 01:19:31,986 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection5] INFO impl.LeaderElection:   Response 1: 3f49ce74-6987-463e-a960-954ebbba5f61<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t3
datanode1_1  | 2022-06-28 01:19:31,986 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection5] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection5 ELECTION round 0: result REJECTED
datanode1_1  | 2022-06-28 01:19:31,986 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection5] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode1_1  | 2022-06-28 01:19:31,986 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection5] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection5
datanode1_1  | 2022-06-28 01:19:31,987 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection5] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:37,139 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5152261485ns, electionTimeout:5151ms
datanode1_1  | 2022-06-28 01:19:37,139 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:37,139 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode1_1  | 2022-06-28 01:19:37,140 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-06-28 01:19:37,140 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection6
datanode1_1  | 2022-06-28 01:19:37,164 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: receive requestVote(ELECTION, 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, group-FD99B4920D70, 4, (t:0, i:0))
datanode1_1  | 2022-06-28 01:19:37,165 [grpc-default-executor-1] INFO impl.VoteContext: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-CANDIDATE: reject ELECTION from 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: already has voted for 3f49ce74-6987-463e-a960-954ebbba5f61 at current term 4
datanode1_1  | 2022-06-28 01:19:37,165 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70 replies to ELECTION vote request: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-3f49ce74-6987-463e-a960-954ebbba5f61#0:FAIL-t4. Peer's state: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70:t4, leader=null, voted=3f49ce74-6987-463e-a960-954ebbba5f61, raftlog=3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:19:37,165 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection6] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection6 ELECTION round 0: submit vote requests at term 4 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:19:37,222 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection6] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection6: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode1_1  | 2022-06-28 01:19:37,222 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection6] INFO impl.LeaderElection:   Response 0: 3f49ce74-6987-463e-a960-954ebbba5f61<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:FAIL-t4
datanode1_1  | 2022-06-28 01:19:37,222 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection6] INFO impl.LeaderElection:   Response 1: 3f49ce74-6987-463e-a960-954ebbba5f61<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t4
datanode1_1  | 2022-06-28 01:19:37,222 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection6] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection6 ELECTION round 0: result REJECTED
datanode1_1  | 2022-06-28 01:19:37,222 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection6] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode1_1  | 2022-06-28 01:19:37,223 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection6] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection6
datanode1_1  | 2022-06-28 01:19:37,223 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection6] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:38,210 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: receive requestVote(ELECTION, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, group-FD99B4920D70, 4, (t:0, i:0))
datanode1_1  | 2022-06-28 01:19:38,211 [grpc-default-executor-1] INFO impl.VoteContext: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FOLLOWER: reject ELECTION from 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: already has voted for 3f49ce74-6987-463e-a960-954ebbba5f61 at current term 4
datanode1_1  | 2022-06-28 01:19:38,211 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70 replies to ELECTION vote request: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda<-3f49ce74-6987-463e-a960-954ebbba5f61#0:FAIL-t4. Peer's state: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70:t4, leader=null, voted=3f49ce74-6987-463e-a960-954ebbba5f61, raftlog=3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:19:42,342 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: receive requestVote(ELECTION, 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, group-FD99B4920D70, 5, (t:0, i:0))
datanode1_1  | 2022-06-28 01:19:42,342 [grpc-default-executor-1] INFO impl.VoteContext: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FOLLOWER: accept ELECTION from 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: our priority 0 <= candidate's priority 0
datanode2_1  | 2022-06-28 01:19:17,901 [pool-23-thread-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: start as a follower, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:19:17,901 [pool-23-thread-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-06-28 01:19:17,901 [pool-23-thread-1] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:17,903 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FD99B4920D70,id=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
datanode2_1  | 2022-06-28 01:19:21,831 [grpc-default-executor-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: receive requestVote(ELECTION, 3f49ce74-6987-463e-a960-954ebbba5f61, group-FD99B4920D70, 1, (t:0, i:0))
datanode2_1  | 2022-06-28 01:19:21,833 [grpc-default-executor-1] INFO impl.VoteContext: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FOLLOWER: accept ELECTION from 3f49ce74-6987-463e-a960-954ebbba5f61: our priority 0 <= candidate's priority 0
datanode2_1  | 2022-06-28 01:19:21,841 [grpc-default-executor-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:3f49ce74-6987-463e-a960-954ebbba5f61
datanode2_1  | 2022-06-28 01:19:21,843 [grpc-default-executor-1] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:21,844 [grpc-default-executor-1] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:21,844 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState was interrupted
datanode2_1  | 2022-06-28 01:19:21,852 [grpc-default-executor-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70 replies to ELECTION vote request: 3f49ce74-6987-463e-a960-954ebbba5f61<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:OK-t1. Peer's state: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70:t1, leader=null, voted=3f49ce74-6987-463e-a960-954ebbba5f61, raftlog=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-06-28 01:19:42,343 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
datanode1_1  | 2022-06-28 01:19:42,343 [grpc-default-executor-1] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:42,343 [grpc-default-executor-1] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:42,347 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState was interrupted
datanode1_1  | 2022-06-28 01:19:42,349 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70 replies to ELECTION vote request: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-3f49ce74-6987-463e-a960-954ebbba5f61#0:OK-t5. Peer's state: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70:t5, leader=null, voted=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, raftlog=3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:19:47,438 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: receive requestVote(ELECTION, 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, group-FD99B4920D70, 6, (t:0, i:0))
datanode1_1  | 2022-06-28 01:19:47,438 [grpc-default-executor-1] INFO impl.VoteContext: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FOLLOWER: accept ELECTION from 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-06-28 01:19:47,439 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
datanode1_1  | 2022-06-28 01:19:47,439 [grpc-default-executor-1] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:47,439 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState was interrupted
datanode1_1  | 2022-06-28 01:19:47,439 [grpc-default-executor-1] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:47,443 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70 replies to ELECTION vote request: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-3f49ce74-6987-463e-a960-954ebbba5f61#0:OK-t6. Peer's state: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70:t6, leader=null, voted=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, raftlog=3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:19:47,467 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: receive requestVote(ELECTION, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, group-FD99B4920D70, 6, (t:0, i:0))
datanode1_1  | 2022-06-28 01:19:47,467 [grpc-default-executor-1] INFO impl.VoteContext: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FOLLOWER: reject ELECTION from 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: already has voted for 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa at current term 6
datanode1_1  | 2022-06-28 01:19:47,467 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70 replies to ELECTION vote request: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda<-3f49ce74-6987-463e-a960-954ebbba5f61#0:FAIL-t6. Peer's state: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70:t6, leader=null, voted=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, raftlog=3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:19:52,612 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: receive requestVote(ELECTION, 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, group-FD99B4920D70, 7, (t:0, i:0))
datanode1_1  | 2022-06-28 01:19:52,613 [grpc-default-executor-1] INFO impl.VoteContext: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FOLLOWER: accept ELECTION from 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-06-28 01:19:52,613 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from  FOLLOWER to FOLLOWER at term 7 for candidate:9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
datanode1_1  | 2022-06-28 01:19:52,613 [grpc-default-executor-1] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:52,613 [grpc-default-executor-1] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:52,613 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState was interrupted
datanode1_1  | 2022-06-28 01:19:52,624 [grpc-default-executor-1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70 replies to ELECTION vote request: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-3f49ce74-6987-463e-a960-954ebbba5f61#0:OK-t7. Peer's state: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70:t7, leader=null, voted=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, raftlog=3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:19:57,648 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5023782163ns, electionTimeout:5021ms
datanode1_1  | 2022-06-28 01:19:57,648 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:17,397 [pool-23-thread-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: start as a follower, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:19:17,399 [pool-23-thread-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-06-28 01:19:17,400 [pool-23-thread-1] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:17,400 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FD99B4920D70,id=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
datanode3_1  | 2022-06-28 01:19:21,780 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: receive requestVote(ELECTION, 3f49ce74-6987-463e-a960-954ebbba5f61, group-FD99B4920D70, 1, (t:0, i:0))
datanode3_1  | 2022-06-28 01:19:21,780 [grpc-default-executor-1] INFO impl.VoteContext: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FOLLOWER: reject ELECTION from 3f49ce74-6987-463e-a960-954ebbba5f61: our priority 1 > candidate's priority 0
datanode3_1  | 2022-06-28 01:19:21,780 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:3f49ce74-6987-463e-a960-954ebbba5f61
datanode3_1  | 2022-06-28 01:19:21,781 [grpc-default-executor-1] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:21,781 [grpc-default-executor-1] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:21,781 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState was interrupted
datanode3_1  | 2022-06-28 01:19:21,798 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70 replies to ELECTION vote request: 3f49ce74-6987-463e-a960-954ebbba5f61<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t1. Peer's state: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70:t1, leader=null, voted=null, raftlog=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:19:26,854 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: receive requestVote(ELECTION, 3f49ce74-6987-463e-a960-954ebbba5f61, group-FD99B4920D70, 2, (t:0, i:0))
datanode3_1  | 2022-06-28 01:19:26,855 [grpc-default-executor-1] INFO impl.VoteContext: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FOLLOWER: reject ELECTION from 3f49ce74-6987-463e-a960-954ebbba5f61: our priority 1 > candidate's priority 0
datanode3_1  | 2022-06-28 01:19:26,855 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:3f49ce74-6987-463e-a960-954ebbba5f61
datanode3_1  | 2022-06-28 01:19:26,855 [grpc-default-executor-1] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:26,855 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState was interrupted
datanode3_1  | 2022-06-28 01:19:26,856 [grpc-default-executor-1] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:26,860 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70 replies to ELECTION vote request: 3f49ce74-6987-463e-a960-954ebbba5f61<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t2. Peer's state: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70:t2, leader=null, voted=null, raftlog=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:19:27,981 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: receive requestVote(ELECTION, 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, group-FD99B4920D70, 2, (t:0, i:0))
datanode3_1  | 2022-06-28 01:19:27,982 [grpc-default-executor-1] INFO impl.VoteContext: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FOLLOWER: reject ELECTION from 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: our priority 1 > candidate's priority 0
datanode3_1  | 2022-06-28 01:19:27,982 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
datanode3_1  | 2022-06-28 01:19:27,982 [grpc-default-executor-1] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:27,982 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState was interrupted
datanode3_1  | 2022-06-28 01:19:27,983 [grpc-default-executor-1] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:27,983 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70 replies to ELECTION vote request: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t2. Peer's state: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70:t2, leader=null, voted=null, raftlog=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:19:31,961 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: receive requestVote(ELECTION, 3f49ce74-6987-463e-a960-954ebbba5f61, group-FD99B4920D70, 3, (t:0, i:0))
datanode3_1  | 2022-06-28 01:19:31,961 [grpc-default-executor-1] INFO impl.VoteContext: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FOLLOWER: reject ELECTION from 3f49ce74-6987-463e-a960-954ebbba5f61: our priority 1 > candidate's priority 0
datanode3_1  | 2022-06-28 01:19:31,961 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:3f49ce74-6987-463e-a960-954ebbba5f61
datanode3_1  | 2022-06-28 01:19:31,962 [grpc-default-executor-1] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:31,962 [grpc-default-executor-1] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:31,962 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState was interrupted
datanode3_1  | 2022-06-28 01:19:31,967 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70 replies to ELECTION vote request: 3f49ce74-6987-463e-a960-954ebbba5f61<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t3. Peer's state: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70:t3, leader=null, voted=null, raftlog=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:19:33,603 [Command processor thread] INFO server.RaftServer: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: addNew group-4EFFB6CB88EB:[4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-4EFFB6CB88EB:java.util.concurrent.CompletableFuture@22bd0ef1[Not completed]
datanode3_1  | 2022-06-28 01:19:33,605 [pool-23-thread-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: new RaftServerImpl for group-4EFFB6CB88EB:[4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-06-28 01:19:33,625 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-06-28 01:19:33,625 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-06-28 01:19:33,625 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-06-28 01:19:33,626 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-06-28 01:19:33,626 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-06-28 01:19:33,626 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-06-28 01:19:33,626 [pool-23-thread-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB: ConfigurationManager, init=-1: [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-06-28 01:19:33,626 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-06-28 01:19:33,626 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-06-28 01:19:33,626 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-06-28 01:19:33,626 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a6bcecaa-1423-464c-8db7-4effb6cb88eb does not exist. Creating ...
datanode3_1  | 2022-06-28 01:19:33,630 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a6bcecaa-1423-464c-8db7-4effb6cb88eb/in_use.lock acquired by nodename 7@472cd7b1c4f7
datanode3_1  | 2022-06-28 01:19:33,636 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a6bcecaa-1423-464c-8db7-4effb6cb88eb has been successfully formatted.
datanode3_1  | 2022-06-28 01:19:33,637 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-4EFFB6CB88EB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-06-28 01:19:33,641 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-06-28 01:19:33,645 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-06-28 01:19:33,653 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-06-28 01:19:33,662 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-06-28 01:19:33,684 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-06-28 01:19:33,685 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-06-28 01:19:33,704 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-06-28 01:19:33,708 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-06-28 01:19:33,709 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/a6bcecaa-1423-464c-8db7-4effb6cb88eb
datanode3_1  | 2022-06-28 01:19:33,711 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-06-28 01:19:33,711 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-06-28 01:19:33,712 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-06-28 01:19:33,712 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-06-28 01:19:33,712 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-06-28 01:19:33,712 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-06-28 01:19:33,714 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-06-28 01:19:33,714 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-06-28 01:19:33,714 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-06-28 01:19:33,751 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-06-28 01:19:33,753 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-06-28 01:19:33,755 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-06-28 01:19:33,764 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b;layoutVersion=3
om1_1        | 2022-06-28 01:18:36,437 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-06-28 01:18:47,038 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
datanode2_1  | 2022-06-28 01:19:26,880 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5033820643ns, electionTimeout:5031ms
datanode2_1  | 2022-06-28 01:19:26,881 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:26,881 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode2_1  | 2022-06-28 01:19:26,884 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-06-28 01:19:26,884 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection1
datanode2_1  | 2022-06-28 01:19:26,908 [grpc-default-executor-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: receive requestVote(ELECTION, 3f49ce74-6987-463e-a960-954ebbba5f61, group-FD99B4920D70, 2, (t:0, i:0))
datanode2_1  | 2022-06-28 01:19:26,911 [grpc-default-executor-1] INFO impl.VoteContext: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-CANDIDATE: reject ELECTION from 3f49ce74-6987-463e-a960-954ebbba5f61: already has voted for 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa at current term 2
datanode2_1  | 2022-06-28 01:19:26,911 [grpc-default-executor-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70 replies to ELECTION vote request: 3f49ce74-6987-463e-a960-954ebbba5f61<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:FAIL-t2. Peer's state: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70:t2, leader=null, voted=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, raftlog=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:19:26,912 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection1] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:19:28,025 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection1] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection1: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-06-28 01:19:28,028 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection1] INFO impl.LeaderElection:   Response 0: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t2
datanode2_1  | 2022-06-28 01:19:28,029 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection1] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection1 ELECTION round 0: result REJECTED
datanode2_1  | 2022-06-28 01:19:28,029 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode2_1  | 2022-06-28 01:19:28,034 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection1] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection1
datanode1_1  | 2022-06-28 01:19:57,649 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from  FOLLOWER to CANDIDATE at term 7 for changeToCandidate
datanode1_1  | 2022-06-28 01:19:57,649 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-06-28 01:19:57,649 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection7
datanode1_1  | 2022-06-28 01:19:57,660 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection7] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection7 ELECTION round 0: submit vote requests at term 8 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:19:57,695 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection7] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection7: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode1_1  | 2022-06-28 01:19:57,695 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection7] INFO impl.LeaderElection:   Response 0: 3f49ce74-6987-463e-a960-954ebbba5f61<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:OK-t8
datanode1_1  | 2022-06-28 01:19:57,695 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection7] INFO impl.LeaderElection:   Response 1: 3f49ce74-6987-463e-a960-954ebbba5f61<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t8
datanode1_1  | 2022-06-28 01:19:57,695 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection7] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection7 ELECTION round 0: result REJECTED
datanode1_1  | 2022-06-28 01:19:57,695 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection7] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from CANDIDATE to FOLLOWER at term 8 for REJECTED
datanode1_1  | 2022-06-28 01:19:57,695 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection7] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection7
datanode1_1  | 2022-06-28 01:19:57,695 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection7] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:19:59,981 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:1010156239454.
datanode1_1  | 2022-06-28 01:20:02,839 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5144148086ns, electionTimeout:5132ms
datanode1_1  | 2022-06-28 01:20:02,840 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:20:02,840 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from  FOLLOWER to CANDIDATE at term 8 for changeToCandidate
datanode1_1  | 2022-06-28 01:20:02,840 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-06-28 01:20:02,840 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection8
datanode1_1  | 2022-06-28 01:20:02,852 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection8] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection8 ELECTION round 0: submit vote requests at term 9 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:20:02,945 [grpc-default-executor-0] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: receive requestVote(ELECTION, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, group-FD99B4920D70, 9, (t:0, i:0))
datanode1_1  | 2022-06-28 01:20:02,945 [grpc-default-executor-0] INFO impl.VoteContext: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-CANDIDATE: reject ELECTION from 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: already has voted for 3f49ce74-6987-463e-a960-954ebbba5f61 at current term 9
datanode1_1  | 2022-06-28 01:20:02,946 [grpc-default-executor-0] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70 replies to ELECTION vote request: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda<-3f49ce74-6987-463e-a960-954ebbba5f61#0:FAIL-t9. Peer's state: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70:t9, leader=null, voted=3f49ce74-6987-463e-a960-954ebbba5f61, raftlog=3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0], old=null
datanode1_1  | 2022-06-28 01:20:03,030 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection8] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection8: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode1_1  | 2022-06-28 01:20:03,030 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection8] INFO impl.LeaderElection:   Response 0: 3f49ce74-6987-463e-a960-954ebbba5f61<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:FAIL-t9
datanode1_1  | 2022-06-28 01:20:03,030 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection8] INFO impl.LeaderElection:   Response 1: 3f49ce74-6987-463e-a960-954ebbba5f61<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t9
datanode1_1  | 2022-06-28 01:20:03,031 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection8] INFO impl.LeaderElection: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection8 ELECTION round 0: result REJECTED
datanode1_1  | 2022-06-28 01:20:03,031 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection8] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: changes role from CANDIDATE to FOLLOWER at term 9 for REJECTED
datanode1_1  | 2022-06-28 01:20:03,031 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection8] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: shutdown 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection8
datanode1_1  | 2022-06-28 01:20:03,033 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-LeaderElection8] INFO impl.RoleInfo: 3f49ce74-6987-463e-a960-954ebbba5f61: start 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-FollowerState
datanode1_1  | 2022-06-28 01:20:03,052 [3f49ce74-6987-463e-a960-954ebbba5f61-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-FD99B4920D70 with new leaderId: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
datanode1_1  | 2022-06-28 01:20:03,053 [3f49ce74-6987-463e-a960-954ebbba5f61-server-thread1] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: change Leader from null to 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda at term 9 for appendEntries, leader elected after 46524ms
datanode1_1  | 2022-06-28 01:20:03,125 [3f49ce74-6987-463e-a960-954ebbba5f61-server-thread2] INFO server.RaftServer$Division: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70: set configuration 0: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-06-28 01:20:03,127 [3f49ce74-6987-463e-a960-954ebbba5f61-server-thread2] INFO segmented.SegmentedRaftLogWorker: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-06-28 01:20:03,133 [3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3f49ce74-6987-463e-a960-954ebbba5f61@group-FD99B4920D70-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70/current/log_inprogress_0
datanode1_1  | 2022-06-28 01:20:16,631 [java.util.concurrent.ThreadPoolExecutor$Worker@7c14eb9c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5,entriesCount=1,lastEntry=(t:1, i:0)
datanode1_1  | 2022-06-28 01:20:59,869 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=229,entriesCount=1,lastEntry=(t:1, i:1)
datanode1_1  | 2022-06-28 01:20:59,974 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=230,entriesCount=1,lastEntry=(t:1, i:2)
datanode1_1  | 2022-06-28 01:21:01,319 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=231,entriesCount=1,lastEntry=(t:1, i:3)
datanode1_1  | 2022-06-28 01:21:01,355 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=234,entriesCount=1,lastEntry=(t:1, i:4)
datanode1_1  | 2022-06-28 01:22:17,389 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=297,entriesCount=1,lastEntry=(t:1, i:5)
datanode1_1  | 2022-06-28 01:22:17,414 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=298,entriesCount=1,lastEntry=(t:1, i:6)
datanode1_1  | 2022-06-28 01:22:17,416 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=299,entriesCount=1,lastEntry=(t:1, i:7)
datanode1_1  | 2022-06-28 01:22:17,446 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=303,entriesCount=1,lastEntry=(t:1, i:8)
datanode1_1  | 2022-06-28 01:23:27,646 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=531,entriesCount=1,lastEntry=(t:1, i:9)
datanode1_1  | 2022-06-28 01:23:27,664 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=532,entriesCount=1,lastEntry=(t:1, i:10)
datanode1_1  | 2022-06-28 01:23:27,673 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=533,entriesCount=1,lastEntry=(t:1, i:11)
datanode1_1  | 2022-06-28 01:23:44,257 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=734,entriesCount=1,lastEntry=(t:1, i:12)
datanode1_1  | 2022-06-28 01:23:44,274 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=735,entriesCount=1,lastEntry=(t:1, i:13)
datanode1_1  | 2022-06-28 01:23:44,286 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=737,entriesCount=1,lastEntry=(t:1, i:14)
datanode1_1  | 2022-06-28 01:23:44,309 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=739,entriesCount=1,lastEntry=(t:1, i:15)
datanode1_1  | 2022-06-28 01:27:56,239 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=879,entriesCount=1,lastEntry=(t:1, i:16)
datanode1_1  | 2022-06-28 01:27:56,246 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=880,entriesCount=1,lastEntry=(t:1, i:17)
datanode1_1  | 2022-06-28 01:27:56,262 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=881,entriesCount=1,lastEntry=(t:1, i:18)
datanode1_1  | 2022-06-28 01:27:56,291 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=884,entriesCount=1,lastEntry=(t:1, i:19)
datanode1_1  | 2022-06-28 01:27:59,875 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1033,entriesCount=1,lastEntry=(t:1, i:20)
datanode1_1  | 2022-06-28 01:27:59,924 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1034,entriesCount=1,lastEntry=(t:1, i:21)
datanode1_1  | 2022-06-28 01:27:59,991 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1035,entriesCount=1,lastEntry=(t:1, i:22)
datanode1_1  | 2022-06-28 01:28:00,044 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1041,entriesCount=1,lastEntry=(t:1, i:23)
datanode1_1  | 2022-06-28 01:28:01,093 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1070,entriesCount=1,lastEntry=(t:1, i:24)
datanode1_1  | 2022-06-28 01:28:01,106 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1071,entriesCount=1,lastEntry=(t:1, i:25)
datanode1_1  | 2022-06-28 01:28:01,111 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1072,entriesCount=1,lastEntry=(t:1, i:26)
datanode1_1  | 2022-06-28 01:28:01,122 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1073,entriesCount=1,lastEntry=(t:1, i:27)
datanode1_1  | 2022-06-28 01:28:03,906 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1242,entriesCount=1,lastEntry=(t:1, i:28)
datanode1_1  | 2022-06-28 01:28:04,322 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1243,entriesCount=1,lastEntry=(t:1, i:29)
datanode1_1  | 2022-06-28 01:28:04,400 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1248,entriesCount=1,lastEntry=(t:1, i:30)
datanode1_1  | 2022-06-28 01:28:04,851 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1287,entriesCount=1,lastEntry=(t:1, i:31)
datanode1_1  | 2022-06-28 01:28:04,976 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1298,entriesCount=1,lastEntry=(t:1, i:32)
datanode1_1  | 2022-06-28 01:28:05,013 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1302,entriesCount=1,lastEntry=(t:1, i:33)
datanode1_1  | 2022-06-28 01:28:05,073 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1309,entriesCount=1,lastEntry=(t:1, i:34)
datanode1_1  | 2022-06-28 01:28:05,092 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1311,entriesCount=1,lastEntry=(t:1, i:35)
datanode1_1  | 2022-06-28 01:28:06,123 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1335,entriesCount=1,lastEntry=(t:1, i:36)
datanode1_1  | 2022-06-28 01:28:06,270 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1336,entriesCount=1,lastEntry=(t:1, i:37)
datanode1_1  | 2022-06-28 01:28:06,499 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1353,entriesCount=1,lastEntry=(t:1, i:38)
datanode1_1  | 2022-06-28 01:28:06,694 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1369,entriesCount=1,lastEntry=(t:1, i:39)
datanode2_1  | 2022-06-28 01:19:28,034 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection1] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:31,954 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: receive requestVote(ELECTION, 3f49ce74-6987-463e-a960-954ebbba5f61, group-FD99B4920D70, 3, (t:0, i:0))
datanode2_1  | 2022-06-28 01:19:31,954 [grpc-default-executor-0] INFO impl.VoteContext: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FOLLOWER: accept ELECTION from 3f49ce74-6987-463e-a960-954ebbba5f61: our priority 0 <= candidate's priority 0
datanode2_1  | 2022-06-28 01:19:31,955 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:3f49ce74-6987-463e-a960-954ebbba5f61
datanode2_1  | 2022-06-28 01:19:31,955 [grpc-default-executor-0] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:31,955 [grpc-default-executor-0] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:31,955 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState was interrupted
datanode2_1  | 2022-06-28 01:19:31,967 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70 replies to ELECTION vote request: 3f49ce74-6987-463e-a960-954ebbba5f61<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:OK-t3. Peer's state: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70:t3, leader=null, voted=3f49ce74-6987-463e-a960-954ebbba5f61, raftlog=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:19:33,197 [Command processor thread] INFO server.RaftServer: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: addNew group-F89EB01CBA86:[9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-F89EB01CBA86:java.util.concurrent.CompletableFuture@64e3035d[Not completed]
datanode2_1  | 2022-06-28 01:19:33,201 [pool-23-thread-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: new RaftServerImpl for group-F89EB01CBA86:[9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-06-28 01:19:33,202 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-06-28 01:19:33,202 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-06-28 01:19:33,202 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-06-28 01:19:33,202 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-06-28 01:19:33,202 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-06-28 01:19:33,203 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-06-28 01:19:33,204 [pool-23-thread-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86: ConfigurationManager, init=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-06-28 01:19:33,204 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-06-28 01:19:33,205 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-06-28 01:19:33,205 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-06-28 01:19:33,205 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e107ff30-8061-4f60-8349-f89eb01cba86 does not exist. Creating ...
datanode2_1  | 2022-06-28 01:19:33,208 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e107ff30-8061-4f60-8349-f89eb01cba86/in_use.lock acquired by nodename 6@65eb9f967bad
datanode2_1  | 2022-06-28 01:19:33,212 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e107ff30-8061-4f60-8349-f89eb01cba86 has been successfully formatted.
datanode2_1  | 2022-06-28 01:19:33,213 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-F89EB01CBA86: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-06-28 01:19:33,245 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-06-28 01:19:33,245 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-06-28 01:19:33,245 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-06-28 01:19:33,245 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-06-28 01:19:33,245 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-06-28 01:19:33,246 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-06-28 01:19:33,246 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-06-28 01:19:33,247 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-06-28 01:19:33,301 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e107ff30-8061-4f60-8349-f89eb01cba86
datanode2_1  | 2022-06-28 01:19:33,340 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-06-28 01:19:33,340 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-06-28 01:19:33,341 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-06-28 01:19:33,341 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-06-28 01:19:33,341 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-06-28 01:19:33,341 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-06-28 01:19:33,341 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
kdc_1        | Jun 28 01:22:52 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379372, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:22:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379372, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:23:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379372, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:23:02 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379382, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:23:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379382, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:23:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379382, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:23:11 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379391, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:23:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379391, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:23:16 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379396, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:23:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379396, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:23:20 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379400, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:23:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379400, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:23:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379400, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:23:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379400, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:23:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379400, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:23:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:23:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:23:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379400, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode3_1  | 2022-06-28 01:19:33,785 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-06-28 01:19:33,785 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-06-28 01:19:33,785 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-06-28 01:19:33,786 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-06-28 01:19:33,786 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-06-28 01:19:33,787 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-06-28 01:19:33,788 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-06-28 01:19:33,799 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-06-28 01:19:33,819 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-06-28 01:19:33,865 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-06-28 01:19:33,890 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-06-28 01:19:33,892 [pool-23-thread-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB: start as a follower, conf=-1: [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-06-28 01:19:33,892 [pool-23-thread-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-06-28 01:19:33,892 [pool-23-thread-1] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-FollowerState
datanode3_1  | 2022-06-28 01:19:33,900 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4EFFB6CB88EB,id=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
datanode3_1  | 2022-06-28 01:19:33,906 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=a6bcecaa-1423-464c-8db7-4effb6cb88eb
datanode3_1  | 2022-06-28 01:19:33,907 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=a6bcecaa-1423-464c-8db7-4effb6cb88eb.
datanode3_1  | 2022-06-28 01:19:37,061 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5099132914ns, electionTimeout:5094ms
datanode3_1  | 2022-06-28 01:19:37,061 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:37,063 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode3_1  | 2022-06-28 01:19:37,065 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-06-28 01:19:37,066 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection1
datanode3_1  | 2022-06-28 01:19:37,096 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection1] INFO impl.LeaderElection: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection1 ELECTION round 0: submit vote requests at term 4 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:19:37,211 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: receive requestVote(ELECTION, 3f49ce74-6987-463e-a960-954ebbba5f61, group-FD99B4920D70, 4, (t:0, i:0))
datanode3_1  | 2022-06-28 01:19:37,212 [grpc-default-executor-1] INFO impl.VoteContext: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-CANDIDATE: reject ELECTION from 3f49ce74-6987-463e-a960-954ebbba5f61: already has voted for 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda at current term 4
datanode3_1  | 2022-06-28 01:19:37,215 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70 replies to ELECTION vote request: 3f49ce74-6987-463e-a960-954ebbba5f61<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t4. Peer's state: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70:t4, leader=null, voted=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, raftlog=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:19:37,237 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: receive requestVote(ELECTION, 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, group-FD99B4920D70, 4, (t:0, i:0))
datanode3_1  | 2022-06-28 01:19:37,237 [grpc-default-executor-1] INFO impl.VoteContext: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-CANDIDATE: reject ELECTION from 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: already has voted for 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda at current term 4
datanode3_1  | 2022-06-28 01:19:37,237 [grpc-default-executor-1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70 replies to ELECTION vote request: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t4. Peer's state: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70:t4, leader=null, voted=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, raftlog=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:19:38,244 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection1] INFO impl.LeaderElection: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode1_1  | 2022-06-28 01:28:06,730 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1370,entriesCount=1,lastEntry=(t:1, i:40)
datanode1_1  | 2022-06-28 01:28:06,783 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1374,entriesCount=1,lastEntry=(t:1, i:41)
datanode1_1  | 2022-06-28 01:28:06,819 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1379,entriesCount=1,lastEntry=(t:1, i:42)
datanode1_1  | 2022-06-28 01:28:06,849 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1382,entriesCount=1,lastEntry=(t:1, i:43)
datanode1_1  | 2022-06-28 01:29:13,116 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1506,entriesCount=1,lastEntry=(t:1, i:44)
datanode1_1  | 2022-06-28 01:29:13,122 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1507,entriesCount=1,lastEntry=(t:1, i:45)
datanode1_1  | 2022-06-28 01:29:13,130 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1508,entriesCount=1,lastEntry=(t:1, i:46)
datanode1_1  | 2022-06-28 01:29:13,150 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1510,entriesCount=1,lastEntry=(t:1, i:47)
datanode1_1  | 2022-06-28 01:29:16,260 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1739,entriesCount=1,lastEntry=(t:1, i:48)
datanode1_1  | 2022-06-28 01:29:16,260 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1740,entriesCount=1,lastEntry=(t:1, i:49)
datanode1_1  | 2022-06-28 01:29:16,293 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1741,entriesCount=1,lastEntry=(t:1, i:50)
datanode1_1  | 2022-06-28 01:29:16,293 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1742,entriesCount=1,lastEntry=(t:1, i:51)
datanode1_1  | 2022-06-28 01:29:21,628 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1905,entriesCount=1,lastEntry=(t:1, i:52)
datanode1_1  | 2022-06-28 01:29:21,637 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1906,entriesCount=1,lastEntry=(t:1, i:53)
datanode1_1  | 2022-06-28 01:29:21,658 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1907,entriesCount=1,lastEntry=(t:1, i:54)
datanode1_1  | 2022-06-28 01:29:21,807 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1908,entriesCount=1,lastEntry=(t:1, i:55)
datanode1_1  | 2022-06-28 01:29:21,808 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1909,entriesCount=1,lastEntry=(t:1, i:56)
datanode1_1  | 2022-06-28 01:29:21,821 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1911,entriesCount=1,lastEntry=(t:1, i:57)
datanode1_1  | 2022-06-28 01:29:32,813 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2025,entriesCount=1,lastEntry=(t:1, i:58)
datanode1_1  | 2022-06-28 01:29:32,826 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2026,entriesCount=1,lastEntry=(t:1, i:59)
datanode1_1  | 2022-06-28 01:29:32,866 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2027,entriesCount=1,lastEntry=(t:1, i:60)
datanode1_1  | 2022-06-28 01:29:33,019 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2029,entriesCount=1,lastEntry=(t:1, i:61)
datanode1_1  | 2022-06-28 01:29:33,026 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2030,entriesCount=1,lastEntry=(t:1, i:62)
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | 2022-06-28 01:19:38,245 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection1] INFO impl.LeaderElection:   Response 0: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:FAIL-t4
datanode3_1  | 2022-06-28 01:19:38,245 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection1] INFO impl.LeaderElection:   Response 1: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda<-3f49ce74-6987-463e-a960-954ebbba5f61#0:FAIL-t4
datanode3_1  | 2022-06-28 01:19:38,245 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection1] INFO impl.LeaderElection: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection1 ELECTION round 0: result REJECTED
datanode3_1  | 2022-06-28 01:19:38,246 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection1] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode3_1  | 2022-06-28 01:19:38,246 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection1] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection1
datanode3_1  | 2022-06-28 01:19:38,246 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection1] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:38,970 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-FollowerState] INFO impl.FollowerState: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5077540498ns, electionTimeout:5069ms
datanode3_1  | 2022-06-28 01:19:38,970 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-FollowerState] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-FollowerState
datanode3_1  | 2022-06-28 01:19:38,970 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-FollowerState] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-06-28 01:19:38,970 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-06-28 01:19:38,971 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-FollowerState] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2
datanode3_1  | 2022-06-28 01:19:38,973 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO impl.LeaderElection: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-06-28 01:19:38,973 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO impl.LeaderElection: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2022-06-28 01:19:38,974 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2
datanode3_1  | 2022-06-28 01:19:38,974 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-06-28 01:19:38,974 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4EFFB6CB88EB with new leaderId: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
datanode3_1  | 2022-06-28 01:19:38,974 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB: change Leader from null to 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda at term 1 for becomeLeader, leader elected after 5333ms
datanode3_1  | 2022-06-28 01:19:38,976 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-06-28 01:19:39,033 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-06-28 01:19:39,042 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-06-28 01:19:39,053 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-06-28 01:19:39,056 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-06-28 01:19:39,056 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-06-28 01:19:39,063 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-06-28 01:19:39,089 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-06-28 01:19:39,115 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderStateImpl
datanode3_1  | 2022-06-28 01:19:39,127 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-06-28 01:19:39,129 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a6bcecaa-1423-464c-8db7-4effb6cb88eb/current/log_inprogress_0
datanode3_1  | 2022-06-28 01:19:39,137 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB-LeaderElection2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-4EFFB6CB88EB: set configuration 0: [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-06-28 01:19:42,309 [grpc-default-executor-2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: receive requestVote(ELECTION, 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, group-FD99B4920D70, 5, (t:0, i:0))
datanode3_1  | 2022-06-28 01:19:42,309 [grpc-default-executor-2] INFO impl.VoteContext: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FOLLOWER: reject ELECTION from 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: our priority 1 > candidate's priority 0
datanode3_1  | 2022-06-28 01:19:42,310 [grpc-default-executor-2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
datanode3_1  | 2022-06-28 01:19:42,310 [grpc-default-executor-2] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:42,310 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState was interrupted
datanode3_1  | 2022-06-28 01:19:42,311 [grpc-default-executor-2] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:42,320 [grpc-default-executor-2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70 replies to ELECTION vote request: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t5. Peer's state: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70:t5, leader=null, voted=null, raftlog=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:19:47,423 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5111786605ns, electionTimeout:5109ms
datanode3_1  | 2022-06-28 01:19:47,424 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:47,424 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
datanode3_1  | 2022-06-28 01:19:47,425 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-06-28 01:19:47,426 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection3
datanode3_1  | 2022-06-28 01:19:47,448 [grpc-default-executor-2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: receive requestVote(ELECTION, 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, group-FD99B4920D70, 6, (t:0, i:0))
datanode3_1  | 2022-06-28 01:19:47,450 [grpc-default-executor-2] INFO impl.VoteContext: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-CANDIDATE: reject ELECTION from 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: already has voted for 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda at current term 6
datanode3_1  | 2022-06-28 01:19:47,450 [grpc-default-executor-2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70 replies to ELECTION vote request: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t6. Peer's state: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70:t6, leader=null, voted=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, raftlog=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:19:47,452 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection3] INFO impl.LeaderElection: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection3 ELECTION round 0: submit vote requests at term 6 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:19:47,482 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection3] INFO impl.LeaderElection: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection3: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-06-28 01:19:47,482 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection3] INFO impl.LeaderElection:   Response 0: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:FAIL-t6
datanode3_1  | 2022-06-28 01:19:47,482 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection3] INFO impl.LeaderElection:   Response 1: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda<-3f49ce74-6987-463e-a960-954ebbba5f61#0:FAIL-t6
datanode3_1  | 2022-06-28 01:19:47,482 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection3] INFO impl.LeaderElection: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection3 ELECTION round 0: result REJECTED
datanode3_1  | 2022-06-28 01:19:47,483 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection3] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: changes role from CANDIDATE to FOLLOWER at term 6 for REJECTED
datanode3_1  | 2022-06-28 01:19:47,483 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection3] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection3
datanode3_1  | 2022-06-28 01:19:47,483 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection3] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:52,612 [grpc-default-executor-2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: receive requestVote(ELECTION, 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, group-FD99B4920D70, 7, (t:0, i:0))
datanode3_1  | 2022-06-28 01:19:52,612 [grpc-default-executor-2] INFO impl.VoteContext: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FOLLOWER: reject ELECTION from 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: our priority 1 > candidate's priority 0
datanode3_1  | 2022-06-28 01:19:52,612 [grpc-default-executor-2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: changes role from  FOLLOWER to FOLLOWER at term 7 for candidate:9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
datanode3_1  | 2022-06-28 01:19:52,613 [grpc-default-executor-2] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:52,613 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState was interrupted
datanode3_1  | 2022-06-28 01:19:52,614 [grpc-default-executor-2] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
kdc_1        | Jun 28 01:23:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379400, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:23:48 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379428, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:23:52 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379428, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:23:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379428, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:24:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379428, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:24:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379428, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:24:07 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379447, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:24:07 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379447, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:24:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379447, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:24:12 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379452, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:24:12 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379452, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:24:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379452, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:24:16 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379456, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:24:16 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379456, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:24:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379456, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:24:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379456, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:24:26 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379466, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:24:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379466, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:24:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379466, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:24:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379466, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:24:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:24:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:24:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379466, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:24:44 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379484, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:24:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379484, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:24:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379484, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:25:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379484, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:25:04 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379504, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:25:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379504, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:25:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379504, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:25:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379504, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:25:18 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379518, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:25:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379518, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:25:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379518, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:25:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379518, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode1_1  | 2022-06-28 01:29:33,042 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2032,entriesCount=1,lastEntry=(t:1, i:63)
datanode1_1  | 2022-06-28 01:29:36,279 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2278,entriesCount=1,lastEntry=(t:1, i:64)
datanode1_1  | 2022-06-28 01:29:36,297 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2279,entriesCount=1,lastEntry=(t:1, i:65)
datanode1_1  | 2022-06-28 01:29:36,341 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2280,entriesCount=1,lastEntry=(t:1, i:66)
datanode1_1  | 2022-06-28 01:29:36,347 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2282,entriesCount=1,lastEntry=(t:1, i:67)
datanode1_1  | 2022-06-28 01:29:42,138 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2447,entriesCount=1,lastEntry=(t:1, i:68)
datanode1_1  | 2022-06-28 01:29:42,387 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2448,entriesCount=1,lastEntry=(t:1, i:69)
datanode1_1  | 2022-06-28 01:29:42,388 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2449,entriesCount=1,lastEntry=(t:1, i:70)
datanode1_1  | 2022-06-28 01:29:42,391 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2450,entriesCount=1,lastEntry=(t:1, i:71)
datanode1_1  | 2022-06-28 01:29:42,477 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2457,entriesCount=1,lastEntry=(t:1, i:72)
datanode1_1  | 2022-06-28 01:29:42,612 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2464,entriesCount=1,lastEntry=(t:1, i:73)
datanode1_1  | 2022-06-28 01:29:42,645 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2467,entriesCount=1,lastEntry=(t:1, i:74)
datanode1_1  | 2022-06-28 01:29:42,837 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2486,entriesCount=1,lastEntry=(t:1, i:75)
datanode1_1  | 2022-06-28 01:29:42,841 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2487,entriesCount=1,lastEntry=(t:1, i:76)
datanode1_1  | 2022-06-28 01:29:43,049 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2501,entriesCount=1,lastEntry=(t:1, i:77)
datanode1_1  | 2022-06-28 01:29:49,302 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2741,entriesCount=1,lastEntry=(t:1, i:78)
datanode1_1  | 2022-06-28 01:29:49,337 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2742,entriesCount=1,lastEntry=(t:1, i:79)
datanode1_1  | 2022-06-28 01:29:49,381 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2743,entriesCount=1,lastEntry=(t:1, i:80)
datanode1_1  | 2022-06-28 01:29:49,433 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2744,entriesCount=1,lastEntry=(t:1, i:81)
datanode1_1  | 2022-06-28 01:29:49,440 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2745,entriesCount=1,lastEntry=(t:1, i:82)
datanode1_1  | 2022-06-28 01:29:49,451 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2746,entriesCount=1,lastEntry=(t:1, i:83)
datanode1_1  | 2022-06-28 01:29:52,451 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2862,entriesCount=1,lastEntry=(t:1, i:84)
datanode1_1  | 2022-06-28 01:29:52,464 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2863,entriesCount=1,lastEntry=(t:1, i:85)
kdc_1        | Jun 28 01:25:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:25:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:26:24 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379584, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:26:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379584, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:26:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.114: ISSUE: authtime 1656379009, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:26:34 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379594, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:26:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379594, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:26:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:26:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:26:48 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379608, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:26:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379608, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:27:08 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379628, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:27:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379628, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:27:19 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379639, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:27:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379639, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:27:28 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379648, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:27:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379648, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2022-06-28 01:19:33,341 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-06-28 01:19:33,342 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-06-28 01:19:33,344 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-06-28 01:19:33,348 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-06-28 01:19:33,349 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-06-28 01:19:33,350 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-06-28 01:19:33,354 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-06-28 01:19:33,355 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-06-28 01:19:33,355 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-06-28 01:19:33,355 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-06-28 01:19:33,355 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-06-28 01:19:33,359 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-06-28 01:19:33,361 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-06-28 01:19:33,363 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-06-28 01:19:33,366 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-06-28 01:19:33,367 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-06-28 01:19:33,367 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-06-28 01:19:33,367 [pool-23-thread-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86: start as a follower, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-06-28 01:19:33,367 [pool-23-thread-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-06-28 01:19:33,367 [pool-23-thread-1] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-FollowerState
datanode2_1  | 2022-06-28 01:19:33,369 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F89EB01CBA86,id=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
datanode2_1  | 2022-06-28 01:19:33,386 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=e107ff30-8061-4f60-8349-f89eb01cba86
datanode2_1  | 2022-06-28 01:19:33,387 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=e107ff30-8061-4f60-8349-f89eb01cba86.
datanode2_1  | 2022-06-28 01:19:37,135 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5167687282ns, electionTimeout:5154ms
datanode2_1  | 2022-06-28 01:19:37,135 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:37,136 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode2_1  | 2022-06-28 01:19:37,136 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-06-28 01:19:37,136 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection2
datanode2_1  | 2022-06-28 01:19:37,143 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection2] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection2 ELECTION round 0: submit vote requests at term 4 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:19:37,198 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: receive requestVote(ELECTION, 3f49ce74-6987-463e-a960-954ebbba5f61, group-FD99B4920D70, 4, (t:0, i:0))
datanode2_1  | 2022-06-28 01:19:37,199 [grpc-default-executor-0] INFO impl.VoteContext: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-CANDIDATE: reject ELECTION from 3f49ce74-6987-463e-a960-954ebbba5f61: already has voted for 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa at current term 4
datanode2_1  | 2022-06-28 01:19:37,200 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70 replies to ELECTION vote request: 3f49ce74-6987-463e-a960-954ebbba5f61<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:FAIL-t4. Peer's state: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70:t4, leader=null, voted=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, raftlog=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:19:37,241 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection2] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2022-06-28 01:19:37,242 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection2] INFO impl.LeaderElection:   Response 0: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t4
datanode2_1  | 2022-06-28 01:19:37,242 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection2] INFO impl.LeaderElection:   Response 1: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-3f49ce74-6987-463e-a960-954ebbba5f61#0:FAIL-t4
datanode2_1  | 2022-06-28 01:19:37,242 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection2] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection2 ELECTION round 0: result REJECTED
datanode2_1  | 2022-06-28 01:19:37,242 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection2] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode2_1  | 2022-06-28 01:19:37,242 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection2] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection2
datanode2_1  | 2022-06-28 01:19:37,243 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection2] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:38,214 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: receive requestVote(ELECTION, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, group-FD99B4920D70, 4, (t:0, i:0))
datanode2_1  | 2022-06-28 01:19:38,214 [grpc-default-executor-0] INFO impl.VoteContext: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FOLLOWER: reject ELECTION from 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: already has voted for 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa at current term 4
datanode2_1  | 2022-06-28 01:19:38,214 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70 replies to ELECTION vote request: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:FAIL-t4. Peer's state: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70:t4, leader=null, voted=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, raftlog=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:19:38,461 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-FollowerState] INFO impl.FollowerState: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5093501238ns, electionTimeout:5079ms
datanode2_1  | 2022-06-28 01:19:38,461 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-FollowerState] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-FollowerState
datanode2_1  | 2022-06-28 01:19:38,462 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-FollowerState] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-06-28 01:19:38,462 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-06-28 01:19:38,462 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-FollowerState] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3
datanode2_1  | 2022-06-28 01:19:38,482 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-06-28 01:19:38,482 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2022-06-28 01:19:38,498 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3
datanode2_1  | 2022-06-28 01:19:38,499 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-06-28 01:19:38,499 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-F89EB01CBA86 with new leaderId: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
datanode2_1  | 2022-06-28 01:19:38,513 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86: change Leader from null to 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa at term 1 for becomeLeader, leader elected after 5285ms
datanode2_1  | 2022-06-28 01:19:38,533 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-06-28 01:19:38,553 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-06-28 01:19:38,560 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-06-28 01:19:38,584 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-06-28 01:19:38,585 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-06-28 01:19:38,594 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-06-28 01:19:38,609 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-06-28 01:19:38,611 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-06-28 01:19:38,614 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderStateImpl
datanode2_1  | 2022-06-28 01:19:38,622 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-06-28 01:19:38,628 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e107ff30-8061-4f60-8349-f89eb01cba86/current/log_inprogress_0
datanode2_1  | 2022-06-28 01:19:38,637 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86-LeaderElection3] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-F89EB01CBA86: set configuration 0: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
kdc_1        | Jun 28 01:27:37 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379657, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:27:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379657, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:27:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:27:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:27:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379657, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:27:51 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379671, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:27:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379671, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:28:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:28:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:29:17 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379757, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:29:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379757, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:29:33 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379773, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:29:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379773, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:29:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:29:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:29:54 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379794, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:30:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379794, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:30:12 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379812, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-06-28 01:18:47,123 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-06-28 01:18:54,178 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-06-28 01:18:55,754 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-06-28 01:18:56,388 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-06-28 01:18:56,391 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-06-28 01:18:56,391 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-06-28 01:18:56,540 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-06-28 01:18:56,827 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om1_1        | 2022-06-28 01:18:58,869 [main] INFO reflections.Reflections: Reflections took 1686 ms to scan 1 urls, producing 113 keys and 337 values [using 2 cores]
om1_1        | 2022-06-28 01:19:00,460 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-06-28 01:19:00,462 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-06-28 01:19:00,463 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-06-28 01:19:03,194 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-06-28 01:19:03,416 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-06-28 01:19:06,955 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2022-06-28 01:19:07,555 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2022-06-28 01:19:07,563 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/1010782356592.crt.
om1_1        | 2022-06-28 01:19:07,581 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-916105677270.crt.
om1_1        | 2022-06-28 01:19:07,801 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-06-28 01:19:08,587 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-06-28 01:19:08,596 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-06-28 01:19:09,601 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om1_1        | 2022-06-28 01:19:09,657 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2022-06-28 01:19:09,682 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2022-06-28 01:19:10,275 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om1_1        | 2022-06-28 01:19:10,916 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-06-28 01:19:10,923 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2022-06-28 01:19:10,979 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2022-06-28 01:19:12,141 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2022-06-28 01:19:12,368 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-06-28 01:19:12,824 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om1:9872, om3:9872, om2:9872
om1_1        | 2022-06-28 01:19:12,928 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2022-06-28 01:19:14,774 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2022-06-28 01:19:15,866 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2022-06-28 01:19:15,879 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
datanode1_1  | 2022-06-28 01:29:52,465 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2864,entriesCount=1,lastEntry=(t:1, i:86)
datanode1_1  | 2022-06-28 01:29:52,918 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2865,entriesCount=1,lastEntry=(t:1, i:87)
datanode1_1  | 2022-06-28 01:29:52,926 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2866,entriesCount=1,lastEntry=(t:1, i:88)
datanode1_1  | 2022-06-28 01:29:52,938 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2868,entriesCount=1,lastEntry=(t:1, i:89)
datanode1_1  | 2022-06-28 01:29:57,842 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2886,entriesCount=1,lastEntry=(t:1, i:90)
datanode1_1  | 2022-06-28 01:29:58,134 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2888,entriesCount=1,lastEntry=(t:1, i:91)
datanode1_1  | 2022-06-28 01:29:58,149 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2889,entriesCount=1,lastEntry=(t:1, i:92)
datanode1_1  | 2022-06-28 01:29:58,174 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2891,entriesCount=1,lastEntry=(t:1, i:93)
datanode1_1  | 2022-06-28 01:29:58,239 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2898,entriesCount=1,lastEntry=(t:1, i:94)
datanode1_1  | 2022-06-28 01:29:58,331 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2906,entriesCount=1,lastEntry=(t:1, i:95)
datanode1_1  | 2022-06-28 01:29:58,354 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2910,entriesCount=1,lastEntry=(t:1, i:96)
datanode1_1  | 2022-06-28 01:29:58,354 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2911,entriesCount=1,lastEntry=(t:1, i:97)
datanode1_1  | 2022-06-28 01:30:04,345 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3146,entriesCount=1,lastEntry=(t:1, i:98)
datanode1_1  | 2022-06-28 01:30:04,443 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3147,entriesCount=1,lastEntry=(t:1, i:99)
datanode1_1  | 2022-06-28 01:30:04,444 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3148,entriesCount=1,lastEntry=(t:1, i:100)
datanode1_1  | 2022-06-28 01:30:04,481 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3151,entriesCount=1,lastEntry=(t:1, i:101)
datanode1_1  | 2022-06-28 01:30:04,506 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3153,entriesCount=1,lastEntry=(t:1, i:102)
datanode1_1  | 2022-06-28 01:30:04,581 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3159,entriesCount=1,lastEntry=(t:1, i:103)
datanode1_1  | 2022-06-28 01:30:04,596 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3163,entriesCount=1,lastEntry=(t:1, i:104)
datanode1_1  | 2022-06-28 01:30:04,606 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3164,entriesCount=1,lastEntry=(t:1, i:105)
datanode1_1  | 2022-06-28 01:30:10,233 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3278,entriesCount=1,lastEntry=(t:1, i:106)
datanode1_1  | 2022-06-28 01:30:10,402 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3279,entriesCount=1,lastEntry=(t:1, i:107)
datanode1_1  | 2022-06-28 01:30:10,447 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3280,entriesCount=1,lastEntry=(t:1, i:108)
datanode1_1  | 2022-06-28 01:30:10,487 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3282,entriesCount=1,lastEntry=(t:1, i:109)
datanode1_1  | 2022-06-28 01:30:10,514 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3285,entriesCount=1,lastEntry=(t:1, i:110)
datanode1_1  | 2022-06-28 01:30:10,514 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3286,entriesCount=1,lastEntry=(t:1, i:111)
datanode1_1  | 2022-06-28 01:30:10,544 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3290,entriesCount=1,lastEntry=(t:1, i:112)
datanode1_1  | 2022-06-28 01:30:10,553 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3293,entriesCount=1,lastEntry=(t:1, i:113)
datanode1_1  | 2022-06-28 01:30:12,629 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3311,entriesCount=1,lastEntry=(t:1, i:114)
datanode1_1  | 2022-06-28 01:30:12,738 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3312,entriesCount=1,lastEntry=(t:1, i:115)
datanode1_1  | 2022-06-28 01:30:12,909 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3330,entriesCount=1,lastEntry=(t:1, i:116)
datanode1_1  | 2022-06-28 01:30:13,042 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3338,entriesCount=1,lastEntry=(t:1, i:117)
datanode1_1  | 2022-06-28 01:30:13,042 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3339,entriesCount=1,lastEntry=(t:1, i:118)
datanode1_1  | 2022-06-28 01:30:13,043 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3341,entriesCount=1,lastEntry=(t:1, i:119)
datanode1_1  | 2022-06-28 01:30:13,092 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3346,entriesCount=1,lastEntry=(t:1, i:120)
datanode1_1  | 2022-06-28 01:30:13,102 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3347,entriesCount=1,lastEntry=(t:1, i:121)
datanode1_1  | 2022-06-28 01:30:40,373 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3373,entriesCount=1,lastEntry=(t:1, i:122)
datanode1_1  | 2022-06-28 01:30:40,381 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3374,entriesCount=1,lastEntry=(t:1, i:123)
datanode1_1  | 2022-06-28 01:30:40,391 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3375,entriesCount=1,lastEntry=(t:1, i:124)
datanode1_1  | 2022-06-28 01:30:40,402 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3376,entriesCount=1,lastEntry=(t:1, i:125)
datanode1_1  | 2022-06-28 01:30:45,513 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3412,entriesCount=1,lastEntry=(t:1, i:126)
datanode1_1  | 2022-06-28 01:30:45,525 [java.util.concurrent.ThreadPoolExecutor$Worker@91b481f[State = -1, empty queue]] WARN server.GrpcLogAppender: 3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1->9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3413,entriesCount=1,lastEntry=(t:1, i:127)
datanode1_1  | 2022-06-28 01:33:25,650 [null-request--thread6] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-12CC6F03A00A->3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1, cid=183, seq=0, Watch-ALL_COMMITTED(132), Message:<EMPTY>, reply=RaftClientReply:client-12CC6F03A00A->3f49ce74-6987-463e-a960-954ebbba5f61@group-A67715D36AB1, cid=183, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 183 and log index 132 is not yet replicated to ALL_COMMITTED, logIndex=132, commits[3f49ce74-6987-463e-a960-954ebbba5f61:c133, 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa:c127, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda:c133]
datanode1_1  | 2022-06-28 01:34:23,526 [ContainerOp-51a7f1ac-dc16-43e5-8dfa-a67715d36ab1-9] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 132.
datanode1_1  | 2022-06-28 01:34:23,526 [ContainerOp-51a7f1ac-dc16-43e5-8dfa-a67715d36ab1-9] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 132.
datanode1_1  | 2022-06-28 01:34:23,537 [ContainerOp-51a7f1ac-dc16-43e5-8dfa-a67715d36ab1-9] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 132.
datanode1_1  | 2022-06-28 01:35:00,714 [BlockDeletingService#2] WARN background.BlockDeletingService: Close Container log Index 132 is not replicated across all the servers in the pipeline 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 as the min replicated index is 127. Deletion is not allowed in this container yet.
datanode1_1  | 2022-06-28 01:36:00,719 [BlockDeletingService#2] WARN background.BlockDeletingService: Close Container log Index 132 is not replicated across all the servers in the pipeline 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 as the min replicated index is 127. Deletion is not allowed in this container yet.
datanode1_1  | 2022-06-28 01:37:00,721 [BlockDeletingService#2] WARN background.BlockDeletingService: Close Container log Index 132 is not replicated across all the servers in the pipeline 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 as the min replicated index is 127. Deletion is not allowed in this container yet.
datanode1_1  | 2022-06-28 01:38:00,722 [BlockDeletingService#2] WARN background.BlockDeletingService: Close Container log Index 132 is not replicated across all the servers in the pipeline 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 as the min replicated index is 127. Deletion is not allowed in this container yet.
datanode1_1  | 2022-06-28 01:39:00,723 [BlockDeletingService#2] WARN background.BlockDeletingService: Close Container log Index 132 is not replicated across all the servers in the pipeline 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 as the min replicated index is 127. Deletion is not allowed in this container yet.
kdc_1        | Jun 28 01:30:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379812, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:30:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:30:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:31:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:31:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:31:41 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379901, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:31:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379901, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:31:52 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379912, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:31:52 kdc krb5kdc[7](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379912, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
kdc_1        | Jun 28 01:32:07 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:32:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Jun 28 01:32:32 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:32:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:32:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:32:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:32:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:33:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:33:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode3_1  | 2022-06-28 01:19:52,616 [grpc-default-executor-2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70 replies to ELECTION vote request: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t7. Peer's state: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70:t7, leader=null, voted=null, raftlog=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:19:57,684 [grpc-default-executor-2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: receive requestVote(ELECTION, 3f49ce74-6987-463e-a960-954ebbba5f61, group-FD99B4920D70, 8, (t:0, i:0))
datanode3_1  | 2022-06-28 01:19:57,685 [grpc-default-executor-2] INFO impl.VoteContext: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FOLLOWER: reject ELECTION from 3f49ce74-6987-463e-a960-954ebbba5f61: our priority 1 > candidate's priority 0
datanode3_1  | 2022-06-28 01:19:57,685 [grpc-default-executor-2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: changes role from  FOLLOWER to FOLLOWER at term 8 for candidate:3f49ce74-6987-463e-a960-954ebbba5f61
datanode3_1  | 2022-06-28 01:19:57,685 [grpc-default-executor-2] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:57,686 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState was interrupted
datanode3_1  | 2022-06-28 01:19:57,686 [grpc-default-executor-2] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:19:57,690 [grpc-default-executor-2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70 replies to ELECTION vote request: 3f49ce74-6987-463e-a960-954ebbba5f61<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t8. Peer's state: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70:t8, leader=null, voted=null, raftlog=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:20:00,162 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:1010156239454.
datanode3_1  | 2022-06-28 01:20:02,844 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5157942557ns, electionTimeout:5156ms
datanode3_1  | 2022-06-28 01:20:02,844 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState
datanode3_1  | 2022-06-28 01:20:02,845 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: changes role from  FOLLOWER to CANDIDATE at term 8 for changeToCandidate
datanode3_1  | 2022-06-28 01:20:02,845 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-06-28 01:20:02,846 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4
datanode3_1  | 2022-06-28 01:20:02,852 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO impl.LeaderElection: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4 ELECTION round 0: submit vote requests at term 9 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:20:02,895 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO impl.LeaderElection: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-06-28 01:20:02,895 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO impl.LeaderElection:   Response 0: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:OK-t9
datanode3_1  | 2022-06-28 01:20:02,895 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO impl.LeaderElection: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4 ELECTION round 0: result PASSED
datanode3_1  | 2022-06-28 01:20:02,896 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: shutdown 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4
datanode3_1  | 2022-06-28 01:20:02,896 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: changes role from CANDIDATE to LEADER at term 9 for changeToLeader
datanode3_1  | 2022-06-28 01:20:02,896 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-FD99B4920D70 with new leaderId: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
datanode3_1  | 2022-06-28 01:20:02,897 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: change Leader from null to 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda at term 9 for becomeLeader, leader elected after 45593ms
datanode3_1  | 2022-06-28 01:20:02,897 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-06-28 01:20:02,898 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-06-28 01:20:02,898 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-06-28 01:20:02,898 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-06-28 01:20:02,899 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-06-28 01:20:02,899 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-06-28 01:20:02,899 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-06-28 01:20:02,899 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-06-28 01:18:11,886 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode2_1  | 2022-06-28 01:19:42,286 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5043557220ns, electionTimeout:5039ms
datanode2_1  | 2022-06-28 01:19:42,286 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:42,286 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
datanode2_1  | 2022-06-28 01:19:42,287 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-06-28 01:19:42,289 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection4
datanode2_1  | 2022-06-28 01:19:42,303 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection4] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection4 ELECTION round 0: submit vote requests at term 5 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:19:42,328 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection4] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection4: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-06-28 01:19:42,330 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection4] INFO impl.LeaderElection:   Response 0: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t5
datanode2_1  | 2022-06-28 01:19:42,330 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection4] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection4 ELECTION round 0: result REJECTED
datanode2_1  | 2022-06-28 01:19:42,330 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection4] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
datanode2_1  | 2022-06-28 01:19:42,330 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection4] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection4
datanode2_1  | 2022-06-28 01:19:42,331 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection4] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:47,423 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5091882454ns, electionTimeout:5069ms
datanode2_1  | 2022-06-28 01:19:47,423 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:47,424 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
datanode2_1  | 2022-06-28 01:19:47,424 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-06-28 01:19:47,424 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection5
datanode2_1  | 2022-06-28 01:19:47,433 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection5] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection5 ELECTION round 0: submit vote requests at term 6 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:19:47,464 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: receive requestVote(ELECTION, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, group-FD99B4920D70, 6, (t:0, i:0))
datanode2_1  | 2022-06-28 01:19:47,465 [grpc-default-executor-0] INFO impl.VoteContext: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-CANDIDATE: reject ELECTION from 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: already has voted for 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa at current term 6
datanode2_1  | 2022-06-28 01:19:47,468 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70 replies to ELECTION vote request: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:FAIL-t6. Peer's state: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70:t6, leader=null, voted=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, raftlog=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:19:47,474 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection5] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection5: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2022-06-28 01:19:47,475 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection5] INFO impl.LeaderElection:   Response 0: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t6
datanode2_1  | 2022-06-28 01:19:47,475 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection5] INFO impl.LeaderElection:   Response 1: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-3f49ce74-6987-463e-a960-954ebbba5f61#0:OK-t6
datanode2_1  | 2022-06-28 01:19:47,476 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection5] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection5 ELECTION round 0: result REJECTED
datanode2_1  | 2022-06-28 01:19:47,476 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection5] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from CANDIDATE to FOLLOWER at term 6 for REJECTED
datanode2_1  | 2022-06-28 01:19:47,476 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection5] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection5
datanode3_1  | 2022-06-28 01:20:02,911 [grpc-default-executor-2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: receive requestVote(ELECTION, 3f49ce74-6987-463e-a960-954ebbba5f61, group-FD99B4920D70, 9, (t:0, i:0))
datanode3_1  | 2022-06-28 01:20:02,957 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-06-28 01:20:02,960 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-06-28 01:20:02,975 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-06-28 01:20:02,992 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-06-28 01:20:02,995 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-06-28 01:20:02,995 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-06-28 01:20:02,998 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-06-28 01:20:02,998 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-06-28 01:20:02,998 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-06-28 01:20:02,998 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-06-28 01:20:02,998 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-06-28 01:20:02,998 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-06-28 01:20:03,002 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO impl.RoleInfo: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: start 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderStateImpl
datanode3_1  | 2022-06-28 01:20:03,002 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO segmented.SegmentedRaftLogWorker: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-06-28 01:20:03,006 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70/current/log_inprogress_0
datanode3_1  | 2022-06-28 01:20:03,020 [4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LeaderElection4] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70: set configuration 0: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:20:03,022 [grpc-default-executor-2] INFO impl.VoteContext: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-LEADER: reject ELECTION from 3f49ce74-6987-463e-a960-954ebbba5f61: already has voted for 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda at current term 9
datanode3_1  | 2022-06-28 01:20:03,022 [grpc-default-executor-2] INFO server.RaftServer$Division: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70 replies to ELECTION vote request: 3f49ce74-6987-463e-a960-954ebbba5f61<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t9. Peer's state: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70:t9, leader=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, voted=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, raftlog=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda@group-FD99B4920D70-SegmentedRaftLog:OPENED:c0, conf=0: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-06-28 01:34:23,595 [ContainerOp-51a7f1ac-dc16-43e5-8dfa-a67715d36ab1-8] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 132.
datanode3_1  | 2022-06-28 01:34:23,597 [ContainerOp-51a7f1ac-dc16-43e5-8dfa-a67715d36ab1-8] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 132.
datanode3_1  | 2022-06-28 01:34:23,623 [ContainerOp-51a7f1ac-dc16-43e5-8dfa-a67715d36ab1-8] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 132.
datanode3_1  | 2022-06-28 01:35:00,476 [BlockDeletingService#2] WARN background.BlockDeletingService: Close Container log Index 132 is not replicated across all the servers in the pipeline 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 as the min replicated index is 127. Deletion is not allowed in this container yet.
datanode3_1  | 2022-06-28 01:36:00,478 [BlockDeletingService#4] WARN background.BlockDeletingService: Close Container log Index 132 is not replicated across all the servers in the pipeline 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 as the min replicated index is 127. Deletion is not allowed in this container yet.
datanode3_1  | 2022-06-28 01:37:00,481 [BlockDeletingService#4] WARN background.BlockDeletingService: Close Container log Index 132 is not replicated across all the servers in the pipeline 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 as the min replicated index is 127. Deletion is not allowed in this container yet.
datanode3_1  | 2022-06-28 01:38:00,482 [BlockDeletingService#4] WARN background.BlockDeletingService: Close Container log Index 132 is not replicated across all the servers in the pipeline 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 as the min replicated index is 127. Deletion is not allowed in this container yet.
datanode3_1  | 2022-06-28 01:39:00,483 [BlockDeletingService#4] WARN background.BlockDeletingService: Close Container log Index 132 is not replicated across all the servers in the pipeline 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 as the min replicated index is 127. Deletion is not allowed in this container yet.
kdc_1        | Jun 28 01:33:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:33:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:33:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:33:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:33:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:33:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:33:52 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:33:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:34:07 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:34:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656379927, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:34:32 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656380072, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:34:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380072, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:34:37 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656380077, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:34:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:34:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:34:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380077, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:34:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380077, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:35:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380077, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:35:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380077, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:35:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380077, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:35:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380077, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:35:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380077, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:35:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:35:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:35:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380077, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:35:52 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380077, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:36:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380077, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:36:07 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656380167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:36:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:36:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:36:32 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:36:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:36:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:36:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:36:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:36:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-06-28 01:18:11,984 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-06-28 01:18:19,215 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-06-28 01:18:21,720 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-06-28 01:18:22,074 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-06-28 01:18:22,074 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-06-28 01:18:22,074 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-06-28 01:18:22,980 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-06-28 01:18:22,983 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-06-28 01:18:23,039 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-06-28 01:18:23,616 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-06-28 01:18:26,233 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2022-06-28 01:18:29,087 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2022-06-28 01:18:29,087 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2022-06-28 01:18:29,111 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2022-06-28 01:18:32,359 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2022-06-28 01:18:32,595 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2022-06-28 01:18:32,602 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2022-06-28 01:18:32,618 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2022-06-28 01:18:32,624 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-06-28 01:18:32,628 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-06-28 01:18:32,628 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-06-28 01:18:32,630 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-06-28 01:18:32,633 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:45e35def-6cad-44ae-bb26-f31c46277acf,clusterId:CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b,subject:om2
om2_1        | 2022-06-28 01:18:33,820 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2022-06-28 01:18:35,551 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b;layoutVersion=3
om2_1        | 2022-06-28 01:18:35,665 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-06-28 01:18:45,880 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2022-06-28 01:16:49,361 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1        | 2022-06-28 01:16:49,363 [main] INFO s3.Gateway: S3Gateway login successful.
s3g_1        | 2022-06-28 01:16:49,687 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2022-06-28 01:16:49,689 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2022-06-28 01:16:49,689 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2022-06-28 01:16:49,799 [main] INFO util.log: Logging initialized @6166ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2022-06-28 01:16:50,214 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2022-06-28 01:16:50,240 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2022-06-28 01:16:50,244 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2022-06-28 01:16:50,244 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2022-06-28 01:16:50,244 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2022-06-28 01:16:50,249 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2022-06-28 01:16:50,510 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.2.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
s3g_1        | STARTUP_MSG:   java = 11.0.14.1
s3g_1        | ************************************************************/
s3g_1        | 2022-06-28 01:16:50,556 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2022-06-28 01:16:50,615 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2022-06-28 01:16:50,821 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 2022-06-28 01:16:51,231 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 2022-06-28 01:16:51,235 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1        | 2022-06-28 01:16:51,327 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2022-06-28 01:16:51,329 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
s3g_1        | 2022-06-28 01:16:51,473 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2022-06-28 01:16:51,473 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2022-06-28 01:16:51,478 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1        | 2022-06-28 01:16:51,562 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2022-06-28 01:16:51,585 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@64bc21ac{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2022-06-28 01:16:51,588 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@61078690{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2022-06-28 01:16:58,532 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Jun 28, 2022 1:17:01 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2022-06-28 01:17:01,070 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5fa5c8cf{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-10678297035499707174/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2022-06-28 01:17:01,091 [main] INFO server.AbstractConnector: Started ServerConnector@5e77f0f4{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2022-06-28 01:17:01,092 [main] INFO server.Server: Started @17460ms
s3g_1        | 2022-06-28 01:17:01,094 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2022-06-28 01:17:01,094 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2022-06-28 01:17:01,096 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1        | 2022-06-28 01:26:31,789 [qtp2123533871-22] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
s3g_1        | 2022-06-28 01:26:31,805 [qtp2123533871-22] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
s3g_1        | 2022-06-28 01:26:33,724 [qtp2123533871-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1088774785, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:26:33,763 [qtp2123533871-22] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1088774785
s3g_1        | 2022-06-28 01:26:41,193 [qtp2123533871-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3383746089, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:26:41,215 [qtp2123533871-18] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-3383746089
s3g_1        | 2022-06-28 01:26:42,210 [qtp2123533871-21] WARN impl.MetricsSystemImpl: S3Gateway metrics system already initialized!
s3g_1        | 2022-06-28 01:26:42,548 [qtp2123533871-21] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 2022-06-28 01:26:55,231 [qtp2123533871-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9610832201, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:26:55,248 [qtp2123533871-21] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-9610832201
s3g_1        | 2022-06-28 01:26:55,868 [qtp2123533871-25] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-rbeuewmjgc, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:26:55,893 [qtp2123533871-25] INFO endpoint.BucketEndpoint: Location is /ozone-test-rbeuewmjgc
s3g_1        | 2022-06-28 01:27:00,811 [qtp2123533871-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-cquyfepsao, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:27:00,836 [qtp2123533871-21] INFO endpoint.BucketEndpoint: Location is /bucket-cquyfepsao
s3g_1        | 2022-06-28 01:27:15,469 [qtp2123533871-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4118624588, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:27:15,485 [qtp2123533871-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-4118624588
s3g_1        | 2022-06-28 01:27:16,178 [qtp2123533871-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6741282977, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:27:16,201 [qtp2123533871-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6741282977
s3g_1        | 2022-06-28 01:27:16,848 [qtp2123533871-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0865895385, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:27:16,866 [qtp2123533871-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-0865895385
s3g_1        | 2022-06-28 01:27:17,495 [qtp2123533871-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0865895385, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:27:17,522 [qtp2123533871-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-0865895385
s3g_1        | 2022-06-28 01:27:26,097 [qtp2123533871-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2757426933, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:27:26,112 [qtp2123533871-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2757426933
s3g_1        | 2022-06-28 01:27:26,766 [qtp2123533871-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6611295494, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:27:26,792 [qtp2123533871-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-6611295494
s3g_1        | 2022-06-28 01:27:35,247 [qtp2123533871-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1580261655, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:27:35,275 [qtp2123533871-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1580261655
s3g_1        | 2022-06-28 01:27:43,828 [qtp2123533871-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1120923398, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:27:43,858 [qtp2123533871-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1120923398
s3g_1        | 2022-06-28 01:27:50,756 [qtp2123533871-23] ERROR signature.AuthorizationV4HeaderParser: AWS access id shouldn't be empty. credential:/20220628/us-west-1/s3/aws4_request
s3g_1        | Jun 28, 2022 1:27:50 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1        | MultiException stack 1 of 1
s3g_1        | javax.ws.rs.WebApplicationException: The authorization header you provided is invalid.
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.wrapOS3Exception(OzoneClientProducer.java:140)
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
kdc_1        | Jun 28 01:37:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:37:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:37:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:37:23 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1656380243, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Jun 28 01:37:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380243, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:37:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380243, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:37:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:37:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:37:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380243, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:37:52 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380243, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:37:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380243, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:38:07 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380243, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:38:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380243, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:38:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380243, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:38:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380243, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Jun 28 01:38:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:38:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om2@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Jun 28 01:38:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1656380243, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-06-28 01:18:45,962 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-06-28 01:18:53,795 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-06-28 01:18:55,779 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-06-28 01:18:56,156 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-06-28 01:18:56,156 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-06-28 01:18:56,156 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-06-28 01:18:56,239 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-06-28 01:18:56,555 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om2_1        | 2022-06-28 01:18:58,258 [main] INFO reflections.Reflections: Reflections took 1247 ms to scan 1 urls, producing 113 keys and 337 values [using 2 cores]
om2_1        | 2022-06-28 01:19:01,011 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-06-28 01:19:01,090 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-06-28 01:19:01,093 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-06-28 01:19:03,675 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-06-28 01:19:03,933 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-06-28 01:19:07,964 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2022-06-28 01:19:08,545 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/1010156239454.crt.
om2_1        | 2022-06-28 01:19:08,550 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2022-06-28 01:19:08,588 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-916105677270.crt.
om2_1        | 2022-06-28 01:19:08,853 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-06-28 01:19:09,632 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-06-28 01:19:09,637 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-06-28 01:19:10,882 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om2_1        | 2022-06-28 01:19:10,948 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2022-06-28 01:19:10,948 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2022-06-28 01:19:11,460 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om2_1        | 2022-06-28 01:19:12,148 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-06-28 01:19:12,149 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2022-06-28 01:19:12,231 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2022-06-28 01:19:13,077 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2022-06-28 01:19:13,144 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-06-28 01:19:13,480 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om2:9872, om1:9872, om3:9872
om2_1        | 2022-06-28 01:19:13,779 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2022-06-28 01:19:15,454 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2022-06-28 01:19:16,125 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2022-06-28 01:19:16,126 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-06-28 01:19:16,136 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2022-06-28 01:19:16,137 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-06-28 01:19:16,138 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-06-28 01:19:16,140 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2022-06-28 01:19:16,142 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-06-28 01:19:16,148 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2022-06-28 01:19:16,155 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-06-28 01:19:16,274 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om2_1        | 2022-06-28 01:19:16,289 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om2_1        | 2022-06-28 01:19:19,519 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2022-06-28 01:19:19,529 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om2_1        | 2022-06-28 01:19:19,535 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om2_1        | 2022-06-28 01:19:19,536 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-06-28 01:19:19,540 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-06-28 01:19:19,563 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-06-28 01:19:19,630 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@6f99b8c4[Not completed]
om2_1        | 2022-06-28 01:19:19,638 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2022-06-28 01:19:15,883 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2022-06-28 01:19:15,883 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-06-28 01:19:15,891 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-06-28 01:19:15,900 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2022-06-28 01:19:15,924 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-06-28 01:19:15,930 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2022-06-28 01:19:15,945 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-06-28 01:19:16,136 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om1_1        | 2022-06-28 01:19:16,139 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om1_1        | 2022-06-28 01:19:19,235 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2022-06-28 01:19:19,248 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om1_1        | 2022-06-28 01:19:19,251 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om1_1        | 2022-06-28 01:19:19,251 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-06-28 01:19:19,252 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-06-28 01:19:19,262 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-06-28 01:19:19,289 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@3b5769b3[Not completed]
om1_1        | 2022-06-28 01:19:19,291 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2022-06-28 01:19:19,381 [main] INFO om.OzoneManager: Creating RPC Server
om1_1        | 2022-06-28 01:19:19,396 [pool-27-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2022-06-28 01:19:19,419 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2022-06-28 01:19:19,422 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2022-06-28 01:19:19,425 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2022-06-28 01:19:19,426 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-06-28 01:19:19,426 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-06-28 01:19:19,426 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2022-06-28 01:19:19,464 [pool-27-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2022-06-28 01:19:19,482 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-06-28 01:19:19,494 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2022-06-28 01:19:19,513 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1        | 2022-06-28 01:19:19,521 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2022-06-28 01:19:19,670 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om1
om1_1        | 2022-06-28 01:19:19,811 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2022-06-28 01:19:19,839 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2022-06-28 01:19:19,869 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2022-06-28 01:19:19,923 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2022-06-28 01:19:19,980 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-06-28 01:19:19,990 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om1_1        | 2022-06-28 01:19:20,238 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-06-28 01:19:20,326 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2022-06-28 01:19:20,337 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2022-06-28 01:19:20,399 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2022-06-28 01:19:20,410 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-06-28 01:19:20,415 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2022-06-28 01:19:20,418 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-06-28 01:19:20,432 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2022-06-28 01:19:20,438 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2022-06-28 01:19:20,444 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2022-06-28 01:19:20,453 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2022-06-28 01:19:20,454 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2022-06-28 01:19:20,521 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2022-06-28 01:19:20,545 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om1_1        | 2022-06-28 01:19:20,560 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2022-06-28 01:19:20,627 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:101)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1        | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1        | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1        | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1        | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1        | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1        | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1        | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1        | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:874)
s3g_1        | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1        | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1        | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:127)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:69)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:103)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:46)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:53)
s3g_1        | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:129)
s3g_1        | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
s3g_1        | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:46)
s3g_1        | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
s3g_1        | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
s3g_1        | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
om1_1        | 2022-06-28 01:19:20,627 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2022-06-28 01:19:20,695 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2022-06-28 01:19:20,696 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2022-06-28 01:19:20,701 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2022-06-28 01:19:20,708 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2022-06-28 01:19:20,727 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2022-06-28 01:19:20,728 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2022-06-28 01:19:21,085 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-06-28 01:19:21,098 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om1_1        | 2022-06-28 01:19:21,100 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om1_1        | 2022-06-28 01:19:21,114 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om1_1        | 2022-06-28 01:19:21,117 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om1_1        | 2022-06-28 01:19:22,575 [main] INFO reflections.Reflections: Reflections took 2801 ms to scan 8 urls, producing 23 keys and 512 values [using 2 cores]
om1_1        | 2022-06-28 01:19:23,957 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2022-06-28 01:19:23,995 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2022-06-28 01:19:27,789 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2022-06-28 01:19:27,929 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2022-06-28 01:19:27,942 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2022-06-28 01:19:28,201 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2022-06-28 01:19:28,210 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2022-06-28 01:19:28,217 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-06-28 01:19:28,227 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2022-06-28 01:19:28,233 [om1-impl-thread1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-06-28 01:19:28,263 [om1-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2022-06-28 01:19:28,292 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2022-06-28 01:19:28,667 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2022-06-28 01:19:28,672 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$449/0x00000008405cac40@24614fbb] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2022-06-28 01:19:28,677 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2022-06-28 01:19:28,681 [Listener at om1/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-06-28 01:19:28,697 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2022-06-28 01:19:28,698 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-06-28 01:19:28,708 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1        | 2022-06-28 01:19:28,723 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2022-06-28 01:19:28,886 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2022-06-28 01:19:28,887 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2022-06-28 01:19:28,887 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om1_1        | 2022-06-28 01:19:28,968 [Listener at om1/9862] INFO util.log: Logging initialized @51546ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2022-06-28 01:19:29,466 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2022-06-28 01:19:29,495 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2022-06-28 01:19:29,506 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2022-06-28 01:19:29,507 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2022-06-28 01:19:29,508 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2022-06-28 01:19:29,524 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2022-06-28 01:19:29,758 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2022-06-28 01:19:29,761 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om1_1        | 2022-06-28 01:19:29,854 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2022-06-28 01:19:29,854 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2022-06-28 01:19:29,871 [Listener at om1/9862] INFO server.session: node0 Scavenging every 660000ms
om1_1        | 2022-06-28 01:19:29,939 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-06-28 01:19:29,943 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@16bc9213{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2022-06-28 01:19:29,948 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5bcaebdb{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2022-06-28 01:16:49,615 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | 2022-06-28 01:19:30,312 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-06-28 01:19:30,361 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5162bede{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-12855050520781235223/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2022-06-28 01:19:30,389 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@1962d811{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2022-06-28 01:19:30,390 [Listener at om1/9862] INFO server.Server: Started @52968ms
om1_1        | 2022-06-28 01:19:30,396 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2022-06-28 01:19:30,396 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2022-06-28 01:19:30,401 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2022-06-28 01:19:30,401 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2022-06-28 01:19:30,402 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2022-06-28 01:19:30,536 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om1_1        | 2022-06-28 01:19:30,817 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36735
om1_1        | 2022-06-28 01:19:30,854 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:19:30,878 [Listener at om1/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om1_1        | 2022-06-28 01:19:30,996 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3137a5cf] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2022-06-28 01:19:33,276 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5043373185ns, electionTimeout:5019ms
om1_1        | 2022-06-28 01:19:33,278 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-06-28 01:19:33,279 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2022-06-28 01:19:33,281 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2022-06-28 01:19:33,283 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1        | 2022-06-28 01:19:33,306 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-06-28 01:19:36,479 [grpc-default-executor-2] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-06-28 01:19:36,497 [grpc-default-executor-2] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om1 at current term 1
om1_1        | 2022-06-28 01:19:36,559 [grpc-default-executor-2] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-06-28 01:19:36,743 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om1_1        | 2022-06-28 01:19:36,744 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om3#0:FAIL-t1
om1_1        | 2022-06-28 01:19:36,744 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om1<-om2#0:FAIL-t1
om1_1        | 2022-06-28 01:19:36,744 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om1_1        | 2022-06-28 01:19:36,752 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om1_1        | 2022-06-28 01:19:36,759 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1        | 2022-06-28 01:19:36,759 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-06-28 01:19:37,288 [om1-server-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om2 at term 1 for appendEntries, leader elected after 17449ms
om1_1        | 2022-06-28 01:19:37,434 [om1-server-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2022-06-28 01:19:37,504 [om1-server-thread1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2022-06-28 01:19:37,966 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2022-06-28 01:19:39,311 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45032
om1_1        | 2022-06-28 01:19:39,382 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:19:40,932 [om1@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1        | [id: "om1"
om1_1        | address: "om1:9872"
om1_1        | , id: "om3"
om1_1        | address: "om3:9872"
om1_1        | , id: "om2"
om1_1        | address: "om2:9872"
om1_1        | ]
om1_1        | 2022-06-28 01:19:54,859 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45072
om1_1        | 2022-06-28 01:19:54,880 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:19:56,075 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om1_1        | 2022-06-28 01:19:56,232 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om1_1        | 2022-06-28 01:20:07,330 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45132
om1_1        | 2022-06-28 01:20:07,359 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:20:08,141 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45136
om1_1        | 2022-06-28 01:20:08,164 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:20:13,682 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45152
om1_1        | 2022-06-28 01:20:13,702 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:20:14,345 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45156
om1_1        | 2022-06-28 01:20:14,347 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:20:14,419 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om1_1        | 2022-06-28 01:20:19,464 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45170
om1_1        | 2022-06-28 01:20:19,486 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:20:27,909 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45212
om1_1        | 2022-06-28 01:20:27,928 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:20:33,826 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45226
om1_1        | 2022-06-28 01:20:33,843 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:20:34,476 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45230
om1_1        | 2022-06-28 01:20:34,482 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:20:34,568 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om1_1        | 2022-06-28 01:20:39,623 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45244
om1_1        | 2022-06-28 01:20:39,637 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:20:44,600 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45260
om1_1        | 2022-06-28 01:20:44,621 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:21:00,587 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45328
om1_1        | 2022-06-28 01:21:00,617 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:21:01,192 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:67614-source for user:testuser
om1_1        | 2022-06-28 01:21:05,208 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45334
om1_1        | 2022-06-28 01:21:05,222 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:21:06,009 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:67614-target for user:testuser
om1_1        | 2022-06-28 01:21:09,900 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45350
om1_1        | 2022-06-28 01:21:09,915 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:21:10,600 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 67614-source
om1_1        | 2022-06-28 01:21:14,533 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45364
om1_1        | 2022-06-28 01:21:14,553 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:21:24,014 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45406
om1_1        | 2022-06-28 01:21:24,048 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:21:24,807 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 67614-source
om1_1        | 2022-06-28 01:21:28,774 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45420
om1_1        | 2022-06-28 01:21:28,796 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:21:29,529 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 67614-target
om1_1        | 2022-06-28 01:21:33,369 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45434
om1_1        | 2022-06-28 01:21:33,392 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:21:34,034 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 67614-target
om1_1        | 2022-06-28 01:21:37,518 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45448
om1_1        | 2022-06-28 01:21:37,540 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:21:38,305 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 67614-target
om1_1        | 2022-06-28 01:21:41,783 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45456
om1_1        | 2022-06-28 01:21:41,802 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:21:46,494 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45470
om1_1        | 2022-06-28 01:21:46,513 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:21:50,992 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45484
om1_1        | 2022-06-28 01:21:51,005 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:21:55,958 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45522
om1_1        | 2022-06-28 01:21:55,978 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:22:00,592 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45546
om1_1        | 2022-06-28 01:22:00,606 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:22:05,835 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45554
om1_1        | 2022-06-28 01:22:05,854 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:22:06,639 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 67614-target
om1_1        | 2022-06-28 01:22:10,514 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45570
om1_1        | 2022-06-28 01:22:10,530 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:22:15,206 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45588
om1_1        | 2022-06-28 01:22:15,265 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:22:16,025 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 67614-target
om1_1        | 2022-06-28 01:22:20,060 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45602
om1_1        | 2022-06-28 01:22:20,079 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:22:20,748 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 67614-source
om1_1        | 2022-06-28 01:22:25,022 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45640
om1_1        | 2022-06-28 01:22:25,039 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:22:34,147 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45658
om1_1        | 2022-06-28 01:22:34,168 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:22:41,229 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45678
om1_1        | 2022-06-28 01:22:41,248 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:22:49,240 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45704
om1_1        | 2022-06-28 01:22:49,254 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:22:56,504 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45746
om1_1        | 2022-06-28 01:22:56,521 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:23:01,262 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45770
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-06-28 01:18:11,259 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-06-28 01:18:11,329 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-06-28 01:18:19,503 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-06-28 01:18:21,853 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-06-28 01:18:22,491 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-06-28 01:18:22,494 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-06-28 01:18:22,494 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-06-28 01:18:23,868 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-06-28 01:18:23,868 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-06-28 01:18:23,912 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-06-28 01:18:24,703 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-06-28 01:18:27,804 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2022-06-28 01:18:31,557 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2022-06-28 01:18:31,557 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2022-06-28 01:18:31,585 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2022-06-28 01:18:36,170 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2022-06-28 01:18:36,436 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2022-06-28 01:18:36,450 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2022-06-28 01:18:36,459 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2022-06-28 01:18:36,490 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-06-28 01:18:36,491 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-06-28 01:18:36,491 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-06-28 01:18:36,491 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-06-28 01:18:36,502 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:45e35def-6cad-44ae-bb26-f31c46277acf,clusterId:CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b,subject:om3
om3_1        | 2022-06-28 01:18:37,709 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2022-06-28 01:18:39,581 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b;layoutVersion=3
om3_1        | 2022-06-28 01:18:39,741 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-06-28 01:18:50,458 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om1_1        | 2022-06-28 01:23:01,280 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:19:19,820 [pool-27-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2022-06-28 01:19:19,859 [main] INFO om.OzoneManager: Creating RPC Server
om2_1        | 2022-06-28 01:19:19,859 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2022-06-28 01:19:19,864 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2022-06-28 01:19:19,864 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2022-06-28 01:19:19,864 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-06-28 01:19:19,864 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-06-28 01:19:19,865 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2022-06-28 01:19:19,934 [pool-27-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2022-06-28 01:19:19,936 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-06-28 01:19:19,966 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2022-06-28 01:19:19,968 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2022-06-28 01:19:19,970 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2022-06-28 01:19:20,216 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 10@om2
om2_1        | 2022-06-28 01:19:20,317 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2022-06-28 01:19:20,341 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2022-06-28 01:19:20,353 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2022-06-28 01:19:20,508 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2022-06-28 01:19:20,516 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-06-28 01:19:20,541 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om2_1        | 2022-06-28 01:19:20,775 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-06-28 01:19:20,909 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2022-06-28 01:19:20,916 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2022-06-28 01:19:21,066 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2022-06-28 01:19:21,073 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-06-28 01:19:21,075 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2022-06-28 01:19:21,085 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-06-28 01:19:21,098 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2022-06-28 01:19:21,099 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2022-06-28 01:19:21,121 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2022-06-28 01:19:21,123 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2022-06-28 01:19:21,124 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2022-06-28 01:19:21,223 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2022-06-28 01:19:21,226 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om2_1        | 2022-06-28 01:19:21,233 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2022-06-28 01:19:21,337 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2022-06-28 01:19:21,346 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2022-06-28 01:19:21,439 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2022-06-28 01:19:21,449 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2022-06-28 01:19:21,450 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2022-06-28 01:19:21,475 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2022-06-28 01:19:21,495 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2022-06-28 01:19:21,508 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2022-06-28 01:19:22,019 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-06-28 01:19:22,036 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om2_1        | 2022-06-28 01:19:22,037 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om2_1        | 2022-06-28 01:19:22,038 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om2_1        | 2022-06-28 01:19:22,039 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om2_1        | 2022-06-28 01:19:22,663 [main] INFO reflections.Reflections: Reflections took 2281 ms to scan 8 urls, producing 23 keys and 512 values [using 2 cores]
om2_1        | 2022-06-28 01:19:23,896 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2022-06-28 01:19:23,977 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2022-06-28 01:19:28,349 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2022-06-28 01:19:47,476 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection5] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:52,597 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5120940640ns, electionTimeout:5107ms
datanode2_1  | 2022-06-28 01:19:52,598 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:52,598 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
datanode2_1  | 2022-06-28 01:19:52,599 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-06-28 01:19:52,599 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection6
datanode2_1  | 2022-06-28 01:19:52,603 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection6] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection6 ELECTION round 0: submit vote requests at term 7 for -1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:19:52,635 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection6] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection6: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2022-06-28 01:19:52,635 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection6] INFO impl.LeaderElection:   Response 0: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-4edc5bf0-d1a3-4fc0-a906-df67e91b4eda#0:FAIL-t7
datanode2_1  | 2022-06-28 01:19:52,635 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection6] INFO impl.LeaderElection:   Response 1: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa<-3f49ce74-6987-463e-a960-954ebbba5f61#0:OK-t7
datanode2_1  | 2022-06-28 01:19:52,635 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection6] INFO impl.LeaderElection: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection6 ELECTION round 0: result REJECTED
datanode2_1  | 2022-06-28 01:19:52,636 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection6] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from CANDIDATE to FOLLOWER at term 7 for REJECTED
datanode2_1  | 2022-06-28 01:19:52,636 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection6] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection6
datanode2_1  | 2022-06-28 01:19:52,636 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-LeaderElection6] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:57,664 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: receive requestVote(ELECTION, 3f49ce74-6987-463e-a960-954ebbba5f61, group-FD99B4920D70, 8, (t:0, i:0))
datanode2_1  | 2022-06-28 01:19:57,665 [grpc-default-executor-0] INFO impl.VoteContext: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FOLLOWER: accept ELECTION from 3f49ce74-6987-463e-a960-954ebbba5f61: our priority 0 <= candidate's priority 0
datanode2_1  | 2022-06-28 01:19:57,665 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from  FOLLOWER to FOLLOWER at term 8 for candidate:3f49ce74-6987-463e-a960-954ebbba5f61
datanode2_1  | 2022-06-28 01:19:57,666 [grpc-default-executor-0] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:57,666 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState was interrupted
datanode2_1  | 2022-06-28 01:19:57,667 [grpc-default-executor-0] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:19:57,669 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70 replies to ELECTION vote request: 3f49ce74-6987-463e-a960-954ebbba5f61<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:OK-t8. Peer's state: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70:t8, leader=null, voted=3f49ce74-6987-463e-a960-954ebbba5f61, raftlog=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:20:00,342 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:1010156239454.
datanode2_1  | 2022-06-28 01:20:02,856 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: receive requestVote(ELECTION, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, group-FD99B4920D70, 9, (t:0, i:0))
datanode2_1  | 2022-06-28 01:20:02,858 [grpc-default-executor-0] INFO impl.VoteContext: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FOLLOWER: accept ELECTION from 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda: our priority 0 <= candidate's priority 1
datanode2_1  | 2022-06-28 01:20:02,858 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: changes role from  FOLLOWER to FOLLOWER at term 9 for candidate:4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
datanode2_1  | 2022-06-28 01:20:02,858 [grpc-default-executor-0] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: shutdown 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:20:02,858 [grpc-default-executor-0] INFO impl.RoleInfo: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa: start 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState
datanode2_1  | 2022-06-28 01:20:02,858 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState] INFO impl.FollowerState: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FollowerState was interrupted
datanode2_1  | 2022-06-28 01:20:02,874 [grpc-default-executor-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: receive requestVote(ELECTION, 3f49ce74-6987-463e-a960-954ebbba5f61, group-FD99B4920D70, 9, (t:0, i:0))
datanode2_1  | 2022-06-28 01:20:02,877 [grpc-default-executor-0] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70 replies to ELECTION vote request: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:OK-t9. Peer's state: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70:t9, leader=null, voted=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, raftlog=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:20:02,877 [grpc-default-executor-1] INFO impl.VoteContext: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-FOLLOWER: reject ELECTION from 3f49ce74-6987-463e-a960-954ebbba5f61: already has voted for 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda at current term 9
datanode2_1  | 2022-06-28 01:20:02,877 [grpc-default-executor-1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70 replies to ELECTION vote request: 3f49ce74-6987-463e-a960-954ebbba5f61<-9b5cffd6-d488-4e7f-a573-cd0e62fb49aa#0:FAIL-t9. Peer's state: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70:t9, leader=null, voted=4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, raftlog=9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLog:OPENED:c-1, conf=-1: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:20:03,061 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-FD99B4920D70 with new leaderId: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
datanode2_1  | 2022-06-28 01:20:03,061 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-server-thread1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: change Leader from null to 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda at term 9 for appendEntries, leader elected after 45249ms
datanode2_1  | 2022-06-28 01:20:03,074 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-server-thread1] INFO server.RaftServer$Division: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70: set configuration 0: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, 3f49ce74-6987-463e-a960-954ebbba5f61|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-06-28 01:20:03,075 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa-server-thread1] INFO segmented.SegmentedRaftLogWorker: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-06-28 01:20:03,079 [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa@group-FD99B4920D70-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6e4f5b77-ba5a-4791-a28a-fd99b4920d70/current/log_inprogress_0
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
recon_1      | STARTUP_MSG:   java = 11.0.14.1
recon_1      | ************************************************************/
recon_1      | 2022-06-28 01:16:49,653 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2022-06-28 01:16:51,419 [main] INFO reflections.Reflections: Reflections took 163 ms to scan 1 urls, producing 13 keys and 35 values 
recon_1      | 2022-06-28 01:16:53,495 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2022-06-28 01:16:53,602 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2022-06-28 01:16:54,088 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
recon_1      | 2022-06-28 01:16:54,088 [main] INFO recon.ReconServer: Recon login successful.
recon_1      | 2022-06-28 01:16:54,089 [main] INFO recon.ReconServer: Initializing secure Recon.
recon_1      | 2022-06-28 01:16:56,005 [main] ERROR client.ReconCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
recon_1      | 2022-06-28 01:16:56,005 [main] INFO client.ReconCertificateClient: Certificate client init case: 0
recon_1      | 2022-06-28 01:16:56,006 [main] INFO client.ReconCertificateClient: Creating keypair for client as keypair and certificate not found.
recon_1      | 2022-06-28 01:16:57,993 [main] INFO recon.ReconServer: Init response: GETCERT
recon_1      | 2022-06-28 01:16:58,033 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.115,host:recon
recon_1      | 2022-06-28 01:16:58,033 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
recon_1      | 2022-06-28 01:16:58,046 [main] ERROR client.ReconCertificateClient: Invalid domain recon
recon_1      | 2022-06-28 01:16:58,276 [main] INFO recon.ReconServer: Creating CSR for Recon.
recon_1      | 2022-06-28 01:17:01,212 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:17:03,214 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:17:05,216 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:17:07,218 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:17:09,220 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:17:11,222 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:17:13,223 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:17:15,225 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:17:17,635 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:45e35def-6cad-44ae-bb26-f31c46277acf is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1      | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1      | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
recon_1      | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:17:19,637 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:17:21,638 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:17:24,311 [main] INFO recon.ReconServer: Successfully stored SCM signed certificate, case:GETCERT.
recon_1      | 2022-06-28 01:17:25,042 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-06-28 01:17:27,145 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2022-06-28 01:17:27,860 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-06-28 01:17:27,909 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2022-06-28 01:17:27,911 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2022-06-28 01:17:30,326 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2022-06-28 01:17:30,327 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2022-06-28 01:17:30,327 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2022-06-28 01:17:30,357 [main] INFO util.log: Logging initialized @45636ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2022-06-28 01:17:30,645 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2022-06-28 01:17:30,684 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2022-06-28 01:17:30,689 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2022-06-28 01:17:30,689 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2022-06-28 01:17:30,689 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2022-06-28 01:17:30,701 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2022-06-28 01:17:30,963 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2022-06-28 01:17:31,546 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2022-06-28 01:17:31,568 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2022-06-28 01:17:31,588 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1      | 2022-06-28 01:17:31,660 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2022-06-28 01:17:33,217 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-06-28 01:17:33,788 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-06-28 01:17:33,989 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2022-06-28 01:17:33,996 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2022-06-28 01:17:34,321 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-06-28 01:17:34,642 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
recon_1      | 2022-06-28 01:17:34,835 [main] INFO reflections.Reflections: Reflections took 182 ms to scan 3 urls, producing 109 keys and 243 values 
recon_1      | 2022-06-28 01:17:35,066 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2022-06-28 01:17:35,197 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2022-06-28 01:17:35,234 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2022-06-28 01:17:35,266 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2022-06-28 01:17:35,449 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1      | 2022-06-28 01:17:35,563 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2022-06-28 01:17:35,595 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2022-06-28 01:17:35,722 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 2022-06-28 01:17:36,076 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2022-06-28 01:17:36,076 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
om2_1        | 2022-06-28 01:19:28,439 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2022-06-28 01:19:28,439 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2022-06-28 01:19:28,676 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2022-06-28 01:19:28,676 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2022-06-28 01:19:28,688 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-06-28 01:19:28,704 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2022-06-28 01:19:28,706 [om2-impl-thread1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-06-28 01:19:28,726 [om2-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2022-06-28 01:19:28,736 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2022-06-28 01:19:28,946 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2022-06-28 01:19:28,954 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2022-06-28 01:19:28,954 [Listener at om2/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-06-28 01:19:28,956 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2022-06-28 01:19:28,956 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-06-28 01:19:28,960 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$449/0x00000008405cac40@24614fbb] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2022-06-28 01:19:28,964 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1        | 2022-06-28 01:19:28,968 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2022-06-28 01:19:29,156 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2022-06-28 01:19:29,156 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2022-06-28 01:19:29,159 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2022-06-28 01:19:29,269 [Listener at om2/9862] INFO util.log: Logging initialized @52587ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2022-06-28 01:19:29,773 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2022-06-28 01:19:29,812 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2022-06-28 01:19:29,819 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2022-06-28 01:19:29,819 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2022-06-28 01:19:29,823 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2022-06-28 01:19:29,835 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2022-06-28 01:19:29,985 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2022-06-28 01:19:29,992 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om2_1        | 2022-06-28 01:19:30,149 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2022-06-28 01:19:30,149 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2022-06-28 01:19:30,165 [Listener at om2/9862] INFO server.session: node0 Scavenging every 660000ms
om2_1        | 2022-06-28 01:19:30,241 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-06-28 01:19:30,244 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@16bc9213{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2022-06-28 01:19:30,251 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5bcaebdb{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2022-06-28 01:19:30,636 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-06-28 01:19:30,699 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5162bede{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-4474532728743987997/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2022-06-28 01:19:30,729 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@1962d811{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2022-06-28 01:19:30,733 [Listener at om2/9862] INFO server.Server: Started @54051ms
om2_1        | 2022-06-28 01:19:30,747 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2022-06-28 01:19:30,748 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2022-06-28 01:19:30,755 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2022-06-28 01:19:30,769 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2022-06-28 01:19:30,943 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2022-06-28 01:19:30,947 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om2_1        | 2022-06-28 01:19:31,167 [Listener at om2/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om2_1        | 2022-06-28 01:19:31,225 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1476359e] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2022-06-28 01:19:31,671 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36809
om2_1        | 2022-06-28 01:19:31,689 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:19:33,822 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5116352779ns, electionTimeout:5104ms
om2_1        | 2022-06-28 01:19:33,823 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-06-28 01:19:33,824 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2022-06-28 01:19:33,827 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2022-06-28 01:19:33,832 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1        | 2022-06-28 01:19:33,868 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-06-28 01:19:36,459 [grpc-default-executor-2] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-06-28 01:19:36,467 [grpc-default-executor-2] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om2 at current term 1
om2_1        | 2022-06-28 01:19:36,490 [grpc-default-executor-2] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-06-28 01:19:36,726 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION PASSED received 2 response(s) and 0 exception(s):
om2_1        | 2022-06-28 01:19:36,726 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t1
om2_1        | 2022-06-28 01:19:36,726 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om2<-om3#0:OK-t1
om2_1        | 2022-06-28 01:19:36,727 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result PASSED
om2_1        | 2022-06-28 01:19:36,729 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1        | 2022-06-28 01:19:36,730 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om2_1        | 2022-06-28 01:19:36,731 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om2 at term 1 for becomeLeader, leader elected after 16390ms
om2_1        | 2022-06-28 01:19:36,744 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om2_1        | 2022-06-28 01:19:36,758 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om2_1        | 2022-06-28 01:19:36,758 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-06-28 01:19:36,781 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om2_1        | 2022-06-28 01:19:36,784 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om2_1        | 2022-06-28 01:19:36,786 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om2_1        | 2022-06-28 01:19:36,804 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om2_1        | 2022-06-28 01:19:36,805 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om2_1        | 2022-06-28 01:19:36,838 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om2_1        | 2022-06-28 01:19:36,841 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-06-28 01:19:36,841 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2022-06-28 01:23:06,176 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45776
om1_1        | 2022-06-28 01:23:06,193 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:23:10,735 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45792
om1_1        | 2022-06-28 01:23:10,752 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:23:15,543 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45806
om1_1        | 2022-06-28 01:23:15,568 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:23:19,914 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45820
om1_1        | 2022-06-28 01:23:19,935 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:23:24,860 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45858
om1_1        | 2022-06-28 01:23:24,885 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:23:29,381 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45866
om1_1        | 2022-06-28 01:23:29,393 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:23:34,189 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45880
om1_1        | 2022-06-28 01:23:34,205 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:23:38,910 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45894
om1_1        | 2022-06-28 01:23:38,931 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:23:43,579 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45910
om1_1        | 2022-06-28 01:23:43,601 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:23:47,957 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45916
om1_1        | 2022-06-28 01:23:47,976 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:23:52,935 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45954
om1_1        | 2022-06-28 01:23:52,953 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:23:53,557 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 67614-target
om1_1        | 2022-06-28 01:23:57,665 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45968
om1_1        | 2022-06-28 01:23:57,690 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:23:58,288 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:67614-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-28 01:24:01,949 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45992
om1_1        | 2022-06-28 01:24:01,969 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:24:02,662 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 67614-target
om1_1        | 2022-06-28 01:24:06,429 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45998
om1_1        | 2022-06-28 01:24:06,451 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:24:07,027 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:67614-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-28 01:24:10,996 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46014
om1_1        | 2022-06-28 01:24:11,016 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:24:15,898 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46028
om1_1        | 2022-06-28 01:24:15,916 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:24:20,362 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46042
om1_1        | 2022-06-28 01:24:20,381 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:24:25,261 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46080
om1_1        | 2022-06-28 01:24:25,293 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:24:29,828 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46086
om1_1        | 2022-06-28 01:24:29,848 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:24:30,500 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 67614-target
om1_1        | 2022-06-28 01:24:34,568 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46100
om1_1        | 2022-06-28 01:24:34,586 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:24:35,187 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 67614-target
om1_1        | 2022-06-28 01:24:39,284 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46114
om1_1        | 2022-06-28 01:24:39,300 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:24:40,036 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 67614-target
om1_1        | 2022-06-28 01:24:44,012 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46130
om1_1        | 2022-06-28 01:24:44,036 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:24:48,580 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46136
om1_1        | 2022-06-28 01:24:48,612 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:24:49,215 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 67614-target
om1_1        | 2022-06-28 01:24:53,589 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46174
om1_1        | 2022-06-28 01:24:53,602 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:25:01,002 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46210
om1_1        | 2022-06-28 01:25:01,017 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:25:08,165 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46230
om1_1        | 2022-06-28 01:25:08,184 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:25:12,778 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46236
om1_1        | 2022-06-28 01:25:12,791 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:25:17,550 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46250
om1_1        | 2022-06-28 01:25:17,576 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:25:22,544 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46264
om1_1        | 2022-06-28 01:25:22,563 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:25:23,166 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 67614-target
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | 2022-06-28 01:19:36,850 [om2@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om2_1        | 2022-06-28 01:19:36,852 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-06-28 01:19:36,852 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-06-28 01:19:36,857 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om2_1        | 2022-06-28 01:19:36,858 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-06-28 01:19:36,858 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om2_1        | 2022-06-28 01:19:36,858 [om2@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om2_1        | 2022-06-28 01:19:36,859 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-06-28 01:19:36,859 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-06-28 01:19:36,864 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderStateImpl
om2_1        | 2022-06-28 01:19:36,925 [om2@group-562213E44849-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2022-06-28 01:19:37,091 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2022-06-28 01:19:37,562 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2022-06-28 01:19:38,055 [om2@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1        | [id: "om1"
om2_1        | address: "om1:9872"
om2_1        | , id: "om3"
om2_1        | address: "om3:9872"
om2_1        | , id: "om2"
om2_1        | address: "om2:9872"
om2_1        | ]
om2_1        | 2022-06-28 01:19:39,505 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46986
om2_1        | 2022-06-28 01:19:39,521 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:25:26,948 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46302
om1_1        | 2022-06-28 01:25:26,983 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:25:27,665 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:67614-target
om1_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-28 01:25:31,676 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46316
om1_1        | 2022-06-28 01:25:31,700 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:26:27,727 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46646
om1_1        | 2022-06-28 01:26:27,749 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:26:33,137 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:45215
om1_1        | 2022-06-28 01:26:33,158 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:26:33,757 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1088774785 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:26:37,693 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46674
om1_1        | 2022-06-28 01:26:37,723 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:26:41,238 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3383746089 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:26:51,671 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46718
om1_1        | 2022-06-28 01:26:51,685 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:26:55,259 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9610832201 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:26:55,900 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-rbeuewmjgc of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:27:00,834 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-cquyfepsao of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:27:11,854 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46804
om1_1        | 2022-06-28 01:27:11,876 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:27:15,493 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4118624588 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:27:16,208 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6741282977 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:27:16,862 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0865895385 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:27:17,512 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-0865895385 in volume:s3v
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-28 01:27:22,569 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46836
om1_1        | 2022-06-28 01:27:22,589 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:27:26,128 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2757426933 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:27:26,785 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6611295494 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:27:27,995 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-3175990109 in volume:s3v
om1_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om2_1        | 2022-06-28 01:19:54,949 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47026
om2_1        | 2022-06-28 01:19:54,951 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:19:55,829 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om2_1        | 2022-06-28 01:19:56,159 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om2_1        | 2022-06-28 01:20:07,410 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47086
om2_1        | 2022-06-28 01:20:07,422 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:20:08,185 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47090
om2_1        | 2022-06-28 01:20:08,191 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:20:13,738 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47106
om2_1        | 2022-06-28 01:20:13,743 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:20:14,363 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47110
om2_1        | 2022-06-28 01:20:14,377 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:20:14,397 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om2_1        | 2022-06-28 01:20:19,517 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47124
om2_1        | 2022-06-28 01:20:19,521 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:20:27,972 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47166
om2_1        | 2022-06-28 01:20:27,983 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:20:33,872 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47180
om2_1        | 2022-06-28 01:20:33,877 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:20:34,507 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47184
om2_1        | 2022-06-28 01:20:34,517 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:20:34,546 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om2_1        | 2022-06-28 01:20:39,683 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47198
om2_1        | 2022-06-28 01:20:39,694 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:20:40,294 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46345
om2_1        | 2022-06-28 01:20:40,302 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:20:44,671 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47214
om2_1        | 2022-06-28 01:20:44,682 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:21:00,656 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47282
om2_1        | 2022-06-28 01:21:00,664 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:21:01,185 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:67614-source for user:testuser
om2_1        | 2022-06-28 01:21:05,269 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47288
om2_1        | 2022-06-28 01:21:05,273 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:21:05,988 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:67614-target for user:testuser
om2_1        | 2022-06-28 01:21:09,939 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47304
om2_1        | 2022-06-28 01:21:09,948 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:21:10,590 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 67614-source
om2_1        | 2022-06-28 01:21:14,596 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47318
om2_1        | 2022-06-28 01:21:14,601 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.0.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.44.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.44.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.4.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.14.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.23.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.44.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.19.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/aws-java-sdk-bundle-1.12.125.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.44.0.jar:/opt/hadoop/share/ozone/lib/solr-solrj-8.6.3.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.44.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.44.v20210927.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.4.9-1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.44.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hive-storage-api-2.7.2.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.44.0.jar:/opt/hadoop/share/ozone/lib/kafka-clients-2.8.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.13.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-intg-3.0.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-2.0.48.Final.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-06-28 01:18:50,508 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-06-28 01:18:58,276 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-06-28 01:19:01,928 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-06-28 01:19:02,688 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-06-28 01:19:02,695 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-06-28 01:19:02,696 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-06-28 01:19:02,792 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-06-28 01:19:02,950 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om3_1        | 2022-06-28 01:19:04,022 [main] INFO reflections.Reflections: Reflections took 780 ms to scan 1 urls, producing 113 keys and 337 values [using 2 cores]
om3_1        | 2022-06-28 01:19:05,017 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-06-28 01:19:05,026 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-06-28 01:19:05,030 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-06-28 01:19:07,351 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-06-28 01:19:07,583 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-06-28 01:19:12,047 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2022-06-28 01:19:12,756 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/1014315781759.crt.
om3_1        | 2022-06-28 01:19:12,793 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2022-06-28 01:19:12,821 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-916105677270.crt.
om3_1        | 2022-06-28 01:19:13,062 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-06-28 01:19:14,018 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-06-28 01:19:14,026 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-06-28 01:19:15,767 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om3_1        | 2022-06-28 01:19:15,841 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2022-06-28 01:19:15,841 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2022-06-28 01:19:16,642 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om3_1        | 2022-06-28 01:19:17,457 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-06-28 01:19:17,458 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2022-06-28 01:19:17,551 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2022-06-28 01:19:18,225 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2022-06-28 01:19:18,262 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-06-28 01:19:18,508 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om3:9872, om1:9872, om2:9872
om3_1        | 2022-06-28 01:19:18,577 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2022-06-28 01:19:19,406 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2022-06-28 01:19:19,761 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2022-06-28 01:19:19,763 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
s3g_1        | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om2_1        | 2022-06-28 01:21:24,086 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47368
om2_1        | 2022-06-28 01:21:24,087 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:21:24,800 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 67614-source
om2_1        | 2022-06-28 01:21:28,842 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47374
om2_1        | 2022-06-28 01:21:28,847 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:21:29,513 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 67614-target
om2_1        | 2022-06-28 01:21:33,432 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47388
om2_1        | 2022-06-28 01:21:33,438 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:21:34,034 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 67614-target
om2_1        | 2022-06-28 01:21:37,591 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47402
om2_1        | 2022-06-28 01:21:37,593 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:21:38,291 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 67614-target
om2_1        | 2022-06-28 01:21:40,372 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41313
om2_1        | 2022-06-28 01:21:40,381 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:21:41,830 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47410
om2_1        | 2022-06-28 01:21:41,840 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:21:46,546 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47424
om2_1        | 2022-06-28 01:21:46,551 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:21:51,044 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47438
om2_1        | 2022-06-28 01:21:51,049 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:21:56,018 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47476
om2_1        | 2022-06-28 01:21:56,023 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:22:00,650 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47500
om2_1        | 2022-06-28 01:22:00,659 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:22:05,911 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47508
om2_1        | 2022-06-28 01:22:05,919 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:22:06,612 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 67614-target
om2_1        | 2022-06-28 01:22:10,568 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47524
om2_1        | 2022-06-28 01:22:10,577 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:22:15,316 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47542
om2_1        | 2022-06-28 01:22:15,323 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:22:16,010 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 67614-target
om2_1        | 2022-06-28 01:22:20,130 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47556
om2_1        | 2022-06-28 01:22:20,135 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:22:20,740 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 67614-source
om2_1        | 2022-06-28 01:22:25,068 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47594
om2_1        | 2022-06-28 01:22:25,077 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:22:34,207 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47612
recon_1      | 2022-06-28 01:17:36,263 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2022-06-28 01:17:36,295 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2022-06-28 01:17:36,296 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2022-06-28 01:17:36,955 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2022-06-28 01:17:36,992 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
recon_1      | 2022-06-28 01:17:37,074 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2022-06-28 01:17:37,074 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2022-06-28 01:17:37,076 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
recon_1      | 2022-06-28 01:17:37,133 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-06-28 01:17:37,138 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@a1be5cb{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 2022-06-28 01:17:37,142 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6a887649{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2022-06-28 01:17:38,448 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-06-28 01:17:38,469 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-06-28 01:17:41,879 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@518b5d87{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-14709854423668997999/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1      | 2022-06-28 01:17:41,898 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@106c73ed{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1      | 2022-06-28 01:17:41,899 [Listener at 0.0.0.0/9891] INFO server.Server: Started @57178ms
recon_1      | 2022-06-28 01:17:41,905 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1      | 2022-06-28 01:17:41,905 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1      | 2022-06-28 01:17:41,907 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1      | 2022-06-28 01:17:41,907 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1      | 2022-06-28 01:17:41,932 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1      | 2022-06-28 01:17:41,943 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1      | 2022-06-28 01:17:41,944 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1      | 2022-06-28 01:17:41,944 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-06-28 01:17:41,944 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1      | 2022-06-28 01:17:41,960 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1      | 2022-06-28 01:17:42,484 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1      | 2022-06-28 01:17:42,489 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-06-28 01:17:42,495 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1      | 2022-06-28 01:17:42,498 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1      | 2022-06-28 01:17:42,499 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1      | 2022-06-28 01:17:42,580 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1      | 2022-06-28 01:17:42,580 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1      | 2022-06-28 01:17:42,614 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1      | 2022-06-28 01:17:42,615 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1      | 2022-06-28 01:17:42,615 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-06-28 01:17:42,625 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 39 milliseconds.
recon_1      | 2022-06-28 01:18:01,945 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:18:01,946 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:18:02,185 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:02,194 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:04,196 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 3 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:04,198 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 4 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:04,199 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:06,201 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 6 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:06,202 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 7 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:06,203 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:08,205 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 9 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:08,206 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 10 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:08,207 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 2022-06-28 01:19:19,765 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2022-06-28 01:19:19,765 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-06-28 01:19:19,766 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-06-28 01:19:19,766 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2022-06-28 01:19:19,772 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-06-28 01:19:19,778 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2022-06-28 01:19:19,781 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2022-06-28 01:19:19,829 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om3_1        | 2022-06-28 01:19:19,838 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om3_1        | 2022-06-28 01:19:22,664 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2022-06-28 01:19:22,681 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om3_1        | 2022-06-28 01:19:22,682 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om3_1        | 2022-06-28 01:19:22,683 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-06-28 01:19:22,687 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-06-28 01:19:22,701 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-06-28 01:19:22,801 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@189fe8af[Not completed]
om3_1        | 2022-06-28 01:19:22,808 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2022-06-28 01:19:22,992 [pool-27-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2022-06-28 01:19:23,005 [main] INFO om.OzoneManager: Creating RPC Server
om3_1        | 2022-06-28 01:19:23,074 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2022-06-28 01:19:23,077 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2022-06-28 01:19:23,077 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2022-06-28 01:19:23,077 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-06-28 01:19:23,078 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-06-28 01:19:23,078 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2022-06-28 01:19:23,172 [pool-27-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2022-06-28 01:19:23,180 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-06-28 01:19:23,187 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2022-06-28 01:19:23,220 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1        | 2022-06-28 01:19:23,242 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2022-06-28 01:19:23,498 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 8@om3
om3_1        | 2022-06-28 01:19:23,748 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2022-06-28 01:19:23,789 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2022-06-28 01:19:23,825 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2022-06-28 01:19:23,940 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2022-06-28 01:19:23,953 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-06-28 01:19:23,990 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om3_1        | 2022-06-28 01:19:24,258 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-06-28 01:19:24,389 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2022-06-28 01:19:24,390 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2022-06-28 01:19:24,499 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2022-06-28 01:19:24,500 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2022-06-28 01:19:24,503 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2022-06-28 01:19:24,511 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-06-28 01:19:24,516 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2022-06-28 01:19:24,517 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2022-06-28 01:19:24,543 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2022-06-28 01:19:24,543 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1        | 2022-06-28 01:19:24,544 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2022-06-28 01:19:24,651 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2022-06-28 01:19:24,660 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om3_1        | 2022-06-28 01:19:24,661 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2022-06-28 01:19:24,742 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om3_1        | 2022-06-28 01:19:24,751 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2022-06-28 01:19:24,848 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2022-06-28 01:19:24,857 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2022-06-28 01:19:24,860 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2022-06-28 01:19:24,875 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2022-06-28 01:19:24,885 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2022-06-28 01:19:24,892 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2022-06-28 01:19:25,257 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2022-06-28 01:19:25,268 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om3_1        | 2022-06-28 01:19:25,278 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om3_1        | 2022-06-28 01:19:25,280 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om3_1        | 2022-06-28 01:19:25,282 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om3_1        | 2022-06-28 01:19:26,096 [main] INFO reflections.Reflections: Reflections took 2265 ms to scan 8 urls, producing 23 keys and 512 values [using 2 cores]
om3_1        | 2022-06-28 01:19:27,381 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2022-06-28 01:19:27,431 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2022-06-28 01:19:31,890 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2022-06-28 01:19:31,944 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2022-06-28 01:19:31,944 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2022-06-28 01:19:32,160 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2022-06-28 01:19:32,163 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1        | 2022-06-28 01:19:32,176 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-06-28 01:19:32,180 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2022-06-28 01:19:32,181 [om3-impl-thread1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-06-28 01:19:32,198 [om3-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2022-06-28 01:19:32,215 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2022-06-28 01:19:32,412 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2022-06-28 01:19:32,415 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$449/0x00000008405aa440@458d6519] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2022-06-28 01:19:32,416 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2022-06-28 01:19:32,417 [Listener at om3/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-06-28 01:19:32,422 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2022-06-28 01:19:32,423 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-06-28 01:19:32,431 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1        | 2022-06-28 01:19:32,428 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2022-06-28 01:19:32,540 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2022-06-28 01:19:32,540 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2022-06-28 01:19:32,540 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2022-06-28 01:19:32,580 [Listener at om3/9862] INFO util.log: Logging initialized @51601ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2022-06-28 01:19:32,834 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2022-06-28 01:19:32,849 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2022-06-28 01:19:32,858 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2022-06-28 01:19:32,858 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2022-06-28 01:19:32,859 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2022-06-28 01:19:32,862 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2022-06-28 01:19:32,953 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2022-06-28 01:19:32,956 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om3_1        | 2022-06-28 01:19:33,020 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2022-06-28 01:19:33,020 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2022-06-28 01:19:33,024 [Listener at om3/9862] INFO server.session: node0 Scavenging every 600000ms
om3_1        | 2022-06-28 01:19:33,042 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-06-28 01:19:33,045 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2413efce{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1        | 2022-06-28 01:19:33,046 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@242c2da4{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-06-28 01:16:53,171 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | 2022-06-28 01:22:34,214 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:22:40,428 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43281
om2_1        | 2022-06-28 01:22:40,442 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:22:41,287 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47632
om2_1        | 2022-06-28 01:22:41,293 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:22:49,288 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47658
om2_1        | 2022-06-28 01:22:49,292 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:22:56,556 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47700
om2_1        | 2022-06-28 01:22:56,563 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:01,314 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47724
om2_1        | 2022-06-28 01:23:01,319 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:06,241 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47730
om2_1        | 2022-06-28 01:23:06,251 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:10,777 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47746
om2_1        | 2022-06-28 01:23:10,783 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:15,594 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47760
om2_1        | 2022-06-28 01:23:15,604 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:19,967 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47774
om2_1        | 2022-06-28 01:23:19,975 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:24,921 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47812
om2_1        | 2022-06-28 01:23:24,928 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:29,423 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47820
om2_1        | 2022-06-28 01:23:29,431 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:34,239 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47834
om2_1        | 2022-06-28 01:23:34,245 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:38,981 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47848
om2_1        | 2022-06-28 01:23:38,991 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:40,483 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38285
om2_1        | 2022-06-28 01:23:40,486 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:43,631 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47864
om2_1        | 2022-06-28 01:23:43,640 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:48,010 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47870
om2_1        | 2022-06-28 01:23:48,015 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:52,995 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47908
om2_1        | 2022-06-28 01:23:53,008 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:53,552 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 67614-target
om2_1        | 2022-06-28 01:23:57,729 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47922
om3_1        | 2022-06-28 01:19:33,549 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-06-28 01:19:33,594 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2b79945f{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-7058257573343652019/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2022-06-28 01:19:33,623 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@1e2abb0c{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2022-06-28 01:19:33,625 [Listener at om3/9862] INFO server.Server: Started @52646ms
om3_1        | 2022-06-28 01:19:33,643 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2022-06-28 01:19:33,644 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2022-06-28 01:19:33,652 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1        | 2022-06-28 01:19:33,657 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2022-06-28 01:19:33,657 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2022-06-28 01:19:33,728 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om3_1        | 2022-06-28 01:19:34,084 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44595
om3_1        | 2022-06-28 01:19:34,125 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-06-28 01:19:34,373 [Listener at om3/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om3_1        | 2022-06-28 01:19:34,396 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4036d9cd] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2022-06-28 01:19:36,397 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-06-28 01:19:36,423 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-06-28 01:19:36,433 [grpc-default-executor-0] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: accept ELECTION from om2: our priority 0 <= candidate's priority 0
om3_1        | 2022-06-28 01:19:36,436 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:om2
om3_1        | 2022-06-28 01:19:36,442 [grpc-default-executor-0] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-06-28 01:19:36,445 [grpc-default-executor-0] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-06-28 01:19:36,456 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState was interrupted
om3_1        | 2022-06-28 01:19:36,596 [grpc-default-executor-0] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:OK-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om2, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-06-28 01:19:36,600 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: reject ELECTION from om1: already has voted for om2 at current term 1
om3_1        | 2022-06-28 01:19:36,617 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om2, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-06-28 01:19:37,300 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om2 at term 1 for appendEntries, leader elected after 13511ms
om3_1        | 2022-06-28 01:19:37,450 [om3-server-thread2] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2022-06-28 01:19:37,490 [om3-server-thread2] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2022-06-28 01:19:37,882 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2022-06-28 01:19:40,725 [om3@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1        | [id: "om1"
om3_1        | address: "om1:9872"
om3_1        | , id: "om3"
om3_1        | address: "om3:9872"
om3_1        | , id: "om2"
om3_1        | address: "om2:9872"
om3_1        | ]
om3_1        | 2022-06-28 01:19:55,961 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om3_1        | 2022-06-28 01:19:56,219 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om3_1        | 2022-06-28 01:20:14,403 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om3_1        | 2022-06-28 01:20:34,558 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om3_1        | 2022-06-28 01:21:01,197 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:67614-source for user:testuser
om3_1        | 2022-06-28 01:21:06,010 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:67614-target for user:testuser
om3_1        | 2022-06-28 01:21:10,609 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 67614-source
om3_1        | 2022-06-28 01:21:24,813 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 67614-source
om3_1        | 2022-06-28 01:21:29,523 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 67614-target
om3_1        | 2022-06-28 01:21:34,043 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 67614-target
om3_1        | 2022-06-28 01:21:38,302 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 67614-target
om3_1        | 2022-06-28 01:22:06,627 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 67614-target
om3_1        | 2022-06-28 01:22:16,022 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 67614-target
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-06-28 01:16:53,214 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-06-28 01:16:53,379 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-06-28 01:16:53,502 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-06-28 01:16:53,535 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-06-28 01:16:53,697 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-06-28 01:16:53,703 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-06-28 01:16:53,718 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2022-06-28 01:16:55,842 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2022-06-28 01:16:55,843 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2022-06-28 01:16:55,853 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2022-06-28 01:16:57,424 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2022-06-28 01:17:00,241 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-06-28 01:17:00,244 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-06-28 01:17:00,600 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-06-28 01:17:00,608 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-06-28 01:17:00,610 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:45e35def-6cad-44ae-bb26-f31c46277acf,clusterId:CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b,subject:scm-sub@scm1.org
scm1.org_1   | 2022-06-28 01:17:00,815 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2022-06-28 01:17:01,300 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-06-28 01:17:01,551 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-06-28 01:17:01,551 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-06-28 01:17:01,558 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-06-28 01:17:01,563 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-06-28 01:17:01,564 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-06-28 01:17:01,571 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-06-28 01:17:01,573 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-06-28 01:17:01,574 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-06-28 01:17:01,574 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-06-28 01:17:01,588 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2022-06-28 01:17:01,589 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2022-06-28 01:17:02,048 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-06-28 01:17:02,050 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm1.org_1   | 2022-06-28 01:17:02,051 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2022-06-28 01:17:02,051 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-06-28 01:17:02,051 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-06-28 01:17:02,067 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-06-28 01:17:02,116 [main] INFO server.RaftServer: 45e35def-6cad-44ae-bb26-f31c46277acf: addNew group-0A2F691DD86B:[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|priority:0] returns group-0A2F691DD86B:java.util.concurrent.CompletableFuture@4098dd77[Not completed]
scm1.org_1   | 2022-06-28 01:17:02,199 [pool-2-thread-1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf: new RaftServerImpl for group-0A2F691DD86B:[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-06-28 01:17:02,201 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-06-28 01:17:02,201 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-06-28 01:17:02,202 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-06-28 01:17:02,202 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-06-28 01:17:02,202 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-06-28 01:17:02,202 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-06-28 01:17:02,236 [pool-2-thread-1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: ConfigurationManager, init=-1: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-06-28 01:17:02,248 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-06-28 01:17:02,265 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-06-28 01:17:02,281 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-06-28 01:17:02,283 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b does not exist. Creating ...
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2496)
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2466)
om1_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-28 01:27:31,754 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46892
om1_1        | 2022-06-28 01:27:31,770 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:27:35,287 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1580261655 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:27:40,288 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46912
om1_1        | 2022-06-28 01:27:40,317 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:27:43,849 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1120923398 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:27:48,412 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46932
om1_1        | 2022-06-28 01:27:48,429 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:27:54,537 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46972
om1_1        | 2022-06-28 01:27:54,557 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:27:58,146 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5564991060 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:28:18,686 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-5564991060/ozone-test-5000324300/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om1_1        | 2022-06-28 01:28:18,688 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-5000324300/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om1_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-5000324300/multipartKey2. Entity too small.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:531)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-28 01:28:20,079 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1        | partName: "etag1"
om1_1        | , partNumber: 2
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-06-28 01:28:20,088 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-28 01:28:20,758 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1        | partName: "etag1"
om1_1        | , partNumber: 1
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-06-28 01:28:20,760 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-28 01:28:25,704 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3-2a006813-f609-44fe-9fcb-309b6e384c0f-108552499976536100-1
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:508)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-28 01:28:26,353 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3-2a006813-f609-44fe-9fcb-309b6e384c0f-108552499976536100-2
recon_1      | 2022-06-28 01:18:10,208 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 12 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:10,210 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 13 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:10,211 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:12,213 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 15 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:12,214 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 16 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:12,215 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:14,218 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 18 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:14,219 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 19 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:14,225 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 20 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:16,240 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 21 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:16,261 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 22 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:16,263 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 23 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:18,267 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 24 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:18,269 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 25 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:18,272 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 26 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:20,274 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 27 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:20,275 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 28 failover attempts. Trying to failover immediately.
om3_1        | 2022-06-28 01:22:20,754 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 67614-source
om3_1        | 2022-06-28 01:23:53,568 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 67614-target
om3_1        | 2022-06-28 01:23:58,289 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:67614-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-28 01:24:02,665 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 67614-target
om3_1        | 2022-06-28 01:24:07,040 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:67614-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-28 01:24:30,488 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 67614-target
om3_1        | 2022-06-28 01:24:35,194 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 67614-target
om3_1        | 2022-06-28 01:24:40,040 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 67614-target
om3_1        | 2022-06-28 01:24:49,209 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 67614-target
om3_1        | 2022-06-28 01:25:23,158 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 67614-target
om3_1        | 2022-06-28 01:25:27,676 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:67614-target
om3_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-28 01:26:33,773 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1088774785 of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:26:41,233 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3383746089 of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:26:55,250 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9610832201 of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:26:55,904 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-rbeuewmjgc of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:27:00,855 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-cquyfepsao of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:27:15,483 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4118624588 of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:27:16,220 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6741282977 of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:27:16,864 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0865895385 of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:27:17,524 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-0865895385 in volume:s3v
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
recon_1      | 2022-06-28 01:18:20,275 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 29 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:22,279 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 30 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:22,280 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 31 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:22,281 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 32 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:24,282 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 33 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:24,284 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 34 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:24,284 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 35 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:26,286 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 36 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:26,287 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 37 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:26,288 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 38 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:28,290 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 39 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:28,292 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 40 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:28,296 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 41 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:30,297 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 42 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:30,298 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 43 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:30,299 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 44 failover attempts. Trying to failover after sleeping for 2000ms.
om2_1        | 2022-06-28 01:23:57,734 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:23:58,273 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:67614-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-28 01:24:02,009 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47946
om2_1        | 2022-06-28 01:24:02,013 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:24:02,645 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 67614-target
om2_1        | 2022-06-28 01:24:06,499 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47962
om2_1        | 2022-06-28 01:24:06,504 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:24:07,022 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:67614-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-28 01:24:11,054 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47968
om2_1        | 2022-06-28 01:24:11,059 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:24:15,945 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47982
om2_1        | 2022-06-28 01:24:15,955 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:24:16,481 [IPC Server handler 12 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket Volume:67614-target Bucket:unreadable-link 
om2_1        | 2022-06-28 01:24:20,410 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47996
om2_1        | 2022-06-28 01:24:20,419 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:24:25,329 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48034
om2_1        | 2022-06-28 01:24:25,339 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:24:25,912 [IPC Server handler 5 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket Volume:67614-source Bucket:unreadable-bucket Key:
om2_1        | 2022-06-28 01:24:29,886 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48040
om2_1        | 2022-06-28 01:24:29,891 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:24:30,473 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 67614-target
om2_1        | 2022-06-28 01:24:34,623 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48054
om2_1        | 2022-06-28 01:24:34,625 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:24:35,184 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 67614-target
om2_1        | 2022-06-28 01:24:39,343 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48068
om2_1        | 2022-06-28 01:24:39,353 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:24:40,031 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 67614-target
om2_1        | 2022-06-28 01:24:40,521 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41295
om2_1        | 2022-06-28 01:24:40,531 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 2022-06-28 01:18:32,301 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 45 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:32,302 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 46 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:32,302 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 47 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:34,304 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 48 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:34,305 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 49 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:34,306 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 50 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:36,308 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 51 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:36,309 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 52 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:36,310 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 53 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:38,311 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 54 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:38,312 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 55 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:38,313 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 56 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:40,314 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 57 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:40,315 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 58 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:40,315 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 59 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:42,317 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 60 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:42,318 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 61 failover attempts. Trying to failover immediately.
scm1.org_1   | 2022-06-28 01:17:02,307 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/in_use.lock acquired by nodename 87@scm1.org
scm1.org_1   | 2022-06-28 01:17:02,321 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b has been successfully formatted.
scm1.org_1   | 2022-06-28 01:17:02,329 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-06-28 01:17:02,339 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-06-28 01:17:02,354 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-06-28 01:17:02,356 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-06-28 01:17:02,363 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2022-06-28 01:17:02,378 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-06-28 01:17:02,550 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-06-28 01:17:02,564 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-06-28 01:17:02,565 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-06-28 01:17:02,578 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b
scm1.org_1   | 2022-06-28 01:17:02,578 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-06-28 01:17:02,579 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-06-28 01:17:02,580 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-06-28 01:17:02,580 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-06-28 01:17:02,580 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-06-28 01:17:02,581 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-06-28 01:17:02,581 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-06-28 01:17:02,581 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-06-28 01:17:02,602 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-06-28 01:17:02,603 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2022-06-28 01:17:02,611 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-06-28 01:17:02,617 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-06-28 01:17:02,617 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-06-28 01:17:02,639 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-06-28 01:17:02,640 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-06-28 01:17:02,640 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-06-28 01:17:02,641 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-06-28 01:17:02,642 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-06-28 01:17:02,643 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-06-28 01:17:02,817 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-06-28 01:17:02,819 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2022-06-28 01:17:02,824 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2022-06-28 01:17:02,824 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2022-06-28 01:17:02,825 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2022-06-28 01:17:02,842 [45e35def-6cad-44ae-bb26-f31c46277acf-impl-thread1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: start as a follower, conf=-1: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-06-28 01:17:02,844 [45e35def-6cad-44ae-bb26-f31c46277acf-impl-thread1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2022-06-28 01:17:02,847 [45e35def-6cad-44ae-bb26-f31c46277acf-impl-thread1] INFO impl.RoleInfo: 45e35def-6cad-44ae-bb26-f31c46277acf: start 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState
scm1.org_1   | 2022-06-28 01:17:02,866 [45e35def-6cad-44ae-bb26-f31c46277acf-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0A2F691DD86B,id=45e35def-6cad-44ae-bb26-f31c46277acf
scm1.org_1   | 2022-06-28 01:17:02,878 [main] INFO server.RaftServer: 45e35def-6cad-44ae-bb26-f31c46277acf: start RPC server
scm1.org_1   | 2022-06-28 01:17:02,995 [main] INFO server.GrpcService: 45e35def-6cad-44ae-bb26-f31c46277acf: GrpcService started, listening on 9894
scm1.org_1   | 2022-06-28 01:17:03,011 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$354/0x000000084031f040@31e76a8d] INFO util.JvmPauseMonitor: JvmPauseMonitor-45e35def-6cad-44ae-bb26-f31c46277acf: Started
scm1.org_1   | 2022-06-28 01:17:08,039 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState] INFO impl.FollowerState: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5193792140ns, electionTimeout:5173ms
scm1.org_1   | 2022-06-28 01:17:08,040 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState] INFO impl.RoleInfo: 45e35def-6cad-44ae-bb26-f31c46277acf: shutdown 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState
scm1.org_1   | 2022-06-28 01:17:08,041 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm1.org_1   | 2022-06-28 01:17:08,043 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-28 01:27:26,123 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2757426933 of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:27:26,796 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6611295494 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:24:44,061 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48084
om2_1        | 2022-06-28 01:24:44,067 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:24:48,658 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48098
om2_1        | 2022-06-28 01:24:48,674 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:24:49,197 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 67614-target
om2_1        | 2022-06-28 01:24:53,639 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48128
om2_1        | 2022-06-28 01:24:53,647 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:25:01,072 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48164
om2_1        | 2022-06-28 01:25:01,083 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:25:08,222 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48184
om2_1        | 2022-06-28 01:25:08,227 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:25:12,820 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48198
om2_1        | 2022-06-28 01:25:12,832 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:25:17,604 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48204
om2_1        | 2022-06-28 01:25:17,612 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:25:22,609 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48242
om2_1        | 2022-06-28 01:25:22,616 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:25:23,149 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 67614-target
om2_1        | 2022-06-28 01:25:27,027 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48256
om2_1        | 2022-06-28 01:25:27,032 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:25:27,671 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:67614-target
om2_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-28 01:25:31,740 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48270
om2_1        | 2022-06-28 01:25:31,749 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:25:40,570 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35309
om2_1        | 2022-06-28 01:25:40,581 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:26:27,788 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48600
om2_1        | 2022-06-28 01:26:27,801 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:26:33,187 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:46047
om2_1        | 2022-06-28 01:26:33,198 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:26:33,630 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:33,740 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:33,760 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1088774785 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:26:37,780 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48628
om2_1        | 2022-06-28 01:26:37,789 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2022-06-28 01:17:08,043 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState] INFO impl.RoleInfo: 45e35def-6cad-44ae-bb26-f31c46277acf: start 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1
scm1.org_1   | 2022-06-28 01:17:08,053 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO impl.LeaderElection: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-06-28 01:17:08,054 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO impl.LeaderElection: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2022-06-28 01:17:08,054 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO impl.RoleInfo: 45e35def-6cad-44ae-bb26-f31c46277acf: shutdown 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1
scm1.org_1   | 2022-06-28 01:17:08,055 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm1.org_1   | 2022-06-28 01:17:08,055 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: change Leader from null to 45e35def-6cad-44ae-bb26-f31c46277acf at term 1 for becomeLeader, leader elected after 5726ms
scm1.org_1   | 2022-06-28 01:17:08,061 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-06-28 01:17:08,065 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-06-28 01:17:08,066 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-06-28 01:17:08,072 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-06-28 01:17:08,072 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-06-28 01:17:08,072 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-06-28 01:17:08,077 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-06-28 01:17:08,079 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-06-28 01:17:08,081 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO impl.RoleInfo: 45e35def-6cad-44ae-bb26-f31c46277acf: start 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderStateImpl
scm1.org_1   | 2022-06-28 01:17:08,131 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2022-06-28 01:17:08,156 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: set configuration 0: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-06-28 01:17:08,194 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/current/log_inprogress_0
scm1.org_1   | 2022-06-28 01:17:09,013 [main] INFO server.RaftServer: 45e35def-6cad-44ae-bb26-f31c46277acf: close
scm1.org_1   | 2022-06-28 01:17:09,015 [main] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: shutdown
scm1.org_1   | 2022-06-28 01:17:09,015 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0A2F691DD86B,id=45e35def-6cad-44ae-bb26-f31c46277acf
scm1.org_1   | 2022-06-28 01:17:09,015 [main] INFO impl.RoleInfo: 45e35def-6cad-44ae-bb26-f31c46277acf: shutdown 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderStateImpl
scm1.org_1   | 2022-06-28 01:17:09,020 [main] INFO impl.PendingRequests: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-PendingRequests: sendNotLeaderResponses
scm1.org_1   | 2022-06-28 01:17:09,024 [main] INFO impl.StateMachineUpdater: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2022-06-28 01:17:09,025 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO impl.StateMachineUpdater: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2022-06-28 01:17:09,025 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO impl.StateMachineUpdater: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2022-06-28 01:17:09,030 [main] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: closes. applyIndex: 0
scm1.org_1   | 2022-06-28 01:17:09,031 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm1.org_1   | 2022-06-28 01:17:09,033 [main] INFO segmented.SegmentedRaftLogWorker: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker close()
scm1.org_1   | 2022-06-28 01:17:09,034 [main] INFO server.GrpcService: 45e35def-6cad-44ae-bb26-f31c46277acf: shutdown server with port 9894 now
scm1.org_1   | 2022-06-28 01:17:09,042 [main] INFO server.GrpcService: 45e35def-6cad-44ae-bb26-f31c46277acf: shutdown server with port 9894 successfully
scm1.org_1   | 2022-06-28 01:17:09,042 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$354/0x000000084031f040@31e76a8d] INFO util.JvmPauseMonitor: JvmPauseMonitor-45e35def-6cad-44ae-bb26-f31c46277acf: Stopped
scm1.org_1   | 2022-06-28 01:17:09,043 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-06-28 01:17:09,046 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b; layoutVersion=4; scmId=45e35def-6cad-44ae-bb26-f31c46277acf
scm1.org_1   | 2022-06-28 01:17:09,062 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm1.org_1   | ************************************************************/
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-06-28 01:17:10,692 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:508)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-28 01:28:26,966 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3
om1_1        | 2022-06-28 01:28:26,969 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om1_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3 because parts are in Invalid order.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:474)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-28 01:28:30,549 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-3753552445/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-5564991060
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-5564991060key: ozone-test-3753552445/multipartKey5
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-28 01:28:31,219 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-5564991060, Key:ozone-test-0179098423/multipartKey. 
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:758)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:282)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-28 01:29:20,963 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47364
om1_1        | 2022-06-28 01:29:20,980 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:29:24,707 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8289378492 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:29:25,407 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-60493 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:29:36,130 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47442
om1_1        | 2022-06-28 01:29:36,165 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:29:39,662 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4399908439 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:30:00,939 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47562
om1_1        | 2022-06-28 01:30:00,975 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:30:06,133 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1615782415 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:30:10,559 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1615782415, Key:ozone-test-2265625205/multidelete/key=value/f4.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-06-28 01:30:18,596 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47612
om1_1        | 2022-06-28 01:30:18,617 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:30:23,474 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2257556859 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:31:47,412 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47886
om1_1        | 2022-06-28 01:31:47,457 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-06-28 01:31:51,939 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2995237214 of layout LEGACY in volume: s3v
om1_1        | 2022-06-28 01:32:15,956 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47978
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-06-28 01:17:10,700 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-06-28 01:17:10,772 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-06-28 01:17:10,836 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-06-28 01:17:10,861 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-06-28 01:17:10,916 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-06-28 01:17:10,917 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-06-28 01:17:11,423 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm1.org_1   | 2022-06-28 01:17:11,533 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2022-06-28 01:17:11,535 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/916105677270.crt.
scm1.org_1   | 2022-06-28 01:17:11,539 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2022-06-28 01:17:11,638 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2022-06-28 01:17:11,638 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2022-06-28 01:17:11,664 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-06-28 01:17:11,837 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-06-28 01:17:12,180 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm1.org_1   | 2022-06-28 01:17:12,181 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm1.org_1   | 2022-06-28 01:17:12,226 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-06-28 01:17:12,244 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:45e35def-6cad-44ae-bb26-f31c46277acf
scm1.org_1   | 2022-06-28 01:17:12,325 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-06-28 01:17:12,388 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-06-28 01:17:12,388 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-06-28 01:17:12,389 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-06-28 01:17:12,389 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-06-28 01:17:12,389 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-06-28 01:17:12,390 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-06-28 01:17:12,391 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-06-28 01:17:12,392 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-06-28 01:17:12,392 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-06-28 01:17:12,404 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2022-06-28 01:17:12,405 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2022-06-28 01:17:12,933 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-06-28 01:17:12,935 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm1.org_1   | 2022-06-28 01:17:12,936 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2022-06-28 01:17:12,936 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-06-28 01:17:12,936 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-06-28 01:17:12,939 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-06-28 01:17:12,942 [45e35def-6cad-44ae-bb26-f31c46277acf-impl-thread1] INFO server.RaftServer: 45e35def-6cad-44ae-bb26-f31c46277acf: found a subdirectory /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b
scm1.org_1   | 2022-06-28 01:17:12,973 [main] INFO server.RaftServer: 45e35def-6cad-44ae-bb26-f31c46277acf: addNew group-0A2F691DD86B:[] returns group-0A2F691DD86B:java.util.concurrent.CompletableFuture@38e83838[Not completed]
scm1.org_1   | 2022-06-28 01:17:12,994 [pool-16-thread-1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf: new RaftServerImpl for group-0A2F691DD86B:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-06-28 01:17:12,996 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-06-28 01:17:12,997 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-06-28 01:17:12,997 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-06-28 01:17:12,998 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-06-28 01:17:12,998 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-06-28 01:17:12,998 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-06-28 01:17:13,005 [pool-16-thread-1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-06-28 01:17:13,005 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-06-28 01:17:13,008 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-06-28 01:17:13,009 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1        | 2022-06-28 01:27:28,000 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-3175990109 in volume:s3v
om3_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2496)
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2466)
om3_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-28 01:27:35,282 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1580261655 of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:27:43,853 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1120923398 of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:27:58,141 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5564991060 of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:28:18,687 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-5564991060/ozone-test-5000324300/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om3_1        | 2022-06-28 01:28:18,691 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-5000324300/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om3_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-5000324300/multipartKey2. Entity too small.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:531)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-28 01:28:20,077 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om3_1        | partName: "etag1"
om3_1        | , partNumber: 2
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-06-28 01:28:20,083 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-28 01:28:20,753 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om3_1        | partName: "etag1"
om3_1        | , partNumber: 1
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-06-28 01:28:20,755 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-28 01:28:25,699 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
scm1.org_1   | 2022-06-28 01:17:13,018 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/in_use.lock acquired by nodename 7@scm1.org
scm1.org_1   | 2022-06-28 01:17:13,023 [pool-16-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=45e35def-6cad-44ae-bb26-f31c46277acf} from /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/current/raft-meta
scm1.org_1   | 2022-06-28 01:17:13,053 [pool-16-thread-1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: set configuration 0: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-06-28 01:17:13,054 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-06-28 01:17:13,056 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-06-28 01:17:13,065 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-06-28 01:17:13,065 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-06-28 01:17:13,067 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2022-06-28 01:17:13,144 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-06-28 01:17:13,153 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-06-28 01:17:13,153 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-06-28 01:17:13,159 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b
scm1.org_1   | 2022-06-28 01:17:13,159 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-06-28 01:17:13,160 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-06-28 01:17:13,161 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-06-28 01:17:13,161 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-06-28 01:17:13,162 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-06-28 01:17:13,163 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-06-28 01:17:13,163 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-06-28 01:17:13,164 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-06-28 01:17:13,174 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-06-28 01:17:13,174 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2022-06-28 01:17:13,175 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-06-28 01:17:13,199 [pool-16-thread-1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: set configuration 0: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-06-28 01:17:13,200 [pool-16-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/current/log_inprogress_0
scm1.org_1   | 2022-06-28 01:17:13,203 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-06-28 01:17:13,203 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-06-28 01:17:13,277 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-06-28 01:17:13,278 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-06-28 01:17:13,279 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-06-28 01:17:13,280 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-06-28 01:17:13,282 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-06-28 01:17:13,282 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-06-28 01:17:13,325 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-06-28 01:17:13,326 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2022-06-28 01:17:13,327 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2022-06-28 01:17:13,327 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2022-06-28 01:17:13,328 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2022-06-28 01:17:13,331 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2022-06-28 01:17:13,331 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2022-06-28 01:17:13,331 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2022-06-28 01:17:13,468 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm1.org_1   | 2022-06-28 01:17:13,613 [main] INFO reflections.Reflections: Reflections took 113 ms to scan 3 urls, producing 109 keys and 243 values 
scm1.org_1   | 2022-06-28 01:17:13,689 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm1.org_1   | 2022-06-28 01:17:13,690 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm1.org_1   | 2022-06-28 01:17:13,709 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2022-06-28 01:17:13,712 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2022-06-28 01:17:13,789 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2022-06-28 01:17:13,804 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2022-06-28 01:17:13,814 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm1.org_1   | 2022-06-28 01:17:13,872 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
om2_1        | 2022-06-28 01:26:40,620 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43115
om2_1        | 2022-06-28 01:26:40,625 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:26:41,191 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:41,196 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:41,212 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3383746089 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:26:41,895 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:41,907 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:41,952 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:43,663 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:44,351 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:44,360 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:44,366 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:44,556 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:45,226 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:45,230 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:45,245 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:45,261 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:45,978 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:45,985 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:45,989 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:45,994 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:46,612 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:46,626 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:46,632 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:46,642 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:47,295 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:47,303 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:47,310 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:47,425 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:48,068 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:48,071 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:48,074 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:48,080 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:51,720 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48672
om2_1        | 2022-06-28 01:26:51,727 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:26:55,227 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:55,234 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:55,245 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9610832201 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:26:55,861 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:55,874 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:55,887 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-rbeuewmjgc of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:26:55,924 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:55,929 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:55,933 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm1.org_1   | 2022-06-28 01:17:13,872 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm1.org_1   | 2022-06-28 01:17:13,881 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm1.org_1   | 2022-06-28 01:17:13,884 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm1.org_1   | 2022-06-28 01:17:13,885 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm1.org_1   | 2022-06-28 01:17:13,885 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm1.org_1   | 2022-06-28 01:17:13,891 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm1.org_1   | 2022-06-28 01:17:13,892 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm1.org_1   | 2022-06-28 01:17:13,925 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2022-06-28 01:17:13,950 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2022-06-28 01:17:14,007 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2022-06-28 01:17:14,027 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2022-06-28 01:17:14,034 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-06-28 01:17:14,042 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm1.org_1   | 2022-06-28 01:17:14,047 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:17:14,049 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-06-28 01:17:14,100 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-06-28 01:17:14,112 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-06-28 01:17:14,115 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 916105677270 on primary SCM
scm1.org_1   | 2022-06-28 01:17:14,123 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm1.org_1   | 2022-06-28 01:17:14,158 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-06-28 01:17:14,199 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2022-06-28 01:17:15,034 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-06-28 01:17:15,043 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-06-28 01:17:15,043 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm1.org_1   | 2022-06-28 01:17:15,095 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-06-28 01:17:15,101 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-06-28 01:17:15,103 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2022-06-28 01:17:15,147 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-06-28 01:17:15,157 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-06-28 01:17:15,158 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm1.org_1   | 2022-06-28 01:17:15,299 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm1.org_1   | 2022-06-28 01:17:15,299 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | Container Balancer status:
scm1.org_1   | Key                            Value
scm1.org_1   | Running                        false
scm1.org_1   | Container Balancer Configuration values:
scm1.org_1   | Key                                                Value
scm1.org_1   | Threshold                                          10
scm1.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm1.org_1   | Max Size to Move per Iteration                     500GB
scm1.org_1   | Max Size Entering Target per Iteration             26GB
scm1.org_1   | Max Size Leaving Source per Iteration              26GB
scm1.org_1   | 
scm1.org_1   | 2022-06-28 01:17:15,300 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-06-28 01:17:15,300 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm1.org_1   | 2022-06-28 01:17:15,305 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm1.org_1   | 2022-06-28 01:17:15,310 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm1.org_1   | 2022-06-28 01:17:15,311 [45e35def-6cad-44ae-bb26-f31c46277acf-impl-thread1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: start as a follower, conf=0: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-06-28 01:17:15,311 [45e35def-6cad-44ae-bb26-f31c46277acf-impl-thread1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm1.org_1   | 2022-06-28 01:17:15,312 [45e35def-6cad-44ae-bb26-f31c46277acf-impl-thread1] INFO impl.RoleInfo: 45e35def-6cad-44ae-bb26-f31c46277acf: start 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState
scm1.org_1   | 2022-06-28 01:17:15,321 [45e35def-6cad-44ae-bb26-f31c46277acf-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0A2F691DD86B,id=45e35def-6cad-44ae-bb26-f31c46277acf
scm1.org_1   | 2022-06-28 01:17:15,333 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 45e35def-6cad-44ae-bb26-f31c46277acf: start RPC server
scm1.org_1   | 2022-06-28 01:17:15,409 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 45e35def-6cad-44ae-bb26-f31c46277acf: GrpcService started, listening on 9894
scm1.org_1   | 2022-06-28 01:17:15,416 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$476/0x000000084055f040@484dde7d] INFO util.JvmPauseMonitor: JvmPauseMonitor-45e35def-6cad-44ae-bb26-f31c46277acf: Started
scm1.org_1   | 2022-06-28 01:17:15,416 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-06-28 01:17:15,418 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm1.org_1   | 2022-06-28 01:17:15,420 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2022-06-28 01:17:15,420 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2022-06-28 01:17:15,527 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2022-06-28 01:17:15,538 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2022-06-28 01:17:15,538 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2022-06-28 01:17:15,811 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2022-06-28 01:17:15,812 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-06-28 01:17:15,820 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm1.org_1   | 2022-06-28 01:17:15,838 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm1.org_1   | 2022-06-28 01:17:15,839 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm1.org_1   | 2022-06-28 01:17:15,840 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-06-28 01:17:15,844 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm1.org_1   | 2022-06-28 01:17:15,892 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2022-06-28 01:17:15,895 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-06-28 01:17:15,900 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2022-06-28 01:17:15,901 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2022-06-28 01:17:15,979 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@63069995] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2022-06-28 01:17:16,012 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2022-06-28 01:17:16,014 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2022-06-28 01:17:16,016 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | 2022-06-28 01:17:16,038 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @6495ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2022-06-28 01:17:16,130 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm1.org_1   | 2022-06-28 01:17:16,136 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm1.org_1   | 2022-06-28 01:17:16,138 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2022-06-28 01:17:16,138 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm1.org_1   | 2022-06-28 01:17:16,138 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2022-06-28 01:17:16,141 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm1.org_1   | 2022-06-28 01:17:16,170 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm1.org_1   | 2022-06-28 01:17:16,171 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm1.org_1   | 2022-06-28 01:17:16,202 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm1.org_1   | 2022-06-28 01:17:16,202 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm1.org_1   | 2022-06-28 01:17:16,204 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm1.org_1   | 2022-06-28 01:17:16,221 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-06-28 01:17:16,227 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6da53709{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm1.org_1   | 2022-06-28 01:17:16,228 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@24f8ff82{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | 2022-06-28 01:17:16,340 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-06-28 01:17:16,352 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7e7e34ef{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-17967663443109114347/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2022-06-28 01:17:16,361 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@cb29b75{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm1.org_1   | 2022-06-28 01:17:16,362 [Listener at 0.0.0.0/9860] INFO server.Server: Started @6819ms
scm1.org_1   | 2022-06-28 01:17:16,366 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm1.org_1   | 2022-06-28 01:17:16,366 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm1.org_1   | 2022-06-28 01:17:16,368 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2022-06-28 01:17:17,440 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35855
scm1.org_1   | 2022-06-28 01:17:17,461 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:17:17,624 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.25.0.115:35855
scm1.org_1   | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:45e35def-6cad-44ae-bb26-f31c46277acf is not the leader. Could not determine the leader node.
scm1.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-06-28 01:17:18,178 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57916
scm1.org_1   | 2022-06-28 01:17:18,196 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:17:18,862 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:43310
scm1.org_1   | 2022-06-28 01:17:18,874 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:17:20,429 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState] INFO impl.FollowerState: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5116669926ns, electionTimeout:5107ms
scm1.org_1   | 2022-06-28 01:17:20,430 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState] INFO impl.RoleInfo: 45e35def-6cad-44ae-bb26-f31c46277acf: shutdown 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState
scm1.org_1   | 2022-06-28 01:17:20,431 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm1.org_1   | 2022-06-28 01:17:20,434 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-06-28 01:17:20,434 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-FollowerState] INFO impl.RoleInfo: 45e35def-6cad-44ae-bb26-f31c46277acf: start 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1
scm1.org_1   | 2022-06-28 01:17:20,456 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO impl.LeaderElection: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-06-28 01:17:20,457 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO impl.LeaderElection: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm1.org_1   | 2022-06-28 01:17:20,458 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO impl.RoleInfo: 45e35def-6cad-44ae-bb26-f31c46277acf: shutdown 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1
scm1.org_1   | 2022-06-28 01:17:20,458 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm1.org_1   | 2022-06-28 01:17:20,458 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm1.org_1   | 2022-06-28 01:17:20,459 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm1.org_1   | 2022-06-28 01:17:20,462 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: change Leader from null to 45e35def-6cad-44ae-bb26-f31c46277acf at term 2 for becomeLeader, leader elected after 7404ms
scm1.org_1   | 2022-06-28 01:17:20,467 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-06-28 01:17:20,474 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-06-28 01:17:20,474 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-06-28 01:17:20,480 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-06-28 01:17:20,480 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-06-28 01:17:20,483 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-06-28 01:17:20,489 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-06-28 01:17:20,491 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-06-28 01:17:20,493 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO impl.RoleInfo: 45e35def-6cad-44ae-bb26-f31c46277acf: start 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderStateImpl
scm1.org_1   | 2022-06-28 01:17:20,500 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm1.org_1   | 2022-06-28 01:17:20,520 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/current/log_inprogress_0 to /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/current/log_0-0
scm1.org_1   | 2022-06-28 01:17:20,525 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderElection1] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: set configuration 1: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:139)
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:126)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseCredentials(AuthorizationV4HeaderParser.java:171)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AuthorizationV4HeaderParser.parseSignature(AuthorizationV4HeaderParser.java:91)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor.parseSignature(AWSSignatureProcessor.java:70)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor$Proxy$_$$_WeldClientProxy.parseSignature(Unknown Source)
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:80)
s3g_1        | 	... 114 more
s3g_1        | 
s3g_1        | 
s3g_1        | 2022-06-28 01:27:58,112 [qtp2123533871-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5564991060, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:27:58,132 [qtp2123533871-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-5564991060
s3g_1        | 2022-06-28 01:28:31,216 [qtp2123533871-18] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-06-28 01:29:08,637 [qtp2123533871-24] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-06-28 01:29:09,353 [qtp2123533871-18] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-06-28 01:29:24,694 [qtp2123533871-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8289378492, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:29:24,724 [qtp2123533871-18] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-8289378492
s3g_1        | 2022-06-28 01:29:25,375 [qtp2123533871-24] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-60493, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:29:25,390 [qtp2123533871-24] INFO endpoint.BucketEndpoint: Location is /destbucket-60493
s3g_1        | 2022-06-28 01:29:30,520 [qtp2123533871-24] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-06-28 01:29:31,153 [qtp2123533871-20] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-06-28 01:29:32,441 [qtp2123533871-24] ERROR endpoint.ObjectEndpoint: Exception occurred in PutObject
s3g_1        | 2022-06-28 01:29:39,632 [qtp2123533871-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4399908439, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:29:39,654 [qtp2123533871-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-4399908439
s3g_1        | 2022-06-28 01:30:06,106 [qtp2123533871-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1615782415, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:30:06,132 [qtp2123533871-20] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-1615782415
s3g_1        | 2022-06-28 01:30:23,433 [qtp2123533871-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2257556859, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:30:23,454 [qtp2123533871-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2257556859
s3g_1        | 2022-06-28 01:31:51,916 [qtp2123533871-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2995237214, with the Bucket Layout null, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-06-28 01:31:51,936 [qtp2123533871-24] INFO endpoint.BucketEndpoint: Location is /bucket-ozone-test-2995237214
s3g_1        | 2022-06-28 01:33:24,684 [qtp2123533871-20] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3f49ce74-6987-463e-a960-954ebbba5f61, CreationTimestamp2022-06-28T01:19:01.898Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #183 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3-2a006813-f609-44fe-9fcb-309b6e384c0f-108552499976536100-1
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:508)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-28 01:28:26,346 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3-2a006813-f609-44fe-9fcb-309b6e384c0f-108552499976536100-2
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:508)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-28 01:28:26,964 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3
om3_1        | 2022-06-28 01:28:26,966 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om3_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3 because parts are in Invalid order.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:474)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-28 01:28:30,552 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-3753552445/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-5564991060
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-5564991060key: ozone-test-3753552445/multipartKey5
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-28 01:28:31,212 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-5564991060, Key:ozone-test-0179098423/multipartKey. 
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:758)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:282)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-28 01:29:24,730 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8289378492 of layout LEGACY in volume: s3v
recon_1      | 2022-06-28 01:18:42,319 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 62 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:44,320 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 63 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:44,321 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 64 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:44,323 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 65 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:46,345 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 66 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:46,349 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 67 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:46,352 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 68 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:48,356 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 69 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:48,357 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 70 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:48,358 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 71 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:50,363 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 72 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:50,364 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 73 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:50,364 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 74 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:52,366 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 75 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:52,367 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 76 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:52,367 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 77 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:54,368 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 78 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:54,370 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 79 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:54,371 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 80 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:56,373 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 81 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:56,378 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 82 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:56,390 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 83 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:56,550 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33684
recon_1      | 2022-06-28 01:18:56,638 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:18:56,907 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40768
recon_1      | 2022-06-28 01:18:56,918 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:18:58,196 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54302
recon_1      | 2022-06-28 01:18:58,242 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:18:58,395 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 84 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:58,396 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 85 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:18:58,397 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 86 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:18:59,740 [IPC Server handler 8 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
recon_1      | 2022-06-28 01:18:59,795 [IPC Server handler 8 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [], networkLocation: /default-rack, certSerialId: 1005480937391, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:00,163 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda to Node DB.
recon_1      | 2022-06-28 01:19:00,367 [IPC Server handler 54 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3f49ce74-6987-463e-a960-954ebbba5f61
recon_1      | 2022-06-28 01:19:00,368 [IPC Server handler 54 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [], networkLocation: /default-rack, certSerialId: 1007988787146, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:00,372 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 3f49ce74-6987-463e-a960-954ebbba5f61 to Node DB.
recon_1      | 2022-06-28 01:19:00,398 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 87 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:00,399 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 88 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:00,402 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 89 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:19:00,558 [IPC Server handler 77 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
recon_1      | 2022-06-28 01:19:00,559 [IPC Server handler 77 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1004767615899, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:00,590 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa to Node DB.
recon_1      | 2022-06-28 01:19:00,656 [IPC Server handler 8 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-06-28 01:19:01,843 [IPC Server handler 41 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-06-28 01:19:02,185 [IPC Server handler 51 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-06-28 01:19:02,408 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 90 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:02,409 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 91 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:02,410 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 92 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:19:02,515 [IPC Server handler 31 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-06-28 01:19:03,725 [IPC Server handler 41 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-06-28 01:19:04,411 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 93 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:04,412 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 94 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:04,413 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 95 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:19:05,482 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=51a7f1ac-dc16-43e5-8dfa-a67715d36ab1. Trying to get from SCM.
recon_1      | 2022-06-28 01:19:05,801 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:01.898Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-06-28 01:19:05,973 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:01.898Z[UTC]].
recon_1      | 2022-06-28 01:19:05,994 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 reported by 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1007988787146, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:06,414 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 96 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:06,429 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 97 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:06,436 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 98 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:19:08,445 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 99 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:08,447 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 100 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:08,448 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 101 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:19:10,450 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 102 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:10,453 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 103 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:10,455 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 104 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:19:11,363 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 reported by 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1005480937391, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:12,356 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 reported by 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1007988787146, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:12,457 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 105 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:12,459 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 106 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:12,459 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 107 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:19:14,462 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 108 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:14,466 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 109 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:14,468 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 110 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:19:14,808 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33762
recon_1      | 2022-06-28 01:19:14,878 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:19:14,880 [IPC Server handler 51 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-06-28 01:19:14,882 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 reported by 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1004767615899, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:14,882 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3f49ce74-6987-463e-a960-954ebbba5f61, CreationTimestamp2022-06-28T01:19:01.898Z[UTC]] moved to OPEN state
recon_1      | 2022-06-28 01:19:16,235 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=e0166ad2-3c82-41e4-a01f-805995535eac. Trying to get from SCM.
recon_1      | 2022-06-28 01:19:16,480 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 111 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:16,482 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 112 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:16,483 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 113 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:19:16,526 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: e0166ad2-3c82-41e4-a01f-805995535eac, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:3f49ce74-6987-463e-a960-954ebbba5f61, CreationTimestamp2022-06-28T01:19:02.051Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-06-28 01:19:16,530 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e0166ad2-3c82-41e4-a01f-805995535eac, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:3f49ce74-6987-463e-a960-954ebbba5f61, CreationTimestamp2022-06-28T01:19:02.051Z[UTC]].
recon_1      | 2022-06-28 01:19:16,539 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70. Trying to get from SCM.
recon_1      | 2022-06-28 01:19:16,559 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 6e4f5b77-ba5a-4791-a28a-fd99b4920d70, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:02.143Z[UTC]] to Recon pipeline metadata.
om1_1        | 2022-06-28 01:32:15,993 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-06-28 01:17:06,154 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | 2022-06-28 01:29:25,417 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-60493 of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:29:39,667 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4399908439 of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:30:06,124 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1615782415 of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:30:10,547 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1615782415, Key:ozone-test-2265625205/multidelete/key=value/f4.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-06-28 01:30:23,459 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2257556859 of layout LEGACY in volume: s3v
om3_1        | 2022-06-28 01:31:51,930 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2995237214 of layout LEGACY in volume: s3v
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:101)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:392)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:552)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:566)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:137)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:494)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:468)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:521)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:254)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #183 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-06-28 01:33:24,709 [qtp2123533871-20] INFO scm.XceiverClientRatis: Could not commit index 132 on pipeline Pipeline[ Id: 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3f49ce74-6987-463e-a960-954ebbba5f61, CreationTimestamp2022-06-28T01:19:01.898Z[UTC]] to all the nodes. Server 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa has failed. Committed by majority.
s3g_1        | 2022-06-28 01:33:24,713 [qtp2123533871-20] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200055 bcsId: 132 on Pipeline[ Id: 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3f49ce74-6987-463e-a960-954ebbba5f61, CreationTimestamp2022-06-28T01:19:01.898Z[UTC]]. Failed nodes: [9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-06-28 01:17:06,164 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-06-28 01:17:06,278 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-06-28 01:17:06,307 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-06-28 01:17:06,308 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-06-28 01:17:06,345 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-06-28 01:17:06,346 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-06-28 01:17:06,527 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-06-28 01:17:06,527 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-06-28 01:17:06,562 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2022-06-28 01:17:08,730 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-06-28 01:17:10,733 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-06-28 01:17:12,737 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-06-28 01:17:14,738 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-06-28 01:17:16,743 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-06-28 01:17:18,908 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:45e35def-6cad-44ae-bb26-f31c46277acf is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-06-28 01:17:20,910 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-06-28 01:17:23,030 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm2.org_1   | 2022-06-28 01:17:23,511 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm2.org_1   | 2022-06-28 01:17:23,511 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2022-06-28 01:17:23,513 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm2.org_1   | 2022-06-28 01:17:24,179 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2022-06-28 01:17:24,256 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2022-06-28 01:17:24,257 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2022-06-28 01:17:24,261 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:c7ed5937-0e47-4abb-91f6-068d38a4ec09,clusterId:CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b,subject:scm-sub@scm2.org
scm2.org_1   | 2022-06-28 01:17:27,219 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm2.org_1   | 2022-06-28 01:17:27,239 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b, SCMID c7ed5937-0e47-4abb-91f6-068d38a4ec09
scm2.org_1   | 2022-06-28 01:17:27,239 [main] INFO server.StorageContainerManager: Primary SCM Node ID 45e35def-6cad-44ae-bb26-f31c46277acf
scm2.org_1   | 2022-06-28 01:17:27,288 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-06-28 01:17:30,660 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-06-28 01:17:30,673 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-06-28 01:17:30,855 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-06-28 01:17:31,025 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-06-28 01:17:31,056 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-06-28 01:17:31,198 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-06-28 01:17:31,201 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-06-28 01:17:32,735 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2022-06-28 01:17:33,117 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2022-06-28 01:17:33,134 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm2.org_1   | 2022-06-28 01:17:33,148 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/940211650497.crt.
scm2.org_1   | 2022-06-28 01:17:33,528 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-06-28 01:17:33,540 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-06-28 01:17:33,673 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-06-28 01:17:34,228 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-06-28 01:17:34,946 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2022-06-28 01:17:34,949 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm2.org_1   | 2022-06-28 01:17:35,150 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2022-06-28 01:17:35,251 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:c7ed5937-0e47-4abb-91f6-068d38a4ec09
scm2.org_1   | 2022-06-28 01:17:35,503 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2022-06-28 01:17:35,713 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm2.org_1   | 2022-06-28 01:17:35,715 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-06-28 01:17:35,719 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm2.org_1   | 2022-06-28 01:17:35,719 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-06-28 01:17:35,720 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-06-28 01:17:35,728 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
om2_1        | 2022-06-28 01:26:56,078 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:56,131 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:56,135 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:56,138 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:57,798 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:57,845 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:57,849 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:57,852 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:57,977 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:58,014 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:58,017 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:58,023 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:58,135 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:58,144 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:58,148 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:58,197 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:58,231 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:58,239 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:58,242 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:58,275 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,027 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,345 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,414 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,424 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,452 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,560 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,566 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,573 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,639 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,645 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,652 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,694 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,748 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,764 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,768 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:26:59,804 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:00,316 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:00,665 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:00,727 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:00,734 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:00,747 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:00,809 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:00,813 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:00,834 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-cquyfepsao of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:27:00,870 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:19:16,561 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6e4f5b77-ba5a-4791-a28a-fd99b4920d70, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:02.143Z[UTC]].
recon_1      | 2022-06-28 01:19:16,568 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70 reported by 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1007988787146, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:17,323 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70 reported by 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1005480937391, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:17,889 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70 reported by 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1004767615899, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:18,484 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 114 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:18,486 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 115 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:18,486 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 116 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:19:20,488 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 117 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:20,489 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 118 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:20,490 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 119 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:19:21,466 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70 reported by 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1007988787146, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:22,491 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 120 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:22,492 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 121 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:22,493 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 122 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:19:31,485 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm2.org_1   | 2022-06-28 01:17:35,734 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-06-28 01:17:35,735 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm2.org_1   | 2022-06-28 01:17:35,736 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2022-06-28 01:17:35,776 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm2.org_1   | 2022-06-28 01:17:35,787 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm2.org_1   | 2022-06-28 01:17:37,113 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm2.org_1   | 2022-06-28 01:17:37,128 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm2.org_1   | 2022-06-28 01:17:37,129 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm2.org_1   | 2022-06-28 01:17:37,131 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-06-28 01:17:37,132 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-06-28 01:17:37,140 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-06-28 01:17:37,165 [main] INFO server.RaftServer: c7ed5937-0e47-4abb-91f6-068d38a4ec09: addNew group-0A2F691DD86B:[] returns group-0A2F691DD86B:java.util.concurrent.CompletableFuture@38e83838[Not completed]
scm2.org_1   | 2022-06-28 01:17:37,274 [pool-16-thread-1] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09: new RaftServerImpl for group-0A2F691DD86B:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-06-28 01:17:20,541 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/current/log_inprogress_1
scm1.org_1   | 2022-06-28 01:17:20,548 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm1.org_1   | 2022-06-28 01:17:20,554 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
om2_1        | 2022-06-28 01:27:00,890 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:00,895 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:00,913 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:00,916 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:00,945 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:00,952 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:00,996 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:01,005 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:01,014 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:02,808 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:02,835 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:02,848 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:02,859 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:02,881 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:02,884 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:02,886 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:02,928 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:02,933 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:02,943 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:02,991 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,283 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,287 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,293 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,317 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,358 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,362 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,364 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,381 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,384 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,388 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,440 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,444 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,448 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,481 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,486 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,489 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,503 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,506 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,508 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:03,584 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:05,318 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:05,430 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:05,451 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:05,467 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:05,497 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 123 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:32,215 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 124 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:33,304 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33812
recon_1      | 2022-06-28 01:19:33,333 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:19:33,334 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70 reported by 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1004767615899, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:33,336 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=e107ff30-8061-4f60-8349-f89eb01cba86. Trying to get from SCM.
recon_1      | 2022-06-28 01:19:33,410 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: e107ff30-8061-4f60-8349-f89eb01cba86, Nodes: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:01.034Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-06-28 01:19:33,411 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e107ff30-8061-4f60-8349-f89eb01cba86, Nodes: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:01.034Z[UTC]].
recon_1      | 2022-06-28 01:19:33,412 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=e107ff30-8061-4f60-8349-f89eb01cba86 reported by 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1004767615899, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:33,412 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e107ff30-8061-4f60-8349-f89eb01cba86, Nodes: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, CreationTimestamp2022-06-28T01:19:01.034Z[UTC]] moved to OPEN state
recon_1      | 2022-06-28 01:19:33,756 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40890
recon_1      | 2022-06-28 01:19:33,848 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-06-28 01:27:05,505 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:05,509 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:05,586 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:05,593 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:05,599 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:05,690 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:07,821 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:07,866 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:07,872 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:07,878 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:11,910 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48758
om2_1        | 2022-06-28 01:27:11,912 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:27:15,463 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:15,471 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:15,478 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4118624588 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:27:16,175 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:16,180 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:16,195 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6741282977 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:27:16,846 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:16,850 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:16,857 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0865895385 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:27:17,492 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:17,498 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:17,507 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-0865895385 in volume:s3v
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-28 01:27:18,137 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:22,640 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48814
om2_1        | 2022-06-28 01:27:22,647 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:27:26,095 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:26,099 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:26,110 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2757426933 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:27:26,763 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:26,767 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:26,778 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6611295494 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:27:27,355 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:27,361 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:27,976 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:27,978 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:27,987 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-3175990109 in volume:s3v
om2_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
scm2.org_1   | 2022-06-28 01:17:37,297 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2022-06-28 01:17:37,298 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm2.org_1   | 2022-06-28 01:17:37,298 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm2.org_1   | 2022-06-28 01:17:37,298 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-06-28 01:17:37,298 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-06-28 01:17:37,299 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2022-06-28 01:17:37,306 [pool-16-thread-1] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2022-06-28 01:17:37,312 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-06-28 01:17:37,324 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2022-06-28 01:17:37,340 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm2.org_1   | 2022-06-28 01:17:37,342 [pool-16-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b does not exist. Creating ...
scm2.org_1   | 2022-06-28 01:17:37,370 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/in_use.lock acquired by nodename 7@scm2.org
scm2.org_1   | 2022-06-28 01:17:37,446 [pool-16-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b has been successfully formatted.
scm2.org_1   | 2022-06-28 01:17:37,454 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm2.org_1   | 2022-06-28 01:17:37,458 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2022-06-28 01:17:37,499 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm2.org_1   | 2022-06-28 01:17:37,499 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-06-28 01:17:37,501 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm2.org_1   | 2022-06-28 01:17:37,802 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-06-28 01:17:37,841 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2022-06-28 01:17:37,842 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2022-06-28 01:17:37,847 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b
scm2.org_1   | 2022-06-28 01:17:37,863 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2022-06-28 01:17:37,864 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2022-06-28 01:17:37,871 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-06-28 01:17:37,871 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm2.org_1   | 2022-06-28 01:17:37,872 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2022-06-28 01:17:37,873 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2022-06-28 01:17:37,881 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2022-06-28 01:17:37,881 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2022-06-28 01:17:37,940 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2022-06-28 01:17:37,941 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm2.org_1   | 2022-06-28 01:17:37,941 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2022-06-28 01:17:37,959 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-06-28 01:17:37,963 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-06-28 01:17:37,986 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2022-06-28 01:17:37,992 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2022-06-28 01:17:37,993 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2022-06-28 01:17:37,994 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2022-06-28 01:17:37,995 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2022-06-28 01:17:37,998 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2022-06-28 01:17:38,092 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2022-06-28 01:17:38,096 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm2.org_1   | 2022-06-28 01:17:38,096 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm2.org_1   | 2022-06-28 01:17:38,097 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm2.org_1   | 2022-06-28 01:17:38,097 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm2.org_1   | 2022-06-28 01:17:38,106 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2022-06-28 01:17:38,108 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2022-06-28 01:17:38,109 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2022-06-28 01:17:38,584 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm2.org_1   | 2022-06-28 01:17:38,850 [main] INFO reflections.Reflections: Reflections took 149 ms to scan 3 urls, producing 109 keys and 243 values 
scm2.org_1   | 2022-06-28 01:17:39,148 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm2.org_1   | 2022-06-28 01:17:39,148 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2022-06-28 01:17:39,154 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm2.org_1   | 2022-06-28 01:17:39,172 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2022-06-28 01:17:39,361 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2022-06-28 01:17:39,405 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2022-06-28 01:17:39,438 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2022-06-28 01:17:39,537 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2022-06-28 01:17:39,541 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm2.org_1   | 2022-06-28 01:17:39,561 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2022-06-28 01:17:39,664 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm2.org_1   | 2022-06-28 01:17:39,665 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2022-06-28 01:17:39,666 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm2.org_1   | 2022-06-28 01:17:39,686 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm2.org_1   | 2022-06-28 01:17:39,699 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm2.org_1   | 2022-06-28 01:17:39,755 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2022-06-28 01:17:39,868 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2022-06-28 01:17:40,032 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2022-06-28 01:17:40,104 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm2.org_1   | 2022-06-28 01:17:40,134 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-06-28 01:17:40,136 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm2.org_1   | 2022-06-28 01:17:40,156 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:17:40,159 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-06-28 01:17:40,231 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
recon_1      | 2022-06-28 01:19:33,849 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=a6bcecaa-1423-464c-8db7-4effb6cb88eb. Trying to get from SCM.
scm1.org_1   | 2022-06-28 01:17:20,555 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:17:20,557 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2022-06-28 01:17:20,561 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-06-28 01:17:20,563 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2022-06-28 01:17:20,570 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-06-28 01:17:20,571 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2022-06-28 01:17:23,692 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: d6b39bb8-4bd1-4f55-957d-3ef2755cf537
scm1.org_1   | 2022-06-28 01:17:24,145 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:17:24,149 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2022-06-28 01:17:24,149 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm1.org_1   | 2022-06-28 01:17:24,811 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:42844
scm1.org_1   | 2022-06-28 01:17:24,814 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:17:24,815 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: c7ed5937-0e47-4abb-91f6-068d38a4ec09
scm1.org_1   | 2022-06-28 01:17:27,032 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:17:39,063 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58242
scm1.org_1   | 2022-06-28 01:17:39,145 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:17:42,060 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39785
scm1.org_1   | 2022-06-28 01:17:42,083 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:17:43,754 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:43702
scm1.org_1   | 2022-06-28 01:17:43,854 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:17:43,856 [IPC Server handler 57 on default port 9863] INFO ha.SCMRatisServerImpl: 45e35def-6cad-44ae-bb26-f31c46277acf: Submitting SetConfiguration request to Ratis server with new SCM peers list: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-06-28 01:17:43,864 [IPC Server handler 57 on default port 9863] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: receive setConfiguration SetConfigurationRequest:client-A3E854C7FC22->45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B, cid=1, seq=0, RW, null, peers:[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-06-28 01:17:43,865 [IPC Server handler 57 on default port 9863] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-A3E854C7FC22->45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B, cid=1, seq=0, RW, null, peers:[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-06-28 01:17:43,888 [IPC Server handler 57 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-06-28 01:17:43,889 [IPC Server handler 57 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-06-28 01:17:43,889 [IPC Server handler 57 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-06-28 01:17:43,925 [IPC Server handler 57 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-06-28 01:17:43,930 [IPC Server handler 57 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-06-28 01:17:43,930 [IPC Server handler 57 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-06-28 01:17:43,951 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->c7ed5937-0e47-4abb-91f6-068d38a4ec09-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->c7ed5937-0e47-4abb-91f6-068d38a4ec09-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2022-06-28 01:17:43,979 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->c7ed5937-0e47-4abb-91f6-068d38a4ec09-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->c7ed5937-0e47-4abb-91f6-068d38a4ec09-GrpcLogAppender: send 45e35def-6cad-44ae-bb26-f31c46277acf->c7ed5937-0e47-4abb-91f6-068d38a4ec09#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2022-06-28 01:17:45,090 [grpc-default-executor-2] INFO server.GrpcLogAppender: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->c7ed5937-0e47-4abb-91f6-068d38a4ec09-InstallSnapshotResponseHandler: received the first reply 45e35def-6cad-44ae-bb26-f31c46277acf<-c7ed5937-0e47-4abb-91f6-068d38a4ec09#0:FAIL-t0,ALREADY_INSTALLED
scm1.org_1   | 2022-06-28 01:17:45,158 [grpc-default-executor-2] INFO server.GrpcLogAppender: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->c7ed5937-0e47-4abb-91f6-068d38a4ec09-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
recon_1      | 2022-06-28 01:19:33,882 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: a6bcecaa-1423-464c-8db7-4effb6cb88eb, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, CreationTimestamp2022-06-28T01:19:02.523Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-06-28 01:19:33,883 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a6bcecaa-1423-464c-8db7-4effb6cb88eb, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, CreationTimestamp2022-06-28T01:19:02.523Z[UTC]].
recon_1      | 2022-06-28 01:19:33,884 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70 reported by 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1005480937391, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:35,150 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 125 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:19:37,155 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 126 failover attempts. Trying to failover immediately.
recon_1      | 2022-06-28 01:19:37,180 [pool-18-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMLeaderNotReadyException): om2 is Leader but not ready to process request yet.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderNotReadyException(OzoneManagerProtocolServerSideTranslatorPB.java:259)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:237)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 2022-06-28 01:17:40,300 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-06-28 01:17:40,389 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm2.org_1   | 2022-06-28 01:17:41,946 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-06-28 01:17:41,965 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-06-28 01:17:41,972 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2022-06-28 01:17:42,117 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-06-28 01:17:42,129 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-06-28 01:17:42,148 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2022-06-28 01:17:42,265 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-06-28 01:17:42,313 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-06-28 01:17:42,356 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm2.org_1   | 2022-06-28 01:17:42,616 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm2.org_1   | 2022-06-28 01:17:42,616 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm2.org_1   | Container Balancer status:
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        false
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                                                Value
scm2.org_1   | Threshold                                          10
scm2.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm2.org_1   | Max Size to Move per Iteration                     500GB
scm2.org_1   | Max Size Entering Target per Iteration             26GB
scm2.org_1   | Max Size Leaving Source per Iteration              26GB
scm2.org_1   | 
scm2.org_1   | 2022-06-28 01:17:42,617 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-06-28 01:17:42,617 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm2.org_1   | 2022-06-28 01:17:42,683 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2022-06-28 01:17:42,698 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2022-06-28 01:17:42,700 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-impl-thread1] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: start with initializing state, conf=-1: [], old=null
scm2.org_1   | 2022-06-28 01:17:42,700 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-impl-thread1] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: changes role from      null to FOLLOWER at term 0 for startInitializing
scm2.org_1   | 2022-06-28 01:17:42,701 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0A2F691DD86B,id=c7ed5937-0e47-4abb-91f6-068d38a4ec09
scm2.org_1   | 2022-06-28 01:17:42,723 [Listener at 0.0.0.0/9860] INFO server.RaftServer: c7ed5937-0e47-4abb-91f6-068d38a4ec09: start RPC server
scm2.org_1   | 2022-06-28 01:17:43,073 [Listener at 0.0.0.0/9860] INFO server.GrpcService: c7ed5937-0e47-4abb-91f6-068d38a4ec09: GrpcService started, listening on 9894
scm2.org_1   | 2022-06-28 01:17:43,091 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$462/0x0000000840529840@36109a76] INFO util.JvmPauseMonitor: JvmPauseMonitor-c7ed5937-0e47-4abb-91f6-068d38a4ec09: Started
scm1.org_1   | 2022-06-28 01:17:45,160 [grpc-default-executor-2] INFO leader.FollowerInfo: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->c7ed5937-0e47-4abb-91f6-068d38a4ec09: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-06-28 01:17:45,161 [grpc-default-executor-2] INFO leader.FollowerInfo: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->c7ed5937-0e47-4abb-91f6-068d38a4ec09: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-06-28 01:17:45,161 [grpc-default-executor-2] INFO leader.FollowerInfo: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->c7ed5937-0e47-4abb-91f6-068d38a4ec09: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2022-06-28 01:17:45,161 [grpc-default-executor-2] INFO leader.FollowerInfo: Follower 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->c7ed5937-0e47-4abb-91f6-068d38a4ec09 acknowledged installing snapshot
scm1.org_1   | 2022-06-28 01:17:45,161 [grpc-default-executor-2] INFO leader.FollowerInfo: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->c7ed5937-0e47-4abb-91f6-068d38a4ec09: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2022-06-28 01:17:45,221 [grpc-default-executor-2] INFO leader.FollowerInfo: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->c7ed5937-0e47-4abb-91f6-068d38a4ec09: nextIndex: updateUnconditionally 7 -> 0
scm1.org_1   | 2022-06-28 01:17:45,231 [grpc-default-executor-2] INFO leader.FollowerInfo: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->c7ed5937-0e47-4abb-91f6-068d38a4ec09: nextIndex: updateUnconditionally 7 -> 0
scm1.org_1   | 2022-06-28 01:17:45,602 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderStateImpl] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: set configuration 7: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|priority:0], old=[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-06-28 01:17:45,715 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderStateImpl] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: set configuration 9: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|priority:0], old=null
scm1.org_1   | 2022-06-28 01:17:45,778 [IPC Server handler 57 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: c7ed5937-0e47-4abb-91f6-068d38a4ec09.
scm1.org_1   | 2022-06-28 01:17:47,831 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:43206
scm1.org_1   | 2022-06-28 01:17:47,843 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:17:48,740 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:47940
scm1.org_1   | 2022-06-28 01:17:48,782 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:17:51,015 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:41522
scm1.org_1   | 2022-06-28 01:17:51,022 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:17:51,023 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: 966cceea-06cb-4ebe-a41c-dc5f70b815ea
scm1.org_1   | 2022-06-28 01:17:51,212 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:17:52,259 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58444
scm1.org_1   | 2022-06-28 01:17:52,289 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:18:03,143 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:48130
scm1.org_1   | 2022-06-28 01:18:03,271 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:18:03,290 [IPC Server handler 57 on default port 9863] INFO ha.SCMRatisServerImpl: 45e35def-6cad-44ae-bb26-f31c46277acf: Submitting SetConfiguration request to Ratis server with new SCM peers list: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|priority:0, 966cceea-06cb-4ebe-a41c-dc5f70b815ea|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-06-28 01:18:03,290 [IPC Server handler 57 on default port 9863] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: receive setConfiguration SetConfigurationRequest:client-A3E854C7FC22->45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B, cid=2, seq=0, RW, null, peers:[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|priority:0, 966cceea-06cb-4ebe-a41c-dc5f70b815ea|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-06-28 01:18:03,290 [IPC Server handler 57 on default port 9863] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-A3E854C7FC22->45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B, cid=2, seq=0, RW, null, peers:[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|priority:0, 966cceea-06cb-4ebe-a41c-dc5f70b815ea|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-06-28 01:18:03,291 [IPC Server handler 57 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-06-28 01:18:03,291 [IPC Server handler 57 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-06-28 01:18:03,291 [IPC Server handler 57 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-06-28 01:18:03,322 [IPC Server handler 57 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-06-28 01:18:03,323 [IPC Server handler 57 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-06-28 01:18:03,323 [IPC Server handler 57 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-06-28 01:18:03,347 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->966cceea-06cb-4ebe-a41c-dc5f70b815ea-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->966cceea-06cb-4ebe-a41c-dc5f70b815ea-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2022-06-28 01:18:03,348 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->966cceea-06cb-4ebe-a41c-dc5f70b815ea-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->966cceea-06cb-4ebe-a41c-dc5f70b815ea-GrpcLogAppender: send 45e35def-6cad-44ae-bb26-f31c46277acf->966cceea-06cb-4ebe-a41c-dc5f70b815ea#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2022-06-28 01:18:05,950 [grpc-default-executor-1] INFO server.GrpcLogAppender: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->966cceea-06cb-4ebe-a41c-dc5f70b815ea-InstallSnapshotResponseHandler: received the first reply 45e35def-6cad-44ae-bb26-f31c46277acf<-966cceea-06cb-4ebe-a41c-dc5f70b815ea#0:FAIL-t0,ALREADY_INSTALLED
scm1.org_1   | 2022-06-28 01:18:05,951 [grpc-default-executor-1] INFO server.GrpcLogAppender: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->966cceea-06cb-4ebe-a41c-dc5f70b815ea-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2022-06-28 01:18:05,951 [grpc-default-executor-1] INFO leader.FollowerInfo: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->966cceea-06cb-4ebe-a41c-dc5f70b815ea: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-06-28 01:18:05,987 [grpc-default-executor-1] INFO leader.FollowerInfo: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->966cceea-06cb-4ebe-a41c-dc5f70b815ea: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-06-28 01:18:05,987 [grpc-default-executor-1] INFO leader.FollowerInfo: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->966cceea-06cb-4ebe-a41c-dc5f70b815ea: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2022-06-28 01:18:05,988 [grpc-default-executor-1] INFO leader.FollowerInfo: Follower 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->966cceea-06cb-4ebe-a41c-dc5f70b815ea acknowledged installing snapshot
scm1.org_1   | 2022-06-28 01:18:05,988 [grpc-default-executor-1] INFO leader.FollowerInfo: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->966cceea-06cb-4ebe-a41c-dc5f70b815ea: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2022-06-28 01:18:06,156 [grpc-default-executor-1] INFO leader.FollowerInfo: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->966cceea-06cb-4ebe-a41c-dc5f70b815ea: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2022-06-28 01:18:06,191 [grpc-default-executor-1] INFO leader.FollowerInfo: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B->966cceea-06cb-4ebe-a41c-dc5f70b815ea: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2022-06-28 01:18:06,844 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderStateImpl] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: set configuration 13: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 966cceea-06cb-4ebe-a41c-dc5f70b815ea|rpc:scm3.org:9894|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|priority:0], old=[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-06-28 01:18:06,888 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-LeaderStateImpl] INFO server.RaftServer$Division: 45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B: set configuration 15: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 966cceea-06cb-4ebe-a41c-dc5f70b815ea|rpc:scm3.org:9894|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|priority:0], old=null
scm1.org_1   | 2022-06-28 01:18:06,955 [IPC Server handler 57 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 966cceea-06cb-4ebe-a41c-dc5f70b815ea.
scm1.org_1   | 2022-06-28 01:18:10,348 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58610
scm1.org_1   | 2022-06-28 01:18:10,508 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:18:12,970 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:41714
scm1.org_1   | 2022-06-28 01:18:13,025 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:18:25,877 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43208
scm1.org_1   | 2022-06-28 01:18:25,973 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:18:27,438 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:41930
scm1.org_1   | 2022-06-28 01:18:27,557 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:18:27,954 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56518
scm1.org_1   | 2022-06-28 01:18:28,027 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:18:28,968 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35032
scm1.org_1   | 2022-06-28 01:18:29,078 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:18:29,079 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 65eb9f967bad, UUID: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
scm1.org_1   | 2022-06-28 01:18:29,583 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:18:29,919 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36280
scm1.org_1   | 2022-06-28 01:18:30,067 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:18:30,067 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 472cd7b1c4f7, UUID: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
scm1.org_1   | 2022-06-28 01:18:30,294 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:18:32,488 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44730
scm1.org_1   | 2022-06-28 01:18:32,590 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:18:32,590 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 3648fb418109, UUID: 3f49ce74-6987-463e-a960-954ebbba5f61
scm1.org_1   | 2022-06-28 01:18:32,853 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:18:34,598 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:54956
scm1.org_1   | 2022-06-28 01:18:34,624 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:18:34,657 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: 08b76774-2661-4405-b148-5002c1f22393
scm1.org_1   | 2022-06-28 01:18:35,104 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:18:35,279 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:36464
scm1.org_1   | 2022-06-28 01:18:35,333 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:18:35,352 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: 78df6789-a05f-4bf9-812f-929a08ff38f3
scm1.org_1   | 2022-06-28 01:18:35,825 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:18:38,898 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:52640
scm1.org_1   | 2022-06-28 01:18:38,936 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:18:38,937 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: dc32ce0f-b653-40a2-b319-a4e3fde675fb
scm1.org_1   | 2022-06-28 01:18:39,171 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:17:43,127 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2022-06-28 01:17:44,605 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: receive installSnapshot: 45e35def-6cad-44ae-bb26-f31c46277acf->c7ed5937-0e47-4abb-91f6-068d38a4ec09#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2022-06-28 01:17:44,622 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2022-06-28 01:17:44,622 [grpc-default-executor-0] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: change Leader from null to 45e35def-6cad-44ae-bb26-f31c46277acf at term 2 for installSnapshot, leader elected after 7168ms
scm2.org_1   | 2022-06-28 01:17:44,632 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: Received notification to install snapshot at index 0
scm2.org_1   | 2022-06-28 01:17:44,633 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm2.org_1   | 2022-06-28 01:17:45,015 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "45e35def-6cad-44ae-bb26-f31c46277acf"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-06-28 01:17:45,018 [grpc-default-executor-0] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: set configuration 1: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-28 01:17:45,033 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: reply installSnapshot: 45e35def-6cad-44ae-bb26-f31c46277acf<-c7ed5937-0e47-4abb-91f6-068d38a4ec09#0:FAIL-t0,ALREADY_INSTALLED
scm2.org_1   | 2022-06-28 01:17:45,088 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: c7ed5937-0e47-4abb-91f6-068d38a4ec09: Completed INSTALL_SNAPSHOT, lastRequest: 45e35def-6cad-44ae-bb26-f31c46277acf->c7ed5937-0e47-4abb-91f6-068d38a4ec09#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2022-06-28 01:17:45,206 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread1] INFO impl.RoleInfo: c7ed5937-0e47-4abb-91f6-068d38a4ec09: start c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-FollowerState
scm2.org_1   | 2022-06-28 01:17:45,210 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread1] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2022-06-28 01:17:45,212 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread1] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: inconsistency entries. Reply:45e35def-6cad-44ae-bb26-f31c46277acf<-c7ed5937-0e47-4abb-91f6-068d38a4ec09#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-06-28 01:17:45,223 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread1] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2022-06-28 01:17:45,223 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread1] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: inconsistency entries. Reply:45e35def-6cad-44ae-bb26-f31c46277acf<-c7ed5937-0e47-4abb-91f6-068d38a4ec09#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-06-28 01:17:45,235 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread1] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: set configuration 0: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-28 01:17:45,235 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread1] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: set configuration 1: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-28 01:17:45,250 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread1] INFO segmented.SegmentedRaftLogWorker: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-SegmentedRaftLogWorker: Starting segment from index:0
scm2.org_1   | 2022-06-28 01:17:45,280 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread1] INFO segmented.SegmentedRaftLogWorker: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm2.org_1   | 2022-06-28 01:17:45,315 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread2] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: set configuration 0: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-28 01:17:45,320 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread2] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: set configuration 1: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-28 01:17:45,424 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/current/log_inprogress_0
scm2.org_1   | 2022-06-28 01:17:45,440 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/current/log_inprogress_0 to /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/current/log_0-0
scm2.org_1   | 2022-06-28 01:17:45,483 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/current/log_inprogress_1
scm2.org_1   | 2022-06-28 01:17:45,504 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:17:45,505 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2022-06-28 01:17:45,506 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-06-28 01:17:45,506 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2022-06-28 01:17:45,525 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm2.org_1   | 2022-06-28 01:17:45,559 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-06-28 01:18:39,752 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35062
scm1.org_1   | 2022-06-28 01:18:39,786 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:18:40,284 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36312
scm1.org_1   | 2022-06-28 01:18:40,316 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:18:42,786 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44762
scm1.org_1   | 2022-06-28 01:18:42,812 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:18:48,036 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58694
scm1.org_1   | 2022-06-28 01:18:48,258 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:18:56,446 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39866
scm1.org_1   | 2022-06-28 01:18:56,490 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:18:56,770 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50136
scm1.org_1   | 2022-06-28 01:18:56,860 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:18:58,062 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35560
scm1.org_1   | 2022-06-28 01:18:58,353 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:19:00,734 [IPC Server handler 33 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
scm1.org_1   | 2022-06-28 01:19:00,771 [IPC Server handler 32 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
scm1.org_1   | 2022-06-28 01:19:00,783 [IPC Server handler 32 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1005480937391, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-06-28 01:19:00,839 [IPC Server handler 33 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1004767615899, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-06-28 01:19:00,899 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-06-28 01:19:00,940 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2022-06-28 01:19:01,018 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-06-28 01:19:01,138 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2022-06-28 01:19:01,115 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e107ff30-8061-4f60-8349-f89eb01cba86 to datanode:9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
scm3.org_1   | Sleeping for 5 seconds
scm3.org_1   | Waiting for the service scm2.org:9894
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-06-28 01:17:46,949 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 127 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-06-28 01:19:38,523 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70 reported by 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1004767615899, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:39,000 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70 reported by 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1005480937391, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:19:40,242 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
scm1.org_1   | 2022-06-28 01:19:01,621 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e107ff30-8061-4f60-8349-f89eb01cba86, Nodes: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:01.034Z[UTC]].
scm1.org_1   | 2022-06-28 01:19:01,631 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:19:01,803 [IPC Server handler 54 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3f49ce74-6987-463e-a960-954ebbba5f61
scm1.org_1   | 2022-06-28 01:19:01,832 [IPC Server handler 54 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1007988787146, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-06-28 01:19:01,833 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-06-28 01:19:01,860 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2022-06-28 01:19:01,861 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2022-06-28 01:19:01,863 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2022-06-28 01:19:01,863 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-06-28 01:19:01,863 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2022-06-28 01:19:01,864 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-06-28 01:19:01,898 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 to datanode:4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
scm1.org_1   | 2022-06-28 01:19:01,916 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 to datanode:9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
scm1.org_1   | 2022-06-28 01:19:01,917 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 to datanode:3f49ce74-6987-463e-a960-954ebbba5f61
scm1.org_1   | 2022-06-28 01:19:02,013 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:01.898Z[UTC]].
scm1.org_1   | 2022-06-28 01:19:02,045 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:19:02,052 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e0166ad2-3c82-41e4-a01f-805995535eac to datanode:3f49ce74-6987-463e-a960-954ebbba5f61
scm1.org_1   | 2022-06-28 01:19:02,136 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e0166ad2-3c82-41e4-a01f-805995535eac, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:02.051Z[UTC]].
scm1.org_1   | 2022-06-28 01:19:02,142 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:19:02,143 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70 to datanode:4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
scm1.org_1   | 2022-06-28 01:19:02,179 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70 to datanode:3f49ce74-6987-463e-a960-954ebbba5f61
scm1.org_1   | 2022-06-28 01:19:02,184 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70 to datanode:9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
scm1.org_1   | 2022-06-28 01:19:02,318 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6e4f5b77-ba5a-4791-a28a-fd99b4920d70, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:02.143Z[UTC]].
scm1.org_1   | 2022-06-28 01:19:02,331 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:19:02,350 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70 contains same datanodes as previous pipelines: PipelineID=51a7f1ac-dc16-43e5-8dfa-a67715d36ab1 nodeIds: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, 3f49ce74-6987-463e-a960-954ebbba5f61, 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
scm1.org_1   | 2022-06-28 01:19:02,523 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a6bcecaa-1423-464c-8db7-4effb6cb88eb to datanode:4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
scm1.org_1   | 2022-06-28 01:19:02,555 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$476/0x000000084055f040@484dde7d] WARN util.JvmPauseMonitor: JvmPauseMonitor-45e35def-6cad-44ae-bb26-f31c46277acf: Detected pause in JVM or host machine (eg GC): pause of approximately 167188807ns. No GCs detected.
scm1.org_1   | 2022-06-28 01:19:02,581 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a6bcecaa-1423-464c-8db7-4effb6cb88eb, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:02.523Z[UTC]].
scm1.org_1   | 2022-06-28 01:19:02,585 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:19:04,186 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:56634
scm1.org_1   | 2022-06-28 01:19:04,334 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:19:04,733 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43330
scm1.org_1   | 2022-06-28 01:19:04,842 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:19:05,697 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42201
scm1.org_1   | 2022-06-28 01:19:05,727 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:19:08,856 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:42062
scm1.org_1   | 2022-06-28 01:19:08,929 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:19:14,118 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:36594
scm1.org_1   | 2022-06-28 01:19:14,140 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:19:14,797 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:55090
scm1.org_1   | 2022-06-28 01:19:14,831 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:19:15,063 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39948
scm1.org_1   | 2022-06-28 01:19:15,158 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:19:15,160 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3f49ce74-6987-463e-a960-954ebbba5f61, CreationTimestamp2022-06-28T01:19:01.898Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-06-28 01:19:15,284 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm1.org_1   | 2022-06-28 01:19:15,356 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm1.org_1   | 2022-06-28 01:19:15,391 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 2022-06-28 01:19:15,416 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm1.org_1   | 2022-06-28 01:19:15,416 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm1.org_1   | 2022-06-28 01:19:15,417 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-06-28 01:19:15,421 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:19:51,538 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54476
recon_1      | 2022-06-28 01:19:51,557 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:20:00,535 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #1 got from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-06-28 01:20:00,786 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1      | 2022-06-28 01:20:01,105 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40996
recon_1      | 2022-06-28 01:20:01,146 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:20:01,167 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33930
recon_1      | 2022-06-28 01:20:01,257 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:20:01,258 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70 reported by 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1004767615899, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:20:02,918 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=6e4f5b77-ba5a-4791-a28a-fd99b4920d70 reported by 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1005480937391, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-06-28 01:20:02,918 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6e4f5b77-ba5a-4791-a28a-fd99b4920d70, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, CreationTimestamp2022-06-28T01:19:02.143Z[UTC]] moved to OPEN state
recon_1      | 2022-06-28 01:20:22,400 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41070
recon_1      | 2022-06-28 01:20:22,458 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:20:22,459 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-06-28 01:20:22,476 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54604
recon_1      | 2022-06-28 01:20:22,566 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-06-28 01:20:22,620 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:20:22,648 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34014
recon_1      | 2022-06-28 01:20:22,727 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:20:40,275 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:20:40,275 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:20:40,337 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-06-28 01:17:46,994 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-06-28 01:17:47,225 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-06-28 01:17:47,295 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-06-28 01:17:47,295 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-06-28 01:17:47,384 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-06-28 01:17:47,387 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-06-28 01:17:47,722 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-06-28 01:17:47,723 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-06-28 01:17:47,913 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2022-06-28 01:17:48,838 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2022-06-28 01:17:49,908 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm3.org_1   | 2022-06-28 01:17:49,908 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2022-06-28 01:17:49,913 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm3.org_1   | 2022-06-28 01:17:50,504 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm3.org_1   | 2022-06-28 01:17:50,555 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2022-06-28 01:17:50,559 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2022-06-28 01:17:50,569 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:966cceea-06cb-4ebe-a41c-dc5f70b815ea,clusterId:CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b,subject:scm-sub@scm3.org
scm3.org_1   | 2022-06-28 01:17:51,351 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2022-06-28 01:17:51,379 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-c0d09c5b-b199-4374-abdd-0a2f691dd86b, SCMID 966cceea-06cb-4ebe-a41c-dc5f70b815ea
scm3.org_1   | 2022-06-28 01:17:51,379 [main] INFO server.StorageContainerManager: Primary SCM Node ID 45e35def-6cad-44ae-bb26-f31c46277acf
scm3.org_1   | 2022-06-28 01:17:51,415 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-06-28 01:17:53,534 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | 2022-06-28 01:19:15,421 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
scm1.org_1   | 2022-06-28 01:19:15,421 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
scm1.org_1   | 2022-06-28 01:19:15,421 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm1.org_1   | 2022-06-28 01:19:15,429 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
scm1.org_1   | 2022-06-28 01:19:16,241 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e0166ad2-3c82-41e4-a01f-805995535eac, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3f49ce74-6987-463e-a960-954ebbba5f61, CreationTimestamp2022-06-28T01:19:02.051Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-06-28 01:19:16,466 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40085
scm1.org_1   | 2022-06-28 01:19:16,481 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:19:19,000 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:52784
scm1.org_1   | 2022-06-28 01:19:19,025 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:19:21,530 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58818
scm1.org_1   | 2022-06-28 01:19:21,680 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:19:33,369 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45401
scm1.org_1   | 2022-06-28 01:19:33,385 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39996
scm1.org_1   | 2022-06-28 01:19:33,406 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:19:33,415 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:19:33,417 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e107ff30-8061-4f60-8349-f89eb01cba86, Nodes: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, CreationTimestamp2022-06-28T01:19:01.034Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-06-28 01:19:33,683 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50270
scm1.org_1   | 2022-06-28 01:19:33,779 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:19:33,781 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a6bcecaa-1423-464c-8db7-4effb6cb88eb, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, CreationTimestamp2022-06-28T01:19:02.523Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-06-28 01:19:51,536 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35734
scm1.org_1   | 2022-06-28 01:19:51,555 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:19:56,496 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43492
scm1.org_1   | 2022-06-28 01:19:56,509 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:19:56,558 [IPC Server handler 88 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm1.org_1   | 2022-06-28 01:19:56,707 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm1.org_1   | 2022-06-28 01:19:56,748 [IPC Server handler 88 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
scm1.org_1   | 2022-06-28 01:20:00,056 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45018
scm1.org_1   | 2022-06-28 01:20:00,070 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:20:00,310 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36580
scm1.org_1   | 2022-06-28 01:20:00,321 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:20:00,408 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35336
scm1.org_1   | 2022-06-28 01:20:00,423 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:20:52,386 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41164
recon_1      | 2022-06-28 01:20:52,455 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54702
recon_1      | 2022-06-28 01:20:52,467 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:20:52,492 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:20:52,550 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34106
recon_1      | 2022-06-28 01:20:52,571 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:21:22,384 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54808
recon_1      | 2022-06-28 01:21:22,400 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41270
recon_1      | 2022-06-28 01:21:22,465 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34216
recon_1      | 2022-06-28 01:21:22,475 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:21:22,504 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:21:22,543 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:21:40,340 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:21:40,340 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:21:40,407 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
scm1.org_1   | 2022-06-28 01:20:00,651 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41737
scm1.org_1   | 2022-06-28 01:20:00,678 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:20:01,031 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50364
scm1.org_1   | 2022-06-28 01:20:01,125 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40106
scm1.org_1   | 2022-06-28 01:20:01,145 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:20:01,203 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:20:02,945 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6e4f5b77-ba5a-4791-a28a-fd99b4920d70, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, CreationTimestamp2022-06-28T01:19:02.143Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-06-28 01:20:08,224 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43556
scm1.org_1   | 2022-06-28 01:20:08,229 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:20:20,105 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43590
scm1.org_1   | 2022-06-28 01:20:20,112 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:20:22,399 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50440
scm1.org_1   | 2022-06-28 01:20:22,486 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:20:22,496 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35858
scm1.org_1   | 2022-06-28 01:20:22,528 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44545
scm1.org_1   | 2022-06-28 01:20:22,532 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:20:22,629 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:20:22,654 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40190
scm1.org_1   | 2022-06-28 01:20:22,707 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:20:29,132 [IPC Server handler 27 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm1.org_1   | 2022-06-28 01:20:45,298 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:60292
scm1.org_1   | 2022-06-28 01:20:45,308 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:20:52,430 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50542
scm1.org_1   | 2022-06-28 01:20:52,461 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35956
scm1.org_1   | 2022-06-28 01:20:52,502 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:20:52,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:20:52,584 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40288
scm1.org_1   | 2022-06-28 01:20:52,618 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:21:15,236 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43784
scm1.org_1   | 2022-06-28 01:21:15,238 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:21:22,395 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50648
scm1.org_1   | 2022-06-28 01:21:22,408 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36066
scm1.org_1   | 2022-06-28 01:21:22,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2496)
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2466)
om2_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-28 01:27:31,806 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48846
om2_1        | 2022-06-28 01:27:31,808 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:27:35,245 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:35,256 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:35,267 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1580261655 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:27:35,924 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:35,929 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:36,534 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:36,537 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:40,359 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48866
om2_1        | 2022-06-28 01:27:40,362 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:27:40,662 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44045
om2_1        | 2022-06-28 01:27:40,674 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:27:43,826 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:43,830 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:43,856 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1120923398 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:27:44,498 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:44,502 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:44,507 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:48,470 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48886
om2_1        | 2022-06-28 01:27:48,475 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:27:54,587 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48926
om2_1        | 2022-06-28 01:27:54,592 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:27:58,102 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:45335
om2_1        | 2022-06-28 01:27:58,107 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:27:58,108 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:58,114 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:58,126 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5564991060 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:27:58,861 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:58,865 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:58,868 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:59,594 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:59,598 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:59,601 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:27:59,624 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:21:52,346 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54914
recon_1      | 2022-06-28 01:21:52,384 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:21:52,405 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41378
recon_1      | 2022-06-28 01:21:52,456 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:21:52,537 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34320
recon_1      | 2022-06-28 01:21:52,543 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:22:22,376 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41498
recon_1      | 2022-06-28 01:22:22,376 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55034
recon_1      | 2022-06-28 01:22:22,411 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.48.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.74.Final.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/a8808d1c3781627c40e0ed25d0bb4ec1e74e3de2 ; compiled by 'runner' on 2022-06-28T00:52Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-06-28 01:17:53,541 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-06-28 01:17:53,625 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-06-28 01:17:53,650 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-06-28 01:17:53,659 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-06-28 01:17:53,714 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-06-28 01:17:53,714 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-06-28 01:17:54,176 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2022-06-28 01:17:54,312 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2022-06-28 01:17:54,314 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/966387782953.crt.
scm3.org_1   | 2022-06-28 01:17:54,323 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2022-06-28 01:17:54,465 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-06-28 01:17:54,465 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-06-28 01:17:54,509 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-06-28 01:17:54,665 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-06-28 01:17:54,915 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm3.org_1   | 2022-06-28 01:17:54,916 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm3.org_1   | 2022-06-28 01:17:54,965 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2022-06-28 01:17:54,989 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:966cceea-06cb-4ebe-a41c-dc5f70b815ea
scm3.org_1   | 2022-06-28 01:17:55,105 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm3.org_1   | 2022-06-28 01:17:55,246 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm3.org_1   | 2022-06-28 01:17:55,248 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-06-28 01:17:55,248 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm3.org_1   | 2022-06-28 01:17:55,249 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-06-28 01:17:55,249 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-06-28 01:17:55,257 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm3.org_1   | 2022-06-28 01:17:55,259 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-06-28 01:17:55,259 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2022-06-28 01:17:55,260 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2022-06-28 01:17:55,293 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm3.org_1   | 2022-06-28 01:17:55,296 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm3.org_1   | 2022-06-28 01:17:56,046 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2022-06-28 01:17:56,049 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm3.org_1   | 2022-06-28 01:17:56,049 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm3.org_1   | 2022-06-28 01:17:56,050 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-06-28 01:17:56,050 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-06-28 01:17:56,052 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-06-28 01:17:56,068 [main] INFO server.RaftServer: 966cceea-06cb-4ebe-a41c-dc5f70b815ea: addNew group-0A2F691DD86B:[] returns group-0A2F691DD86B:java.util.concurrent.CompletableFuture@38e83838[Not completed]
scm3.org_1   | 2022-06-28 01:17:56,123 [pool-16-thread-1] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea: new RaftServerImpl for group-0A2F691DD86B:[] with SCMStateMachine:uninitialized
scm3.org_1   | 2022-06-28 01:17:56,134 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | 2022-06-28 01:17:56,136 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2022-06-28 01:17:56,137 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm3.org_1   | 2022-06-28 01:17:56,137 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-06-28 01:17:56,138 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-06-28 01:17:56,138 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2022-06-28 01:17:56,154 [pool-16-thread-1] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2022-06-28 01:17:56,154 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-06-28 01:17:56,163 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm3.org_1   | 2022-06-28 01:17:56,167 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2022-06-28 01:17:56,168 [pool-16-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b does not exist. Creating ...
scm3.org_1   | 2022-06-28 01:17:56,185 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/in_use.lock acquired by nodename 7@scm3.org
scm3.org_1   | 2022-06-28 01:17:56,210 [pool-16-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b has been successfully formatted.
scm3.org_1   | 2022-06-28 01:17:56,215 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm3.org_1   | 2022-06-28 01:17:56,217 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2022-06-28 01:17:56,232 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2022-06-28 01:17:56,235 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-06-28 01:17:56,237 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm3.org_1   | 2022-06-28 01:17:56,476 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-06-28 01:17:56,489 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2022-06-28 01:17:56,489 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm3.org_1   | 2022-06-28 01:17:56,503 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b
scm3.org_1   | 2022-06-28 01:17:56,503 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2022-06-28 01:17:56,504 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm3.org_1   | 2022-06-28 01:17:56,505 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-06-28 01:17:56,505 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm3.org_1   | 2022-06-28 01:17:56,505 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2022-06-28 01:17:56,506 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm3.org_1   | 2022-06-28 01:17:56,506 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2022-06-28 01:17:56,506 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm3.org_1   | 2022-06-28 01:17:56,515 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2022-06-28 01:28:00,078 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:00,988 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:00,991 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:00,994 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:01,010 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:01,152 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:01,876 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:01,879 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:01,882 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:02,507 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:02,512 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:02,515 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:02,560 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:03,587 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:03,591 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:03,596 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:04,298 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:04,302 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:04,306 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:05,078 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:05,080 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:05,083 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:05,098 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:05,522 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:06,699 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:06,703 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:06,706 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:06,728 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:07,089 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:07,837 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:07,840 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:07,843 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:08,589 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:08,594 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:08,597 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:08,619 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:08,929 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:09,640 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:09,644 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:09,650 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:09,671 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:09,768 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:10,538 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:10,542 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:10,547 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:17:45,646 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread2] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: set configuration 7: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-06-28 01:17:45,729 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:17:45,735 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread2] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: set configuration 9: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-28 01:17:45,737 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm2.org_1   | 2022-06-28 01:17:45,738 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm2.org_1   | 2022-06-28 01:17:45,806 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:17:45,927 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-0A2F691DD86B:[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-06-28 01:17:45,947 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2022-06-28 01:17:45,953 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm2.org_1   | 2022-06-28 01:17:45,953 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm2.org_1   | 2022-06-28 01:17:46,252 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2022-06-28 01:17:46,300 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2022-06-28 01:17:46,300 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2022-06-28 01:17:47,057 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2022-06-28 01:17:47,067 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-06-28 01:17:47,071 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2022-06-28 01:17:47,331 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2022-06-28 01:17:47,332 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2022-06-28 01:17:47,332 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-06-28 01:17:47,333 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2022-06-28 01:17:47,397 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2022-06-28 01:17:47,398 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-06-28 01:17:47,414 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2022-06-28 01:17:47,416 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2022-06-28 01:17:47,601 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-06-28 01:17:47,601 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-06-28 01:17:47,601 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2022-06-28 01:17:47,930 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 916105677270 on Scm Bootstrap Node c7ed5937-0e47-4abb-91f6-068d38a4ec09
scm2.org_1   | 2022-06-28 01:17:47,941 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node c7ed5937-0e47-4abb-91f6-068d38a4ec09
scm2.org_1   | 2022-06-28 01:17:47,981 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4bcff08c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm2.org_1   | 2022-06-28 01:17:48,044 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2022-06-28 01:17:48,045 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm2.org_1   | 2022-06-28 01:17:48,047 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2022-06-28 01:17:48,153 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @20504ms to org.eclipse.jetty.util.log.Slf4jLog
scm2.org_1   | 2022-06-28 01:17:48,492 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2022-06-28 01:17:48,528 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2022-06-28 01:17:48,531 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm2.org_1   | 2022-06-28 01:17:48,537 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm2.org_1   | 2022-06-28 01:17:48,538 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2022-06-28 01:17:48,547 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm2.org_1   | 2022-06-28 01:17:48,665 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2022-06-28 01:17:48,666 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm2.org_1   | 2022-06-28 01:17:48,790 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2022-06-28 01:17:48,790 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2022-06-28 01:17:48,801 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm2.org_1   | 2022-06-28 01:17:48,857 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-06-28 01:21:22,515 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40392
scm1.org_1   | 2022-06-28 01:21:22,542 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:21:22,559 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:21:52,460 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36174
scm1.org_1   | 2022-06-28 01:21:52,478 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50748
scm1.org_1   | 2022-06-28 01:21:52,540 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:21:52,568 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:21:52,602 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40504
scm1.org_1   | 2022-06-28 01:21:52,626 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:22:14,035 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-06-28 01:22:22,369 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50874
scm1.org_1   | 2022-06-28 01:22:22,505 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:22:22,523 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36288
scm1.org_1   | 2022-06-28 01:22:22,616 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40618
scm1.org_1   | 2022-06-28 01:22:22,626 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:22:22,634 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:22:25,580 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44060
scm1.org_1   | 2022-06-28 01:22:25,588 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:22:34,827 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:60690
scm1.org_1   | 2022-06-28 01:22:34,834 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:22:41,998 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44098
scm1.org_1   | 2022-06-28 01:22:42,005 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:22:42,854 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42553
scm1.org_1   | 2022-06-28 01:22:42,856 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:22:49,887 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:60736
scm1.org_1   | 2022-06-28 01:22:49,891 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:22:52,345 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36392
scm1.org_1   | 2022-06-28 01:22:52,387 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:22:52,480 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50972
scm1.org_1   | 2022-06-28 01:22:52,488 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40722
scm1.org_1   | 2022-06-28 01:22:52,491 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:22:52,521 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:23:22,454 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51086
scm1.org_1   | 2022-06-28 01:23:22,470 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:23:22,517 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36512
scm1.org_1   | 2022-06-28 01:23:22,532 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40836
scm1.org_1   | 2022-06-28 01:23:22,532 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-06-28 01:22:22,440 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:22:22,478 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34442
recon_1      | 2022-06-28 01:22:22,520 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:22:40,416 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:22:40,416 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:22:40,461 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:22:42,705 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 25 milliseconds to process 0 existing database records.
recon_1      | 2022-06-28 01:22:42,725 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 20 milliseconds for processing 2 containers.
recon_1      | 2022-06-28 01:22:42,872 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-06-28 01:22:42,878 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 38 milliseconds.
om2_1        | 2022-06-28 01:28:11,274 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:11,277 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:11,280 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:11,292 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:12,254 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:12,257 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:12,260 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:12,991 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:13,001 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:13,005 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:13,026 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:15,447 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:16,185 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:16,189 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:16,192 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:16,215 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:17,946 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:18,670 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:18,672 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:18,675 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:18,683 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-5564991060/ozone-test-5000324300/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1        | 2022-06-28 01:28:18,684 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-5000324300/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om2_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-5000324300/multipartKey2. Entity too small.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:531)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-28 01:28:19,340 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:19,344 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:19,349 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:20,058 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:20,062 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:20,067 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:20,075 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om2_1        | partName: "etag1"
om2_1        | , partNumber: 2
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-06-28 01:28:20,087 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2022-06-28 01:17:48,865 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2dc0cbbc{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2022-06-28 01:17:48,876 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@e0865e7{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2022-06-28 01:17:49,148 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-06-28 01:17:49,190 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@571ecfe2{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-15000024215576981954/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm2.org_1   | 2022-06-28 01:17:49,238 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@45070db0{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm2.org_1   | 2022-06-28 01:17:49,238 [Listener at 0.0.0.0/9860] INFO server.Server: Started @21589ms
scm2.org_1   | 2022-06-28 01:17:49,255 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2022-06-28 01:17:49,255 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2022-06-28 01:17:49,261 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm2.org_1   | 2022-06-28 01:17:51,217 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:18:06,847 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread2] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: set configuration 13: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 966cceea-06cb-4ebe-a41c-dc5f70b815ea|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-06-28 01:18:06,919 [c7ed5937-0e47-4abb-91f6-068d38a4ec09-server-thread2] INFO server.RaftServer$Division: c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B: set configuration 15: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 966cceea-06cb-4ebe-a41c-dc5f70b815ea|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-06-28 01:18:29,588 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:18:30,336 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:18:32,849 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:18:35,122 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:18:35,870 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:18:39,193 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:18:56,835 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57788
scm2.org_1   | 2022-06-28 01:18:57,025 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50630
scm2.org_1   | 2022-06-28 01:18:57,043 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:18:57,086 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:18:58,048 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40532
scm2.org_1   | 2022-06-28 01:18:58,092 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:19:00,740 [IPC Server handler 36 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
scm2.org_1   | 2022-06-28 01:19:00,758 [IPC Server handler 33 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
scm2.org_1   | 2022-06-28 01:19:00,774 [IPC Server handler 33 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1005480937391, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-06-28 01:19:00,792 [IPC Server handler 36 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1004767615899, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-06-28 01:19:00,939 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm2.org_1   | 2022-06-28 01:19:00,967 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm2.org_1   | 2022-06-28 01:19:00,966 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-06-28 01:19:00,972 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-06-28 01:19:01,779 [IPC Server handler 33 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3f49ce74-6987-463e-a960-954ebbba5f61
scm2.org_1   | 2022-06-28 01:19:01,780 [IPC Server handler 33 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1007988787146, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-06-28 01:19:01,794 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm2.org_1   | 2022-06-28 01:19:01,794 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2022-06-28 01:19:01,794 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2022-06-28 01:19:01,794 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-06-28 01:19:01,803 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2022-06-28 01:19:01,810 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-06-28 01:19:01,863 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e107ff30-8061-4f60-8349-f89eb01cba86, Nodes: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:01.034Z[UTC]].
scm2.org_1   | 2022-06-28 01:19:01,888 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-06-28 01:19:01,892 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:19:02,066 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:01.898Z[UTC]].
scm2.org_1   | 2022-06-28 01:19:02,078 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:19:02,143 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e0166ad2-3c82-41e4-a01f-805995535eac, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:02.051Z[UTC]].
scm2.org_1   | 2022-06-28 01:19:02,151 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:19:02,308 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6e4f5b77-ba5a-4791-a28a-fd99b4920d70, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:02.143Z[UTC]].
scm2.org_1   | 2022-06-28 01:19:02,316 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:19:02,646 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a6bcecaa-1423-464c-8db7-4effb6cb88eb, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:02.523Z[UTC]].
scm2.org_1   | 2022-06-28 01:19:02,647 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:19:14,998 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57872
scm2.org_1   | 2022-06-28 01:19:15,158 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:23:22,549 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:23:29,058 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44280
scm1.org_1   | 2022-06-28 01:23:29,061 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:23:52,409 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51190
scm1.org_1   | 2022-06-28 01:23:52,417 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36610
scm1.org_1   | 2022-06-28 01:23:52,465 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:23:52,535 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40946
scm1.org_1   | 2022-06-28 01:23:52,538 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:23:52,545 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:24:22,386 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51308
scm1.org_1   | 2022-06-28 01:24:22,452 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:24:22,500 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36728
scm1.org_1   | 2022-06-28 01:24:22,512 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:24:22,522 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41058
scm1.org_1   | 2022-06-28 01:24:22,543 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:24:52,401 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36836
scm1.org_1   | 2022-06-28 01:24:52,406 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51410
scm1.org_1   | 2022-06-28 01:24:52,483 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:24:52,487 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:24:52,492 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41160
scm1.org_1   | 2022-06-28 01:24:52,516 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:24:54,218 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:44594
scm1.org_1   | 2022-06-28 01:24:54,229 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:25:01,748 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:33010
scm1.org_1   | 2022-06-28 01:25:01,752 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:25:22,394 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51526
scm1.org_1   | 2022-06-28 01:25:22,445 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36946
scm1.org_1   | 2022-06-28 01:25:22,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:25:22,466 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:25:22,507 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41282
scm1.org_1   | 2022-06-28 01:25:22,537 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:25:52,359 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51776
scm1.org_1   | 2022-06-28 01:25:52,393 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37194
scm1.org_1   | 2022-06-28 01:25:52,436 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:25:52,462 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:25:52,488 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41524
scm1.org_1   | 2022-06-28 01:25:52,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:26:22,480 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51874
scm1.org_1   | 2022-06-28 01:26:22,507 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37290
recon_1      | 2022-06-28 01:22:52,372 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55138
recon_1      | 2022-06-28 01:22:52,393 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41602
recon_1      | 2022-06-28 01:22:52,417 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:22:52,461 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:22:52,468 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34544
recon_1      | 2022-06-28 01:22:52,519 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:23:22,368 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55254
recon_1      | 2022-06-28 01:23:22,369 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41714
recon_1      | 2022-06-28 01:23:22,402 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:23:22,456 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34660
recon_1      | 2022-06-28 01:23:22,485 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:23:22,509 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:23:40,463 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:23:40,463 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:23:40,506 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
scm3.org_1   | 2022-06-28 01:17:56,515 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm3.org_1   | 2022-06-28 01:17:56,515 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2022-06-28 01:17:56,520 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-06-28 01:17:56,520 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-06-28 01:17:56,524 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm3.org_1   | 2022-06-28 01:17:56,525 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm3.org_1   | 2022-06-28 01:17:56,525 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm3.org_1   | 2022-06-28 01:17:56,526 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2022-06-28 01:17:56,527 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2022-06-28 01:17:56,527 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | 2022-06-28 01:17:56,560 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2022-06-28 01:17:56,561 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm3.org_1   | 2022-06-28 01:17:56,561 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm3.org_1   | 2022-06-28 01:17:56,561 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm3.org_1   | 2022-06-28 01:17:56,562 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm3.org_1   | 2022-06-28 01:17:56,565 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2022-06-28 01:17:56,565 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2022-06-28 01:17:56,565 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm3.org_1   | 2022-06-28 01:17:56,882 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm3.org_1   | 2022-06-28 01:17:57,109 [main] INFO reflections.Reflections: Reflections took 181 ms to scan 3 urls, producing 109 keys and 243 values 
scm3.org_1   | 2022-06-28 01:17:57,293 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm3.org_1   | 2022-06-28 01:17:57,293 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2022-06-28 01:17:57,297 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2022-06-28 01:17:57,299 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm3.org_1   | 2022-06-28 01:17:57,429 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | 2022-06-28 01:17:57,465 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2022-06-28 01:17:57,486 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2022-06-28 01:17:57,593 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm3.org_1   | 2022-06-28 01:17:57,594 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2022-06-28 01:17:57,610 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2022-06-28 01:17:57,615 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm3.org_1   | 2022-06-28 01:17:57,617 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm3.org_1   | 2022-06-28 01:17:57,617 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm3.org_1   | 2022-06-28 01:17:57,635 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm3.org_1   | 2022-06-28 01:17:57,635 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm3.org_1   | 2022-06-28 01:17:57,695 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm3.org_1   | 2022-06-28 01:17:57,763 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm3.org_1   | 2022-06-28 01:17:57,834 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-06-28 01:17:57,852 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2022-06-28 01:17:57,862 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-06-28 01:17:57,865 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2022-06-28 01:17:57,869 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:17:57,871 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-06-28 01:17:57,921 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | 2022-06-28 01:17:57,985 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-06-28 01:17:58,075 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm3.org_1   | 2022-06-28 01:17:59,631 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-06-28 01:17:59,660 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-06-28 01:17:59,672 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm3.org_1   | 2022-06-28 01:17:59,747 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-06-28 01:17:59,760 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-06-28 01:17:59,780 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2022-06-28 01:17:59,824 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-06-28 01:19:15,160 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3f49ce74-6987-463e-a960-954ebbba5f61, CreationTimestamp2022-06-28T01:19:01.898Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-06-28 01:19:15,344 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm2.org_1   | 2022-06-28 01:19:16,236 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e0166ad2-3c82-41e4-a01f-805995535eac, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3f49ce74-6987-463e-a960-954ebbba5f61, CreationTimestamp2022-06-28T01:19:02.051Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-06-28 01:19:16,236 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm2.org_1   | 2022-06-28 01:19:16,240 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm2.org_1   | 2022-06-28 01:19:16,240 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm2.org_1   | 2022-06-28 01:19:16,240 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm2.org_1   | 2022-06-28 01:19:16,240 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-06-28 01:19:16,240 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm2.org_1   | 2022-06-28 01:19:33,289 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57920
scm2.org_1   | 2022-06-28 01:19:33,324 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:19:33,326 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e107ff30-8061-4f60-8349-f89eb01cba86, Nodes: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, CreationTimestamp2022-06-28T01:19:01.034Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-06-28 01:19:33,752 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50758
scm2.org_1   | 2022-06-28 01:19:33,810 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:19:33,812 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a6bcecaa-1423-464c-8db7-4effb6cb88eb, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, CreationTimestamp2022-06-28T01:19:02.523Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-06-28 01:19:51,533 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40698
scm2.org_1   | 2022-06-28 01:19:51,543 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:19:56,756 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm2.org_1   | 2022-06-28 01:20:01,030 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50858
scm2.org_1   | 2022-06-28 01:20:01,077 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:20:01,183 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58034
scm2.org_1   | 2022-06-28 01:20:01,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:20:02,923 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6e4f5b77-ba5a-4791-a28a-fd99b4920d70, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, CreationTimestamp2022-06-28T01:19:02.143Z[UTC]] moved to OPEN state
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:23:52,383 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41822
recon_1      | 2022-06-28 01:23:52,394 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55358
recon_1      | 2022-06-28 01:23:52,447 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34764
recon_1      | 2022-06-28 01:23:52,463 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:23:52,468 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:23:52,529 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:24:22,348 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41936
recon_1      | 2022-06-28 01:24:22,378 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:24:22,431 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55478
recon_1      | 2022-06-28 01:24:22,463 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34882
recon_1      | 2022-06-28 01:24:22,468 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:24:22,528 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:24:40,510 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:24:40,510 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:24:40,543 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
scm3.org_1   | 2022-06-28 01:17:59,838 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-06-28 01:17:59,858 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm3.org_1   | 2022-06-28 01:18:00,086 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm3.org_1   | 2022-06-28 01:18:00,088 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | Container Balancer status:
scm3.org_1   | Key                            Value
scm3.org_1   | Running                        false
scm3.org_1   | Container Balancer Configuration values:
scm3.org_1   | Key                                                Value
scm3.org_1   | Threshold                                          10
scm3.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm3.org_1   | Max Size to Move per Iteration                     500GB
scm3.org_1   | Max Size Entering Target per Iteration             26GB
scm3.org_1   | Max Size Leaving Source per Iteration              26GB
scm3.org_1   | 
scm3.org_1   | 2022-06-28 01:18:00,092 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-06-28 01:18:00,096 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm3.org_1   | 2022-06-28 01:18:00,100 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2022-06-28 01:18:00,110 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm3.org_1   | 2022-06-28 01:18:00,119 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-impl-thread1] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: start with initializing state, conf=-1: [], old=null
scm3.org_1   | 2022-06-28 01:18:00,120 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-impl-thread1] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2022-06-28 01:18:00,121 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0A2F691DD86B,id=966cceea-06cb-4ebe-a41c-dc5f70b815ea
scm3.org_1   | 2022-06-28 01:18:00,134 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 966cceea-06cb-4ebe-a41c-dc5f70b815ea: start RPC server
scm3.org_1   | 2022-06-28 01:18:00,268 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 966cceea-06cb-4ebe-a41c-dc5f70b815ea: GrpcService started, listening on 9894
scm3.org_1   | 2022-06-28 01:18:00,285 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$459/0x000000084052ac40@7fec6c2f] INFO util.JvmPauseMonitor: JvmPauseMonitor-966cceea-06cb-4ebe-a41c-dc5f70b815ea: Started
scm3.org_1   | 2022-06-28 01:18:00,335 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2022-06-28 01:18:05,073 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: receive installSnapshot: 45e35def-6cad-44ae-bb26-f31c46277acf->966cceea-06cb-4ebe-a41c-dc5f70b815ea#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2022-06-28 01:18:05,116 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm3.org_1   | 2022-06-28 01:18:05,116 [grpc-default-executor-0] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: change Leader from null to 45e35def-6cad-44ae-bb26-f31c46277acf at term 2 for installSnapshot, leader elected after 8901ms
scm3.org_1   | 2022-06-28 01:18:05,139 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: Received notification to install snapshot at index 0
scm3.org_1   | 2022-06-28 01:18:05,235 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm3.org_1   | 2022-06-28 01:18:05,834 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "45e35def-6cad-44ae-bb26-f31c46277acf"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "c7ed5937-0e47-4abb-91f6-068d38a4ec09"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-06-28 01:18:05,847 [grpc-default-executor-0] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: set configuration 9: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-06-28 01:18:05,883 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: reply installSnapshot: 45e35def-6cad-44ae-bb26-f31c46277acf<-966cceea-06cb-4ebe-a41c-dc5f70b815ea#0:FAIL-t0,ALREADY_INSTALLED
scm3.org_1   | 2022-06-28 01:18:05,960 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 966cceea-06cb-4ebe-a41c-dc5f70b815ea: Completed INSTALL_SNAPSHOT, lastRequest: 45e35def-6cad-44ae-bb26-f31c46277acf->966cceea-06cb-4ebe-a41c-dc5f70b815ea#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2022-06-28 01:18:06,114 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread1] INFO impl.RoleInfo: 966cceea-06cb-4ebe-a41c-dc5f70b815ea: start 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-FollowerState
scm3.org_1   | 2022-06-28 01:18:06,121 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread1] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm3.org_1   | 2022-06-28 01:18:06,127 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread1] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: inconsistency entries. Reply:45e35def-6cad-44ae-bb26-f31c46277acf<-966cceea-06cb-4ebe-a41c-dc5f70b815ea#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-06-28 01:18:06,186 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread2] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm3.org_1   | 2022-06-28 01:18:06,187 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread2] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: inconsistency entries. Reply:45e35def-6cad-44ae-bb26-f31c46277acf<-966cceea-06cb-4ebe-a41c-dc5f70b815ea#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-06-28 01:18:06,214 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread1] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: set configuration 0: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-06-28 01:18:06,226 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread1] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: set configuration 1: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-28 01:28:20,726 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:20,735 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:20,741 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:20,749 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1        | partName: "etag1"
om2_1        | , partNumber: 1
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-06-28 01:28:20,750 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2022-06-28 01:20:22,386 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50932
scm2.org_1   | 2022-06-28 01:20:22,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:20:22,516 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40830
scm2.org_1   | 2022-06-28 01:20:22,608 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:20:22,626 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58114
scm2.org_1   | 2022-06-28 01:20:22,708 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:20:52,388 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51026
scm2.org_1   | 2022-06-28 01:20:52,528 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:20:52,586 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40928
scm2.org_1   | 2022-06-28 01:20:52,600 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58218
scm2.org_1   | 2022-06-28 01:20:52,655 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:20:52,671 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:21:22,358 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51136
scm2.org_1   | 2022-06-28 01:21:22,371 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:21:22,388 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41036
scm2.org_1   | 2022-06-28 01:21:22,504 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58324
scm2.org_1   | 2022-06-28 01:21:22,516 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:21:22,549 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:21:52,405 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51244
scm2.org_1   | 2022-06-28 01:21:52,451 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:21:52,462 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41140
scm2.org_1   | 2022-06-28 01:21:52,523 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:21:52,564 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58424
scm2.org_1   | 2022-06-28 01:21:52,576 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:22:22,365 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51360
scm2.org_1   | 2022-06-28 01:22:22,430 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41260
scm2.org_1   | 2022-06-28 01:22:22,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:22:22,494 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:22:22,510 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58546
scm2.org_1   | 2022-06-28 01:22:22,526 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:22:40,136 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-06-28 01:22:52,396 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51468
scm2.org_1   | 2022-06-28 01:22:52,424 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:22:52,455 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58654
scm2.org_1   | 2022-06-28 01:22:52,463 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41366
scm2.org_1   | 2022-06-28 01:22:52,471 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:22:52,521 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:23:22,390 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41476
scm2.org_1   | 2022-06-28 01:23:22,394 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51582
scm2.org_1   | 2022-06-28 01:23:22,431 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:23:22,498 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:23:22,508 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58764
scm2.org_1   | 2022-06-28 01:23:22,536 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:23:52,361 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51684
scm2.org_1   | 2022-06-28 01:23:52,400 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41584
scm2.org_1   | 2022-06-28 01:23:52,462 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:23:52,511 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58868
scm2.org_1   | 2022-06-28 01:23:52,517 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:23:52,527 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:24:22,351 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41698
scm2.org_1   | 2022-06-28 01:24:22,357 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51804
scm2.org_1   | 2022-06-28 01:24:22,380 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:24:22,391 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:24:22,503 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58986
scm2.org_1   | 2022-06-28 01:24:22,527 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:24:52,390 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41802
scm2.org_1   | 2022-06-28 01:24:52,396 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51902
scm2.org_1   | 2022-06-28 01:24:52,433 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:24:52,467 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59092
scm2.org_1   | 2022-06-28 01:24:52,468 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:24:52,519 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:25:22,357 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41916
scm2.org_1   | 2022-06-28 01:25:22,375 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52018
scm2.org_1   | 2022-06-28 01:25:22,405 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:25:22,441 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:24:52,356 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42042
recon_1      | 2022-06-28 01:24:52,385 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55576
recon_1      | 2022-06-28 01:24:52,431 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:24:52,435 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:24:52,464 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34984
recon_1      | 2022-06-28 01:24:52,494 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:25:22,372 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42156
recon_1      | 2022-06-28 01:25:22,382 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55694
recon_1      | 2022-06-28 01:25:22,396 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:25:22,455 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:25:22,474 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35100
recon_1      | 2022-06-28 01:25:22,493 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:25:40,544 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:25:40,544 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:25:40,594 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
scm1.org_1   | 2022-06-28 01:26:22,514 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:26:22,544 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:26:22,565 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41622
scm1.org_1   | 2022-06-28 01:26:22,597 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:26:41,973 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45100
scm1.org_1   | 2022-06-28 01:26:41,979 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:26:52,382 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51982
scm1.org_1   | 2022-06-28 01:26:52,397 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37404
scm1.org_1   | 2022-06-28 01:26:52,405 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:26:52,461 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:26:52,513 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41732
scm1.org_1   | 2022-06-28 01:26:52,526 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:27:02,975 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:33578
scm1.org_1   | 2022-06-28 01:27:02,981 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:27:14,036 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm1.org_1   | 2022-06-28 01:27:22,367 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52102
scm1.org_1   | 2022-06-28 01:27:22,409 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:27:22,481 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37520
scm1.org_1   | 2022-06-28 01:27:22,490 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41850
scm1.org_1   | 2022-06-28 01:27:22,490 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:27:22,505 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:27:29,045 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45296
scm1.org_1   | 2022-06-28 01:27:29,055 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:27:42,903 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36939
scm1.org_1   | 2022-06-28 01:27:42,907 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:27:52,375 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52210
scm1.org_1   | 2022-06-28 01:27:52,398 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37628
scm1.org_1   | 2022-06-28 01:27:52,452 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:27:52,505 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:27:52,514 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41958
scm1.org_1   | 2022-06-28 01:27:52,520 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:27:59,638 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45416
scm1.org_1   | 2022-06-28 01:27:59,644 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:28:02,538 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:33814
scm1.org_1   | 2022-06-28 01:28:02,547 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:28:22,338 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37768
scm1.org_1   | 2022-06-28 01:28:22,392 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52354
scm1.org_1   | 2022-06-28 01:28:22,435 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42098
scm1.org_1   | 2022-06-28 01:28:22,438 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:28:22,478 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:28:22,524 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:28:28,308 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:33932
scm1.org_1   | 2022-06-28 01:28:28,316 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:28:46,583 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:34004
scm1.org_1   | 2022-06-28 01:28:46,602 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:28:52,359 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52494
scm1.org_1   | 2022-06-28 01:28:52,376 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:28:52,468 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42236
scm1.org_1   | 2022-06-28 01:28:52,495 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:28:52,568 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37922
scm1.org_1   | 2022-06-28 01:28:52,705 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:29:22,405 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52628
scm1.org_1   | 2022-06-28 01:29:22,409 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38050
scm1.org_1   | 2022-06-28 01:29:22,458 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:29:22,481 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:29:22,509 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42380
scm1.org_1   | 2022-06-28 01:29:22,532 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:29:26,082 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45822
scm1.org_1   | 2022-06-28 01:29:26,089 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:29:27,509 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:34210
scm1.org_1   | 2022-06-28 01:29:27,514 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:29:40,306 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45874
scm1.org_1   | 2022-06-28 01:29:40,312 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:29:42,180 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:34264
scm1.org_1   | 2022-06-28 01:29:42,182 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:29:52,369 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52772
scm1.org_1   | 2022-06-28 01:29:52,396 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38198
scm1.org_1   | 2022-06-28 01:29:52,438 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:29:52,475 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:29:52,506 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42522
scm1.org_1   | 2022-06-28 01:29:52,539 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:30:06,976 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:45994
scm1.org_1   | 2022-06-28 01:30:06,978 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:30:22,391 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52884
scm1.org_1   | 2022-06-28 01:30:22,427 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38308
scm3.org_1   | 2022-06-28 01:18:06,228 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread1] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: set configuration 7: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-06-28 01:18:06,238 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread1] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: set configuration 9: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-06-28 01:18:06,258 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread1] INFO segmented.SegmentedRaftLogWorker: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-SegmentedRaftLogWorker: Starting segment from index:0
scm3.org_1   | 2022-06-28 01:18:06,402 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread1] INFO segmented.SegmentedRaftLogWorker: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm3.org_1   | 2022-06-28 01:18:06,529 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread2] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: set configuration 0: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-06-28 01:18:06,532 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread2] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: set configuration 1: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-06-28 01:18:06,535 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread2] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: set configuration 7: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-06-28 01:18:06,536 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread2] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: set configuration 9: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-06-28 01:18:06,916 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread2] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: set configuration 13: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 966cceea-06cb-4ebe-a41c-dc5f70b815ea|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-06-28 01:18:06,946 [966cceea-06cb-4ebe-a41c-dc5f70b815ea-server-thread2] INFO server.RaftServer$Division: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B: set configuration 15: [45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 966cceea-06cb-4ebe-a41c-dc5f70b815ea|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-06-28 01:18:07,148 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/current/log_inprogress_0
scm3.org_1   | 2022-06-28 01:18:07,212 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/current/log_inprogress_0 to /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/current/log_0-0
scm3.org_1   | 2022-06-28 01:18:07,411 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/c0d09c5b-b199-4374-abdd-0a2f691dd86b/current/log_inprogress_1
scm3.org_1   | 2022-06-28 01:18:07,438 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-0A2F691DD86B:[45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 966cceea-06cb-4ebe-a41c-dc5f70b815ea|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, c7ed5937-0e47-4abb-91f6-068d38a4ec09|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-06-28 01:18:07,447 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2022-06-28 01:18:07,524 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:18:07,563 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm3.org_1   | 2022-06-28 01:18:07,567 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2022-06-28 01:18:07,567 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm3.org_1   | 2022-06-28 01:18:07,566 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-06-28 01:18:07,612 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2022-06-28 01:18:08,319 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2022-06-28 01:18:08,463 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm3.org_1   | 2022-06-28 01:18:08,464 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm3.org_1   | 2022-06-28 01:18:10,014 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm3.org_1   | 2022-06-28 01:18:10,036 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-06-28 01:18:10,278 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2022-06-28 01:18:10,610 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-06-28 01:18:10,624 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:25:52,317 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42400
recon_1      | 2022-06-28 01:25:52,386 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55940
recon_1      | 2022-06-28 01:25:52,394 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:25:52,411 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:25:52,476 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35350
recon_1      | 2022-06-28 01:25:52,525 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:26:22,343 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42510
recon_1      | 2022-06-28 01:26:22,399 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:26:22,447 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56042
recon_1      | 2022-06-28 01:26:22,457 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35444
recon_1      | 2022-06-28 01:26:22,477 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:26:22,495 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:26:40,599 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:26:40,599 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:26:40,647 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-28 01:28:21,480 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:21,483 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:21,486 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:21,508 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:22,953 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:23,685 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:23,689 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:23,694 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:23,713 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:24,142 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:24,853 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:24,856 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:24,859 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:24,876 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:24,969 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:25,680 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:25,683 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:25,686 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:25,698 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3-2a006813-f609-44fe-9fcb-309b6e384c0f-108552499976536100-1
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:508)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-28 01:28:26,327 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:26,330 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:26,332 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm1.org_1   | 2022-06-28 01:30:22,429 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:30:22,447 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:30:22,489 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42636
scm1.org_1   | 2022-06-28 01:30:22,520 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:30:24,538 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:46068
scm1.org_1   | 2022-06-28 01:30:24,543 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:30:52,345 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52958
scm1.org_1   | 2022-06-28 01:30:52,400 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:30:52,405 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38384
scm1.org_1   | 2022-06-28 01:30:52,458 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:30:52,478 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42710
scm1.org_1   | 2022-06-28 01:30:52,505 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:31:22,380 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53034
scm1.org_1   | 2022-06-28 01:31:22,412 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38460
scm1.org_1   | 2022-06-28 01:31:22,416 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:31:22,478 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:31:22,512 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42784
scm1.org_1   | 2022-06-28 01:31:22,538 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:31:24,796 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:46216
scm1.org_1   | 2022-06-28 01:31:24,799 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:31:28,370 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:34620
scm1.org_1   | 2022-06-28 01:31:28,376 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:31:52,354 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53166
scm1.org_1   | 2022-06-28 01:31:52,382 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38586
scm1.org_1   | 2022-06-28 01:31:52,401 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:31:52,447 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:31:52,481 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42914
scm1.org_1   | 2022-06-28 01:31:52,532 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:32:14,038 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm1.org_1   | 2022-06-28 01:32:17,217 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:46398
scm1.org_1   | 2022-06-28 01:32:17,223 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:32:22,372 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53254
scm1.org_1   | 2022-06-28 01:32:22,373 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38676
scm1.org_1   | 2022-06-28 01:32:22,408 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:32:22,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:32:22,503 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43006
scm1.org_1   | 2022-06-28 01:32:22,516 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:32:32,132 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59314
scm1.org_1   | 2022-06-28 01:32:32,181 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:32:32,786 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33654
scm1.org_1   | 2022-06-28 01:32:32,794 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:32:32,856 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fb66c122-66a4-4d5f-942b-9d2354169a55, Nodes: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-06-28T01:32:32.823Z[UTC]].
scm1.org_1   | 2022-06-28 01:32:36,985 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43040
scm1.org_1   | 2022-06-28 01:32:37,065 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40551
scm1.org_1   | 2022-06-28 01:32:37,078 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:32:37,091 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:32:44,984 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33686
scm1.org_1   | 2022-06-28 01:32:45,040 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:32:52,377 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53342
scm1.org_1   | 2022-06-28 01:32:52,414 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38764
scm1.org_1   | 2022-06-28 01:32:52,415 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:32:52,440 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:32:53,863 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33714
scm1.org_1   | 2022-06-28 01:32:53,912 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:33:00,483 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33736
scm1.org_1   | 2022-06-28 01:33:00,506 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:33:06,991 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43128
scm1.org_1   | 2022-06-28 01:33:07,047 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:33:08,783 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33768
scm1.org_1   | 2022-06-28 01:33:08,822 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:33:17,237 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33780
scm1.org_1   | 2022-06-28 01:33:17,273 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:33:22,370 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53436
scm1.org_1   | 2022-06-28 01:33:22,426 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38856
scm1.org_1   | 2022-06-28 01:33:22,431 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:33:22,463 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:33:26,518 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33808
scm1.org_1   | 2022-06-28 01:33:26,557 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:33:29,062 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:46620
scm1.org_1   | 2022-06-28 01:33:29,067 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-06-28 01:33:35,746 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33830
scm1.org_1   | 2022-06-28 01:33:35,795 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:33:37,021 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43214
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:26:52,364 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56152
recon_1      | 2022-06-28 01:26:52,403 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42612
recon_1      | 2022-06-28 01:26:52,433 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:26:52,454 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:26:52,505 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35556
recon_1      | 2022-06-28 01:26:52,516 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:27:22,342 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42730
recon_1      | 2022-06-28 01:27:22,382 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56266
recon_1      | 2022-06-28 01:27:22,400 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:27:22,423 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:27:22,444 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35672
recon_1      | 2022-06-28 01:27:22,454 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:27:40,649 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:27:40,649 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:27:40,704 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
scm2.org_1   | 2022-06-28 01:25:22,479 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59204
scm2.org_1   | 2022-06-28 01:25:22,529 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:25:52,362 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52270
scm2.org_1   | 2022-06-28 01:25:52,382 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42168
scm2.org_1   | 2022-06-28 01:25:52,412 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:25:52,458 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:25:52,466 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59454
scm2.org_1   | 2022-06-28 01:25:52,506 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:26:22,376 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42260
scm2.org_1   | 2022-06-28 01:26:22,411 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52372
scm2.org_1   | 2022-06-28 01:26:22,452 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:33:37,078 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:33:37,089 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41001
scm1.org_1   | 2022-06-28 01:33:37,097 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:33:44,498 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33852
scm1.org_1   | 2022-06-28 01:33:44,542 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:33:52,374 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38936
scm1.org_1   | 2022-06-28 01:33:52,387 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53516
scm1.org_1   | 2022-06-28 01:33:52,415 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:33:52,445 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:33:52,610 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33888
scm1.org_1   | 2022-06-28 01:33:52,631 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:33:52,859 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm1.org_1   | 2022-06-28 01:33:58,210 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33900
scm1.org_1   | 2022-06-28 01:33:58,261 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:34:07,011 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43302
scm1.org_1   | 2022-06-28 01:34:07,050 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:34:07,353 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33922
scm1.org_1   | 2022-06-28 01:34:07,389 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:34:22,442 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53604
scm1.org_1   | 2022-06-28 01:34:22,452 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:34:22,461 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39026
scm1.org_1   | 2022-06-28 01:34:22,474 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:34:23,570 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm1.org_1   | 2022-06-28 01:34:26,777 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33976
scm1.org_1   | 2022-06-28 01:34:26,831 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:34:37,324 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34002
scm1.org_1   | 2022-06-28 01:34:37,371 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:34:37,373 [IPC Server handler 64 on default port 9860] INFO ipc.Server: IPC Server handler 64 on default port 9860, call Call#0 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.116:34002
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1777)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getContainer(SCMClientProtocolServer.java:218)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:683)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:404)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:213)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:27:42,726 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1      | 2022-06-28 01:27:42,730 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds for processing 2 containers.
recon_1      | 2022-06-28 01:27:42,914 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-06-28 01:27:42,917 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 26 milliseconds.
recon_1      | 2022-06-28 01:27:52,372 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56378
recon_1      | 2022-06-28 01:27:52,376 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42834
recon_1      | 2022-06-28 01:27:52,390 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:27:52,395 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:27:52,461 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35784
recon_1      | 2022-06-28 01:27:52,482 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:28:22,317 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42974
om2_1        | 2022-06-28 01:28:26,355 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3-2a006813-f609-44fe-9fcb-309b6e384c0f-108552499976536100-2
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:508)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-28 01:28:26,941 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:26,944 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:26,946 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:26,953 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-5564991060/ozone-test-4234041436/multipartKey3
om2_1        | 2022-06-28 01:28:26,955 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-4234041436/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5564991060
om2_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5564991060 key: ozone-test-4234041436/multipartKey3 because parts are in Invalid order.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:474)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-28 01:28:27,577 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:27,581 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:27,585 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:28,272 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:28,275 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:28,277 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:28,328 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:29,234 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:29,237 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:29,242 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:29,894 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:29,901 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:29,907 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:30,531 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:30,534 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:30,536 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:30,555 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-3753552445/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-5564991060
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-5564991060key: ozone-test-3753552445/multipartKey5
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 2022-06-28 01:18:10,701 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$459/0x000000084052ac40@7fec6c2f] WARN util.JvmPauseMonitor: JvmPauseMonitor-966cceea-06cb-4ebe-a41c-dc5f70b815ea: Detected pause in JVM or host machine (eg GC): pause of approximately 174248176ns.
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=109ms
scm3.org_1   | 2022-06-28 01:18:10,718 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   | 2022-06-28 01:18:10,719 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2022-06-28 01:18:10,719 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-06-28 01:18:10,719 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2022-06-28 01:18:11,480 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2022-06-28 01:18:11,576 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-06-28 01:18:11,577 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2022-06-28 01:18:11,576 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2022-06-28 01:18:11,702 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:18:11,702 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2022-06-28 01:18:11,702 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2022-06-28 01:18:11,875 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:18:11,920 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:18:12,092 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-06-28 01:18:12,092 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-06-28 01:18:12,092 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2022-06-28 01:18:13,286 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 916105677270 on Scm Bootstrap Node 966cceea-06cb-4ebe-a41c-dc5f70b815ea
scm3.org_1   | 2022-06-28 01:18:13,354 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 966cceea-06cb-4ebe-a41c-dc5f70b815ea
scm3.org_1   | 2022-06-28 01:18:13,438 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6c96e1d5] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2022-06-28 01:18:13,651 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm3.org_1   | 2022-06-28 01:18:13,651 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2022-06-28 01:18:13,655 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2022-06-28 01:18:13,866 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @22022ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2022-06-28 01:18:14,804 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2022-06-28 01:18:14,904 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2022-06-28 01:18:14,906 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2022-06-28 01:18:14,906 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2022-06-28 01:18:14,906 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2022-06-28 01:18:14,971 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2022-06-28 01:18:15,372 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2022-06-28 01:18:15,398 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm3.org_1   | 2022-06-28 01:18:15,569 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2022-06-28 01:18:15,575 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2022-06-28 01:18:15,584 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm3.org_1   | 2022-06-28 01:18:15,925 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-06-28 01:18:15,986 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1aa945f6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2022-06-28 01:18:15,987 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5d852761{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2022-06-28 01:18:17,256 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-06-28 01:18:17,391 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@774c6111{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-9017787032204287699/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2022-06-28 01:18:17,441 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@6162d87c{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2022-06-28 01:18:17,441 [Listener at 0.0.0.0/9860] INFO server.Server: Started @25597ms
scm3.org_1   | 2022-06-28 01:18:17,466 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2022-06-28 01:18:17,466 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2022-06-28 01:18:17,479 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm3.org_1   | 2022-06-28 01:18:29,596 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1      | 2022-06-28 01:28:22,383 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56514
recon_1      | 2022-06-28 01:28:22,406 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:28:22,466 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35924
recon_1      | 2022-06-28 01:28:22,479 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:28:22,535 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:28:40,708 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:28:40,708 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:28:40,747 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:28:52,395 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43118
recon_1      | 2022-06-28 01:28:52,397 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56656
recon_1      | 2022-06-28 01:28:52,435 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:28:52,477 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:28:52,618 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36058
recon_1      | 2022-06-28 01:28:52,734 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:29:22,357 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43256
recon_1      | 2022-06-28 01:29:22,385 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56798
recon_1      | 2022-06-28 01:29:22,400 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:29:22,457 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:29:22,476 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36204
recon_1      | 2022-06-28 01:29:22,512 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:29:40,759 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-06-28 01:34:38,020 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43384
scm1.org_1   | 2022-06-28 01:34:38,052 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:34:45,523 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59702
scm1.org_1   | 2022-06-28 01:34:45,562 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-06-28 01:34:46,350 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34034
scm1.org_1   | 2022-06-28 01:34:46,360 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:34:46,362 [IPC Server handler 64 on default port 9860] INFO ipc.Server: IPC Server handler 64 on default port 9860, call Call#1 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.116:34034
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1777)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.allocateContainer(SCMClientProtocolServer.java:202)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.allocateContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:672)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:396)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:213)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:61195)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-06-28 01:34:53,592 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39102
scm1.org_1   | 2022-06-28 01:34:53,624 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:34:53,724 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53698
scm1.org_1   | 2022-06-28 01:34:53,741 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:34:54,832 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34062
scm1.org_1   | 2022-06-28 01:34:54,879 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:35:03,867 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34092
scm1.org_1   | 2022-06-28 01:35:03,901 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:35:08,045 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43476
scm1.org_1   | 2022-06-28 01:35:08,065 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:35:12,384 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34114
scm1.org_1   | 2022-06-28 01:35:12,428 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:35:20,690 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34126
scm1.org_1   | 2022-06-28 01:35:20,738 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:35:23,577 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39194
scm1.org_1   | 2022-06-28 01:35:23,605 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:35:23,662 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53790
scm2.org_1   | 2022-06-28 01:26:22,476 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:26:22,501 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59554
scm2.org_1   | 2022-06-28 01:26:22,504 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:26:52,349 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42374
scm2.org_1   | 2022-06-28 01:26:52,394 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:26:52,407 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52478
scm2.org_1   | 2022-06-28 01:26:52,444 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:26:52,467 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59660
scm2.org_1   | 2022-06-28 01:26:52,484 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:27:22,364 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52590
scm2.org_1   | 2022-06-28 01:27:22,398 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42492
scm2.org_1   | 2022-06-28 01:27:22,398 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:27:22,448 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59774
scm2.org_1   | 2022-06-28 01:27:22,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:18:30,350 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:18:32,878 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:18:35,149 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:18:35,856 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:18:39,191 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:18:56,563 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55876
scm3.org_1   | 2022-06-28 01:18:56,651 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:18:56,928 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47850
scm3.org_1   | 2022-06-28 01:18:56,992 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:18:58,078 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60736
scm3.org_1   | 2022-06-28 01:18:58,144 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:19:00,833 [IPC Server handler 72 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/9b5cffd6-d488-4e7f-a573-cd0e62fb49aa
scm3.org_1   | 2022-06-28 01:19:00,873 [IPC Server handler 69 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/4edc5bf0-d1a3-4fc0-a906-df67e91b4eda
scm3.org_1   | 2022-06-28 01:19:00,883 [IPC Server handler 69 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1005480937391, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-06-28 01:19:00,916 [IPC Server handler 72 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1004767615899, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-06-28 01:19:00,953 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2022-06-28 01:19:01,106 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm3.org_1   | 2022-06-28 01:19:01,105 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-06-28 01:19:01,108 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-06-28 01:19:01,738 [IPC Server handler 71 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3f49ce74-6987-463e-a960-954ebbba5f61
scm3.org_1   | 2022-06-28 01:19:01,738 [IPC Server handler 71 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1007988787146, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-06-28 01:19:01,767 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm3.org_1   | 2022-06-28 01:19:01,769 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm3.org_1   | 2022-06-28 01:19:01,769 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm3.org_1   | 2022-06-28 01:19:01,771 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-06-28 01:19:01,806 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm3.org_1   | 2022-06-28 01:19:01,807 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-06-28 01:19:01,888 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e107ff30-8061-4f60-8349-f89eb01cba86, Nodes: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:01.034Z[UTC]].
scm3.org_1   | 2022-06-28 01:19:01,906 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:19:01,927 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-06-28 01:19:02,043 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:01.898Z[UTC]].
scm3.org_1   | 2022-06-28 01:19:02,049 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:19:02,171 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e0166ad2-3c82-41e4-a01f-805995535eac, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:02.051Z[UTC]].
scm3.org_1   | 2022-06-28 01:19:02,181 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:19:02,322 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6e4f5b77-ba5a-4791-a28a-fd99b4920d70, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:02.143Z[UTC]].
scm3.org_1   | 2022-06-28 01:19:02,335 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:19:02,602 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a6bcecaa-1423-464c-8db7-4effb6cb88eb, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-06-28T01:19:02.523Z[UTC]].
scm3.org_1   | 2022-06-28 01:19:02,602 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:19:14,992 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55952
scm3.org_1   | 2022-06-28 01:19:15,049 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:19:15,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 51a7f1ac-dc16-43e5-8dfa-a67715d36ab1, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3f49ce74-6987-463e-a960-954ebbba5f61, CreationTimestamp2022-06-28T01:19:01.898Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-06-28 01:19:15,405 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm3.org_1   | 2022-06-28 01:19:16,202 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e0166ad2-3c82-41e4-a01f-805995535eac, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3f49ce74-6987-463e-a960-954ebbba5f61, CreationTimestamp2022-06-28T01:19:02.051Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-06-28 01:19:16,214 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm3.org_1   | 2022-06-28 01:19:16,214 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm3.org_1   | 2022-06-28 01:19:16,214 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm3.org_1   | 2022-06-28 01:19:16,214 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm3.org_1   | 2022-06-28 01:19:16,214 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-06-28 01:19:16,214 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2022-06-28 01:19:33,300 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55998
scm1.org_1   | 2022-06-28 01:35:23,701 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:35:29,963 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34162
scm1.org_1   | 2022-06-28 01:35:30,007 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:35:36,141 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34174
scm1.org_1   | 2022-06-28 01:35:36,156 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:35:38,041 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43562
scm1.org_1   | 2022-06-28 01:35:38,072 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:35:44,277 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34196
scm1.org_1   | 2022-06-28 01:35:44,295 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:35:52,575 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34216
scm1.org_1   | 2022-06-28 01:35:52,607 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:35:53,593 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39274
scm1.org_1   | 2022-06-28 01:35:53,620 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:35:53,720 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53870
scm1.org_1   | 2022-06-28 01:35:53,758 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:36:01,069 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34254
scm1.org_1   | 2022-06-28 01:36:01,091 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:36:08,053 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43648
scm1.org_1   | 2022-06-28 01:36:08,080 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:36:15,102 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34286
scm1.org_1   | 2022-06-28 01:36:15,164 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:36:15,185 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: cce2d13c-a15c-4bdc-8da6-fb42765e8240, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-06-28T01:36:15.165Z[UTC]].
scm1.org_1   | 2022-06-28 01:36:23,384 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34306
scm1.org_1   | 2022-06-28 01:36:23,433 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:36:23,560 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39364
scm1.org_1   | 2022-06-28 01:36:23,602 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:36:23,704 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53960
scm1.org_1   | 2022-06-28 01:36:23,725 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:36:32,308 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34334
scm1.org_1   | 2022-06-28 01:36:32,354 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:36:38,026 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43724
scm1.org_1   | 2022-06-28 01:36:38,071 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:36:40,347 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34362
scm1.org_1   | 2022-06-28 01:36:40,369 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:36:48,488 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34376
scm2.org_1   | 2022-06-28 01:27:22,463 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:27:40,137 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-06-28 01:27:52,374 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42600
scm2.org_1   | 2022-06-28 01:27:52,378 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52702
scm2.org_1   | 2022-06-28 01:27:52,408 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:27:52,457 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59888
scm2.org_1   | 2022-06-28 01:27:52,459 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:27:52,493 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:28:22,382 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42740
scm2.org_1   | 2022-06-28 01:28:22,389 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52840
scm2.org_1   | 2022-06-28 01:28:22,408 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:28:22,479 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:28:22,495 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60028
scm2.org_1   | 2022-06-28 01:28:22,536 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:28:52,382 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52988
scm2.org_1   | 2022-06-28 01:28:52,512 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:28:52,565 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42894
scm2.org_1   | 2022-06-28 01:28:52,631 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60166
scm2.org_1   | 2022-06-28 01:28:52,656 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:28:52,699 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:29:22,375 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53122
scm2.org_1   | 2022-06-28 01:29:22,395 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43020
scm2.org_1   | 2022-06-28 01:29:22,398 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:29:22,452 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60308
scm3.org_1   | 2022-06-28 01:19:33,333 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:19:33,335 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e107ff30-8061-4f60-8349-f89eb01cba86, Nodes: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9b5cffd6-d488-4e7f-a573-cd0e62fb49aa, CreationTimestamp2022-06-28T01:19:01.034Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-06-28 01:19:33,856 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47978
scm3.org_1   | 2022-06-28 01:19:33,915 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:19:51,527 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60902
scm3.org_1   | 2022-06-28 01:19:51,547 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:19:56,729 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm3.org_1   | 2022-06-28 01:20:01,043 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48078
scm3.org_1   | 2022-06-28 01:20:01,127 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:20:01,213 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56120
scm3.org_1   | 2022-06-28 01:20:01,265 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:20:02,916 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6e4f5b77-ba5a-4791-a28a-fd99b4920d70, Nodes: 4edc5bf0-d1a3-4fc0-a906-df67e91b4eda{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:4edc5bf0-d1a3-4fc0-a906-df67e91b4eda, CreationTimestamp2022-06-28T01:19:02.143Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-06-28 01:20:22,388 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48150
scm3.org_1   | 2022-06-28 01:20:22,446 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32806
scm3.org_1   | 2022-06-28 01:20:22,462 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:20:22,610 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:20:22,621 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56200
scm3.org_1   | 2022-06-28 01:20:22,724 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:20:52,390 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48252
scm3.org_1   | 2022-06-28 01:20:52,486 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56298
scm3.org_1   | 2022-06-28 01:20:52,495 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:20:52,553 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32904
scm3.org_1   | 2022-06-28 01:20:52,583 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:20:52,673 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:21:22,391 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33004
scm3.org_1   | 2022-06-28 01:21:22,403 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48354
scm3.org_1   | 2022-06-28 01:21:22,479 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:21:22,495 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56402
scm3.org_1   | 2022-06-28 01:21:22,541 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:21:22,551 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:21:52,406 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48462
scm3.org_1   | 2022-06-28 01:21:52,450 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33110
scm3.org_1   | 2022-06-28 01:21:52,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:21:52,487 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56510
scm3.org_1   | 2022-06-28 01:21:52,495 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:21:52,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:22:22,414 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33236
scm3.org_1   | 2022-06-28 01:22:22,468 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:22:22,471 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48580
scm3.org_1   | 2022-06-28 01:22:22,492 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56632
scm3.org_1   | 2022-06-28 01:22:22,514 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:22:22,545 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:22:52,390 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48686
scm3.org_1   | 2022-06-28 01:22:52,401 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33338
scm3.org_1   | 2022-06-28 01:22:52,430 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:22:52,450 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56734
scm3.org_1   | 2022-06-28 01:22:52,461 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:22:52,512 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:22:57,863 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-06-28 01:23:22,346 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48802
scm3.org_1   | 2022-06-28 01:23:22,380 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33448
scm3.org_1   | 2022-06-28 01:23:22,396 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:23:22,490 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:23:22,496 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56850
scm3.org_1   | 2022-06-28 01:23:22,521 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:23:52,363 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48904
scm3.org_1   | 2022-06-28 01:23:52,405 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33554
scm3.org_1   | 2022-06-28 01:23:52,463 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:23:52,518 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:23:52,534 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56948
scm3.org_1   | 2022-06-28 01:23:52,539 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:24:22,388 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49024
scm3.org_1   | 2022-06-28 01:24:22,424 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:24:22,450 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33674
scm3.org_1   | 2022-06-28 01:24:22,478 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:24:22,504 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57072
scm3.org_1   | 2022-06-28 01:24:22,541 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:24:52,354 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49126
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-28 01:28:31,190 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:31,196 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:31,199 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:31,208 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-5564991060, Key:ozone-test-0179098423/multipartKey. 
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:758)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:645)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:622)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:282)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-06-28 01:28:31,868 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:31,871 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:31,874 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:32,631 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:32,634 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:32,636 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:32,656 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:35,499 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:36,213 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:36,215 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:36,218 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:36,230 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:38,009 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:38,712 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:38,719 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:38,724 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:39,480 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:39,483 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:39,486 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:40,176 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:40,178 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:40,183 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:40,730 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39445
om2_1        | 2022-06-28 01:28:40,734 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:28:40,861 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:40,864 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:40,868 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,684 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,693 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,699 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,791 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,794 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,799 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,832 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,835 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,840 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,846 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,862 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,872 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,906 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,913 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:41,995 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:43,136 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:43,236 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:45,756 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:45,797 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:45,801 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:45,806 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,473 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,484 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,489 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,518 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,523 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,525 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,526 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,528 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,534 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,535 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,534 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,545 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,616 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,646 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:46,647 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:48,200 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:48,205 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:48,211 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:48,230 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:49,200 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:49,205 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:49,209 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:50,565 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:51,265 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:51,267 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:51,270 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:51,962 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:51,966 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:24:52,387 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33772
scm3.org_1   | 2022-06-28 01:24:52,390 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:24:52,468 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:24:52,475 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57170
scm3.org_1   | 2022-06-28 01:24:52,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:25:22,384 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49244
scm3.org_1   | 2022-06-28 01:25:22,396 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:25:22,401 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33894
scm3.org_1   | 2022-06-28 01:25:22,480 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:25:22,504 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57284
scm3.org_1   | 2022-06-28 01:25:22,532 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:25:52,365 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49490
scm3.org_1   | 2022-06-28 01:25:52,398 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34140
scm3.org_1   | 2022-06-28 01:25:52,444 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:25:52,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:25:52,465 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57534
scm3.org_1   | 2022-06-28 01:25:52,517 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:26:22,401 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49584
scm3.org_1   | 2022-06-28 01:26:22,451 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34230
scm3.org_1   | 2022-06-28 01:26:22,464 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:26:22,490 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:26:22,541 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57634
scm3.org_1   | 2022-06-28 01:26:22,598 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:26:52,389 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34344
scm3.org_1   | 2022-06-28 01:26:52,405 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49696
scm3.org_1   | 2022-06-28 01:26:52,433 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:26:52,457 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:26:52,497 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57746
scm3.org_1   | 2022-06-28 01:26:52,524 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:27:22,343 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49810
scm3.org_1   | 2022-06-28 01:27:22,390 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34460
scm3.org_1   | 2022-06-28 01:27:22,400 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:27:22,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57862
scm3.org_1   | 2022-06-28 01:27:22,457 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:27:22,467 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:27:52,383 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34572
scm3.org_1   | 2022-06-28 01:27:52,392 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49926
scm3.org_1   | 2022-06-28 01:27:52,445 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:36:48,544 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:36:53,612 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39444
scm1.org_1   | 2022-06-28 01:36:53,645 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:36:53,684 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54040
scm1.org_1   | 2022-06-28 01:36:53,710 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:36:55,071 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34404
scm1.org_1   | 2022-06-28 01:36:55,087 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:37:02,014 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34426
scm1.org_1   | 2022-06-28 01:37:02,048 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:37:08,038 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43820
scm1.org_1   | 2022-06-28 01:37:08,063 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:37:09,945 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34458
scm1.org_1   | 2022-06-28 01:37:09,985 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:37:10,003 [IPC Server handler 71 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: cce2d13c-a15c-4bdc-8da6-fb42765e8240, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-06-28T01:36:15.165Z[UTC]] moved to CLOSED state
scm1.org_1   | 2022-06-28 01:37:13,893 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=cce2d13c-a15c-4bdc-8da6-fb42765e8240 since it stays at CLOSED stage.
scm1.org_1   | 2022-06-28 01:37:13,941 [45e35def-6cad-44ae-bb26-f31c46277acf@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: cce2d13c-a15c-4bdc-8da6-fb42765e8240, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-06-28T01:36:15.165Z[UTC]] removed.
scm1.org_1   | 2022-06-28 01:37:14,055 [ReplicationMonitor] INFO replication.LegacyReplicationManager: Sending close container command for container #1 to datanode 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
scm1.org_1   | 2022-06-28 01:37:14,069 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 30 milliseconds for processing 3 containers.
scm1.org_1   | 2022-06-28 01:37:17,429 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34470
scm1.org_1   | 2022-06-28 01:37:17,465 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:37:23,579 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39540
scm1.org_1   | 2022-06-28 01:37:23,603 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:37:23,692 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54134
scm1.org_1   | 2022-06-28 01:37:23,698 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:37:30,782 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34508
scm1.org_1   | 2022-06-28 01:37:30,832 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:37:36,541 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34520
scm1.org_1   | 2022-06-28 01:37:36,584 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:37:37,997 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43900
scm1.org_1   | 2022-06-28 01:37:38,016 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:37:42,989 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42347
scm1.org_1   | 2022-06-28 01:37:43,000 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om2_1        | 2022-06-28 01:28:51,968 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:51,983 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:51,987 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:51,994 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:52,009 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:52,012 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:52,015 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:52,063 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:53,067 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:53,844 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:53,847 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:53,849 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:54,508 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:54,511 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:54,517 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:54,531 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:55,561 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:55,563 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:55,569 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:56,151 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:56,823 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:56,826 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:56,832 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:57,550 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:57,553 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:57,556 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:57,568 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:57,572 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:57,577 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:57,596 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:57,599 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:57,601 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:28:57,677 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:00,697 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:01,401 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:01,404 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:01,407 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:01,429 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:01,433 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:01,435 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:01,444 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:01,446 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:01,448 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:01,483 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:01,570 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm1.org_1   | 2022-06-28 01:37:45,858 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34552
scm1.org_1   | 2022-06-28 01:37:45,865 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:37:45,866 [IPC Server handler 6 on default port 9860] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
scm1.org_1   | 2022-06-28 01:37:45,873 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
scm1.org_1   | 2022-06-28 01:37:52,123 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34566
scm1.org_1   | 2022-06-28 01:37:52,138 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:37:53,586 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39624
scm1.org_1   | 2022-06-28 01:37:53,628 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:37:53,685 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54222
scm1.org_1   | 2022-06-28 01:37:53,705 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:38:00,357 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34606
scm1.org_1   | 2022-06-28 01:38:00,364 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:38:00,366 [IPC Server handler 17 on default port 9860] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2022-06-28 01:38:00,409 [ReplicationMonitor] INFO replication.LegacyReplicationManager: Sending close container command for container #1 to datanode 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
scm1.org_1   | 2022-06-28 01:38:00,433 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 26 milliseconds for processing 3 containers.
scm1.org_1   | 2022-06-28 01:38:07,957 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34620
scm1.org_1   | 2022-06-28 01:38:07,994 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:38:08,058 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44000
scm1.org_1   | 2022-06-28 01:38:08,081 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:38:21,550 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34652
scm1.org_1   | 2022-06-28 01:38:21,589 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:38:23,595 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39720
scm1.org_1   | 2022-06-28 01:38:23,611 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:38:23,683 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54316
scm1.org_1   | 2022-06-28 01:38:23,728 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:38:27,624 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34680
scm1.org_1   | 2022-06-28 01:38:27,669 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:38:33,093 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34692
scm1.org_1   | 2022-06-28 01:38:33,134 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:38:38,031 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44082
scm1.org_1   | 2022-06-28 01:38:38,067 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:38:45,944 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34732
scm1.org_1   | 2022-06-28 01:38:45,996 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-06-28 01:38:53,604 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39798
scm1.org_1   | 2022-06-28 01:38:53,656 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:38:53,678 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54396
scm1.org_1   | 2022-06-28 01:38:53,710 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-06-28 01:29:40,759 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:29:40,818 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
om2_1        | 2022-06-28 01:29:02,312 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:02,314 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:02,317 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:02,972 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:02,974 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:02,976 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:02,987 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:04,215 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:04,221 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:04,229 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:05,706 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:06,422 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:06,426 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:06,429 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:07,129 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:07,133 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:07,135 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:08,557 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:08,560 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:08,563 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:08,584 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:08,586 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:08,588 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:08,612 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:09,288 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:09,292 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:09,294 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:09,316 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:09,325 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:09,327 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:09,340 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:09,983 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:09,985 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:09,988 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:10,009 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:10,013 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:10,015 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:10,024 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:10,026 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:10,028 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:10,061 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:10,710 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:11,451 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:11,456 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:11,459 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:29:22,454 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:29:22,510 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:29:52,350 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53266
scm2.org_1   | 2022-06-28 01:29:52,378 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43164
scm2.org_1   | 2022-06-28 01:29:52,407 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:29:52,421 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:29:52,461 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60452
scm2.org_1   | 2022-06-28 01:29:52,537 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:30:22,353 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43278
scm2.org_1   | 2022-06-28 01:30:22,368 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:30:22,376 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53378
scm2.org_1   | 2022-06-28 01:30:22,410 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:30:22,451 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60566
scm2.org_1   | 2022-06-28 01:30:22,481 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:30:52,363 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53452
scm2.org_1   | 2022-06-28 01:30:52,386 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43350
scm2.org_1   | 2022-06-28 01:30:52,400 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:30:52,458 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:30:52,484 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60634
scm2.org_1   | 2022-06-28 01:30:52,506 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:31:22,373 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53526
scm2.org_1   | 2022-06-28 01:31:22,394 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:31:22,429 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43422
scm2.org_1   | 2022-06-28 01:31:22,471 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60714
scm2.org_1   | 2022-06-28 01:31:22,488 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:31:22,532 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:31:52,353 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53658
scm2.org_1   | 2022-06-28 01:31:52,376 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43556
scm2.org_1   | 2022-06-28 01:31:52,378 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:31:52,434 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:31:52,480 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60846
scm2.org_1   | 2022-06-28 01:31:52,523 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:32:22,352 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53750
scm2.org_1   | 2022-06-28 01:32:22,368 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43642
scm2.org_1   | 2022-06-28 01:32:22,401 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:32:22,454 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60934
scm2.org_1   | 2022-06-28 01:32:22,472 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:32:22,499 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:32:32,860 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fb66c122-66a4-4d5f-942b-9d2354169a55, Nodes: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-06-28T01:32:32.823Z[UTC]].
scm2.org_1   | 2022-06-28 01:32:36,975 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60968
scm2.org_1   | 2022-06-28 01:32:37,067 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:32:40,138 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-06-28 01:32:52,368 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53836
scm2.org_1   | 2022-06-28 01:32:52,404 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43736
scm2.org_1   | 2022-06-28 01:32:52,405 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:32:52,446 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:33:07,008 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:32824
scm2.org_1   | 2022-06-28 01:33:07,042 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:33:22,379 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53930
scm2.org_1   | 2022-06-28 01:33:22,407 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43826
scm2.org_1   | 2022-06-28 01:33:22,427 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:33:22,459 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:33:36,984 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:32906
scm2.org_1   | 2022-06-28 01:33:37,028 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:33:52,368 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54010
scm2.org_1   | 2022-06-28 01:33:52,385 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43906
scm2.org_1   | 2022-06-28 01:33:52,405 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:33:52,449 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:34:06,994 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:32998
scm2.org_1   | 2022-06-28 01:34:07,026 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:34:22,345 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54098
scm2.org_1   | 2022-06-28 01:34:22,406 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43998
scm2.org_1   | 2022-06-28 01:34:22,410 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:34:22,423 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:34:23,557 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm2.org_1   | 2022-06-28 01:34:23,569 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 1
scm2.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B is not the leader 45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:696)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:661)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:800)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$12(RaftServerImpl.java:783)
scm2.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
scm3.org_1   | 2022-06-28 01:27:52,464 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57968
scm1.org_1   | 2022-06-28 01:39:08,051 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:44164
om2_1        | 2022-06-28 01:29:11,477 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$13(RaftServerImpl.java:783)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
scm3.org_1   | 2022-06-28 01:27:52,473 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-06-28 01:39:08,081 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:11,481 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
scm3.org_1   | 2022-06-28 01:27:52,495 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
scm3.org_1   | 2022-06-28 01:27:57,864 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om2_1        | 2022-06-28 01:29:11,483 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
om2_1        | 2022-06-28 01:29:11,496 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
om2_1        | 2022-06-28 01:29:11,498 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
scm3.org_1   | 2022-06-28 01:28:22,354 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34716
scm2.org_1   | 2022-06-28 01:34:38,011 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33080
om2_1        | 2022-06-28 01:29:11,500 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
scm3.org_1   | 2022-06-28 01:28:22,362 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50064
scm2.org_1   | 2022-06-28 01:34:38,046 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:11,537 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	... 35 more
scm3.org_1   | 2022-06-28 01:28:22,409 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:34:53,587 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44076
om2_1        | 2022-06-28 01:29:11,729 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:29:52,352 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43404
scm3.org_1   | 2022-06-28 01:28:22,479 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:34:53,616 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:12,439 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:29:52,398 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56938
scm3.org_1   | 2022-06-28 01:28:22,522 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58108
scm2.org_1   | 2022-06-28 01:34:53,678 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54192
om2_1        | 2022-06-28 01:29:12,441 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:29:52,407 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-06-28 01:28:22,539 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:34:53,710 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:12,444 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:29:52,455 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-06-28 01:28:52,379 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50208
scm2.org_1   | 2022-06-28 01:35:08,026 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33174
om2_1        | 2022-06-28 01:29:12,457 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:29:52,471 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36348
scm3.org_1   | 2022-06-28 01:28:52,475 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:35:08,053 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:35:23,602 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44166
recon_1      | 2022-06-28 01:29:52,538 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-06-28 01:28:52,549 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34866
om2_1        | 2022-06-28 01:29:12,458 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:35:23,623 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-06-28 01:30:22,334 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43516
scm3.org_1   | 2022-06-28 01:28:52,614 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:12,460 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:35:23,673 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54284
recon_1      | 2022-06-28 01:30:22,378 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57050
scm3.org_1   | 2022-06-28 01:28:52,624 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58250
om2_1        | 2022-06-28 01:29:12,486 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:12,488 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:30:22,391 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-06-28 01:28:52,727 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:35:23,705 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:12,490 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:30:22,396 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-06-28 01:29:22,342 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50346
scm2.org_1   | 2022-06-28 01:35:38,038 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33252
om2_1        | 2022-06-28 01:29:12,514 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:30:22,452 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36458
scm3.org_1   | 2022-06-28 01:29:22,374 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34990
scm2.org_1   | 2022-06-28 01:35:38,069 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:13,213 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:30:22,473 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-06-28 01:29:22,386 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:35:53,590 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44246
om2_1        | 2022-06-28 01:29:13,908 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:30:40,824 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm3.org_1   | 2022-06-28 01:29:22,439 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58386
scm2.org_1   | 2022-06-28 01:35:53,608 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:13,912 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:30:40,824 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
scm3.org_1   | 2022-06-28 01:29:22,468 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:35:53,698 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54364
om2_1        | 2022-06-28 01:29:13,914 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:30:40,863 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
scm3.org_1   | 2022-06-28 01:29:22,512 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:35:53,757 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:36:08,056 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33338
recon_1      | java.lang.reflect.UndeclaredThrowableException
scm3.org_1   | 2022-06-28 01:29:52,349 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50486
om2_1        | 2022-06-28 01:29:14,567 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:36:08,080 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
scm3.org_1   | 2022-06-28 01:29:52,352 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35134
om2_1        | 2022-06-28 01:29:14,569 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:36:15,189 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: cce2d13c-a15c-4bdc-8da6-fb42765e8240, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-06-28T01:36:15.165Z[UTC]].
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
scm3.org_1   | 2022-06-28 01:29:52,370 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:14,572 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:36:23,611 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44334
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 2022-06-28 01:36:23,625 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:36:23,671 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54456
scm2.org_1   | 2022-06-28 01:36:23,687 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:36:38,017 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33424
scm3.org_1   | 2022-06-28 01:29:52,378 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:14,585 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:36:38,055 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm3.org_1   | 2022-06-28 01:29:52,472 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58532
om2_1        | 2022-06-28 01:29:15,589 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:36:53,605 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44418
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
scm3.org_1   | 2022-06-28 01:29:52,538 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:15,608 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:36:53,627 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
scm3.org_1   | 2022-06-28 01:30:22,373 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50598
om2_1        | 2022-06-28 01:29:15,612 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:36:53,660 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54536
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
scm3.org_1   | 2022-06-28 01:30:22,399 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:16,324 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:36:53,678 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
scm3.org_1   | 2022-06-28 01:30:22,404 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35246
om2_1        | 2022-06-28 01:29:16,328 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:37:08,035 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33518
scm3.org_1   | 2022-06-28 01:30:22,415 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:16,330 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:37:08,045 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm3.org_1   | 2022-06-28 01:30:22,488 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58642
om2_1        | 2022-06-28 01:29:17,034 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:37:13,927 [c7ed5937-0e47-4abb-91f6-068d38a4ec09@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: cce2d13c-a15c-4bdc-8da6-fb42765e8240, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-06-28T01:36:15.165Z[UTC]] removed.
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
om2_1        | 2022-06-28 01:29:17,036 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
scm2.org_1   | 2022-06-28 01:37:23,603 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44506
om2_1        | 2022-06-28 01:29:17,043 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:30:22,511 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
scm2.org_1   | 2022-06-28 01:37:23,618 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:21,021 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49318
scm3.org_1   | 2022-06-28 01:30:52,350 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50676
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
scm2.org_1   | 2022-06-28 01:37:23,654 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54630
om2_1        | 2022-06-28 01:29:21,034 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2022-06-28 01:30:52,392 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
scm2.org_1   | 2022-06-28 01:37:23,678 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:24,692 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:30:52,413 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35320
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 2022-06-28 01:37:38,015 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33598
om2_1        | 2022-06-28 01:29:24,697 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:30:52,453 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58722
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om2_1        | 2022-06-28 01:29:24,718 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8289378492 of layout LEGACY in volume: s3v
recon_1      | 	... 12 more
scm2.org_1   | 2022-06-28 01:37:38,044 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:30:52,462 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:25,373 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
scm2.org_1   | 2022-06-28 01:37:40,139 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-06-28 01:37:44,496 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37588
om2_1        | 2022-06-28 01:29:25,378 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
scm2.org_1   | 2022-06-28 01:37:44,527 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2022-06-28 01:30:52,500 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:25,386 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-60493 of layout LEGACY in volume: s3v
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
scm2.org_1   | 2022-06-28 01:37:45,340 [IPC Server handler 78 on default port 9860] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
scm3.org_1   | 2022-06-28 01:31:22,337 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50752
om2_1        | 2022-06-28 01:29:26,049 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	... 19 more
scm3.org_1   | 2022-06-28 01:31:22,358 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:26,055 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
scm3.org_1   | 2022-06-28 01:31:22,449 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35400
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
scm2.org_1   | 2022-06-28 01:37:45,344 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
scm2.org_1   | 2022-06-28 01:37:53,580 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44596
scm3.org_1   | 2022-06-28 01:31:22,488 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:37:53,630 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:26,068 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
scm3.org_1   | 2022-06-28 01:31:22,509 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58798
scm2.org_1   | 2022-06-28 01:37:53,695 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54718
om2_1        | 2022-06-28 01:29:26,207 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
scm3.org_1   | 2022-06-28 01:31:22,537 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:37:53,723 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:26,850 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:26,853 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:26,855 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm2.org_1   | 2022-06-28 01:37:59,922 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37650
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
om2_1        | 2022-06-28 01:29:26,858 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:31:52,358 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50882
scm2.org_1   | 2022-06-28 01:37:59,960 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om2_1        | 2022-06-28 01:29:27,483 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:31:52,400 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:37:59,961 [IPC Server handler 15 on default port 9860] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om2_1        | 2022-06-28 01:29:27,485 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:31:52,414 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35526
scm3.org_1   | 2022-06-28 01:31:52,457 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:37:59,978 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-06-28 01:38:08,034 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33698
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
scm3.org_1   | 2022-06-28 01:31:52,483 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58926
scm2.org_1   | 2022-06-28 01:38:08,052 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:38:23,592 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44690
recon_1      | 	... 20 more
scm3.org_1   | 2022-06-28 01:31:52,532 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:38:23,614 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:27,487 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
scm3.org_1   | 2022-06-28 01:32:22,351 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50968
scm2.org_1   | 2022-06-28 01:38:23,703 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54810
om2_1        | 2022-06-28 01:29:27,494 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
scm3.org_1   | 2022-06-28 01:32:22,363 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35620
scm2.org_1   | 2022-06-28 01:38:23,733 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:27,496 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
scm3.org_1   | 2022-06-28 01:32:22,397 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:38:38,027 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33782
om2_1        | 2022-06-28 01:29:27,520 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
scm3.org_1   | 2022-06-28 01:32:22,449 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:38:38,075 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:27,541 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
scm3.org_1   | 2022-06-28 01:32:22,500 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59012
scm2.org_1   | 2022-06-28 01:38:53,655 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44770
om2_1        | 2022-06-28 01:29:27,676 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
scm3.org_1   | 2022-06-28 01:32:22,512 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:38:53,696 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:27,696 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
scm3.org_1   | 2022-06-28 01:32:32,876 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fb66c122-66a4-4d5f-942b-9d2354169a55, Nodes: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-06-28T01:32:32.823Z[UTC]].
scm2.org_1   | 2022-06-28 01:38:53,705 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54890
om2_1        | 2022-06-28 01:29:28,359 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
scm3.org_1   | 2022-06-28 01:32:37,007 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59044
scm2.org_1   | 2022-06-28 01:38:53,717 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:28,362 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
scm3.org_1   | 2022-06-28 01:32:37,078 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-06-28 01:39:08,054 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33862
scm2.org_1   | 2022-06-28 01:39:08,082 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
scm3.org_1   | 2022-06-28 01:32:52,362 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51056
om2_1        | 2022-06-28 01:29:28,364 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
om2_1        | 2022-06-28 01:29:28,366 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:32:52,406 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:29,033 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:29,037 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:30:52,327 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43586
scm3.org_1   | 2022-06-28 01:32:52,411 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35704
scm3.org_1   | 2022-06-28 01:32:52,441 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:32:57,864 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-06-28 01:33:06,973 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59142
scm3.org_1   | 2022-06-28 01:33:07,042 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:29,042 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:29,044 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:30:52,375 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:30:52,379 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57124
recon_1      | 2022-06-28 01:30:52,457 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36532
recon_1      | 2022-06-28 01:30:52,458 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:30:52,497 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:31:22,336 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43664
om2_1        | 2022-06-28 01:29:29,046 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:33:22,367 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51154
scm3.org_1   | 2022-06-28 01:33:22,393 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35802
scm3.org_1   | 2022-06-28 01:33:22,427 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:33:22,441 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:33:37,017 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59224
om2_1        | 2022-06-28 01:29:29,077 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:29,090 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:29,189 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:29,216 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:29,869 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:29,871 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:29,873 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:31:22,357 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-06-28 01:33:37,041 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:33:52,363 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51234
scm3.org_1   | 2022-06-28 01:33:52,382 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:33:52,395 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35884
scm3.org_1   | 2022-06-28 01:33:52,443 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:34:06,996 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59316
scm3.org_1   | 2022-06-28 01:34:07,044 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:34:22,412 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35966
scm3.org_1   | 2022-06-28 01:34:22,418 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51318
recon_1      | 2022-06-28 01:31:22,446 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36606
recon_1      | 2022-06-28 01:31:22,498 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57200
recon_1      | 2022-06-28 01:31:22,524 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:31:22,526 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:31:40,867 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:31:40,867 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:31:40,910 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
om2_1        | 2022-06-28 01:29:29,875 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:30,514 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:30,516 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:31,135 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:31,138 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:31,144 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:31,151 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | java.lang.reflect.UndeclaredThrowableException
scm3.org_1   | 2022-06-28 01:34:22,422 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:34:22,432 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
om2_1        | 2022-06-28 01:29:31,819 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:31,822 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:32,431 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:32,434 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:32,436 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:32,438 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:32,440 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:34:23,553 [FixedThreadPoolWithAffinityExecutor-1-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm3.org_1   | 2022-06-28 01:34:23,566 [FixedThreadPoolWithAffinityExecutor-1-0] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 1
scm3.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B is not the leader 45e35def-6cad-44ae-bb26-f31c46277acf|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:696)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:661)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:800)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$12(RaftServerImpl.java:783)
scm3.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
om2_1        | 2022-06-28 01:29:36,206 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49396
om2_1        | 2022-06-28 01:29:36,211 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:29:39,627 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$13(RaftServerImpl.java:783)
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 2022-06-28 01:29:39,635 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:39,650 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4399908439 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:29:40,286 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:40,291 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm3.org_1   | 2022-06-28 01:34:38,012 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59390
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
om2_1        | 2022-06-28 01:29:40,293 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:40,753 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:40,786 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37779
om2_1        | 2022-06-28 01:29:40,799 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2022-06-28 01:34:38,046 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:34:53,589 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36046
scm3.org_1   | 2022-06-28 01:34:53,617 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:34:53,674 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51416
scm3.org_1   | 2022-06-28 01:34:53,689 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:35:08,013 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59482
scm3.org_1   | 2022-06-28 01:35:08,038 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
om2_1        | 2022-06-28 01:29:41,470 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:41,472 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:41,473 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:41,476 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:42,161 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:42,165 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:42,167 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:42,187 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:42,874 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm3.org_1   | 2022-06-28 01:35:23,596 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36138
scm3.org_1   | 2022-06-28 01:35:23,615 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:35:23,677 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51508
scm3.org_1   | 2022-06-28 01:35:23,702 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:35:38,003 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59564
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
om2_1        | 2022-06-28 01:29:42,876 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:42,878 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:43,528 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:43,531 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:43,533 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:35:38,062 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:35:53,577 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36218
scm3.org_1   | 2022-06-28 01:35:53,595 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:35:53,694 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51588
scm3.org_1   | 2022-06-28 01:35:53,739 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
om2_1        | 2022-06-28 01:29:44,174 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:44,176 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:44,179 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
om2_1        | 2022-06-28 01:29:44,789 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:44,791 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:44,793 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:45,483 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:45,485 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:36:08,052 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59658
scm3.org_1   | 2022-06-28 01:36:08,080 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:36:15,191 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: cce2d13c-a15c-4bdc-8da6-fb42765e8240, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-06-28T01:36:15.165Z[UTC]].
scm3.org_1   | 2022-06-28 01:36:23,581 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36312
scm3.org_1   | 2022-06-28 01:36:23,612 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:36:23,680 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51674
scm3.org_1   | 2022-06-28 01:36:23,713 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:45,488 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
scm3.org_1   | 2022-06-28 01:36:38,008 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59734
scm3.org_1   | 2022-06-28 01:36:38,039 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:36:53,584 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36388
scm3.org_1   | 2022-06-28 01:36:53,614 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:36:53,669 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51754
scm3.org_1   | 2022-06-28 01:36:53,680 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:37:08,020 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59826
om2_1        | 2022-06-28 01:29:45,580 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:46,472 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:46,474 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:46,476 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:46,482 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
om2_1        | 2022-06-28 01:29:47,090 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:47,093 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
scm3.org_1   | 2022-06-28 01:37:08,044 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:47,095 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:47,717 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:47,720 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:37:13,931 [966cceea-06cb-4ebe-a41c-dc5f70b815ea@group-0A2F691DD86B-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: cce2d13c-a15c-4bdc-8da6-fb42765e8240, Nodes: 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-06-28T01:36:15.165Z[UTC]] removed.
scm3.org_1   | 2022-06-28 01:37:23,576 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36484
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
om2_1        | 2022-06-28 01:29:47,722 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:47,726 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:48,434 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:48,437 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:48,449 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:37:23,598 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:37:23,664 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51850
scm3.org_1   | 2022-06-28 01:37:23,686 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-06-28 01:37:38,030 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59914
scm3.org_1   | 2022-06-28 01:37:38,060 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:29:48,461 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:49,510 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:49,513 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:49,517 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:49,698 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:37:45,930 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60208
scm3.org_1   | 2022-06-28 01:37:45,952 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2022-06-28 01:37:46,627 [IPC Server handler 54 on default port 9860] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
scm3.org_1   | 2022-06-28 01:37:46,630 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
scm3.org_1   | 2022-06-28 01:37:53,580 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36572
scm3.org_1   | 2022-06-28 01:37:53,620 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:31:52,363 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43790
recon_1      | 2022-06-28 01:31:52,387 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57334
recon_1      | 2022-06-28 01:31:52,399 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:31:52,452 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:31:52,485 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36736
recon_1      | 2022-06-28 01:31:52,531 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:32:22,350 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43884
recon_1      | 2022-06-28 01:32:22,382 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57424
recon_1      | 2022-06-28 01:32:22,396 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-06-28 01:29:50,547 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:50,550 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:50,552 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:50,556 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:51,436 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:51,439 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:51,441 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:52,598 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:52,601 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:52,602 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:52,605 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:53,244 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:53,247 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:53,248 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:53,259 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:53,937 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:29:53,939 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:30:01,012 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49516
om2_1        | 2022-06-28 01:30:01,022 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:30:06,093 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:46251
om2_1        | 2022-06-28 01:30:06,101 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:30:06,102 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:30:06,109 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:30:06,120 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1615782415 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:30:06,952 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:30:06,955 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:30:06,958 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:30:07,138 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:30:07,968 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:30:07,971 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:30:07,976 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:30:08,074 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:30:08,855 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:30:08,857 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:37:53,694 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51938
scm3.org_1   | 2022-06-28 01:37:53,724 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:30:08,860 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:38:00,423 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60262
scm3.org_1   | 2022-06-28 01:38:00,440 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2022-06-28 01:38:00,441 [IPC Server handler 54 on default port 9860] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-06-28 01:38:00,446 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-06-28 01:38:08,004 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60014
om2_1        | 2022-06-28 01:30:08,956 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:32:22,464 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-06-28 01:30:09,704 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:38:08,050 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-06-28 01:32:22,469 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36830
om2_1        | 2022-06-28 01:30:09,707 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:38:23,595 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36668
recon_1      | 2022-06-28 01:32:22,505 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-06-28 01:30:09,708 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:38:23,608 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-06-28 01:32:36,994 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36858
om2_1        | 2022-06-28 01:30:09,711 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:38:23,650 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52030
recon_1      | 2022-06-28 01:32:37,051 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-06-28 01:30:10,459 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:38:23,664 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-06-28 01:32:37,052 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: New container #3 got from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net.
om2_1        | 2022-06-28 01:30:10,462 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:38:38,008 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60094
recon_1      | 2022-06-28 01:32:37,088 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconContainerManager: Pipeline PipelineID=fb66c122-66a4-4d5f-942b-9d2354169a55 not found. Cannot add container #3
om2_1        | 2022-06-28 01:30:10,465 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
scm3.org_1   | 2022-06-28 01:38:38,085 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-06-28 01:32:37,090 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] WARN scm.ReconIncrementalContainerReportHandler: Container 3 not found!
recon_1      | 2022-06-28 01:32:40,911 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:32:40,911 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:32:40,961 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
scm3.org_1   | 2022-06-28 01:38:53,602 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36746
om2_1        | 2022-06-28 01:30:10,496 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
scm3.org_1   | 2022-06-28 01:38:53,657 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-06-28 01:30:10,521 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
scm3.org_1   | 2022-06-28 01:38:53,703 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52106
om2_1        | 2022-06-28 01:30:10,534 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1615782415, Key:ozone-test-2265625205/multidelete/key=value/f4.
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
scm3.org_1   | 2022-06-28 01:38:53,723 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
scm3.org_1   | 2022-06-28 01:39:08,043 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60170
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
scm3.org_1   | 2022-06-28 01:39:08,080 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:293)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om2_1        | 2022-06-28 01:30:11,265 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om2_1        | 2022-06-28 01:30:11,268 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
om2_1        | 2022-06-28 01:30:11,271 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
om2_1        | 2022-06-28 01:30:11,274 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
om2_1        | 2022-06-28 01:30:18,656 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49566
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
om2_1        | 2022-06-28 01:30:18,665 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
om2_1        | 2022-06-28 01:30:23,426 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:36319
recon_1      | 	... 27 more
om2_1        | 2022-06-28 01:30:23,430 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
om2_1        | 2022-06-28 01:30:23,431 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
om2_1        | 2022-06-28 01:30:23,434 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
om2_1        | 2022-06-28 01:30:23,451 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2257556859 of layout LEGACY in volume: s3v
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
om2_1        | 2022-06-28 01:30:24,504 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
om2_1        | 2022-06-28 01:30:24,513 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	... 35 more
om2_1        | 2022-06-28 01:30:24,525 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:32:42,731 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds to process 0 existing database records.
om2_1        | 2022-06-28 01:30:40,847 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40043
recon_1      | 2022-06-28 01:32:42,747 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 14 milliseconds for processing 2 containers.
om2_1        | 2022-06-28 01:30:40,851 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 2022-06-28 01:32:42,931 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
om2_1        | 2022-06-28 01:31:24,754 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:46521
recon_1      | 2022-06-28 01:32:42,934 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=fb66c122-66a4-4d5f-942b-9d2354169a55 from SCM.
om2_1        | 2022-06-28 01:31:24,774 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 2022-06-28 01:32:42,936 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fb66c122-66a4-4d5f-942b-9d2354169a55, Nodes: 9b5cffd6-d488-4e7f-a573-cd0e62fb49aa{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-06-28T01:32:32.823Z[UTC]].
recon_1      | 2022-06-28 01:32:42,940 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 17 milliseconds.
om2_1        | 2022-06-28 01:31:24,775 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:24,781 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:32:52,366 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43974
om2_1        | 2022-06-28 01:31:24,783 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:32:52,395 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57510
om2_1        | 2022-06-28 01:31:25,198 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:32:52,407 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-06-28 01:31:25,952 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:25,955 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:25,958 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:32:52,431 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-06-28 01:31:25,961 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:33:06,966 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36952
om2_1        | 2022-06-28 01:31:26,793 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:26,795 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:26,801 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:33:07,026 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-06-28 01:31:26,826 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:33:22,371 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44064
om2_1        | 2022-06-28 01:31:27,542 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:33:22,395 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57606
recon_1      | 2022-06-28 01:33:22,431 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-06-28 01:31:27,545 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:33:22,459 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-06-28 01:31:27,547 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:33:36,992 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37030
om2_1        | 2022-06-28 01:31:27,550 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:33:37,044 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 2022-06-28 01:31:28,353 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 2022-06-28 01:33:37,117 [EventQueue-ContainerReportForReconContainerReportHandler] INFO scm.ReconContainerManager: Successfully added container #3 to Recon.
recon_1      | 2022-06-28 01:33:40,963 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:33:40,963 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:33:41,008 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
om2_1        | 2022-06-28 01:31:28,355 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
om2_1        | 2022-06-28 01:31:28,356 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
om2_1        | 2022-06-28 01:31:28,384 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
om2_1        | 2022-06-28 01:31:29,188 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
om2_1        | 2022-06-28 01:31:29,190 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
om2_1        | 2022-06-28 01:31:29,192 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
om2_1        | 2022-06-28 01:31:29,206 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
om2_1        | 2022-06-28 01:31:30,128 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:30,133 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:30,136 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
om2_1        | 2022-06-28 01:31:30,152 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
om2_1        | 2022-06-28 01:31:31,039 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:31,043 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
om2_1        | 2022-06-28 01:31:31,051 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
om2_1        | 2022-06-28 01:31:31,061 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om2_1        | 2022-06-28 01:31:31,809 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
om2_1        | 2022-06-28 01:31:31,811 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
om2_1        | 2022-06-28 01:31:31,813 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
om2_1        | 2022-06-28 01:31:32,586 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
om2_1        | 2022-06-28 01:31:32,588 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
om2_1        | 2022-06-28 01:31:32,590 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
om2_1        | 2022-06-28 01:31:32,603 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
om2_1        | 2022-06-28 01:31:33,374 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:33,378 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om2_1        | 2022-06-28 01:31:33,380 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:33,393 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om2_1        | 2022-06-28 01:31:34,286 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om2_1        | 2022-06-28 01:31:34,288 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	... 12 more
om2_1        | 2022-06-28 01:31:34,290 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
om2_1        | 2022-06-28 01:31:34,299 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
om2_1        | 2022-06-28 01:31:34,986 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
om2_1        | 2022-06-28 01:31:34,995 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:34,998 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:35,006 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:35,677 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
om2_1        | 2022-06-28 01:31:35,694 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
om2_1        | 2022-06-28 01:31:35,696 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
om2_1        | 2022-06-28 01:31:35,706 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
om2_1        | 2022-06-28 01:31:36,401 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om2_1        | 2022-06-28 01:31:36,403 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om2_1        | 2022-06-28 01:31:36,405 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
om2_1        | 2022-06-28 01:31:36,412 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	... 20 more
om2_1        | 2022-06-28 01:31:37,101 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:37,103 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
om2_1        | 2022-06-28 01:31:37,108 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
om2_1        | 2022-06-28 01:31:37,122 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:38,010 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:38,013 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:38,015 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:38,024 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:38,777 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:38,781 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:38,783 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:39,542 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:39,544 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:39,546 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:40,272 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:40,274 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:40,276 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:40,887 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40427
om2_1        | 2022-06-28 01:31:40,897 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:31:47,554 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49840
om2_1        | 2022-06-28 01:31:47,560 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:31:51,876 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:38765
om2_1        | 2022-06-28 01:31:51,879 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:31:51,880 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:51,918 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:31:51,926 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2995237214 of layout LEGACY in volume: s3v
om2_1        | 2022-06-28 01:32:16,052 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49932
om2_1        | 2022-06-28 01:32:16,062 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:32:40,931 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34417
om2_1        | 2022-06-28 01:32:40,946 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:33:25,688 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:46799
om2_1        | 2022-06-28 01:33:25,700 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:33:25,702 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 467c2b66f643066ddb7d4406d0729d1b7848f4c9e2433e1b8c9cbda35a5c2b93
om2_1        | 2022-06-28 01:33:40,987 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38581
om2_1        | 2022-06-28 01:33:40,990 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
om2_1        | 2022-06-28 01:34:41,028 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33257
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
om2_1        | 2022-06-28 01:34:41,034 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
om2_1        | 2022-06-28 01:35:41,113 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42653
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
om2_1        | 2022-06-28 01:35:41,121 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:36:41,163 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39711
om2_1        | 2022-06-28 01:36:41,169 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:37:41,228 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37859
om2_1        | 2022-06-28 01:37:41,257 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-06-28 01:38:41,301 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46349
om2_1        | 2022-06-28 01:38:41,310 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:33:52,381 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44144
recon_1      | 2022-06-28 01:33:52,402 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:33:52,432 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57684
recon_1      | 2022-06-28 01:33:52,457 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:34:06,967 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37126
recon_1      | 2022-06-28 01:34:07,002 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:34:07,988 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO scm.ReconContainerManager: Container #1 has state OPEN, but given state is CLOSING.
recon_1      | 2022-06-28 01:34:22,369 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57772
recon_1      | 2022-06-28 01:34:22,389 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44236
recon_1      | 2022-06-28 01:34:22,417 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:34:22,420 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:34:23,556 [EventQueue-IncrementalContainerReportForReconIncrementalContainerReportHandler] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode 3f49ce74-6987-463e-a960-954ebbba5f61{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
recon_1      | 2022-06-28 01:34:38,024 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37208
recon_1      | 2022-06-28 01:34:38,047 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:34:41,010 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:34:41,011 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:34:41,081 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:34:53,592 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57848
recon_1      | 2022-06-28 01:34:53,622 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:34:53,674 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44326
recon_1      | 2022-06-28 01:34:53,715 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:35:08,011 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37298
recon_1      | 2022-06-28 01:35:08,039 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:35:23,589 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:57944
recon_1      | 2022-06-28 01:35:23,610 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:35:23,676 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44418
recon_1      | 2022-06-28 01:35:23,703 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:35:37,995 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37380
recon_1      | 2022-06-28 01:35:38,027 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:35:41,087 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:35:41,087 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:35:41,138 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor55.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:35:53,598 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58024
recon_1      | 2022-06-28 01:35:53,618 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:35:53,677 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44498
recon_1      | 2022-06-28 01:35:53,719 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:36:08,007 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37466
recon_1      | 2022-06-28 01:36:08,046 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:36:23,578 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58112
recon_1      | 2022-06-28 01:36:23,602 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:36:23,675 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44590
recon_1      | 2022-06-28 01:36:23,704 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:36:38,014 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37548
recon_1      | 2022-06-28 01:36:38,074 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:36:41,140 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:36:41,140 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:36:41,198 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor55.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:36:53,591 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58192
recon_1      | 2022-06-28 01:36:53,618 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:36:53,685 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44670
recon_1      | 2022-06-28 01:36:53,702 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:37:08,022 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37642
recon_1      | 2022-06-28 01:37:08,045 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:37:23,565 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58288
recon_1      | 2022-06-28 01:37:23,596 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:37:23,667 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44762
recon_1      | 2022-06-28 01:37:23,685 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:37:38,011 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37722
recon_1      | 2022-06-28 01:37:38,043 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:37:41,199 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:37:41,199 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:37:41,275 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor55.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:37:42,748 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1      | 2022-06-28 01:37:42,755 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 6 milliseconds for processing 3 containers.
recon_1      | 2022-06-28 01:37:43,006 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 6 pipelines in house.
recon_1      | 2022-06-28 01:37:43,022 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 66 milliseconds.
recon_1      | 2022-06-28 01:37:53,585 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58370
recon_1      | 2022-06-28 01:37:53,625 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:37:53,668 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44850
recon_1      | 2022-06-28 01:37:53,701 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:38:08,009 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37822
recon_1      | 2022-06-28 01:38:08,044 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:38:23,583 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58468
recon_1      | 2022-06-28 01:38:23,611 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:38:23,671 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44948
recon_1      | 2022-06-28 01:38:23,700 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:38:38,018 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37904
recon_1      | 2022-06-28 01:38:38,075 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:38:41,281 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-06-28 01:38:41,281 [pool-18-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-06-28 01:38:41,336 [pool-18-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om2:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor55.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-06-28 01:38:53,622 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58544
recon_1      | 2022-06-28 01:38:53,681 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:38:53,716 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45024
recon_1      | 2022-06-28 01:38:53,723 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-06-28 01:39:08,048 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37986
recon_1      | 2022-06-28 01:39:08,095 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
