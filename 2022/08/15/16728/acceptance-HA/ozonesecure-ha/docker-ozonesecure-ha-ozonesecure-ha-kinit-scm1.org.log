Attaching to ozonesecure-ha_recon_1, ozonesecure-ha_s3g_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_kms_1, ozonesecure-ha_scm3.org_1, ozonesecure-ha_datanode2_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_om1_1, ozonesecure-ha_kdc_1, ozonesecure-ha_om2_1, ozonesecure-ha_om3_1, ozonesecure-ha_scm2.org_1
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2022-08-15 20:22:31,011 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = c654f076c8fc/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:58Z
datanode1_1  | STARTUP_MSG:   java = 11.0.14.1
datanode1_1  | ************************************************************/
datanode1_1  | 2022-08-15 20:22:31,072 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2022-08-15 20:22:31,502 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2022-08-15 20:22:32,330 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2022-08-15 20:22:33,381 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2022-08-15 20:22:33,384 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2022-08-15 20:22:34,257 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:c654f076c8fc ip:172.25.0.102
datanode1_1  | 2022-08-15 20:22:37,646 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2022-08-15 20:22:39,206 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2022-08-15 20:22:39,206 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2022-08-15 20:22:41,650 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2022-08-15 20:22:41,676 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2022-08-15 20:22:41,676 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2022-08-15 20:22:41,678 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2022-08-15 20:22:45,537 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2022-08-15 20:22:45,631 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:c654f076c8fc
datanode1_1  | 2022-08-15 20:22:45,637 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2022-08-15 20:22:45,658 [main] ERROR client.DNCertificateClient: Invalid domain c654f076c8fc
datanode1_1  | 2022-08-15 20:22:45,672 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@c654f076c8fc
datanode1_1  | 2022-08-15 20:22:51,004 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2022-08-15 20:22:51,080 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/931661290961.crt.
datanode1_1  | 2022-08-15 20:22:51,109 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2022-08-15 20:22:51,139 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-838496351631.crt.
datanode1_1  | 2022-08-15 20:22:51,151 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2022-08-15 20:22:51,322 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode1_1  | 2022-08-15 20:22:52,341 [main] INFO reflections.Reflections: Reflections took 702 ms to scan 2 urls, producing 89 keys and 198 values 
datanode1_1  | 2022-08-15 20:22:53,000 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode1_1  | 2022-08-15 20:22:54,330 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2022-08-15 20:22:54,498 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode1_1  | 2022-08-15 20:22:54,501 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2022-08-15 20:22:54,530 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2022-08-15 20:22:54,786 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2022-08-15 20:22:54,924 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-08-15 20:22:54,944 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2022-08-15 20:22:54,953 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2022-08-15 20:22:54,961 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2022-08-15 20:22:54,961 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2022-08-15 20:22:55,364 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2022-08-15 20:22:55,392 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2022-08-15 20:23:01,017 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode1_1  | 2022-08-15 20:23:02,270 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-08-15 20:23:02,852 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2022-08-15 20:23:04,255 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2022-08-15 20:23:04,268 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2022-08-15 20:23:04,276 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2022-08-15 20:23:04,277 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2022-08-15 20:23:04,280 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-08-15 20:23:04,284 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2022-08-15 20:23:04,287 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-08-15 20:23:04,372 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode1_1  | 2022-08-15 20:23:04,380 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode1_1  | 2022-08-15 20:23:09,843 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2022-08-15 20:23:09,856 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode1_1  | 2022-08-15 20:23:09,876 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode1_1  | 2022-08-15 20:23:09,880 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-08-15 20:23:09,880 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-08-15 20:23:09,902 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-08-15 20:23:10,595 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode1_1  | 2022-08-15 20:23:11,933 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode1_1  | 2022-08-15 20:23:11,943 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode1_1  | 2022-08-15 20:23:12,506 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2022-08-15 20:23:12,516 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2022-08-15 20:23:12,519 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2022-08-15 20:23:12,860 [main] INFO util.log: Logging initialized @53001ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2022-08-15 20:23:14,131 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2022-08-15 20:23:14,212 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2022-08-15 20:23:14,228 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2022-08-15 20:23:14,236 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2022-08-15 20:23:14,240 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2022-08-15 20:23:14,288 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2022-08-15 20:23:14,705 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2022-08-15 20:23:14,715 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode1_1  | 2022-08-15 20:23:14,946 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2022-08-15 20:23:14,978 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2022-08-15 20:23:14,980 [main] INFO server.session: node0 Scavenging every 600000ms
datanode1_1  | 2022-08-15 20:23:15,163 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-08-15 20:23:15,192 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5d18a787{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2022-08-15 20:23:15,208 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4ff3ca23{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2022-08-15 20:23:15,906 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-08-15 20:23:15,997 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@f81bd2c{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-15932510468620894214/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2022-08-15 20:23:16,084 [main] INFO server.AbstractConnector: Started ServerConnector@3de507af{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2022-08-15 20:23:16,086 [main] INFO server.Server: Started @56242ms
datanode1_1  | 2022-08-15 20:23:16,109 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2022-08-15 20:23:16,111 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2022-08-15 20:23:16,115 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2022-08-15 20:23:16,168 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode1_1  | 2022-08-15 20:23:16,356 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2ba1f7b7] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2022-08-15 20:23:17,070 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2022-08-15 20:23:17,106 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode1_1  | 2022-08-15 20:23:21,903 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072/DS-d4fa58b0-bc66-4300-ac3b-083b976d6c01/container.db for volume DS-d4fa58b0-bc66-4300-ac3b-083b976d6c01
datanode1_1  | 2022-08-15 20:23:22,005 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072/DS-d4fa58b0-bc66-4300-ac3b-083b976d6c01/container.db for volume DS-d4fa58b0-bc66-4300-ac3b-083b976d6c01
datanode1_1  | 2022-08-15 20:23:22,012 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2022-08-15 20:23:22,027 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2022-08-15 20:23:22,557 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode1_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:298)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:493)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode1_1  | Caused by: java.util.concurrent.TimeoutException
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode1_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode1_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	... 1 more
datanode1_1  | 2022-08-15 20:23:22,590 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 11946e6e-1ab1-47b6-94a8-e6dbe917e210
datanode1_1  | 2022-08-15 20:23:22,760 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.RaftServer: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start RPC server
datanode1_1  | 2022-08-15 20:23:22,932 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: GrpcService started, listening on 9856
datanode1_1  | 2022-08-15 20:23:22,966 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: GrpcService started, listening on 9857
datanode1_1  | 2022-08-15 20:23:22,968 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: GrpcService started, listening on 9858
datanode1_1  | 2022-08-15 20:23:22,980 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 11946e6e-1ab1-47b6-94a8-e6dbe917e210 is started using port 9858 for RATIS
datanode1_1  | 2022-08-15 20:23:22,980 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 11946e6e-1ab1-47b6-94a8-e6dbe917e210 is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2022-08-15 20:23:22,980 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 11946e6e-1ab1-47b6-94a8-e6dbe917e210 is started using port 9856 for RATIS_SERVER
datanode1_1  | 2022-08-15 20:23:22,982 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$391/0x00000008405e6c40@5eb23660] INFO util.JvmPauseMonitor: JvmPauseMonitor-11946e6e-1ab1-47b6-94a8-e6dbe917e210: Started
datanode1_1  | 2022-08-15 20:23:23,054 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-08-15 20:23:23,054 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-08-15 20:23:27,792 [Command processor thread] INFO server.RaftServer: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: addNew group-3754BE4DEF15:[11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-3754BE4DEF15:java.util.concurrent.CompletableFuture@45b5f5f2[Not completed]
datanode1_1  | 2022-08-15 20:23:27,923 [pool-23-thread-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: new RaftServerImpl for group-3754BE4DEF15:[11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-08-15 20:23:27,945 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-08-15 20:23:27,950 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-08-15 20:23:27,964 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-08-15 20:23:27,965 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-08-15 20:23:27,971 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-08-15 20:23:27,972 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-08-15 20:23:28,022 [pool-23-thread-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15: ConfigurationManager, init=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-08-15 20:23:28,025 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-08-15 20:23:28,065 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-08-15 20:23:28,071 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-08-15 20:23:28,090 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f3e347f8-57d4-4c72-b323-3754be4def15 does not exist. Creating ...
datanode1_1  | 2022-08-15 20:23:28,135 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f3e347f8-57d4-4c72-b323-3754be4def15/in_use.lock acquired by nodename 7@c654f076c8fc
datanode1_1  | 2022-08-15 20:23:28,176 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f3e347f8-57d4-4c72-b323-3754be4def15 has been successfully formatted.
datanode1_1  | 2022-08-15 20:23:28,212 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-3754BE4DEF15: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-08-15 20:23:28,217 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-08-15 20:23:28,323 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-08-15 20:23:28,417 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-08-15 20:23:28,417 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-08-15 20:23:28,473 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-08-15 20:23:28,745 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-15 20:23:28,818 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-08-15 20:23:28,833 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-08-15 20:23:28,906 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/f3e347f8-57d4-4c72-b323-3754be4def15
datanode1_1  | 2022-08-15 20:23:28,907 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-08-15 20:23:28,914 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-08-15 20:23:28,924 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-15 20:23:28,930 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-08-15 20:23:28,938 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-08-15 20:23:28,939 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-08-15 20:23:28,961 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-08-15 20:23:28,962 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-08-15 20:23:29,074 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-08-15 20:23:29,089 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-08-15 20:23:29,098 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-08-15 20:23:29,170 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-15 20:23:29,176 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-15 20:23:29,207 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-08-15 20:23:29,247 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-08-15 20:23:29,248 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-08-15 20:23:29,250 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-08-15 20:23:29,274 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-08-15 20:23:29,275 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-08-15 20:23:29,609 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-08-15 20:23:29,644 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-08-15 20:23:29,648 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-08-15 20:23:29,649 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-08-15 20:23:29,650 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-08-15 20:23:29,651 [pool-23-thread-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15: start as a follower, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-08-15 20:23:29,651 [pool-23-thread-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-08-15 20:23:29,684 [pool-23-thread-1] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-FollowerState
datanode1_1  | 2022-08-15 20:23:29,748 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3754BE4DEF15,id=11946e6e-1ab1-47b6-94a8-e6dbe917e210
datanode1_1  | 2022-08-15 20:23:29,857 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=f3e347f8-57d4-4c72-b323-3754be4def15
datanode1_1  | 2022-08-15 20:23:29,858 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=f3e347f8-57d4-4c72-b323-3754be4def15.
datanode1_1  | 2022-08-15 20:23:29,859 [Command processor thread] INFO server.RaftServer: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: addNew group-4BEB5C69C54E:[11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0] returns group-4BEB5C69C54E:java.util.concurrent.CompletableFuture@59586ad8[Not completed]
datanode1_1  | 2022-08-15 20:23:29,900 [pool-23-thread-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: new RaftServerImpl for group-4BEB5C69C54E:[11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-08-15 20:23:29,901 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-08-15 20:23:29,911 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-08-15 20:23:29,911 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-08-15 20:23:29,913 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-08-15 20:23:29,913 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-08-15 20:23:29,913 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-08-15 20:23:29,913 [pool-23-thread-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: ConfigurationManager, init=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-08-15 20:23:29,913 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-08-15 20:23:29,914 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-08-15 20:23:29,914 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-08-15 20:23:29,922 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e does not exist. Creating ...
datanode1_1  | 2022-08-15 20:23:29,943 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e/in_use.lock acquired by nodename 7@c654f076c8fc
datanode1_1  | 2022-08-15 20:23:29,948 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e has been successfully formatted.
datanode1_1  | 2022-08-15 20:23:29,948 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-4BEB5C69C54E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-08-15 20:23:29,952 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-08-15 20:23:29,952 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-08-15 20:23:29,955 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-08-15 20:23:29,955 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-08-15 20:23:29,955 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-08-15 20:23:29,957 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-15 20:23:29,960 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-08-15 20:23:29,960 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-08-15 20:23:29,960 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e
datanode1_1  | 2022-08-15 20:23:29,960 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-08-15 20:23:29,960 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-08-15 20:23:29,988 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-15 20:23:29,988 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-08-15 20:23:29,988 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-08-15 20:23:29,989 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-08-15 20:23:30,018 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-08-15 20:23:30,018 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-08-15 20:23:30,022 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-08-15 20:23:30,023 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-08-15 20:23:30,023 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-08-15 20:23:30,024 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-15 20:23:30,024 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-15 20:23:30,048 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-08-15 20:23:30,048 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-08-15 20:23:30,048 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-08-15 20:23:30,051 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-08-15 20:23:30,052 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-08-15 20:23:30,052 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-08-15 20:23:30,053 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-08-15 20:23:30,053 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-08-15 20:23:30,058 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-08-15 20:23:30,058 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-08-15 20:23:30,058 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-08-15 20:23:30,058 [pool-23-thread-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: start as a follower, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode1_1  | 2022-08-15 20:23:30,059 [pool-23-thread-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-08-15 20:23:30,059 [pool-23-thread-1] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:23:30,059 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4BEB5C69C54E,id=11946e6e-1ab1-47b6-94a8-e6dbe917e210
datanode1_1  | 2022-08-15 20:23:30,067 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e
datanode1_1  | 2022-08-15 20:23:34,901 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-FollowerState] INFO impl.FollowerState: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5217402064ns, electionTimeout:5194ms
datanode1_1  | 2022-08-15 20:23:34,904 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-FollowerState] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-FollowerState
datanode1_1  | 2022-08-15 20:23:34,920 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-FollowerState] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-08-15 20:23:34,935 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-08-15 20:23:34,945 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-FollowerState] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1
datanode1_1  | 2022-08-15 20:23:35,002 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-08-15 20:23:35,008 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2022-08-15 20:23:35,012 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1
datanode1_1  | 2022-08-15 20:23:35,023 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2022-08-15 20:23:35,028 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-3754BE4DEF15 with new leaderId: 11946e6e-1ab1-47b6-94a8-e6dbe917e210
datanode1_1  | 2022-08-15 20:23:35,048 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15: change Leader from null to 11946e6e-1ab1-47b6-94a8-e6dbe917e210 at term 1 for becomeLeader, leader elected after 6811ms
datanode1_1  | 2022-08-15 20:23:35,176 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5117123401ns, electionTimeout:5097ms
datanode1_1  | 2022-08-15 20:23:35,199 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:23:35,246 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-08-15 20:23:35,250 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-08-15 20:23:35,255 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2
datanode1_1  | 2022-08-15 20:23:35,238 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-08-15 20:23:35,321 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-08-15 20:23:35,327 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-08-15 20:23:35,473 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-08-15 20:23:35,536 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-08-15 20:23:35,543 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode1_1  | 2022-08-15 20:23:35,600 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-08-15 20:23:35,811 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-08-15 20:23:35,877 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-08-15 20:23:35,995 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderStateImpl
datanode1_1  | 2022-08-15 20:23:36,290 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$391/0x00000008405e6c40@5eb23660] WARN util.JvmPauseMonitor: JvmPauseMonitor-11946e6e-1ab1-47b6-94a8-e6dbe917e210: Detected pause in JVM or host machine (eg GC): pause of approximately 101740504ns. No GCs detected.
datanode1_1  | 2022-08-15 20:23:36,425 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-08-15 20:23:36,931 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-LeaderElection1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15: set configuration 0: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-08-15 20:23:37,342 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-3754BE4DEF15-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f3e347f8-57d4-4c72-b323-3754be4def15/current/log_inprogress_0
datanode1_1  | 2022-08-15 20:23:37,706 [grpc-default-executor-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: receive requestVote(ELECTION, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, group-4BEB5C69C54E, 1, (t:0, i:0))
datanode1_1  | 2022-08-15 20:23:37,733 [grpc-default-executor-1] INFO impl.VoteContext: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-CANDIDATE: reject ELECTION from ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: already has voted for 11946e6e-1ab1-47b6-94a8-e6dbe917e210 at current term 1
datanode1_1  | 2022-08-15 20:23:37,831 [grpc-default-executor-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E replies to ELECTION vote request: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f<-11946e6e-1ab1-47b6-94a8-e6dbe917e210#0:FAIL-t1. Peer's state: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E:t1, leader=null, voted=11946e6e-1ab1-47b6-94a8-e6dbe917e210, raftlog=11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode1_1  | 2022-08-15 20:23:39,045 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: e2584860-2683-4862-8eba-daf2ea0fcaee: group-4BEB5C69C54E not found.
datanode1_1  | 2022-08-15 20:23:39,046 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2: ELECTION REJECTED received 1 response(s) and 1 exception(s):
datanode1_1  | 2022-08-15 20:23:39,046 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2] INFO impl.LeaderElection:   Response 0: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f#0:FAIL-t1
datanode1_1  | 2022-08-15 20:23:39,052 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: e2584860-2683-4862-8eba-daf2ea0fcaee: group-4BEB5C69C54E not found.
datanode1_1  | 2022-08-15 20:23:39,054 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2 ELECTION round 0: result REJECTED
datanode1_1  | 2022-08-15 20:23:39,056 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode1_1  | 2022-08-15 20:23:39,060 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2
datanode1_1  | 2022-08-15 20:23:39,060 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection2] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:23:41,225 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e.
datanode1_1  | 2022-08-15 20:23:41,226 [Command processor thread] INFO server.RaftServer: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: addNew group-E153E5671E57:[11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-E153E5671E57:java.util.concurrent.CompletableFuture@49cd85ae[Not completed]
datanode1_1  | 2022-08-15 20:23:41,233 [pool-23-thread-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: new RaftServerImpl for group-E153E5671E57:[11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-08-15 20:23:41,241 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-08-15 20:23:41,244 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-08-15 20:23:41,244 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-08-15 20:23:41,244 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-08-15 20:23:41,244 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-08-15 20:23:41,244 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-08-15 20:23:41,244 [pool-23-thread-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57: ConfigurationManager, init=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-08-15 20:23:41,248 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-08-15 20:23:41,252 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-08-15 20:23:41,252 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-08-15 20:23:41,252 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57 does not exist. Creating ...
datanode1_1  | 2022-08-15 20:23:41,257 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57/in_use.lock acquired by nodename 7@c654f076c8fc
datanode1_1  | 2022-08-15 20:23:41,275 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57 has been successfully formatted.
datanode1_1  | 2022-08-15 20:23:41,281 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-E153E5671E57: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-08-15 20:23:41,325 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-08-15 20:23:41,330 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-08-15 20:23:41,331 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-08-15 20:23:41,331 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-08-15 20:23:41,331 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-08-15 20:23:41,332 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-15 20:23:41,334 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-08-15 20:23:41,348 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-08-15 20:23:41,353 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57
datanode1_1  | 2022-08-15 20:23:41,359 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-08-15 20:23:41,371 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-08-15 20:23:41,373 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-15 20:23:41,373 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-08-15 20:23:41,373 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-08-15 20:23:41,374 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-08-15 20:23:41,374 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-08-15 20:23:41,374 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-08-15 20:23:41,388 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-08-15 20:23:41,393 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-08-15 20:23:41,393 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-08-15 20:23:41,396 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-15 20:23:41,398 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-15 20:23:41,400 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-08-15 20:23:41,407 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-08-15 20:23:41,410 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-08-15 20:23:41,410 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-08-15 20:23:41,410 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-08-15 20:23:41,411 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-08-15 20:23:41,422 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-08-15 20:23:41,422 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-08-15 20:23:41,424 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-08-15 20:23:41,426 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-08-15 20:23:41,427 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-08-15 20:23:41,429 [pool-23-thread-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57: start as a follower, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode1_1  | 2022-08-15 20:23:41,434 [pool-23-thread-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-08-15 20:23:41,435 [pool-23-thread-1] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57-FollowerState
datanode1_1  | 2022-08-15 20:23:41,451 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E153E5671E57,id=11946e6e-1ab1-47b6-94a8-e6dbe917e210
datanode1_1  | 2022-08-15 20:23:41,470 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=ee87d8de-c101-4564-aff4-e153e5671e57
datanode1_1  | 2022-08-15 20:23:42,612 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=ee87d8de-c101-4564-aff4-e153e5671e57.
datanode1_1  | 2022-08-15 20:23:44,135 [grpc-default-executor-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: receive requestVote(ELECTION, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, group-4BEB5C69C54E, 2, (t:0, i:0))
datanode1_1  | 2022-08-15 20:23:44,136 [grpc-default-executor-1] INFO impl.VoteContext: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FOLLOWER: accept ELECTION from ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: our priority 0 <= candidate's priority 0
datanode1_1  | 2022-08-15 20:23:44,136 [grpc-default-executor-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
datanode1_1  | 2022-08-15 20:23:44,136 [grpc-default-executor-1] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:23:44,136 [grpc-default-executor-1] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:23:44,136 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState was interrupted
datanode1_1  | 2022-08-15 20:23:44,145 [grpc-default-executor-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E replies to ELECTION vote request: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f<-11946e6e-1ab1-47b6-94a8-e6dbe917e210#0:OK-t2. Peer's state: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E:t2, leader=null, voted=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, raftlog=11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode1_1  | 2022-08-15 20:23:44,444 [grpc-default-executor-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57: receive requestVote(ELECTION, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, group-E153E5671E57, 1, (t:0, i:0))
datanode1_1  | 2022-08-15 20:23:44,444 [grpc-default-executor-1] INFO impl.VoteContext: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57-FOLLOWER: accept ELECTION from ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: our priority 0 <= candidate's priority 1
datanode1_1  | 2022-08-15 20:23:44,445 [grpc-default-executor-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
datanode1_1  | 2022-08-15 20:23:44,445 [grpc-default-executor-1] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57-FollowerState
datanode1_1  | 2022-08-15 20:23:44,445 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57-FollowerState] INFO impl.FollowerState: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57-FollowerState was interrupted
datanode1_1  | 2022-08-15 20:23:44,448 [grpc-default-executor-1] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57-FollowerState
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2022-08-15 20:22:31,598 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = 004775ef3c0f/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | 2022-08-15 20:23:44,454 [grpc-default-executor-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57 replies to ELECTION vote request: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f<-11946e6e-1ab1-47b6-94a8-e6dbe917e210#0:OK-t1. Peer's state: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57:t1, leader=null, voted=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, raftlog=11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode1_1  | 2022-08-15 20:23:44,781 [11946e6e-1ab1-47b6-94a8-e6dbe917e210-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-E153E5671E57 with new leaderId: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
datanode1_1  | 2022-08-15 20:23:44,788 [11946e6e-1ab1-47b6-94a8-e6dbe917e210-server-thread1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57: change Leader from null to ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f at term 1 for appendEntries, leader elected after 3456ms
datanode1_1  | 2022-08-15 20:23:44,949 [11946e6e-1ab1-47b6-94a8-e6dbe917e210-server-thread1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57: set configuration 0: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-08-15 20:23:44,958 [11946e6e-1ab1-47b6-94a8-e6dbe917e210-server-thread1] INFO segmented.SegmentedRaftLogWorker: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-08-15 20:23:44,962 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-E153E5671E57-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57/current/log_inprogress_0
datanode1_1  | 2022-08-15 20:23:49,169 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5024042797ns, electionTimeout:5024ms
datanode1_1  | 2022-08-15 20:23:49,169 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:23:49,169 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode1_1  | 2022-08-15 20:23:49,170 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-08-15 20:23:49,170 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection3
datanode1_1  | 2022-08-15 20:23:49,172 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection3] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection3 ELECTION round 0: submit vote requests at term 3 for -1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode1_1  | 2022-08-15 20:23:49,256 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection3] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode1_1  | 2022-08-15 20:23:49,256 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection3] INFO impl.LeaderElection:   Response 0: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-e2584860-2683-4862-8eba-daf2ea0fcaee#0:FAIL-t3
datanode1_1  | 2022-08-15 20:23:49,257 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection3] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection3 ELECTION round 0: result REJECTED
datanode1_1  | 2022-08-15 20:23:49,257 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode1_1  | 2022-08-15 20:23:49,258 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection3] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection3
datanode1_1  | 2022-08-15 20:23:49,266 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection3] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:23:54,347 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5080901525ns, electionTimeout:5035ms
datanode1_1  | 2022-08-15 20:23:54,348 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:23:54,348 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode1_1  | 2022-08-15 20:23:54,348 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-08-15 20:23:54,349 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection4
datanode1_1  | 2022-08-15 20:23:54,355 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection4] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection4 ELECTION round 0: submit vote requests at term 4 for -1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode1_1  | 2022-08-15 20:23:54,424 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection4] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection4: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode1_1  | 2022-08-15 20:23:54,425 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection4] INFO impl.LeaderElection:   Response 0: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-e2584860-2683-4862-8eba-daf2ea0fcaee#0:FAIL-t4
datanode1_1  | 2022-08-15 20:23:54,425 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection4] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection4 ELECTION round 0: result REJECTED
datanode1_1  | 2022-08-15 20:23:54,426 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection4] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode1_1  | 2022-08-15 20:23:54,426 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection4] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection4
datanode1_1  | 2022-08-15 20:23:54,426 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection4] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:23:56,217 [grpc-default-executor-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: receive requestVote(ELECTION, e2584860-2683-4862-8eba-daf2ea0fcaee, group-4BEB5C69C54E, 4, (t:0, i:0))
datanode1_1  | 2022-08-15 20:23:56,218 [grpc-default-executor-1] INFO impl.VoteContext: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FOLLOWER: reject ELECTION from e2584860-2683-4862-8eba-daf2ea0fcaee: already has voted for 11946e6e-1ab1-47b6-94a8-e6dbe917e210 at current term 4
datanode1_1  | 2022-08-15 20:23:56,218 [grpc-default-executor-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E replies to ELECTION vote request: e2584860-2683-4862-8eba-daf2ea0fcaee<-11946e6e-1ab1-47b6-94a8-e6dbe917e210#0:FAIL-t4. Peer's state: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E:t4, leader=null, voted=11946e6e-1ab1-47b6-94a8-e6dbe917e210, raftlog=11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode1_1  | 2022-08-15 20:23:59,600 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5174315155ns, electionTimeout:5173ms
datanode1_1  | 2022-08-15 20:23:59,601 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:23:59,601 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
datanode1_1  | 2022-08-15 20:23:59,601 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-08-15 20:23:59,601 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection5
datanode1_1  | 2022-08-15 20:23:59,604 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection5] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection5 ELECTION round 0: submit vote requests at term 5 for -1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode1_1  | 2022-08-15 20:23:59,663 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection5] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection5: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode1_1  | 2022-08-15 20:23:59,664 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection5] INFO impl.LeaderElection:   Response 0: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-e2584860-2683-4862-8eba-daf2ea0fcaee#0:FAIL-t5
datanode1_1  | 2022-08-15 20:23:59,664 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection5] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection5 ELECTION round 0: result REJECTED
datanode1_1  | 2022-08-15 20:23:59,664 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection5] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
datanode1_1  | 2022-08-15 20:23:59,664 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection5] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection5
datanode1_1  | 2022-08-15 20:23:59,664 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection5] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:24:04,716 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5051657383ns, electionTimeout:5051ms
datanode1_1  | 2022-08-15 20:24:04,716 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:24:04,717 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
datanode1_1  | 2022-08-15 20:24:04,717 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-08-15 20:24:04,717 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection6
datanode1_1  | 2022-08-15 20:24:04,719 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection6] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection6 ELECTION round 0: submit vote requests at term 6 for -1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode1_1  | 2022-08-15 20:24:04,771 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection6] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection6: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode1_1  | 2022-08-15 20:24:04,771 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection6] INFO impl.LeaderElection:   Response 0: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-e2584860-2683-4862-8eba-daf2ea0fcaee#0:FAIL-t6
datanode1_1  | 2022-08-15 20:24:04,771 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection6] INFO impl.LeaderElection:   Response 1: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f#0:OK-t6
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:58Z
datanode2_1  | STARTUP_MSG:   java = 11.0.14.1
datanode2_1  | ************************************************************/
datanode2_1  | 2022-08-15 20:22:31,660 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2022-08-15 20:22:32,039 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2022-08-15 20:22:32,841 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2022-08-15 20:22:33,906 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2022-08-15 20:22:33,909 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2022-08-15 20:22:34,794 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:004775ef3c0f ip:172.25.0.103
datanode2_1  | 2022-08-15 20:22:38,056 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2022-08-15 20:22:39,654 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2022-08-15 20:22:39,678 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2022-08-15 20:22:42,014 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2022-08-15 20:22:42,036 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2022-08-15 20:22:42,039 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2022-08-15 20:22:42,042 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2022-08-15 20:22:48,331 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2022-08-15 20:22:48,418 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:004775ef3c0f
datanode2_1  | 2022-08-15 20:22:48,418 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2022-08-15 20:22:48,448 [main] ERROR client.DNCertificateClient: Invalid domain 004775ef3c0f
datanode2_1  | 2022-08-15 20:22:48,451 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@004775ef3c0f
datanode2_1  | 2022-08-15 20:22:53,920 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2022-08-15 20:22:54,043 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2022-08-15 20:22:54,072 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/934681712113.crt.
datanode2_1  | 2022-08-15 20:22:54,081 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-838496351631.crt.
datanode2_1  | 2022-08-15 20:22:54,082 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2022-08-15 20:22:54,226 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode2_1  | 2022-08-15 20:22:55,431 [main] INFO reflections.Reflections: Reflections took 924 ms to scan 2 urls, producing 89 keys and 198 values 
datanode2_1  | 2022-08-15 20:22:55,918 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode2_1  | 2022-08-15 20:22:57,074 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2022-08-15 20:22:57,224 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode2_1  | 2022-08-15 20:22:57,260 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2022-08-15 20:22:57,264 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2022-08-15 20:22:57,736 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2022-08-15 20:22:57,874 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-08-15 20:22:57,903 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2022-08-15 20:22:57,918 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2022-08-15 20:22:57,919 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2022-08-15 20:22:57,920 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode2_1  | 2022-08-15 20:22:58,231 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2022-08-15 20:22:58,260 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2022-08-15 20:23:04,293 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode2_1  | 2022-08-15 20:23:05,830 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-08-15 20:23:06,312 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2022-08-15 20:23:07,560 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2022-08-15 20:23:07,562 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2022-08-15 20:23:07,566 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2022-08-15 20:23:07,573 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2022-08-15 20:23:07,574 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-15 20:23:07,582 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2022-08-15 20:23:07,650 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-08-15 20:23:07,761 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode2_1  | 2022-08-15 20:23:07,774 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode2_1  | 2022-08-15 20:23:14,228 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2022-08-15 20:23:14,243 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode2_1  | 2022-08-15 20:23:14,248 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode2_1  | 2022-08-15 20:23:14,256 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-08-15 20:23:14,257 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-08-15 20:23:14,269 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-08-15 20:23:14,772 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode2_1  | 2022-08-15 20:23:15,755 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-08-15 20:23:15,795 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-08-15 20:23:16,262 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2022-08-15 20:23:16,267 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2022-08-15 20:23:16,272 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2022-08-15 20:23:16,649 [main] INFO util.log: Logging initialized @56881ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2022-08-15 20:23:17,397 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2022-08-15 20:23:17,453 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2022-08-15 20:23:17,454 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2022-08-15 20:23:17,454 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2022-08-15 20:23:17,454 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2022-08-15 20:23:17,480 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2022-08-15 20:23:17,741 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2022-08-15 20:23:17,742 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode2_1  | 2022-08-15 20:23:18,059 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2022-08-15 20:23:18,072 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2022-08-15 20:23:18,081 [main] INFO server.session: node0 Scavenging every 600000ms
datanode2_1  | 2022-08-15 20:23:18,238 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-08-15 20:23:18,267 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5d18a787{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2022-08-15 20:23:18,288 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4ff3ca23{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2022-08-15 20:23:19,038 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-08-15 20:23:19,161 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@f81bd2c{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-1205971531149502450/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2022-08-15 20:23:19,230 [main] INFO server.AbstractConnector: Started ServerConnector@3de507af{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2022-08-15 20:23:19,240 [main] INFO server.Server: Started @59472ms
datanode2_1  | 2022-08-15 20:23:19,244 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2022-08-15 20:23:19,260 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2022-08-15 20:23:19,268 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2022-08-15 20:23:19,271 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode2_1  | 2022-08-15 20:23:19,482 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1ec795f3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2022-08-15 20:23:20,467 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2022-08-15 20:23:20,550 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode2_1  | 2022-08-15 20:23:22,749 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072/DS-e641de11-d7a9-41bf-a128-b49b761c748a/container.db for volume DS-e641de11-d7a9-41bf-a128-b49b761c748a
datanode2_1  | 2022-08-15 20:23:22,768 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072/DS-e641de11-d7a9-41bf-a128-b49b761c748a/container.db for volume DS-e641de11-d7a9-41bf-a128-b49b761c748a
datanode2_1  | 2022-08-15 20:23:22,772 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2022-08-15 20:23:22,791 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2022-08-15 20:23:23,534 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
datanode2_1  | 2022-08-15 20:23:24,237 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start RPC server
datanode2_1  | 2022-08-15 20:23:24,464 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: GrpcService started, listening on 9856
datanode2_1  | 2022-08-15 20:23:24,472 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: GrpcService started, listening on 9857
datanode2_1  | 2022-08-15 20:23:24,482 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: GrpcService started, listening on 9858
datanode2_1  | 2022-08-15 20:23:24,486 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f is started using port 9858 for RATIS
datanode2_1  | 2022-08-15 20:23:24,486 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2022-08-15 20:24:04,771 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection6] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection6 ELECTION round 0: result REJECTED
datanode1_1  | 2022-08-15 20:24:04,771 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection6] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: changes role from CANDIDATE to FOLLOWER at term 6 for REJECTED
datanode1_1  | 2022-08-15 20:24:04,772 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection6] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection6
datanode1_1  | 2022-08-15 20:24:04,774 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection6] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:24:09,864 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5092233775ns, electionTimeout:5089ms
datanode1_1  | 2022-08-15 20:24:09,865 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:24:09,865 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
datanode1_1  | 2022-08-15 20:24:09,866 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-08-15 20:24:09,866 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection7
datanode1_1  | 2022-08-15 20:24:09,870 [grpc-default-executor-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: receive requestVote(ELECTION, e2584860-2683-4862-8eba-daf2ea0fcaee, group-4BEB5C69C54E, 7, (t:0, i:0))
datanode1_1  | 2022-08-15 20:24:09,880 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection7] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection7 ELECTION round 0: submit vote requests at term 7 for -1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode1_1  | 2022-08-15 20:24:09,880 [grpc-default-executor-1] INFO impl.VoteContext: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-CANDIDATE: reject ELECTION from e2584860-2683-4862-8eba-daf2ea0fcaee: already has voted for 11946e6e-1ab1-47b6-94a8-e6dbe917e210 at current term 7
datanode1_1  | 2022-08-15 20:24:09,881 [grpc-default-executor-1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E replies to ELECTION vote request: e2584860-2683-4862-8eba-daf2ea0fcaee<-11946e6e-1ab1-47b6-94a8-e6dbe917e210#0:FAIL-t7. Peer's state: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E:t7, leader=null, voted=11946e6e-1ab1-47b6-94a8-e6dbe917e210, raftlog=11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode1_1  | 2022-08-15 20:24:10,033 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection7] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection7: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode1_1  | 2022-08-15 20:24:10,033 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection7] INFO impl.LeaderElection:   Response 0: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-e2584860-2683-4862-8eba-daf2ea0fcaee#0:FAIL-t7
datanode1_1  | 2022-08-15 20:24:10,034 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection7] INFO impl.LeaderElection:   Response 1: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f#0:FAIL-t7
datanode1_1  | 2022-08-15 20:24:10,034 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection7] INFO impl.LeaderElection: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection7 ELECTION round 0: result REJECTED
datanode1_1  | 2022-08-15 20:24:10,034 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection7] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: changes role from CANDIDATE to FOLLOWER at term 7 for REJECTED
datanode1_1  | 2022-08-15 20:24:10,034 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection7] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: shutdown 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection7
datanode1_1  | 2022-08-15 20:24:10,034 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-LeaderElection7] INFO impl.RoleInfo: 11946e6e-1ab1-47b6-94a8-e6dbe917e210: start 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-FollowerState
datanode1_1  | 2022-08-15 20:24:10,059 [11946e6e-1ab1-47b6-94a8-e6dbe917e210-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4BEB5C69C54E with new leaderId: e2584860-2683-4862-8eba-daf2ea0fcaee
datanode1_1  | 2022-08-15 20:24:10,059 [11946e6e-1ab1-47b6-94a8-e6dbe917e210-server-thread1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: change Leader from null to e2584860-2683-4862-8eba-daf2ea0fcaee at term 7 for appendEntries, leader elected after 40107ms
datanode1_1  | 2022-08-15 20:24:10,082 [11946e6e-1ab1-47b6-94a8-e6dbe917e210-server-thread1] INFO server.RaftServer$Division: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E: set configuration 0: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-15 20:24:10,083 [11946e6e-1ab1-47b6-94a8-e6dbe917e210-server-thread1] INFO segmented.SegmentedRaftLogWorker: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-08-15 20:24:10,090 [11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 11946e6e-1ab1-47b6-94a8-e6dbe917e210@group-4BEB5C69C54E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e/current/log_inprogress_0
datanode1_1  | 2022-08-15 20:24:56,359 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:941416846787.
datanode1_1  | 2022-08-15 20:36:50,247 [ContainerOp-ee87d8de-c101-4564-aff4-e153e5671e57-7] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 152.
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2022-08-15 20:22:31,069 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = 491064f5c800/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:58Z
datanode3_1  | STARTUP_MSG:   java = 11.0.14.1
datanode3_1  | ************************************************************/
datanode3_1  | 2022-08-15 20:22:31,144 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2022-08-15 20:22:31,581 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2022-08-15 20:22:32,350 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2022-08-15 20:22:33,540 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2022-08-15 20:22:33,541 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2022-08-15 20:22:34,190 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:491064f5c800 ip:172.25.0.104
datanode3_1  | 2022-08-15 20:22:37,701 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2022-08-15 20:22:39,240 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2022-08-15 20:22:39,240 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2022-08-15 20:22:41,774 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2022-08-15 20:22:41,782 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2022-08-15 20:22:41,792 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2022-08-15 20:22:41,794 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2022-08-15 20:22:44,667 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2022-08-15 20:22:44,772 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:491064f5c800
datanode3_1  | 2022-08-15 20:22:44,773 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2022-08-15 20:22:44,801 [main] ERROR client.DNCertificateClient: Invalid domain 491064f5c800
datanode3_1  | 2022-08-15 20:22:44,802 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@491064f5c800
datanode3_1  | 2022-08-15 20:22:50,830 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2022-08-15 20:22:50,951 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2022-08-15 20:22:50,977 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/931151845995.crt.
datanode3_1  | 2022-08-15 20:22:51,000 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-838496351631.crt.
datanode3_1  | 2022-08-15 20:22:51,013 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2022-08-15 20:22:51,211 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode3_1  | 2022-08-15 20:22:52,632 [main] INFO reflections.Reflections: Reflections took 1110 ms to scan 2 urls, producing 89 keys and 198 values 
datanode3_1  | 2022-08-15 20:22:53,181 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode3_1  | 2022-08-15 20:22:54,529 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2022-08-15 20:22:54,690 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode3_1  | 2022-08-15 20:22:54,731 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2022-08-15 20:22:54,747 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2022-08-15 20:22:55,068 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2022-08-15 20:22:55,217 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-08-15 20:22:55,246 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2022-08-15 20:22:55,257 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2022-08-15 20:22:55,264 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2022-08-15 20:22:55,264 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2022-08-15 20:22:55,585 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2022-08-15 20:22:55,615 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2022-08-15 20:23:01,452 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode3_1  | 2022-08-15 20:23:03,110 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-08-15 20:23:03,569 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2022-08-15 20:23:04,614 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2022-08-15 20:23:04,648 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2022-08-15 20:23:04,651 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2022-08-15 20:23:04,658 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2022-08-15 20:23:04,660 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-15 20:23:04,663 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2022-08-15 20:23:04,688 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-08-15 20:23:04,822 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode3_1  | 2022-08-15 20:23:04,834 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode3_1  | 2022-08-15 20:23:11,117 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | 2022-08-15 20:23:11,131 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode3_1  | 2022-08-15 20:23:11,150 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode3_1  | 2022-08-15 20:23:11,152 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-08-15 20:23:11,152 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-08-15 20:23:11,155 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-08-15 20:23:11,696 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode3_1  | 2022-08-15 20:23:12,910 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-08-15 20:23:12,918 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-08-15 20:23:13,420 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2022-08-15 20:23:13,420 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2022-08-15 20:23:13,420 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2022-08-15 20:36:50,247 [ContainerOp-ee87d8de-c101-4564-aff4-e153e5671e57-7] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 152.
datanode1_1  | 2022-08-15 20:36:50,299 [ContainerOp-ee87d8de-c101-4564-aff4-e153e5671e57-7] INFO keyvalue.KeyValueContainer: Container 2 is closed with bcsId 152.
datanode1_1  | 2022-08-15 20:40:41,853 [ContainerOp-4e74fa7e-554b-49cb-895a-4beb5c69c54e-5] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 129.
datanode1_1  | 2022-08-15 20:40:41,854 [ContainerOp-4e74fa7e-554b-49cb-895a-4beb5c69c54e-5] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 129.
datanode1_1  | 2022-08-15 20:40:41,858 [ContainerOp-4e74fa7e-554b-49cb-895a-4beb5c69c54e-5] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 129.
datanode3_1  | 2022-08-15 20:23:13,657 [main] INFO util.log: Logging initialized @54216ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2022-08-15 20:23:14,726 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2022-08-15 20:23:14,803 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2022-08-15 20:23:14,811 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2022-08-15 20:23:14,819 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2022-08-15 20:23:14,819 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2022-08-15 20:23:14,844 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2022-08-15 20:23:15,226 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2022-08-15 20:23:15,241 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode3_1  | 2022-08-15 20:23:15,504 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2022-08-15 20:23:15,505 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2022-08-15 20:23:15,523 [main] INFO server.session: node0 Scavenging every 600000ms
datanode3_1  | 2022-08-15 20:23:15,676 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-08-15 20:23:15,701 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3d837af7{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2022-08-15 20:23:15,710 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1b5a3bba{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2022-08-15 20:23:16,367 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-08-15 20:23:16,452 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@148c571c{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-15586701264429656644/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2022-08-15 20:23:16,537 [main] INFO server.AbstractConnector: Started ServerConnector@34438b38{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2022-08-15 20:23:16,540 [main] INFO server.Server: Started @57099ms
datanode3_1  | 2022-08-15 20:23:16,577 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2022-08-15 20:23:16,580 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2022-08-15 20:23:16,585 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2022-08-15 20:23:16,610 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode3_1  | 2022-08-15 20:23:16,795 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4dfbe053] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2022-08-15 20:23:17,191 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2022-08-15 20:23:17,245 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode3_1  | 2022-08-15 20:23:21,137 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode3_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:298)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:493)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode3_1  | Caused by: java.util.concurrent.TimeoutException
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode3_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode3_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode3_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	... 1 more
datanode3_1  | 2022-08-15 20:23:21,884 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072/DS-60ec4d44-6405-4807-b78e-fcd399dbc165/container.db for volume DS-60ec4d44-6405-4807-b78e-fcd399dbc165
datanode3_1  | 2022-08-15 20:23:21,967 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072/DS-60ec4d44-6405-4807-b78e-fcd399dbc165/container.db for volume DS-60ec4d44-6405-4807-b78e-fcd399dbc165
datanode3_1  | 2022-08-15 20:23:21,977 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2022-08-15 20:23:21,982 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2022-08-15 20:23:22,527 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis e2584860-2683-4862-8eba-daf2ea0fcaee
datanode3_1  | 2022-08-15 20:23:22,688 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: e2584860-2683-4862-8eba-daf2ea0fcaee: start RPC server
datanode3_1  | 2022-08-15 20:23:22,700 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: e2584860-2683-4862-8eba-daf2ea0fcaee: GrpcService started, listening on 9856
datanode3_1  | 2022-08-15 20:23:22,709 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: e2584860-2683-4862-8eba-daf2ea0fcaee: GrpcService started, listening on 9857
datanode3_1  | 2022-08-15 20:23:22,727 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: e2584860-2683-4862-8eba-daf2ea0fcaee: GrpcService started, listening on 9858
datanode3_1  | 2022-08-15 20:23:22,742 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis e2584860-2683-4862-8eba-daf2ea0fcaee is started using port 9858 for RATIS
datanode3_1  | 2022-08-15 20:23:22,745 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis e2584860-2683-4862-8eba-daf2ea0fcaee is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2022-08-15 20:23:22,745 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis e2584860-2683-4862-8eba-daf2ea0fcaee is started using port 9856 for RATIS_SERVER
datanode3_1  | 2022-08-15 20:23:22,745 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$391/0x00000008405e6c40@4b31091f] INFO util.JvmPauseMonitor: JvmPauseMonitor-e2584860-2683-4862-8eba-daf2ea0fcaee: Started
datanode3_1  | 2022-08-15 20:23:22,801 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-08-15 20:23:22,801 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-08-15 20:23:23,965 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$391/0x00000008405e6c40@4b31091f] WARN util.JvmPauseMonitor: JvmPauseMonitor-e2584860-2683-4862-8eba-daf2ea0fcaee: Detected pause in JVM or host machine (eg GC): pause of approximately 111502432ns.
datanode3_1  | GC pool 'ParNew' had collection(s): count=1 time=154ms
datanode3_1  | 2022-08-15 20:23:38,796 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: e2584860-2683-4862-8eba-daf2ea0fcaee: Failed requestVote ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f->e2584860-2683-4862-8eba-daf2ea0fcaee#0
datanode3_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: e2584860-2683-4862-8eba-daf2ea0fcaee: group-4BEB5C69C54E not found.
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:148)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:347)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:356)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:351)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:603)
datanode3_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode3_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:382)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:340)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:866)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode3_1  | 2022-08-15 20:23:38,799 [grpc-default-executor-2] WARN server.GrpcServerProtocolService: e2584860-2683-4862-8eba-daf2ea0fcaee: Failed requestVote 11946e6e-1ab1-47b6-94a8-e6dbe917e210->e2584860-2683-4862-8eba-daf2ea0fcaee#0
datanode3_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: e2584860-2683-4862-8eba-daf2ea0fcaee: group-4BEB5C69C54E not found.
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:148)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:347)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:356)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:351)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:603)
datanode3_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode3_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:382)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:340)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:866)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode2_1  | 2022-08-15 20:23:24,486 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f is started using port 9856 for RATIS_SERVER
datanode2_1  | 2022-08-15 20:23:24,496 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$392/0x00000008405e6040@5f535e29] INFO util.JvmPauseMonitor: JvmPauseMonitor-ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: Started
datanode2_1  | 2022-08-15 20:23:24,561 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-08-15 20:23:24,561 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-08-15 20:23:29,021 [Command processor thread] INFO server.RaftServer: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: addNew group-BC27D48F5863:[ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-BC27D48F5863:java.util.concurrent.CompletableFuture@46149d21[Not completed]
datanode2_1  | 2022-08-15 20:23:29,238 [pool-23-thread-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: new RaftServerImpl for group-BC27D48F5863:[ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-08-15 20:23:29,273 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-08-15 20:23:29,280 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-08-15 20:23:29,292 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-08-15 20:23:29,304 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-08-15 20:23:29,305 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-08-15 20:23:29,305 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-08-15 20:23:29,368 [pool-23-thread-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863: ConfigurationManager, init=-1: [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-08-15 20:23:29,369 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-08-15 20:23:29,402 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-08-15 20:23:29,433 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-08-15 20:23:29,437 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/d9c5810d-5123-4bc2-bd6e-bc27d48f5863 does not exist. Creating ...
datanode2_1  | 2022-08-15 20:23:29,488 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/d9c5810d-5123-4bc2-bd6e-bc27d48f5863/in_use.lock acquired by nodename 6@004775ef3c0f
datanode2_1  | 2022-08-15 20:23:29,524 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/d9c5810d-5123-4bc2-bd6e-bc27d48f5863 has been successfully formatted.
datanode2_1  | 2022-08-15 20:23:29,564 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BC27D48F5863: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-08-15 20:23:29,602 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-08-15 20:23:29,605 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-08-15 20:23:29,712 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-08-15 20:23:29,716 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-15 20:23:29,718 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-08-15 20:23:29,945 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-15 20:23:30,012 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-08-15 20:23:30,015 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-08-15 20:23:30,038 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/d9c5810d-5123-4bc2-bd6e-bc27d48f5863
datanode2_1  | 2022-08-15 20:23:30,054 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-08-15 20:23:30,062 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-08-15 20:23:30,069 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-15 20:23:30,069 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-08-15 20:23:30,072 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-08-15 20:23:30,073 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-08-15 20:23:30,076 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-08-15 20:23:30,077 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-08-15 20:23:30,118 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-08-15 20:23:30,123 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-08-15 20:23:30,124 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-08-15 20:23:30,150 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-15 20:23:30,151 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-15 20:23:30,190 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-08-15 20:23:30,197 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-08-15 20:23:30,199 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-08-15 20:23:30,202 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-08-15 20:23:30,205 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-08-15 20:23:30,212 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-08-15 20:23:30,422 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-15 20:23:30,440 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-08-15 20:23:30,440 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-08-15 20:23:30,441 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-08-15 20:23:30,441 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-08-15 20:23:30,442 [pool-23-thread-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863: start as a follower, conf=-1: [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-08-15 20:23:30,448 [pool-23-thread-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-08-15 20:23:30,449 [pool-23-thread-1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-FollowerState
datanode2_1  | 2022-08-15 20:23:30,485 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BC27D48F5863,id=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
datanode2_1  | 2022-08-15 20:23:30,578 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=d9c5810d-5123-4bc2-bd6e-bc27d48f5863
datanode2_1  | 2022-08-15 20:23:30,580 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=d9c5810d-5123-4bc2-bd6e-bc27d48f5863.
datanode2_1  | 2022-08-15 20:23:30,582 [Command processor thread] INFO server.RaftServer: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: addNew group-4BEB5C69C54E:[11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0] returns group-4BEB5C69C54E:java.util.concurrent.CompletableFuture@112b28f7[Not completed]
datanode2_1  | 2022-08-15 20:23:30,611 [pool-23-thread-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: new RaftServerImpl for group-4BEB5C69C54E:[11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-08-15 20:23:30,618 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-08-15 20:23:30,619 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-08-15 20:23:30,619 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-08-15 20:23:30,623 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-08-15 20:23:30,625 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-08-15 20:23:30,634 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-08-15 20:23:30,635 [pool-23-thread-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: ConfigurationManager, init=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-08-15 20:23:30,636 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-08-15 20:23:30,637 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-08-15 20:23:30,644 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-08-15 20:23:30,648 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e does not exist. Creating ...
datanode2_1  | 2022-08-15 20:23:30,650 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e/in_use.lock acquired by nodename 6@004775ef3c0f
datanode2_1  | 2022-08-15 20:23:30,659 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e has been successfully formatted.
datanode2_1  | 2022-08-15 20:23:30,660 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-4BEB5C69C54E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-08-15 20:23:30,661 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-08-15 20:23:30,681 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-08-15 20:23:30,686 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-08-15 20:23:30,690 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-15 20:23:30,693 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-08-15 20:23:30,695 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-15 20:23:30,695 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-08-15 20:23:30,704 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-08-15 20:23:30,706 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e
datanode2_1  | 2022-08-15 20:23:30,720 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-08-15 20:23:30,720 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-08-15 20:23:30,720 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-15 20:23:30,720 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-08-15 20:23:30,720 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-08-15 20:23:30,721 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-08-15 20:23:30,721 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-08-15 20:23:30,724 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-08-15 20:23:30,725 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-08-15 20:23:30,728 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-08-15 20:23:30,728 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-08-15 20:23:30,728 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-15 20:23:30,729 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-15 20:23:30,743 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-08-15 20:23:30,744 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-08-15 20:23:30,745 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-08-15 20:23:30,745 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-08-15 20:23:30,745 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-08-15 20:23:30,747 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-08-15 20:23:30,748 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-15 20:23:30,756 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-08-15 20:23:30,756 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-08-15 20:23:30,756 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-08-15 20:23:30,756 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-08-15 20:23:30,757 [pool-23-thread-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: start as a follower, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-15 20:23:30,757 [pool-23-thread-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-08-15 20:23:30,757 [pool-23-thread-1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
datanode2_1  | 2022-08-15 20:23:30,767 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4BEB5C69C54E,id=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
datanode2_1  | 2022-08-15 20:23:30,779 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e
datanode2_1  | 2022-08-15 20:23:35,598 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-FollowerState] INFO impl.FollowerState: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5149543365ns, electionTimeout:5103ms
datanode2_1  | 2022-08-15 20:23:35,599 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-FollowerState] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: shutdown ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-FollowerState
datanode2_1  | 2022-08-15 20:23:35,616 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-FollowerState] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-08-15 20:23:35,624 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-15 20:23:35,631 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-FollowerState] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1
datanode2_1  | 2022-08-15 20:23:35,672 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO impl.LeaderElection: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-08-15 20:23:35,682 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO impl.LeaderElection: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2022-08-15 20:23:35,689 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: shutdown ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1
datanode2_1  | 2022-08-15 20:23:35,693 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-08-15 20:23:35,697 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BC27D48F5863 with new leaderId: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
datanode2_1  | 2022-08-15 20:23:35,726 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863: change Leader from null to ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f at term 1 for becomeLeader, leader elected after 6111ms
datanode2_1  | 2022-08-15 20:23:35,779 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-08-15 20:23:35,828 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-08-15 20:23:35,839 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-08-15 20:23:35,866 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-08-15 20:23:35,869 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-08-15 20:23:39,131 [grpc-default-executor-3] INFO server.RaftServer: e2584860-2683-4862-8eba-daf2ea0fcaee: addNew group-4BEB5C69C54E:[11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] returns group-4BEB5C69C54E:java.util.concurrent.CompletableFuture@17518dd2[Not completed]
datanode3_1  | 2022-08-15 20:23:39,362 [pool-23-thread-1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee: new RaftServerImpl for group-4BEB5C69C54E:[11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-08-15 20:23:39,384 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-08-15 20:23:39,386 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-08-15 20:23:39,386 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-08-15 20:23:39,386 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-08-15 20:23:39,386 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-08-15 20:23:39,388 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-08-15 20:23:39,436 [pool-23-thread-1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: ConfigurationManager, init=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-08-15 20:23:39,447 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-08-15 20:23:39,455 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-08-15 20:23:39,472 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-08-15 20:23:39,481 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e does not exist. Creating ...
datanode3_1  | 2022-08-15 20:23:39,518 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e/in_use.lock acquired by nodename 9@491064f5c800
datanode3_1  | 2022-08-15 20:23:39,575 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e has been successfully formatted.
datanode3_1  | 2022-08-15 20:23:39,867 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-4BEB5C69C54E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-08-15 20:23:39,899 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-08-15 20:23:39,953 [grpc-default-executor-0] INFO server.RaftServer: e2584860-2683-4862-8eba-daf2ea0fcaee: addNew group-E153E5671E57:[11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1] returns group-E153E5671E57:java.util.concurrent.CompletableFuture@5c806cff[Not completed]
datanode3_1  | 2022-08-15 20:23:39,961 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-08-15 20:23:40,099 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-08-15 20:23:40,168 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-15 20:23:40,214 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-08-15 20:23:40,217 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-15 20:23:40,297 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-08-15 20:23:40,302 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-08-15 20:23:40,319 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e
datanode3_1  | 2022-08-15 20:23:40,323 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-08-15 20:23:40,324 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-08-15 20:23:40,332 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-15 20:23:40,333 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-08-15 20:23:40,334 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-08-15 20:23:40,335 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-08-15 20:23:40,335 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-08-15 20:23:40,338 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-08-15 20:23:40,400 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-08-15 20:23:40,411 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-08-15 20:23:40,412 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-08-15 20:23:40,463 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-15 20:23:40,464 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-15 20:23:40,477 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-08-15 20:23:40,508 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-08-15 20:23:35,907 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-08-15 20:23:35,951 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5193578629ns, electionTimeout:5154ms
datanode2_1  | 2022-08-15 20:23:35,985 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: shutdown ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
datanode2_1  | 2022-08-15 20:23:35,986 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-08-15 20:23:35,988 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-15 20:23:35,988 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2
datanode2_1  | 2022-08-15 20:23:36,059 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-08-15 20:23:36,060 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2] INFO impl.LeaderElection: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-15 20:23:36,139 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-08-15 20:23:36,163 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderStateImpl
datanode2_1  | 2022-08-15 20:23:36,776 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-08-15 20:23:36,961 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: receive requestVote(ELECTION, 11946e6e-1ab1-47b6-94a8-e6dbe917e210, group-4BEB5C69C54E, 1, (t:0, i:0))
datanode2_1  | 2022-08-15 20:23:36,987 [grpc-default-executor-1] INFO impl.VoteContext: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-CANDIDATE: reject ELECTION from 11946e6e-1ab1-47b6-94a8-e6dbe917e210: already has voted for ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f at current term 1
datanode2_1  | 2022-08-15 20:23:37,005 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E replies to ELECTION vote request: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f#0:FAIL-t1. Peer's state: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E:t1, leader=null, voted=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, raftlog=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-15 20:23:37,316 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-LeaderElection1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863: set configuration 0: [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-08-15 20:23:37,906 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-BC27D48F5863-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/d9c5810d-5123-4bc2-bd6e-bc27d48f5863/current/log_inprogress_0
datanode2_1  | 2022-08-15 20:23:39,008 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2] INFO impl.LeaderElection: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: e2584860-2683-4862-8eba-daf2ea0fcaee: group-4BEB5C69C54E not found.
datanode2_1  | 2022-08-15 20:23:39,008 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2] INFO impl.LeaderElection: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2: ELECTION REJECTED received 1 response(s) and 1 exception(s):
datanode2_1  | 2022-08-15 20:23:39,009 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2] INFO impl.LeaderElection:   Response 0: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f<-11946e6e-1ab1-47b6-94a8-e6dbe917e210#0:FAIL-t1
datanode2_1  | 2022-08-15 20:23:39,009 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: e2584860-2683-4862-8eba-daf2ea0fcaee: group-4BEB5C69C54E not found.
datanode2_1  | 2022-08-15 20:23:39,009 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2] INFO impl.LeaderElection: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2 ELECTION round 0: result REJECTED
datanode2_1  | 2022-08-15 20:23:39,015 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode2_1  | 2022-08-15 20:23:39,016 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: shutdown ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2
datanode2_1  | 2022-08-15 20:23:39,016 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection2] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
datanode2_1  | 2022-08-15 20:23:39,215 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e.
datanode2_1  | 2022-08-15 20:23:39,216 [Command processor thread] INFO server.RaftServer: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: addNew group-E153E5671E57:[11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-E153E5671E57:java.util.concurrent.CompletableFuture@361a0eac[Not completed]
datanode3_1  | 2022-08-15 20:23:40,512 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-08-15 20:23:40,513 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-08-15 20:23:40,521 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-08-15 20:23:40,531 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-08-15 20:23:40,761 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-08-15 20:23:40,764 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-08-15 20:23:40,767 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-08-15 20:23:40,768 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-08-15 20:23:40,782 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-08-15 20:23:40,800 [pool-23-thread-1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee: new RaftServerImpl for group-E153E5671E57:[11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-08-15 20:23:40,801 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-08-15 20:23:40,801 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-08-15 20:23:40,804 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-08-15 20:23:40,812 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-08-15 20:23:40,816 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-08-15 20:23:40,817 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-08-15 20:23:40,817 [pool-23-thread-1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57: ConfigurationManager, init=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-08-15 20:23:40,817 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-08-15 20:23:40,817 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-08-15 20:23:40,819 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-08-15 20:23:40,820 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57 does not exist. Creating ...
datanode3_1  | 2022-08-15 20:23:40,831 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57/in_use.lock acquired by nodename 9@491064f5c800
datanode3_1  | 2022-08-15 20:23:40,836 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57 has been successfully formatted.
datanode3_1  | 2022-08-15 20:23:40,837 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-E153E5671E57: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-08-15 20:23:40,838 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-08-15 20:23:40,861 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-08-15 20:23:40,863 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-08-15 20:23:40,867 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-15 20:23:40,867 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-08-15 20:23:40,868 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-15 20:23:40,872 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-08-15 20:23:40,875 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-08-15 20:23:40,876 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57
datanode3_1  | 2022-08-15 20:23:40,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-08-15 20:23:40,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-08-15 20:23:40,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-15 20:23:40,877 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-08-15 20:23:40,877 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-08-15 20:23:40,877 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-08-15 20:23:40,877 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-08-15 20:23:40,877 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-08-15 20:23:40,878 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-08-15 20:23:40,904 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-08-15 20:23:40,905 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-08-15 20:23:40,910 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-15 20:23:40,917 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-15 20:23:40,919 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-08-15 20:23:40,920 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-08-15 20:23:40,920 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-08-15 20:23:40,920 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-08-15 20:23:40,925 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-08-15 20:23:40,926 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-08-15 20:23:40,932 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-08-15 20:23:40,934 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-08-15 20:23:40,935 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-08-15 20:23:40,936 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-08-15 20:23:40,939 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-08-15 20:23:40,941 [pool-23-thread-1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: start as a follower, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-15 20:23:40,953 [pool-23-thread-1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-08-15 20:23:40,957 [pool-23-thread-1] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: start e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState
datanode3_1  | 2022-08-15 20:23:40,996 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4BEB5C69C54E,id=e2584860-2683-4862-8eba-daf2ea0fcaee
datanode3_1  | 2022-08-15 20:23:41,044 [pool-23-thread-1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57: start as a follower, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-08-15 20:23:41,047 [pool-23-thread-1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-08-15 20:23:41,047 [pool-23-thread-1] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: start e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57-FollowerState
datanode3_1  | 2022-08-15 20:23:41,051 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E153E5671E57,id=e2584860-2683-4862-8eba-daf2ea0fcaee
datanode3_1  | 2022-08-15 20:23:44,101 [grpc-default-executor-0] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: receive requestVote(ELECTION, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, group-4BEB5C69C54E, 2, (t:0, i:0))
datanode3_1  | 2022-08-15 20:23:44,108 [grpc-default-executor-0] INFO impl.VoteContext: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FOLLOWER: reject ELECTION from ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: our priority 1 > candidate's priority 0
datanode3_1  | 2022-08-15 20:23:44,109 [grpc-default-executor-0] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
datanode3_1  | 2022-08-15 20:23:44,109 [grpc-default-executor-0] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: shutdown e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState
datanode3_1  | 2022-08-15 20:23:44,111 [grpc-default-executor-0] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: start e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState
datanode3_1  | 2022-08-15 20:23:44,111 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState was interrupted
datanode3_1  | 2022-08-15 20:23:44,120 [grpc-default-executor-0] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E replies to ELECTION vote request: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f<-e2584860-2683-4862-8eba-daf2ea0fcaee#0:FAIL-t2. Peer's state: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E:t2, leader=null, voted=null, raftlog=e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-15 20:23:44,438 [grpc-default-executor-0] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57: receive requestVote(ELECTION, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, group-E153E5671E57, 1, (t:0, i:0))
datanode3_1  | 2022-08-15 20:23:44,438 [grpc-default-executor-0] INFO impl.VoteContext: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57-FOLLOWER: accept ELECTION from ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: our priority 0 <= candidate's priority 1
datanode3_1  | 2022-08-15 20:23:44,438 [grpc-default-executor-0] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
datanode3_1  | 2022-08-15 20:23:44,438 [grpc-default-executor-0] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: shutdown e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57-FollowerState
datanode3_1  | 2022-08-15 20:23:44,439 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57-FollowerState] INFO impl.FollowerState: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57-FollowerState was interrupted
datanode3_1  | 2022-08-15 20:23:44,439 [grpc-default-executor-0] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: start e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57-FollowerState
kdc_1        | Aug 15 20:20:50 kdc krb5kdc[8](info): Loaded
kdc_1        | Aug 15 20:20:50 kdc krb5kdc[8](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Aug 15 20:20:50 kdc krb5kdc[8](info): setting up network...
kdc_1        | Aug 15 20:20:50 kdc krb5kdc[8](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Aug 15 20:20:50 kdc krb5kdc[8](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Aug 15 20:20:50 kdc krb5kdc[8](info): set up 4 sockets
kdc_1        | Aug 15 20:20:50 kdc krb5kdc[8](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Aug 15 20:20:53 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660594853, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:20:59 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660594859, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:21:02 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.114: ISSUE: authtime 1660594862, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:21:08 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.115: ISSUE: authtime 1660594868, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:21:20 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1660594880, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:21:26 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1660594886, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:21:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1660594868, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:21:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660594880, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:21:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660594859, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:21:46 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1660594906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:21:46 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660594906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:21:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660594906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:21:58 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660594906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:22:01 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660594921, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:22:03 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1660594923, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:22:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1660594923, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:22:09 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660594921, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:22:11 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1660594931, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:22:14 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660594934, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:22:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1660594931, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:22:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660594934, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:22:38 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1660594958, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:22:38 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1660594958, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:22:39 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1660594959, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:22:39 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660594959, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:22:42 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1660594962, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:22:43 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1660594963, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:22:43 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1660594963, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:22:46 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1660594962, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:22:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1660594963, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:22:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1660594963, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:22:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1660594958, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:22:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1660594958, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:22:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1660594959, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:23:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660594959, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:23:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1660594958, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Aug 15 20:23:19 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1660594958, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Aug 15 20:23:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1660594959, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Aug 15 20:23:24 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595004, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:23:26 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1660595006, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:23:29 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1660595009, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:23:29 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1660595009, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:23:30 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1660595006, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:23:33 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1660595009, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:23:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1660595009, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:23:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595004, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:23:55 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595035, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:24:00 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1660594868, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:24:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595035, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:24:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:24:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:24:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:24:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:24:17 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:24:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:24:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:24:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:24:45 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:24:50 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:25:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:25:09 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:25:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:25:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:25:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:25:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:25:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:25:37 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:25:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:25:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:26:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:26:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:26:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:26:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:26:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:26:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:26:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:26:30 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:26:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:26:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:26:44 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:26:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-08-15 20:22:31,242 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:59Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-08-15 20:22:31,313 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-08-15 20:22:39,161 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-08-15 20:22:41,744 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-08-15 20:22:42,248 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-08-15 20:22:42,252 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-08-15 20:22:42,263 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-08-15 20:22:44,194 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-08-15 20:22:44,194 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-08-15 20:22:44,294 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-08-15 20:22:45,256 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-08-15 20:22:48,003 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2022-08-15 20:22:51,527 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2022-08-15 20:22:51,529 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2022-08-15 20:22:51,542 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2022-08-15 20:22:59,264 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2022-08-15 20:22:59,650 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2022-08-15 20:22:59,683 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2022-08-15 20:22:59,724 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2022-08-15 20:22:59,731 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-08-15 20:22:59,743 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-08-15 20:22:59,743 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-08-15 20:22:59,751 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-08-15 20:22:59,762 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:17440e9e-0b34-4cd8-8102-cb903e52057d,clusterId:CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072,subject:om2
om2_1        | 2022-08-15 20:23:00,996 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2022-08-15 20:23:03,029 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072;layoutVersion=3
om2_1        | 2022-08-15 20:23:03,238 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
datanode2_1  | 2022-08-15 20:23:39,218 [pool-23-thread-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: new RaftServerImpl for group-E153E5671E57:[11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-08-15 20:23:39,219 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-08-15 20:23:39,219 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-08-15 20:23:39,219 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-08-15 20:23:39,219 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-08-15 20:23:39,219 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-08-15 20:23:39,219 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-08-15 20:23:39,221 [pool-23-thread-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57: ConfigurationManager, init=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-08-15 20:23:39,223 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-08-15 20:23:39,226 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-08-15 20:23:39,227 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-08-15 20:23:39,228 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57 does not exist. Creating ...
datanode2_1  | 2022-08-15 20:23:39,235 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57/in_use.lock acquired by nodename 6@004775ef3c0f
datanode2_1  | 2022-08-15 20:23:39,243 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57 has been successfully formatted.
datanode2_1  | 2022-08-15 20:23:39,244 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-E153E5671E57: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-08-15 20:23:39,250 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-08-15 20:23:39,286 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-08-15 20:23:39,286 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-08-15 20:23:39,286 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-15 20:23:39,286 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-08-15 20:23:39,297 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-15 20:23:39,303 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-08-15 20:23:39,312 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-08-15 20:23:39,316 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57
datanode2_1  | 2022-08-15 20:23:39,322 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-08-15 20:23:39,322 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-08-15 20:23:39,322 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-15 20:23:39,322 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-08-15 20:23:39,322 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-08-15 20:23:39,322 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-08-15 20:23:39,326 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-08-15 20:23:39,326 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-08-15 20:23:39,331 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-08-15 20:23:39,331 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-08-15 20:23:39,342 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-08-15 20:23:39,343 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-15 20:23:39,343 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-15 20:23:39,350 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-08-15 20:23:39,350 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-08-15 20:23:39,350 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-08-15 20:23:39,350 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-08-15 20:23:39,351 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-08-15 20:23:39,352 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-08-15 20:23:39,360 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-15 20:23:39,360 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-08-15 20:23:39,361 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-08-15 20:23:39,362 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
kdc_1        | Aug 15 20:26:54 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:26:58 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:26:59 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595219, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:27:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595219, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:27:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595219, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:27:09 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595229, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:27:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595229, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:27:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:27:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:27:17 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595229, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:27:22 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595229, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-08-15 20:22:30,231 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
kdc_1        | Aug 15 20:27:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595229, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:27:34 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595254, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:27:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595254, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:27:45 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595254, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:27:49 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595269, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:27:53 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595269, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:27:58 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595269, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:27:59 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595279, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:28:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595279, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:28:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595279, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:28:09 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595289, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:28:12 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595289, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:28:14 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:28:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:28:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:28:17 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:28:18 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595298, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:28:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595298, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode3_1  | 2022-08-15 20:23:44,455 [grpc-default-executor-0] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57 replies to ELECTION vote request: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f<-e2584860-2683-4862-8eba-daf2ea0fcaee#0:OK-t1. Peer's state: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57:t1, leader=null, voted=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, raftlog=e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-08-15 20:23:44,828 [e2584860-2683-4862-8eba-daf2ea0fcaee-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-E153E5671E57 with new leaderId: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
datanode3_1  | 2022-08-15 20:23:44,833 [e2584860-2683-4862-8eba-daf2ea0fcaee-server-thread1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57: change Leader from null to ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f at term 1 for appendEntries, leader elected after 3990ms
datanode3_1  | 2022-08-15 20:23:44,927 [e2584860-2683-4862-8eba-daf2ea0fcaee-server-thread1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57: set configuration 0: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-08-15 20:23:44,964 [e2584860-2683-4862-8eba-daf2ea0fcaee-server-thread1] INFO segmented.SegmentedRaftLogWorker: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-08-15 20:23:45,260 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e2584860-2683-4862-8eba-daf2ea0fcaee@group-E153E5671E57-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57/current/log_inprogress_0
datanode3_1  | 2022-08-15 20:23:49,179 [grpc-default-executor-0] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: receive requestVote(ELECTION, 11946e6e-1ab1-47b6-94a8-e6dbe917e210, group-4BEB5C69C54E, 3, (t:0, i:0))
datanode3_1  | 2022-08-15 20:23:49,180 [grpc-default-executor-0] INFO impl.VoteContext: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FOLLOWER: reject ELECTION from 11946e6e-1ab1-47b6-94a8-e6dbe917e210: our priority 1 > candidate's priority 0
datanode3_1  | 2022-08-15 20:23:49,180 [grpc-default-executor-0] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:11946e6e-1ab1-47b6-94a8-e6dbe917e210
datanode3_1  | 2022-08-15 20:23:49,180 [grpc-default-executor-0] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: shutdown e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState
datanode3_1  | 2022-08-15 20:23:49,180 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState was interrupted
datanode3_1  | 2022-08-15 20:23:49,180 [grpc-default-executor-0] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: start e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState
datanode3_1  | 2022-08-15 20:23:49,184 [grpc-default-executor-0] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E replies to ELECTION vote request: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-e2584860-2683-4862-8eba-daf2ea0fcaee#0:FAIL-t3. Peer's state: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E:t3, leader=null, voted=null, raftlog=e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-15 20:23:54,270 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5089688902ns, electionTimeout:5087ms
datanode3_1  | 2022-08-15 20:23:54,271 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: shutdown e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState
datanode3_1  | 2022-08-15 20:23:54,271 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode3_1  | 2022-08-15 20:23:54,274 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-08-15 20:23:54,274 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: start e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection1
datanode3_1  | 2022-08-15 20:23:54,282 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection1] INFO impl.LeaderElection: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection1 ELECTION round 0: submit vote requests at term 4 for -1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-15 20:23:54,421 [grpc-default-executor-0] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: receive requestVote(ELECTION, 11946e6e-1ab1-47b6-94a8-e6dbe917e210, group-4BEB5C69C54E, 4, (t:0, i:0))
datanode3_1  | 2022-08-15 20:23:54,421 [grpc-default-executor-0] INFO impl.VoteContext: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-CANDIDATE: reject ELECTION from 11946e6e-1ab1-47b6-94a8-e6dbe917e210: already has voted for e2584860-2683-4862-8eba-daf2ea0fcaee at current term 4
datanode3_1  | 2022-08-15 20:23:54,421 [grpc-default-executor-0] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E replies to ELECTION vote request: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-e2584860-2683-4862-8eba-daf2ea0fcaee#0:FAIL-t4. Peer's state: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E:t4, leader=null, voted=e2584860-2683-4862-8eba-daf2ea0fcaee, raftlog=e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-15 20:23:54,711 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$391/0x00000008405e6c40@4b31091f] WARN util.JvmPauseMonitor: JvmPauseMonitor-e2584860-2683-4862-8eba-daf2ea0fcaee: Detected pause in JVM or host machine (eg GC): pause of approximately 138525647ns.
datanode3_1  | GC pool 'ParNew' had collection(s): count=1 time=142ms
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:59Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-08-15 20:22:30,307 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-08-15 20:22:37,234 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-08-15 20:22:40,343 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-08-15 20:22:40,948 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-08-15 20:22:40,952 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-08-15 20:22:40,954 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-08-15 20:22:42,925 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-08-15 20:22:42,931 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-08-15 20:22:43,028 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-08-15 20:22:43,907 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-08-15 20:22:46,743 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2022-08-15 20:22:50,762 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2022-08-15 20:22:50,763 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2022-08-15 20:22:50,779 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2022-08-15 20:22:56,422 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2022-08-15 20:22:56,669 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2022-08-15 20:22:56,672 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2022-08-15 20:22:56,696 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2022-08-15 20:22:56,708 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-08-15 20:22:56,710 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-08-15 20:22:56,718 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-08-15 20:22:56,725 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-08-15 20:22:56,736 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:17440e9e-0b34-4cd8-8102-cb903e52057d,clusterId:CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072,subject:om1
om1_1        | 2022-08-15 20:22:58,189 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2022-08-15 20:23:00,067 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072;layoutVersion=3
om1_1        | 2022-08-15 20:23:00,328 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-08-15 20:23:11,750 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
kdc_1        | Aug 15 20:28:27 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595298, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:28:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595298, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:28:37 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595298, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:28:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595298, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:28:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595298, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:28:48 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595328, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:28:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595328, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:28:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595328, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:29:02 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595328, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:29:06 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595328, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:29:07 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595347, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:29:07 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595347, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:29:11 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595347, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:29:12 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595352, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:29:12 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595352, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:29:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:29:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
datanode3_1  | 2022-08-15 20:23:56,303 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection1] INFO impl.LeaderElection: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-08-15 20:23:56,316 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection1] INFO impl.LeaderElection:   Response 0: e2584860-2683-4862-8eba-daf2ea0fcaee<-11946e6e-1ab1-47b6-94a8-e6dbe917e210#0:FAIL-t4
datanode3_1  | 2022-08-15 20:23:56,316 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection1] INFO impl.LeaderElection:   Response 1: e2584860-2683-4862-8eba-daf2ea0fcaee<-ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f#0:FAIL-t4
datanode3_1  | 2022-08-15 20:23:56,317 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection1] INFO impl.LeaderElection: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection1 ELECTION round 0: result REJECTED
datanode3_1  | 2022-08-15 20:23:56,318 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode3_1  | 2022-08-15 20:23:56,322 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection1] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: shutdown e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection1
datanode3_1  | 2022-08-15 20:23:56,326 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection1] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: start e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState
datanode3_1  | 2022-08-15 20:23:56,341 [pool-23-thread-1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee: new RaftServerImpl for group-8E6307B8CDA8:[e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-08-15 20:23:56,332 [Command processor thread] INFO server.RaftServer: e2584860-2683-4862-8eba-daf2ea0fcaee: addNew group-8E6307B8CDA8:[e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-8E6307B8CDA8:java.util.concurrent.CompletableFuture@506232a[Not completed]
datanode3_1  | 2022-08-15 20:23:56,350 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-08-15 20:23:56,351 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-08-15 20:23:56,351 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-08-15 20:23:56,351 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-08-15 20:23:56,351 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-08-15 20:23:56,351 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-08-15 20:23:56,352 [pool-23-thread-1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8: ConfigurationManager, init=-1: [e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-08-15 20:23:56,352 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-08-15 20:23:56,352 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-08-15 20:23:56,355 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-08-15 20:23:56,355 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/8115b5cd-243e-460c-8d63-8e6307b8cda8 does not exist. Creating ...
datanode3_1  | 2022-08-15 20:23:56,365 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/8115b5cd-243e-460c-8d63-8e6307b8cda8/in_use.lock acquired by nodename 9@491064f5c800
datanode3_1  | 2022-08-15 20:23:56,370 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/8115b5cd-243e-460c-8d63-8e6307b8cda8 has been successfully formatted.
datanode3_1  | 2022-08-15 20:23:56,389 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-8E6307B8CDA8: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-08-15 20:23:56,458 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-08-15 20:23:56,460 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-08-15 20:23:56,484 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-08-15 20:23:56,485 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-15 20:23:56,488 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-08-15 20:23:56,488 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-15 20:23:56,492 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-08-15 20:23:56,499 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-08-15 20:23:56,499 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/8115b5cd-243e-460c-8d63-8e6307b8cda8
datanode3_1  | 2022-08-15 20:23:56,499 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-08-15 20:23:56,500 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-08-15 20:23:56,501 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-15 20:23:56,501 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-08-15 20:23:56,514 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-08-15 20:23:56,514 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-08-15 20:23:56,514 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-08-15 20:23:56,514 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-08-15 20:23:56,515 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-08-15 20:23:56,521 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-08-15 20:23:56,550 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-08-15 20:23:56,558 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-15 20:23:56,558 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:59Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-08-15 20:23:11,830 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-08-15 20:23:18,822 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-08-15 20:23:22,214 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-08-15 20:23:22,941 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-08-15 20:23:22,941 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-08-15 20:23:22,945 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-08-15 20:23:23,133 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-08-15 20:23:23,925 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om1_1        | 2022-08-15 20:23:26,213 [main] INFO reflections.Reflections: Reflections took 1436 ms to scan 1 urls, producing 113 keys and 334 values [using 2 cores]
om1_1        | 2022-08-15 20:23:27,128 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-08-15 20:23:27,128 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-08-15 20:23:27,129 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-08-15 20:23:29,842 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-08-15 20:23:30,100 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-08-15 20:23:34,988 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2022-08-15 20:23:35,837 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2022-08-15 20:23:35,873 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/941416846787.crt.
om1_1        | 2022-08-15 20:23:35,908 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-838496351631.crt.
om1_1        | 2022-08-15 20:23:36,181 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-08-15 20:23:37,393 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-08-15 20:23:37,395 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-08-15 20:23:39,131 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om1_1        | 2022-08-15 20:23:39,202 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2022-08-15 20:23:39,202 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2022-08-15 20:23:40,121 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om1_1        | 2022-08-15 20:23:40,830 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-08-15 20:23:40,844 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2022-08-15 20:23:40,945 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2022-08-15 20:23:41,884 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2022-08-15 20:23:41,922 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-08-15 20:23:42,144 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om1:9872, om3:9872, om2:9872
om1_1        | 2022-08-15 20:23:42,233 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1        | 2022-08-15 20:23:43,781 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2022-08-15 20:23:44,581 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2022-08-15 20:23:44,591 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-08-15 20:23:44,595 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2022-08-15 20:23:44,609 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-08-15 20:23:44,610 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-08-15 20:23:44,613 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2022-08-15 20:23:44,646 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-08-15 20:23:44,662 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2022-08-15 20:23:44,667 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-08-15 20:23:44,810 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om1_1        | 2022-08-15 20:23:44,812 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om1_1        | 2022-08-15 20:23:47,531 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2022-08-15 20:23:47,570 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om1_1        | 2022-08-15 20:23:47,573 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om1_1        | 2022-08-15 20:23:47,575 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-08-15 20:23:47,576 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-08-15 20:23:47,599 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-08-15 20:23:47,659 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@18cb7c6[Not completed]
om1_1        | 2022-08-15 20:23:47,666 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2022-08-15 20:23:47,761 [pool-27-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2022-08-15 20:23:47,769 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2022-08-15 20:23:47,773 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2022-08-15 20:23:47,774 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2022-08-15 20:23:47,776 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-08-15 20:23:47,777 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-08-15 20:23:47,780 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2022-08-15 20:23:47,796 [main] INFO om.OzoneManager: Creating RPC Server
om1_1        | 2022-08-15 20:23:47,837 [pool-27-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2022-08-15 20:23:47,844 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-08-15 20:23:47,868 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2022-08-15 20:23:47,878 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1        | 2022-08-15 20:23:47,930 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2022-08-15 20:23:48,075 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om1
om1_1        | 2022-08-15 20:23:48,205 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2022-08-15 20:23:48,225 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2022-08-15 20:23:48,233 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2022-08-15 20:23:48,282 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2022-08-15 20:23:48,288 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-08-15 20:23:48,290 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om1_1        | 2022-08-15 20:23:48,374 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
datanode2_1  | 2022-08-15 20:23:39,364 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-08-15 20:23:39,367 [pool-23-thread-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57: start as a follower, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-08-15 20:23:39,367 [pool-23-thread-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-08-15 20:23:39,367 [pool-23-thread-1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-FollowerState
datanode2_1  | 2022-08-15 20:23:39,377 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E153E5671E57,id=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
datanode2_1  | 2022-08-15 20:23:39,381 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=ee87d8de-c101-4564-aff4-e153e5671e57
datanode2_1  | 2022-08-15 20:23:41,851 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=ee87d8de-c101-4564-aff4-e153e5671e57.
datanode2_1  | 2022-08-15 20:23:44,058 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5042328701ns, electionTimeout:5037ms
datanode2_1  | 2022-08-15 20:23:44,059 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: shutdown ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
datanode2_1  | 2022-08-15 20:23:44,059 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode2_1  | 2022-08-15 20:23:44,059 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-15 20:23:44,059 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection3
datanode2_1  | 2022-08-15 20:23:44,067 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection3] INFO impl.LeaderElection: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection3 ELECTION round 0: submit vote requests at term 2 for -1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-15 20:23:44,186 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection3] INFO impl.LeaderElection: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection3: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2022-08-15 20:23:44,189 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection3] INFO impl.LeaderElection:   Response 0: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f<-11946e6e-1ab1-47b6-94a8-e6dbe917e210#0:OK-t2
datanode2_1  | 2022-08-15 20:23:44,190 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection3] INFO impl.LeaderElection:   Response 1: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f<-e2584860-2683-4862-8eba-daf2ea0fcaee#0:FAIL-t2
datanode2_1  | 2022-08-15 20:23:44,191 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection3] INFO impl.LeaderElection: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection3 ELECTION round 0: result REJECTED
datanode2_1  | 2022-08-15 20:23:44,199 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode2_1  | 2022-08-15 20:23:44,201 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection3] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: shutdown ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection3
datanode2_1  | 2022-08-15 20:23:44,201 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-LeaderElection3] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
datanode2_1  | 2022-08-15 20:23:44,427 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-FollowerState] INFO impl.FollowerState: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5059702837ns, electionTimeout:5047ms
datanode2_1  | 2022-08-15 20:23:44,427 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-FollowerState] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: shutdown ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-FollowerState
datanode2_1  | 2022-08-15 20:23:44,428 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-FollowerState] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-08-15 20:23:44,428 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-15 20:23:44,428 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-FollowerState] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4
datanode2_1  | 2022-08-15 20:23:44,432 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO impl.LeaderElection: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4 ELECTION round 0: submit vote requests at term 1 for -1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-08-15 20:23:44,480 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO impl.LeaderElection: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-08-15 20:23:44,480 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO impl.LeaderElection:   Response 0: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f<-11946e6e-1ab1-47b6-94a8-e6dbe917e210#0:OK-t1
datanode2_1  | 2022-08-15 20:23:44,481 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO impl.LeaderElection: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4 ELECTION round 0: result PASSED
datanode2_1  | 2022-08-15 20:23:44,488 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: shutdown ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4
datanode2_1  | 2022-08-15 20:23:44,488 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-08-15 20:23:44,488 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-E153E5671E57 with new leaderId: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
datanode2_1  | 2022-08-15 20:23:44,488 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57: change Leader from null to ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f at term 1 for becomeLeader, leader elected after 5240ms
datanode2_1  | 2022-08-15 20:23:44,488 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-08-15 20:23:44,489 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-08-15 20:23:44,495 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-08-15 20:23:44,540 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-08-15 20:23:44,541 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-08-15 20:23:44,541 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-08-15 20:23:44,542 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-08-15 20:23:44,542 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-08-15 20:23:44,590 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-08-15 20:23:44,594 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-15 20:23:44,594 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-08-15 20:23:44,602 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-08-15 20:23:44,614 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-08-15 20:23:44,616 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-15 20:23:44,621 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-08-15 20:23:44,630 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-15 20:23:44,631 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-08-15 20:23:44,631 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-08-15 20:23:44,631 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-08-15 20:23:44,631 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-15 20:23:44,633 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderStateImpl
datanode2_1  | 2022-08-15 20:23:44,636 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO segmented.SegmentedRaftLogWorker: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-08-15 20:23:44,641 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ee87d8de-c101-4564-aff4-e153e5671e57/current/log_inprogress_0
datanode2_1  | 2022-08-15 20:23:44,757 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57-LeaderElection4] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-E153E5671E57: set configuration 0: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-08-15 20:23:49,256 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: receive requestVote(ELECTION, 11946e6e-1ab1-47b6-94a8-e6dbe917e210, group-4BEB5C69C54E, 3, (t:0, i:0))
datanode2_1  | 2022-08-15 20:23:49,257 [grpc-default-executor-1] INFO impl.VoteContext: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FOLLOWER: accept ELECTION from 11946e6e-1ab1-47b6-94a8-e6dbe917e210: our priority 0 <= candidate's priority 0
datanode2_1  | 2022-08-15 20:23:49,257 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:11946e6e-1ab1-47b6-94a8-e6dbe917e210
datanode2_1  | 2022-08-15 20:23:49,257 [grpc-default-executor-1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: shutdown ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
datanode2_1  | 2022-08-15 20:23:49,258 [grpc-default-executor-1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
datanode2_1  | 2022-08-15 20:23:49,258 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState was interrupted
datanode2_1  | 2022-08-15 20:23:49,266 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E replies to ELECTION vote request: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f#0:OK-t3. Peer's state: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E:t3, leader=null, voted=11946e6e-1ab1-47b6-94a8-e6dbe917e210, raftlog=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-15 20:23:54,408 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: receive requestVote(ELECTION, 11946e6e-1ab1-47b6-94a8-e6dbe917e210, group-4BEB5C69C54E, 4, (t:0, i:0))
datanode2_1  | 2022-08-15 20:23:54,408 [grpc-default-executor-1] INFO impl.VoteContext: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FOLLOWER: accept ELECTION from 11946e6e-1ab1-47b6-94a8-e6dbe917e210: our priority 0 <= candidate's priority 0
datanode2_1  | 2022-08-15 20:23:54,409 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:11946e6e-1ab1-47b6-94a8-e6dbe917e210
datanode2_1  | 2022-08-15 20:23:54,409 [grpc-default-executor-1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: shutdown ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
datanode2_1  | 2022-08-15 20:23:54,409 [grpc-default-executor-1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
datanode2_1  | 2022-08-15 20:23:54,413 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState was interrupted
datanode2_1  | 2022-08-15 20:23:54,430 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E replies to ELECTION vote request: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f#0:OK-t4. Peer's state: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E:t4, leader=null, voted=11946e6e-1ab1-47b6-94a8-e6dbe917e210, raftlog=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-15 20:23:56,214 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: receive requestVote(ELECTION, e2584860-2683-4862-8eba-daf2ea0fcaee, group-4BEB5C69C54E, 4, (t:0, i:0))
datanode2_1  | 2022-08-15 20:23:56,220 [grpc-default-executor-1] INFO impl.VoteContext: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FOLLOWER: reject ELECTION from e2584860-2683-4862-8eba-daf2ea0fcaee: already has voted for 11946e6e-1ab1-47b6-94a8-e6dbe917e210 at current term 4
datanode2_1  | 2022-08-15 20:23:56,221 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E replies to ELECTION vote request: e2584860-2683-4862-8eba-daf2ea0fcaee<-ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f#0:FAIL-t4. Peer's state: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E:t4, leader=null, voted=11946e6e-1ab1-47b6-94a8-e6dbe917e210, raftlog=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-15 20:23:59,645 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: receive requestVote(ELECTION, 11946e6e-1ab1-47b6-94a8-e6dbe917e210, group-4BEB5C69C54E, 5, (t:0, i:0))
datanode2_1  | 2022-08-15 20:23:59,647 [grpc-default-executor-1] INFO impl.VoteContext: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FOLLOWER: accept ELECTION from 11946e6e-1ab1-47b6-94a8-e6dbe917e210: our priority 0 <= candidate's priority 0
datanode2_1  | 2022-08-15 20:23:59,648 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:11946e6e-1ab1-47b6-94a8-e6dbe917e210
datanode2_1  | 2022-08-15 20:23:59,648 [grpc-default-executor-1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: shutdown ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
datanode2_1  | 2022-08-15 20:23:59,648 [grpc-default-executor-1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
datanode2_1  | 2022-08-15 20:23:59,648 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState was interrupted
datanode2_1  | 2022-08-15 20:23:59,665 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E replies to ELECTION vote request: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f#0:OK-t5. Peer's state: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E:t5, leader=null, voted=11946e6e-1ab1-47b6-94a8-e6dbe917e210, raftlog=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-15 20:24:04,724 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: receive requestVote(ELECTION, 11946e6e-1ab1-47b6-94a8-e6dbe917e210, group-4BEB5C69C54E, 6, (t:0, i:0))
datanode2_1  | 2022-08-15 20:24:04,724 [grpc-default-executor-1] INFO impl.VoteContext: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FOLLOWER: accept ELECTION from 11946e6e-1ab1-47b6-94a8-e6dbe917e210: our priority 0 <= candidate's priority 0
datanode2_1  | 2022-08-15 20:24:04,724 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:11946e6e-1ab1-47b6-94a8-e6dbe917e210
datanode2_1  | 2022-08-15 20:24:04,724 [grpc-default-executor-1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: shutdown ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
datanode2_1  | 2022-08-15 20:24:04,725 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState was interrupted
datanode2_1  | 2022-08-15 20:24:04,726 [grpc-default-executor-1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
om2_1        | 2022-08-15 20:23:14,296 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | 2022-08-15 20:23:56,560 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-08-15 20:23:56,580 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-08-15 20:23:56,580 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-08-15 20:23:56,580 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-08-15 20:23:56,580 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-08-15 20:23:56,581 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-08-15 20:23:56,581 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-08-15 20:23:56,582 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-08-15 20:23:56,582 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-08-15 20:23:56,582 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-08-15 20:23:56,582 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-08-15 20:23:56,583 [pool-23-thread-1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8: start as a follower, conf=-1: [e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-08-15 20:23:56,583 [pool-23-thread-1] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-08-15 20:23:56,583 [pool-23-thread-1] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: start e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-FollowerState
datanode3_1  | 2022-08-15 20:23:56,621 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8E6307B8CDA8,id=e2584860-2683-4862-8eba-daf2ea0fcaee
datanode3_1  | 2022-08-15 20:23:56,641 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=8115b5cd-243e-460c-8d63-8e6307b8cda8
datanode3_1  | 2022-08-15 20:23:56,642 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=8115b5cd-243e-460c-8d63-8e6307b8cda8.
datanode3_1  | 2022-08-15 20:23:59,610 [grpc-default-executor-3] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: receive requestVote(ELECTION, 11946e6e-1ab1-47b6-94a8-e6dbe917e210, group-4BEB5C69C54E, 5, (t:0, i:0))
datanode3_1  | 2022-08-15 20:23:59,611 [grpc-default-executor-3] INFO impl.VoteContext: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FOLLOWER: reject ELECTION from 11946e6e-1ab1-47b6-94a8-e6dbe917e210: our priority 1 > candidate's priority 0
datanode3_1  | 2022-08-15 20:23:59,611 [grpc-default-executor-3] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:11946e6e-1ab1-47b6-94a8-e6dbe917e210
datanode3_1  | 2022-08-15 20:23:59,615 [grpc-default-executor-3] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: shutdown e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState
datanode3_1  | 2022-08-15 20:23:59,615 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState was interrupted
datanode3_1  | 2022-08-15 20:23:59,616 [grpc-default-executor-3] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: start e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState
datanode3_1  | 2022-08-15 20:23:59,620 [grpc-default-executor-3] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E replies to ELECTION vote request: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-e2584860-2683-4862-8eba-daf2ea0fcaee#0:FAIL-t5. Peer's state: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E:t5, leader=null, voted=null, raftlog=e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-15 20:24:01,780 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-FollowerState] INFO impl.FollowerState: e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5196610879ns, electionTimeout:5158ms
datanode3_1  | 2022-08-15 20:24:01,780 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-FollowerState] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: shutdown e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-FollowerState
datanode3_1  | 2022-08-15 20:24:01,780 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-FollowerState] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-08-15 20:24:01,780 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-08-15 20:24:01,781 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-FollowerState] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: start e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2
datanode3_1  | 2022-08-15 20:24:01,783 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO impl.LeaderElection: e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-08-15 20:24:01,785 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO impl.LeaderElection: e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2022-08-15 20:24:01,785 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: shutdown e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2
datanode3_1  | 2022-08-15 20:24:01,786 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-08-15 20:24:01,786 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8E6307B8CDA8 with new leaderId: e2584860-2683-4862-8eba-daf2ea0fcaee
datanode3_1  | 2022-08-15 20:24:01,797 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8: change Leader from null to e2584860-2683-4862-8eba-daf2ea0fcaee at term 1 for becomeLeader, leader elected after 5327ms
datanode2_1  | 2022-08-15 20:24:04,736 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E replies to ELECTION vote request: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f#0:OK-t6. Peer's state: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E:t6, leader=null, voted=11946e6e-1ab1-47b6-94a8-e6dbe917e210, raftlog=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-15 20:24:09,885 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: receive requestVote(ELECTION, e2584860-2683-4862-8eba-daf2ea0fcaee, group-4BEB5C69C54E, 7, (t:0, i:0))
datanode2_1  | 2022-08-15 20:24:09,885 [grpc-default-executor-1] INFO impl.VoteContext: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FOLLOWER: accept ELECTION from e2584860-2683-4862-8eba-daf2ea0fcaee: our priority 0 <= candidate's priority 1
datanode2_1  | 2022-08-15 20:24:09,886 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: changes role from  FOLLOWER to FOLLOWER at term 7 for candidate:e2584860-2683-4862-8eba-daf2ea0fcaee
datanode2_1  | 2022-08-15 20:24:09,886 [grpc-default-executor-1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: shutdown ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
datanode2_1  | 2022-08-15 20:24:09,886 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState was interrupted
datanode2_1  | 2022-08-15 20:24:09,889 [grpc-default-executor-1] INFO impl.RoleInfo: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f: start ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FollowerState
datanode2_1  | 2022-08-15 20:24:09,891 [grpc-default-executor-1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E replies to ELECTION vote request: e2584860-2683-4862-8eba-daf2ea0fcaee<-ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f#0:OK-t7. Peer's state: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E:t7, leader=null, voted=e2584860-2683-4862-8eba-daf2ea0fcaee, raftlog=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-15 20:24:09,924 [grpc-default-executor-0] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: receive requestVote(ELECTION, 11946e6e-1ab1-47b6-94a8-e6dbe917e210, group-4BEB5C69C54E, 7, (t:0, i:0))
datanode2_1  | 2022-08-15 20:24:09,924 [grpc-default-executor-0] INFO impl.VoteContext: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-FOLLOWER: reject ELECTION from 11946e6e-1ab1-47b6-94a8-e6dbe917e210: already has voted for e2584860-2683-4862-8eba-daf2ea0fcaee at current term 7
datanode2_1  | 2022-08-15 20:24:09,926 [grpc-default-executor-0] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E replies to ELECTION vote request: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f#0:FAIL-t7. Peer's state: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E:t7, leader=null, voted=e2584860-2683-4862-8eba-daf2ea0fcaee, raftlog=ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-15 20:24:10,092 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4BEB5C69C54E with new leaderId: e2584860-2683-4862-8eba-daf2ea0fcaee
datanode2_1  | 2022-08-15 20:24:10,093 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f-server-thread1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: change Leader from null to e2584860-2683-4862-8eba-daf2ea0fcaee at term 7 for appendEntries, leader elected after 39431ms
datanode2_1  | 2022-08-15 20:24:10,129 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f-server-thread1] INFO server.RaftServer$Division: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E: set configuration 0: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-08-15 20:24:10,130 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f-server-thread1] INFO segmented.SegmentedRaftLogWorker: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-08-15 20:24:10,132 [ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f@group-4BEB5C69C54E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e/current/log_inprogress_0
datanode2_1  | 2022-08-15 20:24:56,334 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:941416846787.
datanode2_1  | 2022-08-15 20:36:50,117 [ContainerOp-ee87d8de-c101-4564-aff4-e153e5671e57-7] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 152.
datanode2_1  | 2022-08-15 20:36:50,117 [ContainerOp-ee87d8de-c101-4564-aff4-e153e5671e57-7] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 152.
datanode2_1  | 2022-08-15 20:36:50,151 [ContainerOp-ee87d8de-c101-4564-aff4-e153e5671e57-7] INFO keyvalue.KeyValueContainer: Container 2 is closed with bcsId 152.
datanode2_1  | 2022-08-15 20:40:41,881 [ContainerOp-4e74fa7e-554b-49cb-895a-4beb5c69c54e-8] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 129.
datanode2_1  | 2022-08-15 20:40:41,892 [ContainerOp-4e74fa7e-554b-49cb-895a-4beb5c69c54e-8] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 129.
datanode2_1  | 2022-08-15 20:40:41,917 [ContainerOp-4e74fa7e-554b-49cb-895a-4beb5c69c54e-8] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 129.
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2022-08-15 20:21:03,055 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
kdc_1        | Aug 15 20:29:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595352, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:29:17 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595357, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:29:17 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595357, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:29:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595357, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:29:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595357, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:29:27 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595367, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:29:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595367, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:29:36 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595367, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:29:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595367, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:29:45 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595367, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:29:46 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595386, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:29:50 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595386, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:29:55 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595386, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:30:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595386, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:30:06 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595406, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:30:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595406, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:30:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:30:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:30:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595406, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:30:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595406, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:30:21 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:30:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:30:30 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:30:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595421, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:31:11 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595471, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:31:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:31:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:31:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595471, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:31:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.114: ISSUE: authtime 1660594862, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:31:22 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595482, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:31:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595482, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:31:37 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595497, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:31:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595497, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:31:54 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595514, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:31:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595514, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:59Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-08-15 20:23:14,368 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-08-15 20:23:22,443 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-08-15 20:23:25,958 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-08-15 20:23:26,720 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-08-15 20:23:26,722 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-08-15 20:23:26,723 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-08-15 20:23:26,785 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-08-15 20:23:27,006 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om2_1        | 2022-08-15 20:23:28,173 [main] INFO reflections.Reflections: Reflections took 886 ms to scan 1 urls, producing 113 keys and 334 values [using 2 cores]
om2_1        | 2022-08-15 20:23:29,775 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-08-15 20:23:29,775 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-08-15 20:23:29,777 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-08-15 20:23:32,592 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-08-15 20:23:32,872 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-08-15 20:23:37,704 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2022-08-15 20:23:38,550 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2022-08-15 20:23:38,608 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/944499913495.crt.
om2_1        | 2022-08-15 20:23:38,643 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-838496351631.crt.
om2_1        | 2022-08-15 20:23:38,928 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-08-15 20:23:39,918 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-08-15 20:23:39,931 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-08-15 20:23:42,043 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om2_1        | 2022-08-15 20:23:42,123 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2022-08-15 20:23:42,123 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2022-08-15 20:23:42,867 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om2_1        | 2022-08-15 20:23:43,334 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-08-15 20:23:43,341 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2022-08-15 20:23:43,443 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2022-08-15 20:23:44,071 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2022-08-15 20:23:44,186 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-08-15 20:23:44,391 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om2:9872, om1:9872, om3:9872
om2_1        | 2022-08-15 20:23:44,469 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
kdc_1        | Aug 15 20:32:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595514, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:32:10 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595530, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:32:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595530, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:32:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:32:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:32:20 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595540, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:32:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595540, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:32:29 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595549, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:32:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595549, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:32:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595549, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:32:44 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595564, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:32:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595564, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:33:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:33:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:33:58 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595638, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:34:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595638, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:34:14 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595654, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:34:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
om2_1        | 2022-08-15 20:23:46,405 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2022-08-15 20:23:46,865 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2022-08-15 20:23:46,871 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-08-15 20:23:46,873 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2022-08-15 20:23:46,875 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-08-15 20:23:46,875 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-08-15 20:23:46,877 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2022-08-15 20:23:46,882 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-08-15 20:23:47,084 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2022-08-15 20:23:47,088 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-08-15 20:23:47,199 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om2_1        | 2022-08-15 20:23:47,202 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om2_1        | 2022-08-15 20:23:49,356 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2022-08-15 20:23:49,367 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om2_1        | 2022-08-15 20:23:49,372 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om2_1        | 2022-08-15 20:23:49,375 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-08-15 20:23:49,377 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-08-15 20:23:49,391 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-08-15 20:23:49,467 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@3f3b0b19[Not completed]
om2_1        | 2022-08-15 20:23:49,476 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2022-08-15 20:23:49,623 [pool-27-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2022-08-15 20:23:49,682 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2022-08-15 20:23:49,687 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2022-08-15 20:23:49,687 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2022-08-15 20:23:49,693 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-08-15 20:23:49,693 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-08-15 20:23:49,693 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2022-08-15 20:23:49,726 [main] INFO om.OzoneManager: Creating RPC Server
om2_1        | 2022-08-15 20:23:49,756 [pool-27-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2022-08-15 20:23:49,756 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-08-15 20:23:49,787 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2022-08-15 20:23:49,789 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2022-08-15 20:23:49,793 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2022-08-15 20:23:49,969 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om2
om2_1        | 2022-08-15 20:23:50,112 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2022-08-15 20:23:50,143 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2022-08-15 20:23:50,150 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2022-08-15 20:23:50,243 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2022-08-15 20:23:50,264 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-08-15 20:23:50,275 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om2_1        | 2022-08-15 20:23:50,430 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-08-15 20:23:50,647 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2022-08-15 20:23:50,648 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2022-08-15 20:23:50,732 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2022-08-15 20:23:50,756 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-08-15 20:23:50,769 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2022-08-15 20:23:50,771 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-08-15 20:23:50,790 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2022-08-15 20:23:50,791 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2022-08-15 20:23:50,807 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2022-08-15 20:23:50,808 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2022-08-15 20:23:50,816 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2022-08-15 20:23:50,933 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2022-08-15 20:23:50,953 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om2_1        | 2022-08-15 20:23:50,991 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2022-08-15 20:23:48,475 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2022-08-15 20:23:48,486 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2022-08-15 20:23:48,600 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2022-08-15 20:23:48,608 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-08-15 20:23:48,617 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2022-08-15 20:23:48,638 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-08-15 20:23:48,645 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2022-08-15 20:23:48,648 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2022-08-15 20:23:48,687 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2022-08-15 20:23:48,689 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2022-08-15 20:23:48,692 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2022-08-15 20:23:48,857 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2022-08-15 20:23:48,857 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om1_1        | 2022-08-15 20:23:48,858 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2022-08-15 20:23:48,916 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:59Z
recon_1      | STARTUP_MSG:   java = 11.0.14.1
recon_1      | ************************************************************/
recon_1      | 2022-08-15 20:21:03,102 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2022-08-15 20:21:05,489 [main] INFO reflections.Reflections: Reflections took 306 ms to scan 1 urls, producing 16 keys and 48 values 
recon_1      | 2022-08-15 20:21:07,588 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2022-08-15 20:21:07,685 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2022-08-15 20:21:08,246 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
recon_1      | 2022-08-15 20:21:08,246 [main] INFO recon.ReconServer: Recon login successful.
recon_1      | 2022-08-15 20:21:08,246 [main] INFO recon.ReconServer: Initializing secure Recon.
recon_1      | 2022-08-15 20:21:09,548 [main] ERROR client.ReconCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
recon_1      | 2022-08-15 20:21:09,548 [main] INFO client.ReconCertificateClient: Certificate client init case: 0
recon_1      | 2022-08-15 20:21:09,549 [main] INFO client.ReconCertificateClient: Creating keypair for client as keypair and certificate not found.
recon_1      | 2022-08-15 20:21:12,433 [main] INFO recon.ReconServer: Init response: GETCERT
recon_1      | 2022-08-15 20:21:12,462 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.115,host:recon
recon_1      | 2022-08-15 20:21:12,462 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
recon_1      | 2022-08-15 20:21:12,479 [main] ERROR client.ReconCertificateClient: Invalid domain recon
recon_1      | 2022-08-15 20:21:12,769 [main] INFO recon.ReconServer: Creating CSR for Recon.
datanode3_1  | 2022-08-15 20:24:01,799 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-08-15 20:24:01,834 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-08-15 20:24:01,838 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-08-15 20:24:01,850 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-08-15 20:24:01,850 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-08-15 20:24:01,851 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-08-15 20:24:01,871 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-08-15 20:24:01,875 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-08-15 20:24:01,880 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: start e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderStateImpl
datanode3_1  | 2022-08-15 20:24:01,898 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-08-15 20:24:01,906 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-LeaderElection2] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8: set configuration 0: [e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-08-15 20:24:01,907 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e2584860-2683-4862-8eba-daf2ea0fcaee@group-8E6307B8CDA8-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/8115b5cd-243e-460c-8d63-8e6307b8cda8/current/log_inprogress_0
datanode3_1  | 2022-08-15 20:24:04,729 [grpc-default-executor-3] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: receive requestVote(ELECTION, 11946e6e-1ab1-47b6-94a8-e6dbe917e210, group-4BEB5C69C54E, 6, (t:0, i:0))
datanode3_1  | 2022-08-15 20:24:04,729 [grpc-default-executor-3] INFO impl.VoteContext: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FOLLOWER: reject ELECTION from 11946e6e-1ab1-47b6-94a8-e6dbe917e210: our priority 1 > candidate's priority 0
datanode3_1  | 2022-08-15 20:24:04,730 [grpc-default-executor-3] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:11946e6e-1ab1-47b6-94a8-e6dbe917e210
datanode3_1  | 2022-08-15 20:24:04,730 [grpc-default-executor-3] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: shutdown e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState
datanode3_1  | 2022-08-15 20:24:04,730 [grpc-default-executor-3] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: start e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState
datanode3_1  | 2022-08-15 20:24:04,730 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState was interrupted
datanode3_1  | 2022-08-15 20:24:04,749 [grpc-default-executor-3] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E replies to ELECTION vote request: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-e2584860-2683-4862-8eba-daf2ea0fcaee#0:FAIL-t6. Peer's state: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E:t6, leader=null, voted=null, raftlog=e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c-1, conf=-1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-15 20:24:09,853 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState] INFO impl.FollowerState: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5123607237ns, electionTimeout:5105ms
datanode3_1  | 2022-08-15 20:24:09,854 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: shutdown e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState
datanode3_1  | 2022-08-15 20:24:09,854 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
datanode3_1  | 2022-08-15 20:24:09,854 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-08-15 20:24:09,854 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-FollowerState] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: start e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3
datanode3_1  | 2022-08-15 20:24:09,860 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO impl.LeaderElection: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3 ELECTION round 0: submit vote requests at term 7 for -1: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-15 20:24:09,896 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO impl.LeaderElection: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3: ELECTION PASSED received 2 response(s) and 0 exception(s):
datanode3_1  | 2022-08-15 20:24:09,896 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO impl.LeaderElection:   Response 0: e2584860-2683-4862-8eba-daf2ea0fcaee<-11946e6e-1ab1-47b6-94a8-e6dbe917e210#0:FAIL-t7
datanode3_1  | 2022-08-15 20:24:09,896 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO impl.LeaderElection:   Response 1: e2584860-2683-4862-8eba-daf2ea0fcaee<-ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f#0:OK-t7
datanode3_1  | 2022-08-15 20:24:09,896 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO impl.LeaderElection: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3 ELECTION round 0: result PASSED
kdc_1        | Aug 15 20:34:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:34:17 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595654, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:34:35 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595675, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:34:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595675, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:34:46 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595686, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:34:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595686, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:34:58 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595698, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:35:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595698, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:35:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:35:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:35:21 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595721, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:35:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595721, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:35:28 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595728, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:35:28 kdc krb5kdc[8](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595728, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
kdc_1        | Aug 15 20:35:39 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:35:43 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:35:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:35:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
recon_1      | 2022-08-15 20:21:15,659 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:21:17,661 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:21:19,663 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:21:21,665 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:21:23,667 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:21:25,669 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:21:27,670 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:21:29,672 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:21:32,524 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:17440e9e-0b34-4cd8-8102-cb903e52057d is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1      | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1      | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
recon_1      | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:21:34,526 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:21:36,528 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:21:39,073 [main] INFO recon.ReconServer: Successfully stored SCM signed certificate, case:GETCERT.
recon_1      | 2022-08-15 20:21:39,721 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-08-15 20:21:41,669 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2022-08-15 20:21:42,838 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
datanode3_1  | 2022-08-15 20:24:09,897 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: shutdown e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3
datanode3_1  | 2022-08-15 20:24:09,897 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: changes role from CANDIDATE to LEADER at term 7 for changeToLeader
datanode3_1  | 2022-08-15 20:24:09,897 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-4BEB5C69C54E with new leaderId: e2584860-2683-4862-8eba-daf2ea0fcaee
datanode3_1  | 2022-08-15 20:24:09,897 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: change Leader from null to e2584860-2683-4862-8eba-daf2ea0fcaee at term 7 for becomeLeader, leader elected after 30018ms
datanode3_1  | 2022-08-15 20:24:09,897 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-08-15 20:24:09,907 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-08-15 20:24:09,913 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-08-15 20:24:09,915 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-08-15 20:24:09,917 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-08-15 20:24:09,918 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-08-15 20:24:09,918 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-08-15 20:24:09,920 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-08-15 20:24:09,943 [grpc-default-executor-3] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: receive requestVote(ELECTION, 11946e6e-1ab1-47b6-94a8-e6dbe917e210, group-4BEB5C69C54E, 7, (t:0, i:0))
datanode3_1  | 2022-08-15 20:24:09,988 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-08-15 20:24:09,989 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-15 20:24:09,991 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-08-15 20:24:09,998 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-08-15 20:24:09,998 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-08-15 20:24:09,999 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-08-15 20:24:10,003 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode3_1  | 2022-08-15 20:24:10,003 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-15 20:24:10,003 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode3_1  | 2022-08-15 20:24:10,004 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-08-15 20:24:10,004 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-08-15 20:24:10,005 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-08-15 20:24:10,009 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO impl.RoleInfo: e2584860-2683-4862-8eba-daf2ea0fcaee: start e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderStateImpl
datanode3_1  | 2022-08-15 20:24:10,010 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-08-15 20:24:10,012 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4e74fa7e-554b-49cb-895a-4beb5c69c54e/current/log_inprogress_0
datanode3_1  | 2022-08-15 20:24:10,023 [e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LeaderElection3] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E: set configuration 0: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-15 20:24:10,027 [grpc-default-executor-3] INFO impl.VoteContext: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-LEADER: reject ELECTION from 11946e6e-1ab1-47b6-94a8-e6dbe917e210: already has voted for e2584860-2683-4862-8eba-daf2ea0fcaee at current term 7
datanode3_1  | 2022-08-15 20:24:10,028 [grpc-default-executor-3] INFO server.RaftServer$Division: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E replies to ELECTION vote request: 11946e6e-1ab1-47b6-94a8-e6dbe917e210<-e2584860-2683-4862-8eba-daf2ea0fcaee#0:FAIL-t7. Peer's state: e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E:t7, leader=e2584860-2683-4862-8eba-daf2ea0fcaee, voted=e2584860-2683-4862-8eba-daf2ea0fcaee, raftlog=e2584860-2683-4862-8eba-daf2ea0fcaee@group-4BEB5C69C54E-SegmentedRaftLog:OPENED:c0, conf=0: [11946e6e-1ab1-47b6-94a8-e6dbe917e210|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, e2584860-2683-4862-8eba-daf2ea0fcaee|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-15 20:24:55,987 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:941416846787.
kdc_1        | Aug 15 20:36:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:36:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:36:12 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:36:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:36:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:36:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:36:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:36:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:36:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:36:33 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:36:37 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:36:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:36:56 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595739, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:37:00 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595820, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:37:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595820, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:37:04 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595824, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:37:07 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595824, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:37:11 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595824, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
om1_1        | 2022-08-15 20:23:48,916 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2022-08-15 20:23:48,977 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2022-08-15 20:23:48,986 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2022-08-15 20:23:48,992 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2022-08-15 20:23:49,004 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2022-08-15 20:23:49,009 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2022-08-15 20:23:49,016 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2022-08-15 20:23:49,610 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-08-15 20:23:49,623 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om1_1        | 2022-08-15 20:23:49,632 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om1_1        | 2022-08-15 20:23:49,634 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om1_1        | 2022-08-15 20:23:49,637 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om1_1        | 2022-08-15 20:23:50,443 [main] INFO reflections.Reflections: Reflections took 2088 ms to scan 8 urls, producing 23 keys and 517 values [using 2 cores]
om1_1        | 2022-08-15 20:23:51,896 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2022-08-15 20:23:51,949 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2022-08-15 20:23:57,266 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2022-08-15 20:23:57,368 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2022-08-15 20:23:57,368 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2022-08-15 20:23:57,669 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2022-08-15 20:23:57,673 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2022-08-15 20:23:57,691 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-15 20:23:57,695 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2022-08-15 20:23:57,697 [om1-impl-thread1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-08-15 20:23:57,705 [om1-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2022-08-15 20:23:57,724 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2022-08-15 20:23:57,891 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2022-08-15 20:23:57,916 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$452/0x00000008405b2440@129a9d88] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2022-08-15 20:23:57,917 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2022-08-15 20:23:57,917 [Listener at om1/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-08-15 20:23:57,919 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2022-08-15 20:23:57,923 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-08-15 20:23:57,940 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1        | 2022-08-15 20:23:57,953 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2022-08-15 20:23:58,208 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2022-08-15 20:23:58,208 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2022-08-15 20:23:58,209 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om1_1        | 2022-08-15 20:23:58,363 [Listener at om1/9862] INFO util.log: Logging initialized @56873ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2022-08-15 20:23:58,907 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2022-08-15 20:23:58,961 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2022-08-15 20:23:58,976 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2022-08-15 20:23:58,983 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2022-08-15 20:23:58,984 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2022-08-15 20:23:58,993 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2022-08-15 20:23:59,278 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2022-08-15 20:23:59,280 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om1_1        | 2022-08-15 20:23:59,418 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2022-08-15 20:23:59,418 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2022-08-15 20:23:59,431 [Listener at om1/9862] INFO server.session: node0 Scavenging every 660000ms
om1_1        | 2022-08-15 20:23:59,515 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-08-15 20:23:59,522 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@40bb73ff{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2022-08-15 20:36:50,190 [ContainerOp-ee87d8de-c101-4564-aff4-e153e5671e57-7] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 152.
datanode3_1  | 2022-08-15 20:36:50,204 [ContainerOp-ee87d8de-c101-4564-aff4-e153e5671e57-7] INFO keyvalue.KeyValueContainer: Container 2 is synced with bcsId 152.
datanode3_1  | 2022-08-15 20:36:50,231 [ContainerOp-ee87d8de-c101-4564-aff4-e153e5671e57-7] INFO keyvalue.KeyValueContainer: Container 2 is closed with bcsId 152.
datanode3_1  | 2022-08-15 20:40:41,853 [ContainerOp-4e74fa7e-554b-49cb-895a-4beb5c69c54e-6] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 129.
datanode3_1  | 2022-08-15 20:40:41,879 [ContainerOp-4e74fa7e-554b-49cb-895a-4beb5c69c54e-6] INFO keyvalue.KeyValueContainer: Container 1 is synced with bcsId 129.
datanode3_1  | 2022-08-15 20:40:41,889 [ContainerOp-4e74fa7e-554b-49cb-895a-4beb5c69c54e-6] INFO keyvalue.KeyValueContainer: Container 1 is closed with bcsId 129.
recon_1      | 2022-08-15 20:21:42,900 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2022-08-15 20:21:42,902 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2022-08-15 20:21:44,891 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2022-08-15 20:21:44,894 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2022-08-15 20:21:44,894 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2022-08-15 20:21:44,965 [main] INFO util.log: Logging initialized @47114ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2022-08-15 20:21:45,457 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2022-08-15 20:21:45,495 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2022-08-15 20:21:45,509 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2022-08-15 20:21:45,510 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2022-08-15 20:21:45,510 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2022-08-15 20:21:45,524 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2022-08-15 20:21:45,920 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2022-08-15 20:21:46,546 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2022-08-15 20:21:46,583 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2022-08-15 20:21:46,594 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTaskWithFSO with controller.
recon_1      | 2022-08-15 20:21:46,636 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2022-08-15 20:21:48,445 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-08-15 20:21:49,152 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-08-15 20:21:49,439 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2022-08-15 20:21:49,443 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2022-08-15 20:21:49,837 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-08-15 20:21:50,268 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
recon_1      | 2022-08-15 20:21:50,473 [main] INFO reflections.Reflections: Reflections took 183 ms to scan 3 urls, producing 109 keys and 246 values 
recon_1      | 2022-08-15 20:21:50,806 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2022-08-15 20:21:51,014 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2022-08-15 20:21:51,047 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2022-08-15 20:21:51,061 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2022-08-15 20:21:51,196 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1      | 2022-08-15 20:21:51,309 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2022-08-15 20:21:51,350 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2022-08-15 20:21:51,705 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 2022-08-15 20:21:52,041 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2022-08-15 20:21:52,041 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2022-08-15 20:21:52,275 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2022-08-15 20:21:52,328 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2022-08-15 20:21:52,328 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2022-08-15 20:21:53,086 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2022-08-15 20:21:53,092 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
recon_1      | 2022-08-15 20:21:53,250 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2022-08-15 20:21:53,261 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2022-08-15 20:21:53,272 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
recon_1      | 2022-08-15 20:21:53,363 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-08-15 20:21:53,375 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6980fa39{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 2022-08-15 20:21:53,384 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7a285418{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2022-08-15 20:21:54,375 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-08-15 20:21:54,399 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-08-15 20:21:58,734 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@525d09b7{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-2872598487636999943/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1      | 2022-08-15 20:21:58,778 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@106387cf{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1      | 2022-08-15 20:21:58,784 [Listener at 0.0.0.0/9891] INFO server.Server: Started @60933ms
recon_1      | 2022-08-15 20:21:58,797 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1      | 2022-08-15 20:21:58,868 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1      | 2022-08-15 20:21:58,870 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1      | 2022-08-15 20:21:58,870 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1      | 2022-08-15 20:21:58,888 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1      | 2022-08-15 20:21:58,908 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1      | 2022-08-15 20:21:58,908 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1      | 2022-08-15 20:21:58,912 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-08-15 20:21:58,916 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1      | 2022-08-15 20:21:58,917 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1      | 2022-08-15 20:21:59,552 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1      | 2022-08-15 20:21:59,560 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-08-15 20:21:59,560 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1      | 2022-08-15 20:21:59,584 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1      | 2022-08-15 20:21:59,636 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1      | 2022-08-15 20:21:59,740 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1      | 2022-08-15 20:21:59,740 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1      | 2022-08-15 20:21:59,746 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1      | 2022-08-15 20:21:59,746 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1      | 2022-08-15 20:21:59,804 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-08-15 20:21:59,820 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 75 milliseconds.
recon_1      | 2022-08-15 20:22:18,917 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:22:18,918 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:22:19,095 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:19,114 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:21,117 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 3 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:21,119 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 4 failover attempts. Trying to failover immediately.
kdc_1        | Aug 15 20:37:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:37:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:37:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595824, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:37:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595824, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:37:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595824, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:37:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595824, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:37:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595824, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:37:36 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595824, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:37:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595824, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:37:44 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595824, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:37:47 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595867, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:37:51 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595867, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:37:55 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595867, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:37:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595867, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:38:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595867, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:38:07 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595867, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:38:11 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595867, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:38:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
om1_1        | 2022-08-15 20:23:59,528 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@56cdf69b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2022-08-15 20:24:00,043 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-08-15 20:24:00,116 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@253e74c2{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-2182562778583437369/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2022-08-15 20:24:00,156 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@713b2ee9{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2022-08-15 20:24:00,161 [Listener at om1/9862] INFO server.Server: Started @58666ms
om1_1        | 2022-08-15 20:24:00,173 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2022-08-15 20:24:00,173 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2022-08-15 20:24:00,181 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2022-08-15 20:24:00,195 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2022-08-15 20:24:00,197 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2022-08-15 20:24:00,508 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om1_1        | 2022-08-15 20:24:00,737 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46845
om1_1        | 2022-08-15 20:24:00,754 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:24:01,056 [Listener at om1/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om1_1        | 2022-08-15 20:24:01,091 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@ab02c2d] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2022-08-15 20:24:02,726 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5028679748ns, electionTimeout:5023ms
om1_1        | 2022-08-15 20:24:02,727 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-08-15 20:24:02,729 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2022-08-15 20:24:02,741 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2022-08-15 20:24:02,741 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1        | 2022-08-15 20:24:02,756 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-15 20:24:06,554 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.797730916s. [closed=[], committed=[buffered_nanos=2013316544, remote_addr=om3/172.25.0.113:9872]]
om1_1        | 2022-08-15 20:24:06,576 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-08-15 20:24:06,584 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om1 at current term 1
om1_1        | 2022-08-15 20:24:06,594 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.807143895s. [closed=[], committed=[buffered_nanos=1653438653, remote_addr=om2/172.25.0.112:9872]]
om1_1        | 2022-08-15 20:24:06,600 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION REJECTED received 0 response(s) and 2 exception(s):
om1_1        | 2022-08-15 20:24:06,604 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.797730916s. [closed=[], committed=[buffered_nanos=2013316544, remote_addr=om3/172.25.0.113:9872]]
om1_1        | 2022-08-15 20:24:06,604 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 2.807143895s. [closed=[], committed=[buffered_nanos=1653438653, remote_addr=om2/172.25.0.112:9872]]
om1_1        | 2022-08-15 20:24:06,606 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om1_1        | 2022-08-15 20:24:06,643 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-15 20:24:06,647 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om1_1        | 2022-08-15 20:24:06,648 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1        | 2022-08-15 20:24:06,648 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-08-15 20:24:06,851 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-08-15 20:24:06,851 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: reject ELECTION from om2: already has voted for om1 at current term 1
om1_1        | 2022-08-15 20:24:06,851 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-15 20:24:08,846 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53666
om1_1        | 2022-08-15 20:24:08,901 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:24:11,813 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5165280227ns, electionTimeout:5146ms
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2022-08-15 20:21:02,479 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1        | 2022-08-15 20:21:02,488 [main] INFO s3.Gateway: S3Gateway login successful.
s3g_1        | 2022-08-15 20:21:02,808 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2022-08-15 20:21:02,808 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2022-08-15 20:21:02,808 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2022-08-15 20:21:02,929 [main] INFO util.log: Logging initialized @6231ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2022-08-15 20:21:03,597 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2022-08-15 20:21:03,637 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2022-08-15 20:21:03,642 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2022-08-15 20:21:03,658 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2022-08-15 20:21:03,658 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2022-08-15 20:21:03,663 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2022-08-15 20:21:04,051 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.2.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:59Z
s3g_1        | STARTUP_MSG:   java = 11.0.14.1
s3g_1        | ************************************************************/
s3g_1        | 2022-08-15 20:21:04,070 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2022-08-15 20:21:04,170 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2022-08-15 20:21:04,481 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 2022-08-15 20:21:05,079 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 2022-08-15 20:21:05,083 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1        | 2022-08-15 20:21:05,187 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2022-08-15 20:21:05,208 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
s3g_1        | 2022-08-15 20:21:05,398 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2022-08-15 20:21:05,399 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2022-08-15 20:21:05,426 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1        | 2022-08-15 20:21:05,547 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2022-08-15 20:21:05,576 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@72f46e16{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2022-08-15 20:21:05,577 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2416a51{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
kdc_1        | Aug 15 20:38:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:38:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595867, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:38:19 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595867, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:38:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595867, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:38:26 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1660595906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:38:30 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:38:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:38:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:38:43 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:38:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:38:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:38:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:39:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:39:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:39:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1660595906, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:39:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:39:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:39:26 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om2_1        | 2022-08-15 20:23:51,058 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2022-08-15 20:23:51,060 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2022-08-15 20:23:51,078 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2022-08-15 20:23:51,092 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2022-08-15 20:23:51,096 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2022-08-15 20:23:51,101 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2022-08-15 20:23:51,108 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2022-08-15 20:23:51,119 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2022-08-15 20:23:51,649 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-08-15 20:23:51,662 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om2_1        | 2022-08-15 20:23:51,670 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om2_1        | 2022-08-15 20:23:51,680 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om2_1        | 2022-08-15 20:23:51,690 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om2_1        | 2022-08-15 20:23:52,277 [main] INFO reflections.Reflections: Reflections took 2057 ms to scan 8 urls, producing 23 keys and 517 values [using 2 cores]
om2_1        | 2022-08-15 20:23:53,447 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2022-08-15 20:23:53,472 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2022-08-15 20:23:58,750 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2022-08-15 20:23:58,849 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2022-08-15 20:23:58,849 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2022-08-15 20:23:59,110 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2022-08-15 20:23:59,110 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2022-08-15 20:23:59,160 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-08-15 20:23:59,171 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2022-08-15 20:23:59,173 [om2-impl-thread1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-08-15 20:23:59,210 [om2-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2022-08-15 20:23:59,231 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2022-08-15 20:23:59,492 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2022-08-15 20:23:59,504 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2022-08-15 20:23:59,505 [Listener at om2/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-08-15 20:23:59,511 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2022-08-15 20:23:59,511 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-08-15 20:23:59,517 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$452/0x00000008405b2440@272aa224] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2022-08-15 20:23:59,527 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1        | 2022-08-15 20:23:59,520 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2022-08-15 20:23:59,757 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2022-08-15 20:23:59,760 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2022-08-15 20:23:59,763 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2022-08-15 20:23:59,961 [Listener at om2/9862] INFO util.log: Logging initialized @55707ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2022-08-15 20:24:00,502 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2022-08-15 20:24:00,535 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2022-08-15 20:24:00,547 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2022-08-15 20:24:00,547 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2022-08-15 20:24:00,547 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2022-08-15 20:24:00,551 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2022-08-15 20:24:00,740 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2022-08-15 20:24:00,743 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om2_1        | 2022-08-15 20:24:00,986 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2022-08-15 20:24:00,986 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2022-08-15 20:24:01,005 [Listener at om2/9862] INFO server.session: node0 Scavenging every 600000ms
om2_1        | 2022-08-15 20:24:01,086 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-08-15 20:24:01,102 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68852b5{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2022-08-15 20:21:11,917 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Aug 15, 2022 8:21:15 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2022-08-15 20:21:15,053 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6a902015{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-3567936316015388024/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2022-08-15 20:21:15,076 [main] INFO server.AbstractConnector: Started ServerConnector@6691490c{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2022-08-15 20:21:15,076 [main] INFO server.Server: Started @18379ms
s3g_1        | 2022-08-15 20:21:15,079 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2022-08-15 20:21:15,079 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2022-08-15 20:21:15,088 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1        | 2022-08-15 20:31:19,501 [qtp864326906-20] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
s3g_1        | 2022-08-15 20:31:19,528 [qtp864326906-20] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
s3g_1        | 2022-08-15 20:31:19,537 [qtp864326906-20] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
s3g_1        | 2022-08-15 20:31:21,521 [qtp864326906-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2972544550, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:31:29,351 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0854404852, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:31:30,433 [qtp864326906-25] WARN impl.MetricsSystemImpl: S3Gateway metrics system already initialized!
s3g_1        | 2022-08-15 20:31:30,818 [qtp864326906-25] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 2022-08-15 20:31:44,144 [qtp864326906-25] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0897557074, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:31:44,742 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-zohirdzrfr, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:31:48,635 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-xmdkdafcgo, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:32:01,489 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4899227404, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:32:02,215 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8572712417, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:32:02,913 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1164551495, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:32:03,639 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1164551495, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:32:05,319 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3098390070, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:32:17,461 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8574156590, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:32:18,167 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3551266484, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:32:27,247 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0466368430, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:32:35,962 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9431911695, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | Aug 15, 2022 8:32:43 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1        | MultiException stack 1 of 1
s3g_1        | javax.ws.rs.WebApplicationException: The authorization header you provided is invalid.
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.wrapOS3Exception(OzoneClientProducer.java:141)
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:102)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1        | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1        | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1        | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1        | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1        | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1        | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
om2_1        | 2022-08-15 20:24:01,108 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5035ce0b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2022-08-15 20:24:01,629 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-08-15 20:24:01,701 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4b6eae98{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-15676618973347207594/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2022-08-15 20:24:01,756 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@3c554dd5{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2022-08-15 20:24:01,756 [Listener at om2/9862] INFO server.Server: Started @57503ms
om2_1        | 2022-08-15 20:24:01,770 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2022-08-15 20:24:01,770 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2022-08-15 20:24:01,777 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2022-08-15 20:24:01,798 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2022-08-15 20:24:01,856 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2022-08-15 20:24:02,042 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om2_1        | 2022-08-15 20:24:02,149 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38285
om2_1        | 2022-08-15 20:24:02,162 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-15 20:24:02,402 [Listener at om2/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om2_1        | 2022-08-15 20:24:02,420 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@128160af] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2022-08-15 20:24:04,259 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5086034582ns, electionTimeout:5030ms
om2_1        | 2022-08-15 20:24:04,273 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-08-15 20:24:04,290 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2022-08-15 20:24:04,293 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2022-08-15 20:24:04,298 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1        | 2022-08-15 20:24:04,334 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-08-15 20:24:06,138 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-08-15 20:24:06,142 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om2 at current term 1
om2_1        | 2022-08-15 20:24:06,359 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-08-15 20:24:06,530 [grpc-default-executor-4] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-08-15 20:24:06,530 [grpc-default-executor-4] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om2 at current term 1
om2_1        | 2022-08-15 20:24:06,537 [grpc-default-executor-4] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-08-15 20:24:06,881 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om2_1        | 2022-08-15 20:24:06,885 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t1
om2_1        | 2022-08-15 20:24:06,885 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t1
om2_1        | 2022-08-15 20:24:06,886 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om2_1        | 2022-08-15 20:24:06,889 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om2_1        | 2022-08-15 20:24:06,893 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1        | 2022-08-15 20:24:06,894 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-08-15 20:24:08,965 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35904
om2_1        | 2022-08-15 20:24:08,974 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-15 20:24:11,838 [grpc-default-executor-3] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 2, (t:0, i:~))
om2_1        | 2022-08-15 20:24:11,840 [grpc-default-executor-3] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om2_1        | 2022-08-15 20:24:11,840 [grpc-default-executor-3] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om1
om2_1        | 2022-08-15 20:24:11,840 [grpc-default-executor-3] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-08-15 20:24:11,840 [grpc-default-executor-3] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-08-15 20:24:11,840 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState was interrupted
s3g_1        | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1        | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:874)
s3g_1        | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1        | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1        | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:127)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:69)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:103)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:46)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:53)
s3g_1        | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:129)
s3g_1        | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
s3g_1        | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:46)
s3g_1        | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
s3g_1        | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
s3g_1        | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
s3g_1        | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
recon_1      | 2022-08-15 20:22:21,123 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:23,126 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 6 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:23,127 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 7 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:23,128 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:25,135 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 9 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:25,136 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 10 failover attempts. Trying to failover immediately.
kdc_1        | Aug 15 20:39:30 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 15 20:39:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:39:45 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:39:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:39:53 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:39:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:40:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:40:06 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:40:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:40:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:40:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:40:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:40:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:40:22 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:40:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:40:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:40:54 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660595966, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:40:57 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1660596057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om2_1        | 2022-08-15 20:24:11,866 [grpc-default-executor-3] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:OK-t2. Peer's state: om2@group-562213E44849:t2, leader=null, voted=om1, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-08-15 20:24:12,173 [om2-server-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om1 at term 2 for appendEntries, leader elected after 22030ms
om2_1        | 2022-08-15 20:24:12,318 [om2-server-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2022-08-15 20:24:12,373 [om2-server-thread1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2022-08-15 20:24:12,599 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2022-08-15 20:24:13,029 [om2@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1        | [id: "om1"
om2_1        | address: "om1:9872"
om2_1        | , id: "om3"
om2_1        | address: "om3:9872"
om2_1        | , id: "om2"
om2_1        | address: "om2:9872"
om2_1        | ]
om2_1        | 2022-08-15 20:24:51,558 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om2_1        | 2022-08-15 20:24:51,836 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om2_1        | 2022-08-15 20:25:10,595 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om2_1        | 2022-08-15 20:25:32,020 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om2_1        | 2022-08-15 20:26:00,161 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:95409-source for user:testuser
om2_1        | 2022-08-15 20:26:04,938 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:95409-target for user:testuser
om2_1        | 2022-08-15 20:26:09,522 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 95409-source
om2_1        | 2022-08-15 20:26:22,293 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 95409-source
om2_1        | 2022-08-15 20:26:26,880 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 95409-target
om2_1        | 2022-08-15 20:26:31,533 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 95409-target
om2_1        | 2022-08-15 20:26:36,118 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 95409-target
om2_1        | 2022-08-15 20:27:04,652 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 95409-target
om2_1        | 2022-08-15 20:27:13,922 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 95409-target
om2_1        | 2022-08-15 20:27:18,768 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 95409-source
om2_1        | 2022-08-15 20:28:52,997 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 95409-target
om2_1        | 2022-08-15 20:28:57,907 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:95409-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:29:02,847 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 95409-target
om2_1        | 2022-08-15 20:29:07,610 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:95409-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:29:31,944 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 95409-target
om2_1        | 2022-08-15 20:29:36,894 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 95409-target
om2_1        | 2022-08-15 20:29:41,630 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 95409-target
om2_1        | 2022-08-15 20:29:51,327 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 95409-target
om2_1        | 2022-08-15 20:30:26,322 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 95409-target
om2_1        | 2022-08-15 20:30:31,035 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:95409-target
om2_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:31:21,572 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2972544550 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:31:29,379 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0854404852 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:31:44,179 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0897557074 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:31:44,769 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-zohirdzrfr of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:31:48,686 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-xmdkdafcgo of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:32:01,507 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4899227404 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:32:02,234 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8572712417 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:32:02,938 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1164551495 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:32:03,666 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-1164551495 in volume:s3v
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
kdc_1        | Aug 15 20:41:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596057, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:41:01 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1660596061, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:41:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596061, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:41:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596061, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:41:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596061, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:41:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:41:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:41:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596061, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:41:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596061, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:41:27 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596061, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:41:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596061, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:41:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596061, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:41:39 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596061, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:41:44 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596061, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:41:47 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1660596107, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:41:51 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596107, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:41:55 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596107, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:41:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596107, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
recon_1      | 2022-08-15 20:22:25,137 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:27,138 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 12 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:27,139 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 13 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:27,140 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:29,145 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 15 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:29,147 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 16 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:29,147 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:31,152 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 18 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:31,153 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 19 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:31,154 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 20 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:33,157 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 21 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:33,159 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 22 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:33,162 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 23 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:35,164 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 24 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:35,165 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 25 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:35,168 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 26 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:37,170 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 27 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:37,175 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 28 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:37,178 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 29 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:39,182 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 30 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:39,186 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 31 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:39,237 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 32 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:41,256 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 33 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:41,257 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 34 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:41,258 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 35 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:43,260 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 36 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:43,262 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 37 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:43,263 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 38 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:45,265 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 39 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:45,266 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 40 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:45,267 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 41 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:47,269 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 42 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:47,271 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 43 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:47,271 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 44 failover attempts. Trying to failover after sleeping for 2000ms.
kdc_1        | Aug 15 20:42:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596107, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:42:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596107, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:42:12 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596107, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:42:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:42:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:42:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596107, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:42:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596107, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:42:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596107, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:42:28 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.117: ISSUE: authtime 1660596148, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 15 20:42:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596148, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:42:36 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596148, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:42:39 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596148, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:42:44 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596148, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:42:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596148, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:42:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596148, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:42:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596148, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:43:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596148, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:43:07 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596148, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:139)
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:126)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor.parseSignature(AWSSignatureProcessor.java:86)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor$Proxy$_$$_WeldClientProxy.parseSignature(Unknown Source)
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:81)
s3g_1        | 	... 114 more
s3g_1        | 
s3g_1        | 
s3g_1        | 2022-08-15 20:32:51,491 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6832627311, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:34:05,552 [qtp864326906-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0172643642, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:34:06,276 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-82438, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:34:21,469 [qtp864326906-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1197578926, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:34:42,024 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6614062836, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:34:53,259 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4509533375, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:35:05,666 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8409873988, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-15 20:35:28,037 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2278251128, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om1_1        | 2022-08-15 20:24:11,814 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-08-15 20:24:11,814 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om1_1        | 2022-08-15 20:24:11,814 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2022-08-15 20:24:11,815 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection2
om1_1        | 2022-08-15 20:24:11,821 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-15 20:24:11,878 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
om1_1        | 2022-08-15 20:24:11,879 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 0: om1<-om2#0:OK-t2
om1_1        | 2022-08-15 20:24:11,880 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2 ELECTION round 0: result PASSED
om1_1        | 2022-08-15 20:24:11,880 [om1@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection2
om1_1        | 2022-08-15 20:24:11,880 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
om1_1        | 2022-08-15 20:24:11,880 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om1 at term 2 for becomeLeader, leader elected after 23654ms
om1_1        | 2022-08-15 20:24:11,898 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om1_1        | 2022-08-15 20:24:11,907 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2022-08-15 20:24:11,907 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-08-15 20:24:11,925 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om1_1        | 2022-08-15 20:24:11,929 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om1_1        | 2022-08-15 20:24:11,930 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om1_1        | 2022-08-15 20:24:11,945 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2022-08-15 20:24:11,947 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om1_1        | 2022-08-15 20:24:11,976 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2022-08-15 20:24:11,977 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-08-15 20:24:11,977 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2022-08-15 20:24:11,984 [om1@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2022-08-15 20:24:11,985 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-08-15 20:24:11,986 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-08-15 20:24:11,996 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2022-08-15 20:24:11,996 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-08-15 20:24:11,997 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2022-08-15 20:24:11,998 [om1@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2022-08-15 20:24:11,998 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-08-15 20:24:11,998 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-08-15 20:24:12,002 [om1@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderStateImpl
om1_1        | 2022-08-15 20:24:12,023 [om1@group-562213E44849-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2022-08-15 20:24:12,079 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2022-08-15 20:24:12,152 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2022-08-15 20:24:12,873 [om1@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1        | [id: "om1"
om1_1        | address: "om1:9872"
om1_1        | , id: "om3"
om1_1        | address: "om3:9872"
om1_1        | , id: "om2"
om1_1        | address: "om2:9872"
om1_1        | ]
om1_1        | 2022-08-15 20:24:29,904 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53724
om1_1        | 2022-08-15 20:24:29,926 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:24:34,941 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53746
om1_1        | 2022-08-15 20:24:34,960 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:24:40,418 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53768
om1_1        | 2022-08-15 20:24:40,439 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-08-15 20:21:06,748 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:58Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-08-15 20:21:06,818 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-08-15 20:21:07,235 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-15 20:21:07,393 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-08-15 20:21:07,402 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-08-15 20:21:07,579 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-08-15 20:21:07,606 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-08-15 20:21:07,658 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2022-08-15 20:21:10,938 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2022-08-15 20:21:10,938 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2022-08-15 20:21:10,952 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2022-08-15 20:21:14,318 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2022-08-15 20:21:16,147 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-08-15 20:21:16,148 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-08-15 20:21:16,367 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-08-15 20:21:16,367 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-08-15 20:21:16,369 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:17440e9e-0b34-4cd8-8102-cb903e52057d,clusterId:CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072,subject:scm-sub@scm1.org
scm1.org_1   | 2022-08-15 20:21:16,487 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2022-08-15 20:21:16,677 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-08-15 20:21:16,863 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-08-15 20:21:16,886 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-15 20:21:16,891 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-08-15 20:21:16,892 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-15 20:21:16,895 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-15 20:21:16,897 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-08-15 20:21:16,904 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-15 20:21:16,905 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-08-15 20:21:16,905 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-08-15 20:21:16,948 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2022-08-15 20:21:16,952 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2022-08-15 20:21:17,292 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-08-15 20:21:17,295 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm1.org_1   | 2022-08-15 20:21:17,296 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2022-08-15 20:21:17,296 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-08-15 20:21:17,297 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-08-15 20:21:17,301 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-08-15 20:21:17,312 [main] INFO server.RaftServer: 17440e9e-0b34-4cd8-8102-cb903e52057d: addNew group-D1FD779EF072:[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|priority:0] returns group-D1FD779EF072:java.util.concurrent.CompletableFuture@5e922647[Not completed]
scm1.org_1   | 2022-08-15 20:21:17,339 [pool-2-thread-1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d: new RaftServerImpl for group-D1FD779EF072:[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-08-15 20:21:17,341 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-08-15 20:21:17,342 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-08-15 20:21:17,343 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-08-15 20:21:17,343 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-08-15 20:21:17,343 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-08-15 20:21:17,344 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-08-15 20:21:17,350 [pool-2-thread-1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: ConfigurationManager, init=-1: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-08-15 20:21:17,350 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-08-15 20:21:17,354 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-08-15 20:21:17,355 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-08-15 20:21:17,356 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072 does not exist. Creating ...
scm1.org_1   | 2022-08-15 20:21:17,366 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/in_use.lock acquired by nodename 90@scm1.org
scm1.org_1   | 2022-08-15 20:21:17,373 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072 has been successfully formatted.
scm1.org_1   | 2022-08-15 20:21:17,377 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-08-15 20:21:17,380 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-08-15 20:21:17,387 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-08-15 20:21:17,387 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-15 20:21:17,389 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2022-08-15 20:21:17,395 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-08-15 20:21:17,468 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-08-15 20:21:17,501 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-08-15 20:21:17,502 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-08-15 20:21:17,516 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072
scm1.org_1   | 2022-08-15 20:21:17,517 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-08-15 20:21:17,517 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-08-15 20:21:17,518 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-08-15 20:21:17,519 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-08-15 20:21:17,519 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-08-15 20:21:17,520 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-08-15 20:21:17,521 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-08-15 20:21:17,521 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-08-15 20:21:17,549 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2022-08-15 20:24:45,153 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53788
om1_1        | 2022-08-15 20:24:45,177 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:24:50,374 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53800
om1_1        | 2022-08-15 20:24:50,402 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:24:51,338 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om1_1        | 2022-08-15 20:24:51,806 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om1_1        | 2022-08-15 20:25:04,120 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53854
om1_1        | 2022-08-15 20:25:04,135 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:25:04,792 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53864
om1_1        | 2022-08-15 20:25:04,803 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:25:09,861 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53870
om1_1        | 2022-08-15 20:25:09,876 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:25:10,567 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53880
om1_1        | 2022-08-15 20:25:10,571 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:25:10,586 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om1_1        | 2022-08-15 20:25:14,261 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42245
om1_1        | 2022-08-15 20:25:14,271 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:25:16,002 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53886
om1_1        | 2022-08-15 20:25:16,021 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:25:25,125 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53934
om1_1        | 2022-08-15 20:25:25,142 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:25:31,258 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53946
om1_1        | 2022-08-15 20:25:31,309 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:25:31,985 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53958
om1_1        | 2022-08-15 20:25:31,992 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:25:32,010 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om1_1        | 2022-08-15 20:25:37,198 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53970
om1_1        | 2022-08-15 20:25:37,214 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:25:42,161 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53984
om1_1        | 2022-08-15 20:25:42,190 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:25:59,469 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54042
om1_1        | 2022-08-15 20:25:59,509 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:26:00,138 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:95409-source for user:testuser
om1_1        | 2022-08-15 20:26:04,212 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54046
om1_1        | 2022-08-15 20:26:04,230 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:26:04,915 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:95409-target for user:testuser
om1_1        | 2022-08-15 20:26:08,868 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54058
om1_1        | 2022-08-15 20:26:08,889 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:26:09,509 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 95409-source
recon_1      | 2022-08-15 20:22:49,273 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 45 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:49,274 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 46 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:49,276 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 47 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:51,278 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 48 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:51,283 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 49 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:51,285 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 50 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:53,290 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 51 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:53,292 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 52 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:53,293 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 53 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:55,295 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 54 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:55,297 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 55 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:55,298 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 56 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:57,299 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 57 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:57,301 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 58 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:57,305 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 59 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:22:59,313 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 60 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:22:59,315 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 61 failover attempts. Trying to failover immediately.
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:32:05,350 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3098390070 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:32:17,497 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8574156590 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:32:18,215 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3551266484 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:32:19,767 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-9808591045 in volume:s3v
om2_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2498)
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2468)
om2_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:32:27,270 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0466368430 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:32:35,983 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9431911695 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:32:51,514 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6832627311 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:33:09,237 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-6832627311/ozone-test-2497758006/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1        | 2022-08-15 20:33:09,257 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2497758006/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om2_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-2497758006/multipartKey2. Entity too small.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-08-15 20:22:31,884 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:59Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-08-15 20:22:31,962 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-08-15 20:22:39,846 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-08-15 20:22:42,079 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-08-15 20:22:42,574 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-08-15 20:22:42,576 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-08-15 20:22:42,582 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-08-15 20:22:44,415 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-08-15 20:22:44,435 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-08-15 20:22:44,508 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-08-15 20:22:45,437 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-08-15 20:22:48,558 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2022-08-15 20:22:52,120 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2022-08-15 20:22:52,126 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2022-08-15 20:22:52,152 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2022-08-15 20:23:00,616 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2022-08-15 20:23:00,848 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2022-08-15 20:23:00,848 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2022-08-15 20:23:00,868 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2022-08-15 20:23:00,884 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-08-15 20:23:00,894 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-08-15 20:23:00,899 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-08-15 20:23:00,906 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-08-15 20:23:00,911 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:17440e9e-0b34-4cd8-8102-cb903e52057d,clusterId:CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072,subject:om3
om3_1        | 2022-08-15 20:23:02,169 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2022-08-15 20:23:03,992 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072;layoutVersion=3
om3_1        | 2022-08-15 20:23:04,202 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
kdc_1        | Aug 15 20:43:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1660596148, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 15 20:43:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 15 20:43:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
scm1.org_1   | 2022-08-15 20:21:17,550 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2022-08-15 20:21:17,550 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-08-15 20:21:17,567 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-08-15 20:21:17,568 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-08-15 20:21:17,571 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-08-15 20:21:17,572 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-08-15 20:21:17,573 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-08-15 20:21:17,573 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-08-15 20:21:17,575 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-08-15 20:21:17,575 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-08-15 20:21:17,605 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-08-15 20:21:17,606 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2022-08-15 20:21:17,606 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2022-08-15 20:21:17,606 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2022-08-15 20:21:17,607 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2022-08-15 20:21:17,608 [17440e9e-0b34-4cd8-8102-cb903e52057d-impl-thread1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: start as a follower, conf=-1: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-08-15 20:21:17,609 [17440e9e-0b34-4cd8-8102-cb903e52057d-impl-thread1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2022-08-15 20:21:17,610 [17440e9e-0b34-4cd8-8102-cb903e52057d-impl-thread1] INFO impl.RoleInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d: start 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState
scm1.org_1   | 2022-08-15 20:21:17,616 [17440e9e-0b34-4cd8-8102-cb903e52057d-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D1FD779EF072,id=17440e9e-0b34-4cd8-8102-cb903e52057d
scm1.org_1   | 2022-08-15 20:21:17,628 [main] INFO server.RaftServer: 17440e9e-0b34-4cd8-8102-cb903e52057d: start RPC server
scm1.org_1   | 2022-08-15 20:21:17,699 [main] INFO server.GrpcService: 17440e9e-0b34-4cd8-8102-cb903e52057d: GrpcService started, listening on 9894
scm1.org_1   | 2022-08-15 20:21:17,708 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$354/0x000000084031f040@4c361f63] INFO util.JvmPauseMonitor: JvmPauseMonitor-17440e9e-0b34-4cd8-8102-cb903e52057d: Started
scm1.org_1   | 2022-08-15 20:21:22,705 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState] INFO impl.FollowerState: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5095389691ns, electionTimeout:5086ms
scm1.org_1   | 2022-08-15 20:21:22,708 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState] INFO impl.RoleInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d: shutdown 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState
scm1.org_1   | 2022-08-15 20:21:22,708 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2022-08-15 20:23:14,713 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:59Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-08-15 20:23:14,826 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-08-15 20:23:22,571 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-08-15 20:23:25,840 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-08-15 20:23:26,532 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-08-15 20:23:26,533 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-08-15 20:23:26,536 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-08-15 20:23:26,581 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-08-15 20:23:26,768 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om3_1        | 2022-08-15 20:23:27,849 [main] INFO reflections.Reflections: Reflections took 643 ms to scan 1 urls, producing 113 keys and 334 values [using 2 cores]
om3_1        | 2022-08-15 20:23:29,731 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-08-15 20:23:29,736 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-08-15 20:23:29,736 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-08-15 20:23:32,493 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-08-15 20:23:32,914 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-08-15 20:23:38,337 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2022-08-15 20:23:39,191 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2022-08-15 20:23:39,198 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/945251588123.crt.
om3_1        | 2022-08-15 20:23:39,265 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-838496351631.crt.
om3_1        | 2022-08-15 20:23:39,577 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-08-15 20:23:40,616 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-08-15 20:23:40,627 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-08-15 20:23:42,272 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om3_1        | 2022-08-15 20:23:42,343 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2022-08-15 20:23:42,343 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2022-08-15 20:23:42,942 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om3_1        | 2022-08-15 20:23:43,657 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-08-15 20:23:43,673 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2022-08-15 20:23:43,820 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2022-08-15 20:23:44,839 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2022-08-15 20:23:44,936 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-08-15 20:23:45,280 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om3:9872, om1:9872, om2:9872
om3_1        | 2022-08-15 20:23:45,485 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
scm1.org_1   | 2022-08-15 20:21:22,718 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-08-15 20:21:22,719 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState] INFO impl.RoleInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d: start 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1
scm1.org_1   | 2022-08-15 20:21:22,726 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO impl.LeaderElection: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-08-15 20:21:22,727 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO impl.LeaderElection: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2022-08-15 20:21:22,728 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO impl.RoleInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d: shutdown 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1
scm1.org_1   | 2022-08-15 20:21:22,728 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm1.org_1   | 2022-08-15 20:21:22,728 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: change Leader from null to 17440e9e-0b34-4cd8-8102-cb903e52057d at term 1 for becomeLeader, leader elected after 5351ms
scm1.org_1   | 2022-08-15 20:21:22,734 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-08-15 20:21:22,739 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-08-15 20:21:22,741 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-08-15 20:21:22,746 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-08-15 20:21:22,747 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-08-15 20:21:22,748 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-08-15 20:21:22,759 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-08-15 20:21:22,765 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-08-15 20:21:22,769 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO impl.RoleInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d: start 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderStateImpl
scm1.org_1   | 2022-08-15 20:21:22,791 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2022-08-15 20:21:22,815 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: set configuration 0: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-15 20:21:22,878 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/current/log_inprogress_0
scm1.org_1   | 2022-08-15 20:21:23,710 [main] INFO server.RaftServer: 17440e9e-0b34-4cd8-8102-cb903e52057d: close
scm1.org_1   | 2022-08-15 20:21:23,711 [main] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: shutdown
scm1.org_1   | 2022-08-15 20:21:23,712 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D1FD779EF072,id=17440e9e-0b34-4cd8-8102-cb903e52057d
scm1.org_1   | 2022-08-15 20:21:23,712 [main] INFO impl.RoleInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d: shutdown 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderStateImpl
scm1.org_1   | 2022-08-15 20:21:23,717 [main] INFO impl.PendingRequests: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-PendingRequests: sendNotLeaderResponses
scm1.org_1   | 2022-08-15 20:21:23,720 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO impl.StateMachineUpdater: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2022-08-15 20:21:23,720 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO impl.StateMachineUpdater: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2022-08-15 20:21:23,724 [main] INFO impl.StateMachineUpdater: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2022-08-15 20:21:23,729 [main] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: closes. applyIndex: 0
scm1.org_1   | 2022-08-15 20:21:23,731 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm1.org_1   | 2022-08-15 20:21:23,732 [main] INFO segmented.SegmentedRaftLogWorker: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker close()
scm1.org_1   | 2022-08-15 20:21:23,735 [main] INFO server.GrpcService: 17440e9e-0b34-4cd8-8102-cb903e52057d: shutdown server with port 9894 now
scm1.org_1   | 2022-08-15 20:21:23,742 [main] INFO server.GrpcService: 17440e9e-0b34-4cd8-8102-cb903e52057d: shutdown server with port 9894 successfully
scm1.org_1   | 2022-08-15 20:21:23,743 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$354/0x000000084031f040@4c361f63] INFO util.JvmPauseMonitor: JvmPauseMonitor-17440e9e-0b34-4cd8-8102-cb903e52057d: Stopped
scm1.org_1   | 2022-08-15 20:21:23,743 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-15 20:21:23,746 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072; layoutVersion=4; scmId=17440e9e-0b34-4cd8-8102-cb903e52057d
scm1.org_1   | 2022-08-15 20:21:23,768 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm1.org_1   | ************************************************************/
om2_1        | 2022-08-15 20:33:10,737 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om2_1        | partName: "etag1"
om2_1        | , partNumber: 2
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-08-15 20:33:10,774 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:33:11,498 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1        | partName: "etag1"
om2_1        | , partNumber: 1
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-08-15 20:33:11,499 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:33:15,454 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3-f1d95bf0-ad24-4b2c-9460-5e2d0f741790-108828792582373412-1
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:33:16,182 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3-f1d95bf0-ad24-4b2c-9460-5e2d0f741790-108828792582373412-2
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:33:16,876 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3
om2_1        | 2022-08-15 20:33:16,880 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om2_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3 because parts are in Invalid order.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:33:20,999 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-1691574458/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-6832627311
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-6832627311key: ozone-test-1691574458/multipartKey5
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:33:21,735 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-6832627311, Key:ozone-test-3193360831/multipartKey. 
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:759)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:283)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 2022-08-15 20:23:46,606 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2022-08-15 20:23:47,002 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2022-08-15 20:23:47,012 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-08-15 20:23:47,013 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2022-08-15 20:23:47,014 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-08-15 20:23:47,015 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-08-15 20:23:47,017 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2022-08-15 20:23:47,025 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-08-15 20:23:47,026 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2022-08-15 20:23:47,029 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2022-08-15 20:23:47,057 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om3_1        | 2022-08-15 20:23:47,061 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om3_1        | 2022-08-15 20:23:49,481 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2022-08-15 20:23:49,502 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om3_1        | 2022-08-15 20:23:49,507 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om3_1        | 2022-08-15 20:23:49,512 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-08-15 20:23:49,515 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-08-15 20:23:49,529 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-08-15 20:23:49,618 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@6e847a7[Not completed]
om3_1        | 2022-08-15 20:23:49,618 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2022-08-15 20:23:49,689 [pool-27-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2022-08-15 20:23:49,750 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2022-08-15 20:23:49,763 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2022-08-15 20:23:49,765 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2022-08-15 20:23:49,765 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-08-15 20:23:49,765 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-08-15 20:23:49,766 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2022-08-15 20:23:49,787 [main] INFO om.OzoneManager: Creating RPC Server
om3_1        | 2022-08-15 20:23:49,823 [pool-27-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2022-08-15 20:23:49,830 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-08-15 20:23:49,846 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2022-08-15 20:23:49,857 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1        | 2022-08-15 20:23:49,861 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2022-08-15 20:23:50,003 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 8@om3
om3_1        | 2022-08-15 20:23:50,152 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2022-08-15 20:23:50,172 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2022-08-15 20:23:50,189 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2022-08-15 20:23:50,282 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2022-08-15 20:23:50,320 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-08-15 20:23:50,341 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om3_1        | 2022-08-15 20:23:50,628 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-08-15 20:23:50,824 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2022-08-15 20:23:50,825 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2022-08-15 20:23:50,934 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2022-08-15 20:23:50,934 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2022-08-15 20:23:50,939 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2022-08-15 20:23:50,942 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-08-15 20:23:50,950 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2022-08-15 20:23:50,951 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2022-08-15 20:23:50,959 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2022-08-15 20:23:50,967 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1        | 2022-08-15 20:23:50,968 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2022-08-15 20:23:51,174 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2022-08-15 20:23:51,180 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om3_1        | 2022-08-15 20:23:51,195 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
recon_1      | 2022-08-15 20:22:59,316 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 62 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:01,319 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 63 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:01,321 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 64 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:01,323 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 65 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:03,324 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 66 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:03,325 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 67 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:03,326 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 68 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:05,328 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 69 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:05,329 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 70 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:05,330 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 71 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:07,332 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 72 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:07,333 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 73 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:07,333 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 74 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:09,335 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 75 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:09,336 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 76 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:09,337 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 77 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2022-08-15 20:26:13,479 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54070
om1_1        | 2022-08-15 20:26:13,505 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:26:14,350 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46011
om1_1        | 2022-08-15 20:26:14,354 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:26:21,523 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54112
om1_1        | 2022-08-15 20:26:21,553 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:26:22,269 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 95409-source
om1_1        | 2022-08-15 20:26:26,212 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54124
om1_1        | 2022-08-15 20:26:26,232 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:26:26,880 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 95409-target
om1_1        | 2022-08-15 20:26:30,875 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54136
om1_1        | 2022-08-15 20:26:30,896 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:26:31,508 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 95409-target
om1_1        | 2022-08-15 20:26:35,460 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54158
om1_1        | 2022-08-15 20:26:35,476 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:26:36,110 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 95409-target
om1_1        | 2022-08-15 20:26:40,052 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54162
om1_1        | 2022-08-15 20:26:40,072 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:26:44,715 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54176
om1_1        | 2022-08-15 20:26:44,732 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:26:49,677 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54212
om1_1        | 2022-08-15 20:26:49,698 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:26:54,318 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54224
om1_1        | 2022-08-15 20:26:54,360 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:26:59,015 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54236
om1_1        | 2022-08-15 20:26:59,041 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:27:03,929 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54240
om1_1        | 2022-08-15 20:27:03,948 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:27:04,632 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 95409-target
om1_1        | 2022-08-15 20:27:08,833 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54252
om1_1        | 2022-08-15 20:27:08,857 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:27:13,274 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54268
om1_1        | 2022-08-15 20:27:13,292 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:27:13,898 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 95409-target
om1_1        | 2022-08-15 20:27:14,414 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42211
om1_1        | 2022-08-15 20:27:14,420 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:27:17,979 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54282
om1_1        | 2022-08-15 20:27:17,995 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-08-15 20:21:25,462 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:58Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-08-15 20:21:25,474 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-08-15 20:21:25,557 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-15 20:21:25,614 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-08-15 20:21:25,626 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-08-15 20:21:25,660 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-08-15 20:21:25,662 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-08-15 20:21:26,150 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm1.org_1   | 2022-08-15 20:21:26,256 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2022-08-15 20:21:26,259 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/838496351631.crt.
scm1.org_1   | 2022-08-15 20:21:26,268 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2022-08-15 20:21:26,438 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2022-08-15 20:21:26,438 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2022-08-15 20:21:26,487 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-15 20:21:26,674 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-15 20:21:26,974 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm1.org_1   | 2022-08-15 20:21:26,975 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm1.org_1   | 2022-08-15 20:21:27,030 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-08-15 20:21:27,052 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:17440e9e-0b34-4cd8-8102-cb903e52057d
scm1.org_1   | 2022-08-15 20:21:27,125 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-08-15 20:21:27,191 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-08-15 20:21:27,192 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-15 20:21:27,192 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-08-15 20:21:27,193 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-15 20:21:27,193 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-15 20:21:27,194 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-08-15 20:21:27,196 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-15 20:21:27,196 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-08-15 20:21:27,197 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-08-15 20:21:27,209 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2022-08-15 20:21:27,210 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2022-08-15 20:21:27,721 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-08-15 20:21:27,724 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm1.org_1   | 2022-08-15 20:21:27,725 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2022-08-15 20:21:27,725 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-08-15 20:21:27,726 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-08-15 20:21:27,729 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-08-15 20:21:27,733 [17440e9e-0b34-4cd8-8102-cb903e52057d-impl-thread1] INFO server.RaftServer: 17440e9e-0b34-4cd8-8102-cb903e52057d: found a subdirectory /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072
scm1.org_1   | 2022-08-15 20:21:27,739 [main] INFO server.RaftServer: 17440e9e-0b34-4cd8-8102-cb903e52057d: addNew group-D1FD779EF072:[] returns group-D1FD779EF072:java.util.concurrent.CompletableFuture@67328bcb[Not completed]
scm1.org_1   | 2022-08-15 20:21:27,765 [pool-16-thread-1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d: new RaftServerImpl for group-D1FD779EF072:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-08-15 20:21:27,767 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-08-15 20:21:27,767 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-08-15 20:21:27,767 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-08-15 20:21:27,768 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-08-15 20:21:27,768 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-08-15 20:21:27,768 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-08-15 20:21:27,775 [pool-16-thread-1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-08-15 20:21:27,782 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-08-15 20:21:27,786 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2022-08-15 20:23:51,280 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om3_1        | 2022-08-15 20:23:51,282 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2022-08-15 20:23:51,333 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2022-08-15 20:23:51,349 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2022-08-15 20:23:51,356 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2022-08-15 20:23:51,361 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2022-08-15 20:23:51,394 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2022-08-15 20:23:51,394 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2022-08-15 20:23:52,065 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2022-08-15 20:23:52,067 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om3_1        | 2022-08-15 20:23:52,071 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om3_1        | 2022-08-15 20:23:52,075 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om3_1        | 2022-08-15 20:23:52,085 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om3_1        | 2022-08-15 20:23:52,318 [main] INFO reflections.Reflections: Reflections took 2088 ms to scan 8 urls, producing 23 keys and 517 values [using 2 cores]
om3_1        | 2022-08-15 20:23:53,589 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2022-08-15 20:23:53,645 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2022-08-15 20:23:58,636 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2022-08-15 20:23:58,723 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2022-08-15 20:23:58,724 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2022-08-15 20:23:58,973 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2022-08-15 20:23:58,973 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1        | 2022-08-15 20:23:58,980 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-15 20:23:58,981 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2022-08-15 20:23:58,983 [om3-impl-thread1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-08-15 20:23:59,013 [om3-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2022-08-15 20:23:59,032 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2022-08-15 20:23:59,329 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2022-08-15 20:23:59,340 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$452/0x00000008405b2040@618f0ba] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2022-08-15 20:23:59,345 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2022-08-15 20:23:59,346 [Listener at om3/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-08-15 20:23:59,347 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2022-08-15 20:23:59,352 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-08-15 20:23:59,361 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1        | 2022-08-15 20:23:59,373 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2022-08-15 20:23:59,601 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2022-08-15 20:23:59,608 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2022-08-15 20:23:59,608 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2022-08-15 20:23:59,741 [Listener at om3/9862] INFO util.log: Logging initialized @54652ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2022-08-15 20:24:00,398 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2022-08-15 20:24:00,454 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2022-08-15 20:24:00,463 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2022-08-15 20:24:00,472 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2022-08-15 20:24:00,472 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2022-08-15 20:24:00,542 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2022-08-15 20:24:00,722 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2022-08-15 20:24:00,731 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om3_1        | 2022-08-15 20:24:00,935 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2022-08-15 20:24:00,944 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2022-08-15 20:24:00,957 [Listener at om3/9862] INFO server.session: node0 Scavenging every 600000ms
om3_1        | 2022-08-15 20:24:01,089 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-08-15 20:24:01,129 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6fc3c9d6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 2022-08-15 20:23:11,338 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 78 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:11,340 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 79 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:11,340 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 80 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:13,342 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 81 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:13,343 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 82 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:13,347 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 83 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:15,350 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 84 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:15,352 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 85 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:15,353 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 86 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:17,355 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 87 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:17,356 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 88 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:17,356 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 89 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:19,091 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49266
recon_1      | 2022-08-15 20:23:19,138 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:23:19,411 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 90 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:19,473 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 91 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:19,474 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 92 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:19,804 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49460
recon_1      | 2022-08-15 20:23:19,834 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:34:05,572 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0172643642 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:34:06,293 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-82438 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:34:21,531 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1197578926 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:34:25,810 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1197578926, Key:thereisnosuchfile.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:34:28,704 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1197578926, Key:ozone-test-4339809727/deletetestapidir/key=value/.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:34:32,371 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1197578926, Key:ozone-test-4339809727/deletetestapiprefix/key=value/file.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 2022-08-15 20:24:01,146 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3ee910d0{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | 2022-08-15 20:24:01,724 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-08-15 20:24:01,794 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6c76e4dc{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-9974056029249228510/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2022-08-15 20:24:01,837 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@2472d568{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2022-08-15 20:24:01,841 [Listener at om3/9862] INFO server.Server: Started @56760ms
om3_1        | 2022-08-15 20:24:01,847 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2022-08-15 20:24:01,847 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2022-08-15 20:24:01,849 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1        | 2022-08-15 20:24:01,884 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2022-08-15 20:24:01,857 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2022-08-15 20:24:02,182 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om3_1        | 2022-08-15 20:24:02,392 [Listener at om3/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om3_1        | 2022-08-15 20:24:02,437 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2a76555a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2022-08-15 20:24:03,162 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36397
om3_1        | 2022-08-15 20:24:03,186 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-15 20:24:04,172 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5189399748ns, electionTimeout:5089ms
om3_1        | 2022-08-15 20:24:04,173 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-08-15 20:24:04,195 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2022-08-15 20:24:04,198 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2022-08-15 20:24:04,208 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1        | 2022-08-15 20:24:04,266 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-15 20:24:06,220 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-08-15 20:24:06,249 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om3 at current term 1
om3_1        | 2022-08-15 20:24:06,289 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-15 20:24:06,777 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om3_1        | 2022-08-15 20:24:06,777 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:FAIL-t1
om3_1        | 2022-08-15 20:24:06,777 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om3<-om2#0:FAIL-t1
om3_1        | 2022-08-15 20:24:06,778 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om3_1        | 2022-08-15 20:24:06,782 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om3_1        | 2022-08-15 20:24:06,783 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om3_1        | 2022-08-15 20:24:06,783 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-08-15 20:24:06,834 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-08-15 20:24:06,834 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: reject ELECTION from om2: already has voted for om3 at current term 1
om3_1        | 2022-08-15 20:24:06,834 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-15 20:24:09,008 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60058
om3_1        | 2022-08-15 20:24:09,013 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-15 20:24:11,850 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 2, (t:0, i:~))
om3_1        | 2022-08-15 20:24:11,853 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om3_1        | 2022-08-15 20:24:11,853 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om1
om3_1        | 2022-08-15 20:24:11,854 [grpc-default-executor-1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-08-15 20:24:11,854 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState was interrupted
om3_1        | 2022-08-15 20:24:11,857 [grpc-default-executor-1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
scm1.org_1   | 2022-08-15 20:21:27,791 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-08-15 20:21:27,802 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/in_use.lock acquired by nodename 6@scm1.org
scm1.org_1   | 2022-08-15 20:21:27,813 [pool-16-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=17440e9e-0b34-4cd8-8102-cb903e52057d} from /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/current/raft-meta
scm1.org_1   | 2022-08-15 20:21:27,843 [pool-16-thread-1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: set configuration 0: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-15 20:21:27,844 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-08-15 20:21:27,845 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-08-15 20:21:27,852 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-08-15 20:21:27,852 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-15 20:21:27,854 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2022-08-15 20:21:27,921 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-08-15 20:21:27,929 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-08-15 20:21:27,929 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-08-15 20:21:27,935 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072
scm1.org_1   | 2022-08-15 20:21:27,935 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-08-15 20:21:27,936 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-08-15 20:21:27,937 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-08-15 20:21:27,937 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-08-15 20:21:27,938 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-08-15 20:21:27,938 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-08-15 20:21:27,939 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-08-15 20:21:27,939 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-08-15 20:21:27,947 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-08-15 20:21:27,948 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2022-08-15 20:21:27,948 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-08-15 20:21:27,971 [pool-16-thread-1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: set configuration 0: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-15 20:21:27,971 [pool-16-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/current/log_inprogress_0
scm1.org_1   | 2022-08-15 20:21:27,974 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-15 20:21:27,974 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-08-15 20:21:28,024 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-08-15 20:21:28,025 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-08-15 20:21:28,026 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-08-15 20:21:28,026 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-08-15 20:21:28,028 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-08-15 20:21:28,028 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-08-15 20:21:28,090 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-08-15 20:21:28,091 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2022-08-15 20:21:28,091 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2022-08-15 20:21:28,091 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2022-08-15 20:21:28,092 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2022-08-15 20:21:28,095 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2022-08-15 20:21:28,095 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2022-08-15 20:21:28,095 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2022-08-15 20:21:28,265 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm1.org_1   | 2022-08-15 20:21:28,423 [main] INFO reflections.Reflections: Reflections took 129 ms to scan 3 urls, producing 109 keys and 246 values 
scm1.org_1   | 2022-08-15 20:21:28,507 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm1.org_1   | 2022-08-15 20:21:28,507 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm1.org_1   | 2022-08-15 20:21:28,511 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2022-08-15 20:21:28,513 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2022-08-15 20:21:28,581 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2022-08-15 20:21:28,605 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
om1_1        | 2022-08-15 20:27:18,748 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 95409-source
om1_1        | 2022-08-15 20:27:23,012 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54318
om1_1        | 2022-08-15 20:27:23,028 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:27:31,088 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54334
om1_1        | 2022-08-15 20:27:31,110 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:27:38,220 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54362
om1_1        | 2022-08-15 20:27:38,240 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:27:45,714 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54380
om1_1        | 2022-08-15 20:27:45,732 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:27:53,328 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54428
om1_1        | 2022-08-15 20:27:53,342 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:27:58,499 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54432
om1_1        | 2022-08-15 20:27:58,525 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:28:03,402 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54444
om1_1        | 2022-08-15 20:28:03,426 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:28:08,051 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54456
om1_1        | 2022-08-15 20:28:08,065 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:28:12,927 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54468
om1_1        | 2022-08-15 20:28:12,944 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:28:14,469 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35043
om1_1        | 2022-08-15 20:28:14,485 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:28:17,936 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54482
om1_1        | 2022-08-15 20:28:17,957 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:28:23,224 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54510
om1_1        | 2022-08-15 20:28:23,241 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:28:27,968 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54522
om1_1        | 2022-08-15 20:28:27,987 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:28:32,842 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54544
om1_1        | 2022-08-15 20:28:32,864 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:28:37,749 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54556
om1_1        | 2022-08-15 20:28:37,775 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:28:42,367 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54570
om1_1        | 2022-08-15 20:28:42,384 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:28:47,144 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54574
om1_1        | 2022-08-15 20:28:47,168 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:28:52,357 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54610
om1_1        | 2022-08-15 20:28:52,373 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:28:52,989 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 95409-target
om1_1        | 2022-08-15 20:28:57,056 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54622
om1_1        | 2022-08-15 20:28:57,085 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:28:57,874 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:95409-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:29:02,082 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54636
om1_1        | 2022-08-15 20:29:02,101 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:29:02,831 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 95409-target
om1_1        | 2022-08-15 20:29:06,892 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54648
om1_1        | 2022-08-15 20:29:06,911 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:29:07,601 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:95409-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:29:11,542 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54660
om1_1        | 2022-08-15 20:29:11,557 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:29:14,534 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41549
om1_1        | 2022-08-15 20:29:14,543 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:29:16,556 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54666
om1_1        | 2022-08-15 20:29:16,577 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:29:17,167 [IPC Server handler 17 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket Volume:95409-target Bucket:unreadable-link 
om1_1        | 2022-08-15 20:29:21,746 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54702
om1_1        | 2022-08-15 20:29:21,764 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:29:26,479 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54714
om1_1        | 2022-08-15 20:29:26,496 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:29:27,087 [IPC Server handler 12 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket Volume:95409-source Bucket:unreadable-bucket Key:
om1_1        | 2022-08-15 20:29:31,210 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54726
om1_1        | 2022-08-15 20:29:31,245 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:29:31,916 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 95409-target
om1_1        | 2022-08-15 20:29:36,114 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54748
om1_1        | 2022-08-15 20:29:36,145 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:29:36,874 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 95409-target
om1_1        | 2022-08-15 20:29:40,893 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54752
om1_1        | 2022-08-15 20:29:40,912 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:29:41,609 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 95409-target
om1_1        | 2022-08-15 20:29:45,434 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54766
om1_1        | 2022-08-15 20:29:45,456 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:29:50,491 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54802
om1_1        | 2022-08-15 20:29:50,517 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:29:51,307 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 95409-target
om1_1        | 2022-08-15 20:29:55,483 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54814
om1_1        | 2022-08-15 20:29:55,501 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:30:03,085 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54830
om1_1        | 2022-08-15 20:30:03,102 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:30:10,310 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54846
om1_1        | 2022-08-15 20:30:10,332 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:30:14,593 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33189
om1_1        | 2022-08-15 20:30:14,608 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-15 20:24:11,864 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:OK-t2. Peer's state: om3@group-562213E44849:t2, leader=null, voted=om1, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-15 20:24:12,160 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om1 at term 2 for appendEntries, leader elected after 21988ms
om3_1        | 2022-08-15 20:24:12,243 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2022-08-15 20:24:12,263 [om3-server-thread1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2022-08-15 20:24:12,513 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2022-08-15 20:24:13,026 [om3@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1        | [id: "om1"
om3_1        | address: "om1:9872"
om3_1        | , id: "om3"
om3_1        | address: "om3:9872"
om3_1        | , id: "om2"
om3_1        | address: "om2:9872"
om3_1        | ]
om3_1        | 2022-08-15 20:24:51,642 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om3_1        | 2022-08-15 20:24:51,984 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om3_1        | 2022-08-15 20:25:10,594 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om3_1        | 2022-08-15 20:25:32,032 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om3_1        | 2022-08-15 20:26:00,157 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:95409-source for user:testuser
om3_1        | 2022-08-15 20:26:04,944 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:95409-target for user:testuser
om3_1        | 2022-08-15 20:26:09,525 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 95409-source
om3_1        | 2022-08-15 20:26:22,289 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 95409-source
om3_1        | 2022-08-15 20:26:26,889 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 95409-target
om3_1        | 2022-08-15 20:26:31,520 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 95409-target
om3_1        | 2022-08-15 20:26:36,123 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 95409-target
om3_1        | 2022-08-15 20:27:04,639 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 95409-target
om3_1        | 2022-08-15 20:27:13,905 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 95409-target
om3_1        | 2022-08-15 20:27:18,782 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 95409-source
om3_1        | 2022-08-15 20:28:53,009 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 95409-target
om3_1        | 2022-08-15 20:28:57,903 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:95409-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:29:02,844 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 95409-target
om3_1        | 2022-08-15 20:29:07,607 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:95409-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:29:31,935 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 95409-target
om3_1        | 2022-08-15 20:29:36,884 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 95409-target
om3_1        | 2022-08-15 20:29:41,629 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 95409-target
om3_1        | 2022-08-15 20:29:51,324 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 95409-target
om3_1        | 2022-08-15 20:30:26,323 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 95409-target
om3_1        | 2022-08-15 20:30:31,059 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:95409-target
om3_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
scm1.org_1   | 2022-08-15 20:21:28,606 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm1.org_1   | 2022-08-15 20:21:28,620 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm1.org_1   | 2022-08-15 20:21:28,698 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm1.org_1   | 2022-08-15 20:21:28,698 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm1.org_1   | 2022-08-15 20:21:28,706 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm1.org_1   | 2022-08-15 20:21:28,706 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm1.org_1   | 2022-08-15 20:21:28,709 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm1.org_1   | 2022-08-15 20:21:28,710 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm1.org_1   | 2022-08-15 20:21:28,716 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm1.org_1   | 2022-08-15 20:21:28,717 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm1.org_1   | 2022-08-15 20:21:28,757 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2022-08-15 20:21:28,785 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2022-08-15 20:21:28,846 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2022-08-15 20:21:28,875 [main] INFO UnderReplicatedQueueThread: Starting UnderReplicatedQueueThread Service.
scm1.org_1   | 2022-08-15 20:21:28,877 [main] INFO ha.SCMServiceManager: Registering service UnderReplicatedQueueThread.
scm1.org_1   | 2022-08-15 20:21:28,880 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-08-15 20:21:28,886 [main] INFO OverReplicatedQueueThread: Starting OverReplicatedQueueThread Service.
scm1.org_1   | 2022-08-15 20:21:28,887 [main] INFO ha.SCMServiceManager: Registering service OverReplicatedQueueThread.
scm1.org_1   | 2022-08-15 20:21:28,888 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2022-08-15 20:21:28,898 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm1.org_1   | 2022-08-15 20:21:28,902 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:21:28,905 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-08-15 20:21:28,943 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-08-15 20:21:28,958 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-08-15 20:21:28,959 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 838496351631 on primary SCM
scm1.org_1   | 2022-08-15 20:21:28,963 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm1.org_1   | 2022-08-15 20:21:28,992 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-08-15 20:21:29,031 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2022-08-15 20:21:29,762 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-08-15 20:21:29,771 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-08-15 20:21:29,772 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm1.org_1   | 2022-08-15 20:21:29,828 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-08-15 20:21:29,839 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-08-15 20:21:29,840 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2022-08-15 20:21:29,879 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-08-15 20:21:29,943 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-08-15 20:21:29,944 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm1.org_1   | 2022-08-15 20:21:30,129 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm1.org_1   | 2022-08-15 20:21:30,132 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | Container Balancer status:
scm1.org_1   | Key                            Value
scm1.org_1   | Running                        false
scm1.org_1   | Container Balancer Configuration values:
scm1.org_1   | Key                                                Value
scm1.org_1   | Threshold                                          10
scm1.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm1.org_1   | Max Size to Move per Iteration                     500GB
scm1.org_1   | Max Size Entering Target per Iteration             26GB
scm1.org_1   | Max Size Leaving Source per Iteration              26GB
scm1.org_1   | 
scm1.org_1   | 2022-08-15 20:21:30,136 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-08-15 20:21:30,137 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm1.org_1   | 2022-08-15 20:21:30,161 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm1.org_1   | 2022-08-15 20:21:30,162 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm1.org_1   | 2022-08-15 20:21:30,163 [17440e9e-0b34-4cd8-8102-cb903e52057d-impl-thread1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: start as a follower, conf=0: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-15 20:21:30,163 [17440e9e-0b34-4cd8-8102-cb903e52057d-impl-thread1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm1.org_1   | 2022-08-15 20:21:30,165 [17440e9e-0b34-4cd8-8102-cb903e52057d-impl-thread1] INFO impl.RoleInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d: start 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState
scm1.org_1   | 2022-08-15 20:21:30,184 [17440e9e-0b34-4cd8-8102-cb903e52057d-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D1FD779EF072,id=17440e9e-0b34-4cd8-8102-cb903e52057d
scm1.org_1   | 2022-08-15 20:21:30,190 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 17440e9e-0b34-4cd8-8102-cb903e52057d: start RPC server
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:34:42,058 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6614062836 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:34:53,294 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4509533375 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:34:57,264 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-4509533375, Key:ozone-test-3363941668/multidelete/key=value/f4.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-15 20:35:05,680 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8409873988 of layout LEGACY in volume: s3v
om2_1        | 2022-08-15 20:35:28,048 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2278251128 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:30:15,095 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54860
om1_1        | 2022-08-15 20:30:15,127 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:30:20,480 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54896
om1_1        | 2022-08-15 20:30:20,508 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:30:25,557 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54908
om1_1        | 2022-08-15 20:30:25,578 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:30:26,305 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 95409-target
om1_1        | 2022-08-15 20:30:30,367 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54920
om1_1        | 2022-08-15 20:30:30,384 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:30:31,025 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:95409-target
om1_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:30:35,279 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54934
om1_1        | 2022-08-15 20:30:35,305 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:31:14,660 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38691
om1_1        | 2022-08-15 20:31:14,667 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:31:15,138 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55224
om1_1        | 2022-08-15 20:31:15,158 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:31:20,880 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:33909
om1_1        | 2022-08-15 20:31:20,904 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:31:21,460 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:21,542 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:21,559 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2972544550 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:31:25,600 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55274
om1_1        | 2022-08-15 20:31:25,626 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:31:29,346 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:29,355 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:29,372 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0854404852 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:31:30,076 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:30,089 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:30,120 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:32,143 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:32,883 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:32,891 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:32,898 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:33,046 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:33,743 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:33,751 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:33,764 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:33,773 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:34,490 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:34,495 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:34,499 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:34,508 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:35,188 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:35,202 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:35,206 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:35,211 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:35,906 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:35,913 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:35,918 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:36,133 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:36,817 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:36,823 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:36,826 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:36,832 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:40,491 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55326
om1_1        | 2022-08-15 20:31:40,508 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:31:44,140 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:44,147 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:44,162 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0897557074 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:31:44,732 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:44,746 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:44,769 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-zohirdzrfr of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:31:44,795 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
scm1.org_1   | 2022-08-15 20:21:30,342 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 17440e9e-0b34-4cd8-8102-cb903e52057d: GrpcService started, listening on 9894
scm1.org_1   | 2022-08-15 20:21:30,347 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-08-15 20:21:30,348 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm1.org_1   | 2022-08-15 20:21:30,355 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2022-08-15 20:21:30,355 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2022-08-15 20:21:30,360 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$485/0x0000000840552840@52bcd7c9] INFO util.JvmPauseMonitor: JvmPauseMonitor-17440e9e-0b34-4cd8-8102-cb903e52057d: Started
scm1.org_1   | 2022-08-15 20:21:30,514 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2022-08-15 20:21:30,544 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2022-08-15 20:21:30,544 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2022-08-15 20:21:30,967 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2022-08-15 20:21:30,972 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-08-15 20:21:30,978 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm1.org_1   | 2022-08-15 20:21:31,061 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm1.org_1   | 2022-08-15 20:21:31,132 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm1.org_1   | 2022-08-15 20:21:31,140 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-08-15 20:21:31,145 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm1.org_1   | 2022-08-15 20:21:31,200 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2022-08-15 20:21:31,202 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-08-15 20:21:31,202 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2022-08-15 20:21:31,203 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2022-08-15 20:21:31,307 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@70b437bb] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2022-08-15 20:21:31,339 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2022-08-15 20:21:31,340 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2022-08-15 20:21:31,342 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | 2022-08-15 20:21:31,395 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @7139ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2022-08-15 20:21:31,596 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm1.org_1   | 2022-08-15 20:21:31,603 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm1.org_1   | 2022-08-15 20:21:31,609 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2022-08-15 20:21:31,612 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2022-08-15 20:21:31,612 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm1.org_1   | 2022-08-15 20:21:31,615 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm1.org_1   | 2022-08-15 20:21:31,672 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm1.org_1   | 2022-08-15 20:21:31,696 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm1.org_1   | 2022-08-15 20:21:31,846 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm1.org_1   | 2022-08-15 20:21:31,862 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm1.org_1   | 2022-08-15 20:21:31,865 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm1.org_1   | 2022-08-15 20:21:31,929 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-08-15 20:21:31,943 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@79de9f90{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm1.org_1   | 2022-08-15 20:21:31,948 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1e32a3ed{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | 2022-08-15 20:21:32,243 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43413
scm1.org_1   | 2022-08-15 20:21:32,298 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:21:32,344 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-08-15 20:21:32,372 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3725471{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-8545384381193990240/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2022-08-15 20:21:32,388 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@645a9649{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm1.org_1   | 2022-08-15 20:21:32,389 [Listener at 0.0.0.0/9860] INFO server.Server: Started @8133ms
scm1.org_1   | 2022-08-15 20:21:32,394 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm1.org_1   | 2022-08-15 20:21:32,394 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm1.org_1   | 2022-08-15 20:21:32,396 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2022-08-15 20:21:32,514 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.25.0.115:43413
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:31:21,579 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2972544550 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:31:29,386 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0854404852 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:31:44,170 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0897557074 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:31:44,774 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-zohirdzrfr of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:31:48,659 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-xmdkdafcgo of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:32:01,522 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4899227404 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:32:02,253 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8572712417 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:32:02,931 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1164551495 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:32:03,659 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-1164551495 in volume:s3v
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:32:05,342 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3098390070 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:32:17,480 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8574156590 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:32:18,197 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3551266484 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:32:19,752 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-9808591045 in volume:s3v
om3_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2498)
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2468)
om3_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:32:27,281 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0466368430 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:32:35,994 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9431911695 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:32:51,508 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6832627311 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:33:09,237 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-6832627311/ozone-test-2497758006/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om3_1        | 2022-08-15 20:33:09,241 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2497758006/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om3_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-2497758006/multipartKey2. Entity too small.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | 2022-08-15 20:23:21,489 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 93 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:21,515 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 94 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:21,531 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 95 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:22,137 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35534
recon_1      | 2022-08-15 20:23:22,342 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:23:23,360 [IPC Server handler 3 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/11946e6e-1ab1-47b6-94a8-e6dbe917e210
recon_1      | 2022-08-15 20:23:23,633 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 96 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:23,660 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 97 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:23,662 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 98 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:23,720 [IPC Server handler 3 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931661290961, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:24,041 [IPC Server handler 2 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e2584860-2683-4862-8eba-daf2ea0fcaee
recon_1      | 2022-08-15 20:23:24,110 [IPC Server handler 2 on default port 9891] INFO node.SCMNodeManager: Registered Data node : e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931151845995, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:24,180 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 11946e6e-1ab1-47b6-94a8-e6dbe917e210 to Node DB.
recon_1      | 2022-08-15 20:23:24,213 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node e2584860-2683-4862-8eba-daf2ea0fcaee to Node DB.
recon_1      | 2022-08-15 20:23:24,711 [IPC Server handler 18 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-15 20:23:24,855 [IPC Server handler 3 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
recon_1      | 2022-08-15 20:23:24,855 [IPC Server handler 3 on default port 9891] INFO node.SCMNodeManager: Registered Data node : ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 934681712113, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:24,867 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f to Node DB.
recon_1      | 2022-08-15 20:23:25,251 [IPC Server handler 0 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-15 20:23:25,729 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 99 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:25,731 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 100 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:25,750 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 101 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:25,753 [IPC Server handler 27 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-15 20:23:26,622 [IPC Server handler 5 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-15 20:23:27,626 [IPC Server handler 9 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
om1_1        | 2022-08-15 20:31:44,800 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:44,807 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:44,990 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,041 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,044 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,049 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,191 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,246 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,251 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,261 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,383 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,431 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,435 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,446 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,591 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,600 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,684 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,702 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,717 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:45,750 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:46,805 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:47,011 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:47,099 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:47,118 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:47,250 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:47,254 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:47,259 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:47,329 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:47,344 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:47,381 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:47,454 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:47,470 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:47,489 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,015 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,470 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,546 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,553 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,621 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,639 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,650 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-xmdkdafcgo of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:31:48,709 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,734 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,742 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,788 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,794 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,846 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,871 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,922 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,928 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:48,935 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:49,231 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:49,389 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:49,420 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:49,448 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:49,452 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:49,475 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:49,480 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:49,931 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:49,935 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:49,941 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:49,980 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:50,024 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:50,032 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:50,051 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:50,057 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:50,062 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:50,105 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:50,123 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:50,160 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:50,367 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:51,698 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:51,792 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:51,798 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:51,817 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:51,936 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:53,217 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:53,308 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:53,314 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:31:57,591 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55398
om1_1        | 2022-08-15 20:31:57,614 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:32:01,486 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:01,491 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:01,501 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4899227404 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:32:02,211 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:02,219 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:02,229 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8572712417 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:32:02,908 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:02,914 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:02,925 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1164551495 of layout LEGACY in volume: s3v
recon_1      | 2022-08-15 20:23:27,757 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 102 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:27,758 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 103 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:27,759 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 104 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:28,670 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=f3e347f8-57d4-4c72-b323-3754be4def15. Trying to get from SCM.
recon_1      | 2022-08-15 20:23:29,012 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: f3e347f8-57d4-4c72-b323-3754be4def15, Nodes: 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:11946e6e-1ab1-47b6-94a8-e6dbe917e210, CreationTimestamp2022-08-15T20:23:25.182Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-08-15 20:23:29,210 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f3e347f8-57d4-4c72-b323-3754be4def15, Nodes: 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:11946e6e-1ab1-47b6-94a8-e6dbe917e210, CreationTimestamp2022-08-15T20:23:25.182Z[UTC]].
recon_1      | 2022-08-15 20:23:29,760 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 105 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:29,762 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 106 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:29,762 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 107 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:29,812 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=d9c5810d-5123-4bc2-bd6e-bc27d48f5863. Trying to get from SCM.
recon_1      | 2022-08-15 20:23:29,833 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: d9c5810d-5123-4bc2-bd6e-bc27d48f5863, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:25.733Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-08-15 20:23:29,834 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d9c5810d-5123-4bc2-bd6e-bc27d48f5863, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:25.733Z[UTC]].
recon_1      | 2022-08-15 20:23:29,834 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=d9c5810d-5123-4bc2-bd6e-bc27d48f5863 reported by ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 934681712113, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:29,834 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d9c5810d-5123-4bc2-bd6e-bc27d48f5863, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, CreationTimestamp2022-08-15T20:23:25.733Z[UTC]] moved to OPEN state
recon_1      | 2022-08-15 20:23:29,977 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e. Trying to get from SCM.
scm1.org_1   | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:17440e9e-0b34-4cd8-8102-cb903e52057d is not the leader. Could not determine the leader node.
scm1.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-08-15 20:21:32,837 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:51640
scm1.org_1   | 2022-08-15 20:21:32,861 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:21:35,216 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60744
scm1.org_1   | 2022-08-15 20:21:35,232 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:21:35,332 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState] INFO impl.FollowerState: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5167304372ns, electionTimeout:5108ms
scm1.org_1   | 2022-08-15 20:21:35,333 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState] INFO impl.RoleInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d: shutdown 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState
scm1.org_1   | 2022-08-15 20:21:35,334 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm1.org_1   | 2022-08-15 20:21:35,337 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-08-15 20:21:35,337 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-FollowerState] INFO impl.RoleInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d: start 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1
scm1.org_1   | 2022-08-15 20:21:35,370 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO impl.LeaderElection: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-15 20:21:35,371 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO impl.LeaderElection: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm1.org_1   | 2022-08-15 20:21:35,372 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO impl.RoleInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d: shutdown 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1
scm1.org_1   | 2022-08-15 20:21:35,373 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm1.org_1   | 2022-08-15 20:21:35,373 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm1.org_1   | 2022-08-15 20:21:35,373 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm1.org_1   | 2022-08-15 20:21:35,387 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: change Leader from null to 17440e9e-0b34-4cd8-8102-cb903e52057d at term 2 for becomeLeader, leader elected after 7529ms
scm1.org_1   | 2022-08-15 20:21:35,404 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-08-15 20:21:35,410 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-08-15 20:21:35,411 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-08-15 20:21:35,420 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-08-15 20:21:35,421 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-08-15 20:21:35,426 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-08-15 20:21:35,431 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-08-15 20:21:35,440 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-08-15 20:21:35,445 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO impl.RoleInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d: start 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderStateImpl
scm1.org_1   | 2022-08-15 20:21:35,465 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm1.org_1   | 2022-08-15 20:21:35,477 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/current/log_inprogress_0 to /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/current/log_0-0
om1_1        | 2022-08-15 20:32:03,636 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:03,642 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:03,654 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-1164551495 in volume:s3v
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:32:04,360 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:05,316 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:05,321 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:05,333 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3098390070 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:32:09,036 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55430
om1_1        | 2022-08-15 20:32:09,067 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:32:13,715 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55442
om1_1        | 2022-08-15 20:32:13,732 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:32:14,706 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35199
om1_1        | 2022-08-15 20:32:14,710 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:32:17,444 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:42065
om1_1        | 2022-08-15 20:32:17,455 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:32:17,456 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:17,464 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:17,476 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8574156590 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:32:18,164 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:18,169 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:18,181 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3551266484 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:32:18,868 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:18,872 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:19,727 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:19,731 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:19,746 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-9808591045 in volume:s3v
om1_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2498)
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2468)
om1_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:32:23,656 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55488
om1_1        | 2022-08-15 20:32:23,673 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:32:27,244 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:27,249 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
scm1.org_1   | 2022-08-15 20:21:35,507 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/current/log_inprogress_1
scm1.org_1   | 2022-08-15 20:21:35,507 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderElection1] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: set configuration 1: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-15 20:21:35,515 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm1.org_1   | 2022-08-15 20:21:35,520 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm1.org_1   | 2022-08-15 20:21:35,527 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:21:35,536 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2022-08-15 20:21:35,538 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-08-15 20:21:35,539 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2022-08-15 20:21:35,548 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-08-15 20:21:35,549 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2022-08-15 20:21:38,259 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59434
scm1.org_1   | 2022-08-15 20:21:38,272 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:21:38,336 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: 3fa27e21-96df-4954-913e-c2b6f8845795
scm1.org_1   | 2022-08-15 20:21:38,530 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: bd7e083b-2107-4207-bc11-ddad2e6a2f41
scm1.org_1   | 2022-08-15 20:21:38,835 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:21:38,835 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2022-08-15 20:21:38,835 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm1.org_1   | 2022-08-15 20:21:40,241 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:21:57,322 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:32856
scm1.org_1   | 2022-08-15 20:21:57,405 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:21:58,413 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:52058
scm1.org_1   | 2022-08-15 20:21:58,527 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:21:58,529 [IPC Server handler 0 on default port 9863] INFO ha.SCMRatisServerImpl: 17440e9e-0b34-4cd8-8102-cb903e52057d: Submitting SetConfiguration request to Ratis server with new SCM peers list: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-08-15 20:21:58,531 [IPC Server handler 0 on default port 9863] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: receive setConfiguration SetConfigurationRequest:client-5FDD121650E7->17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072, cid=1, seq=0, RW, null, peers:[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-08-15 20:21:58,531 [IPC Server handler 0 on default port 9863] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-5FDD121650E7->17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072, cid=1, seq=0, RW, null, peers:[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-08-15 20:21:58,601 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-08-15 20:21:58,601 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-15 20:21:58,602 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-08-15 20:21:58,613 [IPC Server handler 0 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-08-15 20:21:58,624 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-08-15 20:21:58,624 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-08-15 20:21:58,678 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->3fa27e21-96df-4954-913e-c2b6f8845795-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->3fa27e21-96df-4954-913e-c2b6f8845795-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2022-08-15 20:21:58,709 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->3fa27e21-96df-4954-913e-c2b6f8845795-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->3fa27e21-96df-4954-913e-c2b6f8845795-GrpcLogAppender: send 17440e9e-0b34-4cd8-8102-cb903e52057d->3fa27e21-96df-4954-913e-c2b6f8845795#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2022-08-15 20:21:59,043 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42201
scm1.org_1   | 2022-08-15 20:21:59,064 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:21:59,830 [grpc-default-executor-0] INFO server.GrpcLogAppender: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->3fa27e21-96df-4954-913e-c2b6f8845795-InstallSnapshotResponseHandler: received the first reply 17440e9e-0b34-4cd8-8102-cb903e52057d<-3fa27e21-96df-4954-913e-c2b6f8845795#0:FAIL-t0,ALREADY_INSTALLED
scm1.org_1   | 2022-08-15 20:21:59,832 [grpc-default-executor-0] INFO server.GrpcLogAppender: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->3fa27e21-96df-4954-913e-c2b6f8845795-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2022-08-15 20:21:59,835 [grpc-default-executor-0] INFO leader.FollowerInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->3fa27e21-96df-4954-913e-c2b6f8845795: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-15 20:21:59,837 [grpc-default-executor-0] INFO leader.FollowerInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->3fa27e21-96df-4954-913e-c2b6f8845795: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-15 20:21:59,837 [grpc-default-executor-0] INFO leader.FollowerInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->3fa27e21-96df-4954-913e-c2b6f8845795: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2022-08-15 20:21:59,838 [grpc-default-executor-0] INFO leader.FollowerInfo: Follower 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->3fa27e21-96df-4954-913e-c2b6f8845795 acknowledged installing snapshot
scm1.org_1   | 2022-08-15 20:21:59,838 [grpc-default-executor-0] INFO leader.FollowerInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->3fa27e21-96df-4954-913e-c2b6f8845795: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2022-08-15 20:21:59,925 [grpc-default-executor-0] INFO leader.FollowerInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->3fa27e21-96df-4954-913e-c2b6f8845795: nextIndex: updateUnconditionally 7 -> 0
scm1.org_1   | 2022-08-15 20:21:59,995 [grpc-default-executor-0] INFO leader.FollowerInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->3fa27e21-96df-4954-913e-c2b6f8845795: nextIndex: updateUnconditionally 0 -> 0
scm1.org_1   | 2022-08-15 20:22:00,403 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderStateImpl] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: set configuration 7: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|priority:0], old=[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-08-15 20:22:00,565 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderStateImpl] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: set configuration 9: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|priority:0], old=null
scm1.org_1   | 2022-08-15 20:22:00,635 [IPC Server handler 0 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 3fa27e21-96df-4954-913e-c2b6f8845795.
scm1.org_1   | 2022-08-15 20:22:03,369 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:59828
scm1.org_1   | 2022-08-15 20:22:03,379 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:22:05,033 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:37196
scm1.org_1   | 2022-08-15 20:22:05,098 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:22:07,482 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:42450
scm1.org_1   | 2022-08-15 20:22:07,500 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:22:07,501 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: b7365c8d-2724-48d2-bef1-0dcca965a3a4
scm1.org_1   | 2022-08-15 20:22:07,703 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:22:10,006 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33056
scm1.org_1   | 2022-08-15 20:22:10,052 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:22:21,029 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:37398
scm1.org_1   | 2022-08-15 20:22:21,188 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:22:21,193 [IPC Server handler 22 on default port 9863] INFO ha.SCMRatisServerImpl: 17440e9e-0b34-4cd8-8102-cb903e52057d: Submitting SetConfiguration request to Ratis server with new SCM peers list: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|priority:0, b7365c8d-2724-48d2-bef1-0dcca965a3a4|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-08-15 20:22:21,232 [IPC Server handler 22 on default port 9863] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: receive setConfiguration SetConfigurationRequest:client-5FDD121650E7->17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072, cid=2, seq=0, RW, null, peers:[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|priority:0, b7365c8d-2724-48d2-bef1-0dcca965a3a4|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-08-15 20:22:21,244 [IPC Server handler 22 on default port 9863] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-5FDD121650E7->17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072, cid=2, seq=0, RW, null, peers:[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|priority:0, b7365c8d-2724-48d2-bef1-0dcca965a3a4|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-08-15 20:22:21,252 [IPC Server handler 22 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-08-15 20:22:21,263 [IPC Server handler 22 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-15 20:22:21,276 [IPC Server handler 22 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om3_1        | 2022-08-15 20:33:10,755 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om3_1        | partName: "etag1"
om3_1        | , partNumber: 2
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-08-15 20:33:10,758 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:33:11,495 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om3_1        | partName: "etag1"
om3_1        | , partNumber: 1
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-08-15 20:33:11,499 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:33:15,454 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3-f1d95bf0-ad24-4b2c-9460-5e2d0f741790-108828792582373412-1
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:33:16,165 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3-f1d95bf0-ad24-4b2c-9460-5e2d0f741790-108828792582373412-2
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:33:16,873 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3
om3_1        | 2022-08-15 20:33:16,874 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om3_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3 because parts are in Invalid order.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
recon_1      | 2022-08-15 20:23:29,991 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 4e74fa7e-554b-49cb-895a-4beb5c69c54e, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:25.974Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-08-15 20:23:29,992 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4e74fa7e-554b-49cb-895a-4beb5c69c54e, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:25.974Z[UTC]].
recon_1      | 2022-08-15 20:23:29,993 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e reported by 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931661290961, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:30,666 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e reported by ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 934681712113, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:31,765 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 108 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:31,766 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 109 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:31,767 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 110 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:33,769 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 111 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:33,772 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 112 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:33,773 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 113 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:35,142 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e reported by 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931661290961, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:35,722 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e reported by ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 934681712113, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:35,774 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 114 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:35,776 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 115 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:35,777 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 116 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2022-08-15 20:32:27,261 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0466368430 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:32:27,968 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:27,975 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:28,674 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:28,678 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:32,400 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55524
om1_1        | 2022-08-15 20:32:32,419 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:32:35,960 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:35,964 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:35,980 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9431911695 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:32:36,662 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:36,666 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:36,671 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:40,692 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55542
om1_1        | 2022-08-15 20:32:40,712 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:32:47,346 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55558
om1_1        | 2022-08-15 20:32:47,363 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:32:51,473 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:36719
om1_1        | 2022-08-15 20:32:51,476 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:32:51,477 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:51,493 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:51,505 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6832627311 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:32:52,278 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:52,286 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:52,290 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:53,051 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:53,056 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:53,073 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:53,611 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:54,464 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:54,468 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:54,497 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:54,766 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:55,514 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:55,518 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:56,236 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:56,239 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:57,404 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:57,407 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:57,411 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:58,163 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:58,168 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:58,172 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
scm1.org_1   | 2022-08-15 20:22:21,296 [IPC Server handler 22 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-08-15 20:22:21,296 [IPC Server handler 22 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-08-15 20:22:21,300 [IPC Server handler 22 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-08-15 20:22:21,300 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->b7365c8d-2724-48d2-bef1-0dcca965a3a4-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->b7365c8d-2724-48d2-bef1-0dcca965a3a4-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2022-08-15 20:22:21,327 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->b7365c8d-2724-48d2-bef1-0dcca965a3a4-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->b7365c8d-2724-48d2-bef1-0dcca965a3a4-GrpcLogAppender: send 17440e9e-0b34-4cd8-8102-cb903e52057d->b7365c8d-2724-48d2-bef1-0dcca965a3a4#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2022-08-15 20:22:24,346 [grpc-default-executor-0] INFO server.GrpcLogAppender: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->b7365c8d-2724-48d2-bef1-0dcca965a3a4-InstallSnapshotResponseHandler: received the first reply 17440e9e-0b34-4cd8-8102-cb903e52057d<-b7365c8d-2724-48d2-bef1-0dcca965a3a4#0:FAIL-t0,ALREADY_INSTALLED
scm1.org_1   | 2022-08-15 20:22:24,346 [grpc-default-executor-0] INFO server.GrpcLogAppender: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->b7365c8d-2724-48d2-bef1-0dcca965a3a4-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2022-08-15 20:22:24,350 [grpc-default-executor-0] INFO leader.FollowerInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->b7365c8d-2724-48d2-bef1-0dcca965a3a4: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-15 20:22:24,350 [grpc-default-executor-0] INFO leader.FollowerInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->b7365c8d-2724-48d2-bef1-0dcca965a3a4: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-15 20:22:24,350 [grpc-default-executor-0] INFO leader.FollowerInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->b7365c8d-2724-48d2-bef1-0dcca965a3a4: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2022-08-15 20:22:24,350 [grpc-default-executor-0] INFO leader.FollowerInfo: Follower 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->b7365c8d-2724-48d2-bef1-0dcca965a3a4 acknowledged installing snapshot
scm1.org_1   | 2022-08-15 20:22:24,351 [grpc-default-executor-0] INFO leader.FollowerInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->b7365c8d-2724-48d2-bef1-0dcca965a3a4: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2022-08-15 20:22:24,561 [grpc-default-executor-0] INFO leader.FollowerInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->b7365c8d-2724-48d2-bef1-0dcca965a3a4: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2022-08-15 20:22:24,577 [grpc-default-executor-0] INFO leader.FollowerInfo: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072->b7365c8d-2724-48d2-bef1-0dcca965a3a4: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2022-08-15 20:22:25,799 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderStateImpl] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: set configuration 13: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|priority:0, b7365c8d-2724-48d2-bef1-0dcca965a3a4|rpc:scm3.org:9894|priority:0], old=[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-08-15 20:22:25,873 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-LeaderStateImpl] INFO server.RaftServer$Division: 17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072: set configuration 15: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|priority:0, b7365c8d-2724-48d2-bef1-0dcca965a3a4|rpc:scm3.org:9894|priority:0], old=null
scm1.org_1   | 2022-08-15 20:22:25,981 [IPC Server handler 22 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: b7365c8d-2724-48d2-bef1-0dcca965a3a4.
scm1.org_1   | 2022-08-15 20:22:32,531 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33214
scm1.org_1   | 2022-08-15 20:22:32,711 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:22:32,769 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:42662
scm1.org_1   | 2022-08-15 20:22:32,815 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:22:46,252 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:49812
scm1.org_1   | 2022-08-15 20:22:46,413 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:22:47,598 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53376
scm1.org_1   | 2022-08-15 20:22:47,747 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:22:48,099 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:42342
scm1.org_1   | 2022-08-15 20:22:48,241 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:22:48,868 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55404
scm1.org_1   | 2022-08-15 20:22:49,065 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:22:49,070 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 491064f5c800, UUID: e2584860-2683-4862-8eba-daf2ea0fcaee
scm1.org_1   | 2022-08-15 20:22:49,451 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48122
scm1.org_1   | 2022-08-15 20:22:49,483 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:22:49,595 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
recon_1      | 2022-08-15 20:23:37,778 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 117 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:37,779 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 118 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:37,780 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 119 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:39,299 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=ee87d8de-c101-4564-aff4-e153e5671e57. Trying to get from SCM.
recon_1      | 2022-08-15 20:23:39,303 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: ee87d8de-c101-4564-aff4-e153e5671e57, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:26.205Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-08-15 20:23:39,305 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ee87d8de-c101-4564-aff4-e153e5671e57, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:26.205Z[UTC]].
recon_1      | 2022-08-15 20:23:39,305 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee87d8de-c101-4564-aff4-e153e5671e57 reported by ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 934681712113, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:39,305 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e reported by ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 934681712113, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:39,782 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 120 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:39,787 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 121 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:39,788 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 122 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:39,948 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49534
recon_1      | 2022-08-15 20:23:40,076 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:23:40,078 [IPC Server handler 1 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-15 20:23:40,079 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e reported by e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931151845995, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om1_1        | 2022-08-15 20:32:58,993 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:58,997 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:59,028 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:32:59,526 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:00,396 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:00,400 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:00,432 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:00,911 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:01,776 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:01,784 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:01,788 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:02,607 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:02,610 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:02,632 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:03,024 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:03,816 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:03,820 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:03,844 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:03,993 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:04,981 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:04,987 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:05,695 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:05,699 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:06,641 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:06,644 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:06,647 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:07,388 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:07,395 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:07,426 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:07,552 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:08,314 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:08,318 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:08,339 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:08,441 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:09,215 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:09,218 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:09,229 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-6832627311/ozone-test-2497758006/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om1_1        | 2022-08-15 20:33:09,230 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2497758006/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om1_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-2497758006/multipartKey2. Entity too small.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2022-08-15 20:22:49,600 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn c654f076c8fc, UUID: 11946e6e-1ab1-47b6-94a8-e6dbe917e210
scm1.org_1   | 2022-08-15 20:22:49,923 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:22:52,397 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46628
scm1.org_1   | 2022-08-15 20:22:52,552 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:22:52,553 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 004775ef3c0f, UUID: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
scm1.org_1   | 2022-08-15 20:22:52,871 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:22:59,238 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:33542
scm1.org_1   | 2022-08-15 20:22:59,260 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:22:59,270 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: 8091fe14-ac2c-4638-85c6-ec44cc3d5ec3
scm1.org_1   | 2022-08-15 20:22:59,506 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:23:01,590 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48144
scm1.org_1   | 2022-08-15 20:23:01,612 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:23:02,257 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:48316
scm1.org_1   | 2022-08-15 20:23:02,272 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55432
scm1.org_1   | 2022-08-15 20:23:02,364 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:23:02,425 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:23:02,441 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: f8f40df5-01f9-4d81-a27c-e5554a05dfb7
scm1.org_1   | 2022-08-15 20:23:02,636 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:23:03,133 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:55606
scm1.org_1   | 2022-08-15 20:23:03,181 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:23:03,182 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: 852ecc74-1a1a-4fdf-948a-91be24fbec5e
scm1.org_1   | 2022-08-15 20:23:03,433 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:23:05,148 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46666
scm1.org_1   | 2022-08-15 20:23:05,258 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:23:07,223 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$485/0x0000000840552840@52bcd7c9] WARN util.JvmPauseMonitor: JvmPauseMonitor-17440e9e-0b34-4cd8-8102-cb903e52057d: Detected pause in JVM or host machine (eg GC): pause of approximately 132131373ns. No GCs detected.
scm1.org_1   | 2022-08-15 20:23:17,090 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33328
scm1.org_1   | 2022-08-15 20:23:17,186 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:23:18,986 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52476
scm1.org_1   | 2022-08-15 20:23:19,084 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:23:19,489 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56324
scm1.org_1   | 2022-08-15 20:23:19,643 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:23:21,865 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46662
scm1.org_1   | 2022-08-15 20:23:21,962 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:23:24,430 [IPC Server handler 50 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e2584860-2683-4862-8eba-daf2ea0fcaee
scm1.org_1   | 2022-08-15 20:23:24,473 [IPC Server handler 50 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931151845995, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-08-15 20:23:24,531 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-08-15 20:23:24,563 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:33:09,934 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:09,937 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:09,941 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:10,722 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:10,726 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:10,734 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1        | partName: "etag1"
om1_1        | , partNumber: 2
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-08-15 20:33:10,737 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:33:11,466 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:11,469 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:11,479 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1        | partName: "etag1"
om1_1        | , partNumber: 1
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-08-15 20:33:11,480 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:33:12,239 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:12,242 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:12,269 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:12,656 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:13,468 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:13,471 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:13,494 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:13,769 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:14,566 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:14,569 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:14,585 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:14,690 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:14,761 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46507
om1_1        | 2022-08-15 20:33:14,772 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:33:15,438 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:15,441 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
recon_1      | 2022-08-15 20:23:40,881 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee87d8de-c101-4564-aff4-e153e5671e57 reported by e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931151845995, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:40,882 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e reported by e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931151845995, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:41,335 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee87d8de-c101-4564-aff4-e153e5671e57 reported by 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931661290961, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:41,336 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e reported by 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931661290961, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:41,790 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 123 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:41,791 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 124 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:41,792 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 125 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:43,794 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 126 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:43,795 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 127 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:43,795 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 128 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:44,497 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=ee87d8de-c101-4564-aff4-e153e5671e57 reported by ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 934681712113, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:44,499 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ee87d8de-c101-4564-aff4-e153e5671e57, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, CreationTimestamp2022-08-15T20:23:26.205Z[UTC]] moved to OPEN state
recon_1      | 2022-08-15 20:23:44,500 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e reported by ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 934681712113, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:23:45,797 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 129 failover attempts. Trying to failover immediately.
scm1.org_1   | 2022-08-15 20:23:24,761 [IPC Server handler 91 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/11946e6e-1ab1-47b6-94a8-e6dbe917e210
scm1.org_1   | 2022-08-15 20:23:24,762 [IPC Server handler 91 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931661290961, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-08-15 20:23:24,801 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2022-08-15 20:23:24,801 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-08-15 20:23:24,832 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=8115b5cd-243e-460c-8d63-8e6307b8cda8 to datanode:e2584860-2683-4862-8eba-daf2ea0fcaee
scm1.org_1   | 2022-08-15 20:23:25,059 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8115b5cd-243e-460c-8d63-8e6307b8cda8, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:24.678Z[UTC]].
scm1.org_1   | 2022-08-15 20:23:25,059 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:23:25,182 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f3e347f8-57d4-4c72-b323-3754be4def15 to datanode:11946e6e-1ab1-47b6-94a8-e6dbe917e210
scm1.org_1   | 2022-08-15 20:23:25,503 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f3e347f8-57d4-4c72-b323-3754be4def15, Nodes: 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:25.182Z[UTC]].
scm1.org_1   | 2022-08-15 20:23:25,503 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:23:25,649 [IPC Server handler 50 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
scm1.org_1   | 2022-08-15 20:23:25,692 [IPC Server handler 50 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 934681712113, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-08-15 20:23:25,720 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-08-15 20:23:25,733 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d9c5810d-5123-4bc2-bd6e-bc27d48f5863 to datanode:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
scm1.org_1   | 2022-08-15 20:23:25,763 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2022-08-15 20:23:25,764 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2022-08-15 20:23:25,764 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2022-08-15 20:23:25,764 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-08-15 20:23:25,764 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2022-08-15 20:23:25,764 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-08-15 20:23:25,888 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d9c5810d-5123-4bc2-bd6e-bc27d48f5863, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:25.733Z[UTC]].
scm1.org_1   | 2022-08-15 20:23:25,889 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:23:25,974 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e to datanode:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
scm1.org_1   | 2022-08-15 20:23:26,069 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e to datanode:11946e6e-1ab1-47b6-94a8-e6dbe917e210
scm1.org_1   | 2022-08-15 20:23:26,069 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e to datanode:e2584860-2683-4862-8eba-daf2ea0fcaee
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:33:21,017 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-1691574458/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-6832627311
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-6832627311key: ozone-test-1691574458/multipartKey5
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:33:21,733 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-6832627311, Key:ozone-test-3193360831/multipartKey. 
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:759)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:283)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:34:05,568 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0172643642 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:34:06,292 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-82438 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:34:21,512 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1197578926 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:34:25,805 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1197578926, Key:thereisnosuchfile.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:34:28,708 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1197578926, Key:ozone-test-4339809727/deletetestapidir/key=value/.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:34:32,367 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1197578926, Key:ozone-test-4339809727/deletetestapiprefix/key=value/file.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2022-08-15 20:23:26,166 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4e74fa7e-554b-49cb-895a-4beb5c69c54e, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:25.974Z[UTC]].
scm1.org_1   | 2022-08-15 20:23:26,166 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:23:26,205 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ee87d8de-c101-4564-aff4-e153e5671e57 to datanode:e2584860-2683-4862-8eba-daf2ea0fcaee
scm1.org_1   | 2022-08-15 20:23:26,222 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ee87d8de-c101-4564-aff4-e153e5671e57 to datanode:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
scm1.org_1   | 2022-08-15 20:23:26,222 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ee87d8de-c101-4564-aff4-e153e5671e57 to datanode:11946e6e-1ab1-47b6-94a8-e6dbe917e210
scm1.org_1   | 2022-08-15 20:23:26,311 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ee87d8de-c101-4564-aff4-e153e5671e57, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:26.205Z[UTC]].
scm1.org_1   | 2022-08-15 20:23:26,329 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:23:26,340 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=ee87d8de-c101-4564-aff4-e153e5671e57 contains same datanodes as previous pipelines: PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e nodeIds: e2584860-2683-4862-8eba-daf2ea0fcaee, ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, 11946e6e-1ab1-47b6-94a8-e6dbe917e210
scm1.org_1   | 2022-08-15 20:23:28,596 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f3e347f8-57d4-4c72-b323-3754be4def15, Nodes: 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:11946e6e-1ab1-47b6-94a8-e6dbe917e210, CreationTimestamp2022-08-15T20:23:25.182Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-08-15 20:23:28,711 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:23:28,834 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-15 20:23:28,904 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44049
scm1.org_1   | 2022-08-15 20:23:28,925 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:23:29,861 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d9c5810d-5123-4bc2-bd6e-bc27d48f5863, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, CreationTimestamp2022-08-15T20:23:25.733Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-08-15 20:23:29,901 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:23:29,912 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-15 20:23:30,025 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-15 20:23:30,700 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-15 20:23:31,026 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:49938
scm1.org_1   | 2022-08-15 20:23:31,125 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:23:34,122 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:53508
scm1.org_1   | 2022-08-15 20:23:34,199 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:23:34,388 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:42474
scm1.org_1   | 2022-08-15 20:23:34,459 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:23:35,156 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-15 20:23:35,729 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1      | 2022-08-15 20:23:45,798 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 130 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:45,799 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 131 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:47,801 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 132 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:47,802 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 133 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:47,803 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 134 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:49,804 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 135 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:49,806 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 136 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:49,806 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 137 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:51,808 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 138 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:51,809 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 139 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:23:51,810 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 140 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:23:56,513 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49590
recon_1      | 2022-08-15 20:23:56,653 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:23:56,657 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=8115b5cd-243e-460c-8d63-8e6307b8cda8. Trying to get from SCM.
recon_1      | 2022-08-15 20:23:56,925 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 8115b5cd-243e-460c-8d63-8e6307b8cda8, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:e2584860-2683-4862-8eba-daf2ea0fcaee, CreationTimestamp2022-08-15T20:23:24.678Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-08-15 20:23:56,926 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8115b5cd-243e-460c-8d63-8e6307b8cda8, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:e2584860-2683-4862-8eba-daf2ea0fcaee, CreationTimestamp2022-08-15T20:23:24.678Z[UTC]].
recon_1      | 2022-08-15 20:23:56,928 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e reported by e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931151845995, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:24:01,716 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:34:42,046 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6614062836 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:34:53,275 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4509533375 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:34:57,246 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-4509533375, Key:ozone-test-3363941668/multidelete/key=value/f4.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-15 20:35:05,678 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8409873988 of layout LEGACY in volume: s3v
om3_1        | 2022-08-15 20:35:28,061 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2278251128 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-15 20:23:39,258 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-15 20:23:40,260 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56420
scm1.org_1   | 2022-08-15 20:23:40,294 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:23:41,352 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-15 20:23:43,288 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:33698
scm1.org_1   | 2022-08-15 20:23:43,307 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:23:44,517 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ee87d8de-c101-4564-aff4-e153e5671e57, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, CreationTimestamp2022-08-15T20:23:26.205Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-08-15 20:23:44,572 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-15 20:23:44,583 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-15 20:23:44,588 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 2022-08-15 20:23:44,588 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm1.org_1   | 2022-08-15 20:23:44,588 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm1.org_1   | 2022-08-15 20:23:44,588 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-08-15 20:23:44,592 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm1.org_1   | 2022-08-15 20:23:44,592 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
scm1.org_1   | 2022-08-15 20:23:44,592 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
scm1.org_1   | 2022-08-15 20:23:44,592 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO UnderReplicatedQueueThread: Service UnderReplicatedQueueThread transitions to RUNNING.
scm1.org_1   | 2022-08-15 20:23:44,592 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO OverReplicatedQueueThread: Service OverReplicatedQueueThread transitions to RUNNING.
scm1.org_1   | 2022-08-15 20:23:44,592 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm1.org_1   | 2022-08-15 20:23:44,593 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
scm1.org_1   | 2022-08-15 20:23:45,833 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:48470
scm1.org_1   | 2022-08-15 20:23:45,864 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:23:46,256 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:55766
scm1.org_1   | 2022-08-15 20:23:46,271 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:23:52,248 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33456
scm1.org_1   | 2022-08-15 20:23:52,359 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:23:56,516 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56464
scm1.org_1   | 2022-08-15 20:23:56,654 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:23:56,716 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8115b5cd-243e-460c-8d63-8e6307b8cda8, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e2584860-2683-4862-8eba-daf2ea0fcaee, CreationTimestamp2022-08-15T20:23:24.678Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-08-15 20:23:56,885 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35633
scm1.org_1   | 2022-08-15 20:23:56,907 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:24:09,937 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 4e74fa7e-554b-49cb-895a-4beb5c69c54e, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:e2584860-2683-4862-8eba-daf2ea0fcaee, CreationTimestamp2022-08-15T20:23:25.974Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-08-15 20:24:11,377 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52668
scm1.org_1   | 2022-08-15 20:24:11,414 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:24:14,590 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46844
scm1.org_1   | 2022-08-15 20:24:14,617 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:24:40,002 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56580
scm1.org_1   | 2022-08-15 20:24:40,033 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:24:41,366 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52758
scm1.org_1   | 2022-08-15 20:24:41,388 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:24:44,573 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46934
scm1.org_1   | 2022-08-15 20:24:44,606 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:24:52,147 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:50208
scm1.org_1   | 2022-08-15 20:24:52,182 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:24:52,356 [IPC Server handler 0 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm1.org_1   | 2022-08-15 20:24:52,497 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm1.org_1   | 2022-08-15 20:24:52,532 [IPC Server handler 0 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
scm1.org_1   | 2022-08-15 20:24:56,054 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:55798
scm1.org_1   | 2022-08-15 20:24:56,066 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:24:56,424 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47020
scm1.org_1   | 2022-08-15 20:24:56,439 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48518
scm1.org_1   | 2022-08-15 20:24:56,446 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:24:56,447 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:24:56,634 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56656
scm1.org_1   | 2022-08-15 20:24:56,747 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46693
scm1.org_1   | 2022-08-15 20:24:56,762 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:24:56,866 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:24:57,184 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46984
scm1.org_1   | 2022-08-15 20:24:57,284 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:24:57,347 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52830
scm1.org_1   | 2022-08-15 20:24:57,446 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:25:04,822 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:50272
scm1.org_1   | 2022-08-15 20:25:04,834 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:25:16,662 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:50302
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 141 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:24:01,803 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e reported by e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931151845995, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:24:02,907 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 142 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:24:04,229 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 143 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:24:06,234 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 144 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:24:06,241 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 145 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:24:06,251 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 146 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:24:08,258 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
scm1.org_1   | 2022-08-15 20:25:16,671 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:25:19,125 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52892
scm1.org_1   | 2022-08-15 20:25:19,200 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:25:19,259 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40529
scm1.org_1   | 2022-08-15 20:25:19,293 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47064
scm1.org_1   | 2022-08-15 20:25:19,297 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:25:19,385 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:25:19,432 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56752
scm1.org_1   | 2022-08-15 20:25:19,474 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:25:43,038 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40996
scm1.org_1   | 2022-08-15 20:25:43,040 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:25:49,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52992
scm1.org_1   | 2022-08-15 20:25:49,298 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47160
scm1.org_1   | 2022-08-15 20:25:49,330 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56844
scm1.org_1   | 2022-08-15 20:25:49,392 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:25:49,471 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:25:49,550 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:25:58,243 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:50438
scm1.org_1   | 2022-08-15 20:25:58,248 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:25:58,320 [IPC Server handler 5 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm1.org_1   | 2022-08-15 20:26:14,223 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:50478
scm1.org_1   | 2022-08-15 20:26:14,229 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:26:19,234 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56934
scm1.org_1   | 2022-08-15 20:26:19,307 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47250
scm1.org_1   | 2022-08-15 20:26:19,309 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:26:19,312 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53076
scm1.org_1   | 2022-08-15 20:26:19,318 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:26:19,347 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:26:28,881 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-08-15 20:26:49,121 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53176
scm1.org_1   | 2022-08-15 20:26:49,150 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47356
scm1.org_1   | 2022-08-15 20:26:49,152 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:26:49,227 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:26:49,239 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57034
scm1.org_1   | 2022-08-15 20:26:49,279 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:27:00,053 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35735
scm1.org_1   | 2022-08-15 20:27:00,056 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:27:19,180 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57132
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 147 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:24:08,263 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 148 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:24:08,270 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 149 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:24:09,923 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e74fa7e-554b-49cb-895a-4beb5c69c54e reported by e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931151845995, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-15 20:24:09,925 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 4e74fa7e-554b-49cb-895a-4beb5c69c54e, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:e2584860-2683-4862-8eba-daf2ea0fcaee, CreationTimestamp2022-08-15T20:23:25.974Z[UTC]] moved to OPEN state
recon_1      | 2022-08-15 20:24:10,275 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
om1_1        | 2022-08-15 20:33:15,449 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3-f1d95bf0-ad24-4b2c-9460-5e2d0f741790-108828792582373412-1
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:33:16,138 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:16,141 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:16,157 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3-f1d95bf0-ad24-4b2c-9460-5e2d0f741790-108828792582373412-2
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:33:16,854 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:16,859 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:16,877 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-6832627311/ozone-test-7654415715/multipartKey3
om1_1        | 2022-08-15 20:33:16,881 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7654415715/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6832627311
om1_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6832627311 key: ozone-test-7654415715/multipartKey3 because parts are in Invalid order.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:33:17,565 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:17,568 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:18,291 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:18,294 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:19,528 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:19,531 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:19,535 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:20,266 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:20,271 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:20,983 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:20,988 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 150 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:24:10,282 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 151 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-15 20:24:10,286 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 152 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-15 20:24:11,366 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49462
recon_1      | 2022-08-15 20:24:11,418 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:24:14,223 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
om1_1        | 2022-08-15 20:33:21,002 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-1691574458/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-6832627311
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-6832627311key: ozone-test-1691574458/multipartKey5
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:33:21,709 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:21,714 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:21,738 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-6832627311, Key:ozone-test-3193360831/multipartKey. 
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:759)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:283)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:33:22,435 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:22,438 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:22,444 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:23,265 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:23,269 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:23,296 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:23,693 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:24,496 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:24,500 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:24,518 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:24,625 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:25,365 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:25,370 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:25,378 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:26,173 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:26,179 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:26,182 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:26,939 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:26,942 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:26,948 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:27,657 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:27,661 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:28,534 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:28,536 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:28,540 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:28,632 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:28,636 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:28,660 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:28,675 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:28,684 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:28,753 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:28,793 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:28,804 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:28,833 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:29,864 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:29,939 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:29,991 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:30,033 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:30,042 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:30,889 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:30,893 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:30,920 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:30,926 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:30,934 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:30,935 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:30,939 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:30,948 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:32,403 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:32,407 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:33,302 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:33,305 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:33,309 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:33,697 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:34,505 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:34,508 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:34,511 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:35,234 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:35,240 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:35,265 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:35,315 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:35,737 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:36,608 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:24:14,576 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35718
recon_1      | 2022-08-15 20:24:14,633 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:24:39,971 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49714
recon_1      | 2022-08-15 20:24:40,008 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:24:41,337 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49554
recon_1      | 2022-08-15 20:24:41,378 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:24:44,536 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35804
recon_1      | 2022-08-15 20:24:44,590 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:24:56,617 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49782
recon_1      | 2022-08-15 20:24:56,688 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 2022-08-15 20:33:36,611 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:37,314 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:37,316 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:38,320 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:38,330 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:38,334 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:39,001 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:39,721 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:39,725 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:39,728 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
scm1.org_1   | 2022-08-15 20:27:19,186 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53272
scm1.org_1   | 2022-08-15 20:27:19,197 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47446
scm1.org_1   | 2022-08-15 20:27:19,210 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:27:19,250 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:27:19,309 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:27:23,891 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:50726
scm1.org_1   | 2022-08-15 20:27:23,898 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:27:31,828 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:41346
scm1.org_1   | 2022-08-15 20:27:31,831 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:27:38,914 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:50770
scm1.org_1   | 2022-08-15 20:27:38,923 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:27:46,481 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:41392
scm1.org_1   | 2022-08-15 20:27:46,484 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:27:49,067 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53382
scm1.org_1   | 2022-08-15 20:27:49,126 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47556
scm1.org_1   | 2022-08-15 20:27:49,168 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:27:49,194 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:27:49,214 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57242
scm1.org_1   | 2022-08-15 20:27:49,278 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:28:19,189 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47648
scm1.org_1   | 2022-08-15 20:28:19,215 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53472
scm1.org_1   | 2022-08-15 20:28:19,270 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:28:19,280 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:28:19,294 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57330
scm1.org_1   | 2022-08-15 20:28:19,321 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:28:49,236 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47750
scm1.org_1   | 2022-08-15 20:28:49,243 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:28:49,257 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57434
scm1.org_1   | 2022-08-15 20:28:49,260 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53574
scm1.org_1   | 2022-08-15 20:28:49,262 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:28:49,277 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:28:58,164 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:51030
scm1.org_1   | 2022-08-15 20:28:58,172 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:28:58,916 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:28:58,916 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:29:19,126 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47842
scm1.org_1   | 2022-08-15 20:29:19,150 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53666
scm1.org_1   | 2022-08-15 20:29:19,195 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57528
scm1.org_1   | 2022-08-15 20:29:19,209 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-08-15 20:21:20,139 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | 2022-08-15 20:29:19,246 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:29:19,249 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:29:28,916 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:29:28,916 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:29:49,109 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53772
scm1.org_1   | 2022-08-15 20:29:49,202 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:29:49,229 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47940
scm1.org_1   | 2022-08-15 20:29:49,232 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57624
scm1.org_1   | 2022-08-15 20:29:49,258 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:29:49,258 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:29:56,321 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:51222
scm1.org_1   | 2022-08-15 20:29:56,331 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:29:58,919 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:29:58,919 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:30:03,799 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:41842
scm1.org_1   | 2022-08-15 20:30:03,803 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:30:19,125 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53860
scm1.org_1   | 2022-08-15 20:30:19,176 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:30:19,241 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48034
scm1.org_1   | 2022-08-15 20:30:19,244 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57718
scm1.org_1   | 2022-08-15 20:30:19,262 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:30:19,270 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:30:28,919 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:30:28,920 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:30:49,063 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53992
scm1.org_1   | 2022-08-15 20:30:49,136 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:30:49,165 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48168
scm1.org_1   | 2022-08-15 20:30:49,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57846
scm1.org_1   | 2022-08-15 20:30:49,191 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:30:49,213 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:30:58,920 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:30:58,920 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:31:19,112 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54222
scm1.org_1   | 2022-08-15 20:31:19,136 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:31:19,210 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48398
scm1.org_1   | 2022-08-15 20:31:19,238 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58080
scm1.org_1   | 2022-08-15 20:31:19,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:31:19,266 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:31:28,883 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 2 containers.
om1_1        | 2022-08-15 20:33:40,470 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:40,475 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:40,502 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:40,574 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:41,533 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:42,275 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:42,281 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:42,299 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:42,353 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:42,488 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:43,263 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:43,270 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:43,975 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:43,978 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:45,270 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:45,273 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:45,276 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:45,692 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:46,383 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:46,390 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:46,395 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:47,100 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:47,103 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:48,568 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:48,571 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:48,602 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:48,631 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:49,492 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:49,496 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:49,511 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:49,532 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:50,221 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:50,225 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:50,243 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:50,309 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:51,112 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:51,874 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:51,879 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:51,898 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:51,933 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:52,032 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:52,802 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:52,805 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:52,822 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:52,856 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
scm1.org_1   | 2022-08-15 20:31:28,920 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:31:28,921 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:31:30,134 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:51694
scm1.org_1   | 2022-08-15 20:31:30,142 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:31:49,172 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54350
scm1.org_1   | 2022-08-15 20:31:49,261 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58196
scm1.org_1   | 2022-08-15 20:31:49,312 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:31:49,318 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48532
scm1.org_1   | 2022-08-15 20:31:49,379 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:31:49,392 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:31:49,505 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:42390
scm1.org_1   | 2022-08-15 20:31:49,523 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:31:58,921 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:31:58,921 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:32:00,106 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33239
scm1.org_1   | 2022-08-15 20:32:00,109 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:32:19,092 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54448
scm1.org_1   | 2022-08-15 20:32:19,114 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48626
scm1.org_1   | 2022-08-15 20:32:19,199 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:32:19,212 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:32:19,214 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58310
scm1.org_1   | 2022-08-15 20:32:19,217 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:32:28,922 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:32:28,922 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:32:49,221 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58420
scm1.org_1   | 2022-08-15 20:32:49,231 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54556
scm1.org_1   | 2022-08-15 20:32:49,240 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48730
scm1.org_1   | 2022-08-15 20:32:49,248 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:32:49,258 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:32:49,291 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:32:53,096 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52004
scm1.org_1   | 2022-08-15 20:32:53,098 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:32:56,258 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:42628
scm1.org_1   | 2022-08-15 20:32:56,265 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:32:58,922 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:32:58,923 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:33:18,322 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:42710
scm1.org_1   | 2022-08-15 20:33:18,329 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:33:19,156 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48876
scm3.org_1   | Sleeping for 5 seconds
scm3.org_1   | Waiting for the service scm2.org:9894
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-08-15 20:22:02,859 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:58Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-08-15 20:21:20,147 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-08-15 20:21:20,213 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-08-15 20:21:20,239 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-08-15 20:21:20,239 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-08-15 20:21:20,279 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-08-15 20:21:20,279 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-08-15 20:21:20,399 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-08-15 20:21:20,399 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-08-15 20:21:20,434 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2022-08-15 20:21:22,680 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-15 20:21:24,681 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-15 20:21:26,683 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-15 20:21:28,685 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-15 20:21:30,705 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-15 20:21:32,920 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:17440e9e-0b34-4cd8-8102-cb903e52057d is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-15 20:21:34,922 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-15 20:21:37,026 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm2.org_1   | 2022-08-15 20:21:37,625 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm2.org_1   | 2022-08-15 20:21:37,626 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2022-08-15 20:33:19,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54702
scm1.org_1   | 2022-08-15 20:33:19,208 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58560
scm1.org_1   | 2022-08-15 20:33:19,220 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:33:19,240 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:33:19,270 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:33:28,923 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:33:28,923 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:33:31,014 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:42802
scm1.org_1   | 2022-08-15 20:33:31,021 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:33:49,157 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54860
scm1.org_1   | 2022-08-15 20:33:49,180 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49034
scm1.org_1   | 2022-08-15 20:33:49,190 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:33:49,192 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58718
scm1.org_1   | 2022-08-15 20:33:49,221 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:33:49,226 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:33:58,923 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:33:58,923 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:34:08,590 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:42970
scm1.org_1   | 2022-08-15 20:34:08,592 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:34:19,101 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:54988
scm1.org_1   | 2022-08-15 20:34:19,132 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49162
scm1.org_1   | 2022-08-15 20:34:19,148 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:34:19,179 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58846
scm1.org_1   | 2022-08-15 20:34:19,185 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:34:19,237 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:34:22,220 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52434
scm1.org_1   | 2022-08-15 20:34:22,222 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:34:28,923 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:34:28,923 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:34:42,763 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52526
scm1.org_1   | 2022-08-15 20:34:42,767 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:34:49,055 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55136
scm1.org_1   | 2022-08-15 20:34:49,112 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49304
scm1.org_1   | 2022-08-15 20:34:49,114 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:34:49,182 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:34:49,210 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:58988
scm1.org_1   | 2022-08-15 20:34:49,213 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:34:54,044 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52578
scm1.org_1   | 2022-08-15 20:34:54,048 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:58Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-08-15 20:22:02,877 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-08-15 20:22:03,109 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-08-15 20:22:03,234 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-08-15 20:22:03,239 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-08-15 20:22:03,374 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-08-15 20:22:03,378 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-08-15 20:22:03,900 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-08-15 20:22:03,900 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-08-15 20:22:04,068 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2022-08-15 20:22:05,181 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2022-08-15 20:22:06,170 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm3.org_1   | 2022-08-15 20:22:06,170 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2022-08-15 20:22:06,180 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm3.org_1   | 2022-08-15 20:22:06,851 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm3.org_1   | 2022-08-15 20:22:06,959 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2022-08-15 20:22:06,960 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2022-08-15 20:22:06,963 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:b7365c8d-2724-48d2-bef1-0dcca965a3a4,clusterId:CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072,subject:scm-sub@scm3.org
scm3.org_1   | 2022-08-15 20:22:07,914 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2022-08-15 20:22:07,953 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072, SCMID b7365c8d-2724-48d2-bef1-0dcca965a3a4
scm3.org_1   | 2022-08-15 20:22:07,953 [main] INFO server.StorageContainerManager: Primary SCM Node ID 17440e9e-0b34-4cd8-8102-cb903e52057d
scm3.org_1   | 2022-08-15 20:22:08,000 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-08-15 20:22:10,946 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | 2022-08-15 20:21:37,627 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm2.org_1   | 2022-08-15 20:21:37,952 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2022-08-15 20:21:37,985 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2022-08-15 20:21:37,986 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2022-08-15 20:21:37,990 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:3fa27e21-96df-4954-913e-c2b6f8845795,clusterId:CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072,subject:scm-sub@scm2.org
scm2.org_1   | 2022-08-15 20:21:40,419 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm2.org_1   | 2022-08-15 20:21:40,456 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-9b83354a-0b87-41d3-bfcc-d1fd779ef072, SCMID 3fa27e21-96df-4954-913e-c2b6f8845795
scm2.org_1   | 2022-08-15 20:21:40,463 [main] INFO server.StorageContainerManager: Primary SCM Node ID 17440e9e-0b34-4cd8-8102-cb903e52057d
scm2.org_1   | 2022-08-15 20:21:40,534 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-08-15 20:21:43,894 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | 2022-08-15 20:24:56,703 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #1 got from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-08-15 20:24:56,926 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1      | 2022-08-15 20:24:57,214 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35854
recon_1      | 2022-08-15 20:24:57,239 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49620
recon_1      | 2022-08-15 20:24:57,288 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:24:57,446 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:25:14,231 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:25:14,232 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:25:14,321 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:58Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-08-15 20:21:43,918 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-08-15 20:21:44,089 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-08-15 20:21:44,171 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-08-15 20:21:44,208 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-08-15 20:21:44,295 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-08-15 20:21:44,295 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-08-15 20:21:45,299 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2022-08-15 20:21:45,769 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2022-08-15 20:21:45,776 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/860541509204.crt.
scm2.org_1   | 2022-08-15 20:21:45,804 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm2.org_1   | 2022-08-15 20:21:46,352 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-08-15 20:21:46,353 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-08-15 20:21:46,442 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-08-15 20:21:46,921 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-08-15 20:21:47,819 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2022-08-15 20:21:47,832 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm2.org_1   | 2022-08-15 20:21:48,075 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2022-08-15 20:21:48,138 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:3fa27e21-96df-4954-913e-c2b6f8845795
scm2.org_1   | 2022-08-15 20:21:48,411 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2022-08-15 20:21:48,626 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm2.org_1   | 2022-08-15 20:21:48,627 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-08-15 20:21:48,627 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm2.org_1   | 2022-08-15 20:21:48,628 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-08-15 20:21:48,628 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-08-15 20:21:48,629 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm2.org_1   | 2022-08-15 20:21:48,631 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-08-15 20:21:48,631 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm2.org_1   | 2022-08-15 20:21:48,632 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2022-08-15 20:21:48,646 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm2.org_1   | 2022-08-15 20:21:48,648 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm2.org_1   | 2022-08-15 20:21:50,272 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm2.org_1   | 2022-08-15 20:21:50,280 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm2.org_1   | 2022-08-15 20:21:50,288 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm2.org_1   | 2022-08-15 20:21:50,294 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-08-15 20:21:50,294 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-08-15 20:21:50,309 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-08-15 20:21:50,374 [main] INFO server.RaftServer: 3fa27e21-96df-4954-913e-c2b6f8845795: addNew group-D1FD779EF072:[] returns group-D1FD779EF072:java.util.concurrent.CompletableFuture@67328bcb[Not completed]
scm2.org_1   | 2022-08-15 20:21:50,439 [pool-16-thread-1] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795: new RaftServerImpl for group-D1FD779EF072:[] with SCMStateMachine:uninitialized
om1_1        | 2022-08-15 20:33:53,707 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:54,493 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:54,497 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:55,193 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:55,196 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:56,277 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:56,280 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:56,283 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:57,021 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:57,030 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:57,034 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:57,746 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:57,758 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:33:57,769 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:01,855 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55938
om1_1        | 2022-08-15 20:34:01,873 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:34:05,550 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:05,554 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:05,563 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0172643642 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:34:06,271 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:06,279 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:06,286 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-82438 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:34:06,975 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:06,978 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:06,981 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:07,104 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:07,838 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:07,842 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:07,845 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:07,849 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:08,549 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:08,552 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:08,556 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:08,603 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:08,616 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:08,764 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:08,777 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:09,539 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:09,542 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:09,546 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:09,550 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:10,224 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:10,229 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:10,233 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:10,252 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
recon_1      | 2022-08-15 20:25:19,113 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49682
recon_1      | 2022-08-15 20:25:19,191 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:25:19,199 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-08-15 20:25:19,264 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:35936
recon_1      | 2022-08-15 20:25:19,308 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-08-15 20:25:19,316 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49880
recon_1      | 2022-08-15 20:25:19,371 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:25:19,402 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:25:49,163 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49782
recon_1      | 2022-08-15 20:25:49,300 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49978
recon_1      | 2022-08-15 20:25:49,306 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36030
recon_1      | 2022-08-15 20:25:49,397 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:25:49,535 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:25:49,560 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:26:14,322 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:26:14,322 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:26:14,384 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/f9bd49e04356e18c407e743f2120cd723b3ec5f9 ; compiled by 'runner' on 2022-08-15T19:58Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-08-15 20:22:10,954 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-08-15 20:22:11,005 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-08-15 20:22:11,034 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-08-15 20:22:11,046 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-08-15 20:22:11,083 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-08-15 20:22:11,083 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-08-15 20:22:11,704 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2022-08-15 20:22:11,826 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2022-08-15 20:22:11,829 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/889554376605.crt.
scm3.org_1   | 2022-08-15 20:22:11,839 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2022-08-15 20:22:11,981 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-08-15 20:22:11,981 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-08-15 20:22:12,011 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-08-15 20:22:12,174 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-15 20:34:58,924 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:34:58,924 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:35:09,397 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:43240
scm1.org_1   | 2022-08-15 20:35:09,399 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:35:19,133 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49440
scm1.org_1   | 2022-08-15 20:35:19,156 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55266
scm1.org_1   | 2022-08-15 20:35:19,190 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:35:19,205 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:35:19,218 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59124
scm1.org_1   | 2022-08-15 20:35:19,231 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:35:28,925 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:35:28,925 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:35:44,307 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:52772
scm1.org_1   | 2022-08-15 20:35:44,309 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:35:49,071 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55368
scm1.org_1   | 2022-08-15 20:35:49,117 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49542
scm1.org_1   | 2022-08-15 20:35:49,121 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:35:49,177 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:35:49,214 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59226
scm1.org_1   | 2022-08-15 20:35:49,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:35:52,031 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48956
scm1.org_1   | 2022-08-15 20:35:52,057 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:35:52,425 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36250
scm1.org_1   | 2022-08-15 20:35:52,436 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:35:52,457 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 1481bf08-d4dd-442f-9fa2-0fe0347d9a1f, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-08-15T20:35:52.440Z[UTC]].
scm1.org_1   | 2022-08-15 20:35:54,906 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34335
scm1.org_1   | 2022-08-15 20:35:54,914 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:35:58,925 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:35:58,926 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:35:59,255 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36264
scm1.org_1   | 2022-08-15 20:35:59,296 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:36:03,589 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36276
scm1.org_1   | 2022-08-15 20:36:03,606 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:36:08,037 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36288
scm1.org_1   | 2022-08-15 20:36:08,061 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:36:12,297 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36292
scm3.org_1   | 2022-08-15 20:22:12,508 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm3.org_1   | 2022-08-15 20:22:12,508 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm3.org_1   | 2022-08-15 20:22:12,558 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2022-08-15 20:22:12,579 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:b7365c8d-2724-48d2-bef1-0dcca965a3a4
scm3.org_1   | 2022-08-15 20:22:12,666 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm3.org_1   | 2022-08-15 20:22:12,746 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm3.org_1   | 2022-08-15 20:22:12,747 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-08-15 20:22:12,748 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm3.org_1   | 2022-08-15 20:22:12,748 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-08-15 20:22:12,748 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-08-15 20:22:12,749 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm3.org_1   | 2022-08-15 20:22:12,751 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-08-15 20:22:12,751 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2022-08-15 20:22:12,752 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2022-08-15 20:22:12,766 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm3.org_1   | 2022-08-15 20:22:12,766 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm3.org_1   | 2022-08-15 20:22:13,737 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2022-08-15 20:22:13,747 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm3.org_1   | 2022-08-15 20:22:13,748 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm3.org_1   | 2022-08-15 20:22:13,749 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-08-15 20:22:13,749 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-08-15 20:22:13,752 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-08-15 20:22:13,780 [main] INFO server.RaftServer: b7365c8d-2724-48d2-bef1-0dcca965a3a4: addNew group-D1FD779EF072:[] returns group-D1FD779EF072:java.util.concurrent.CompletableFuture@67328bcb[Not completed]
scm3.org_1   | 2022-08-15 20:22:13,841 [pool-16-thread-1] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4: new RaftServerImpl for group-D1FD779EF072:[] with SCMStateMachine:uninitialized
scm3.org_1   | 2022-08-15 20:22:13,853 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | 2022-08-15 20:22:13,853 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2022-08-15 20:22:13,853 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm3.org_1   | 2022-08-15 20:22:13,854 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-08-15 20:22:13,854 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-08-15 20:22:13,854 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2022-08-15 20:22:13,860 [pool-16-thread-1] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2022-08-15 20:22:13,863 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-08-15 20:22:13,869 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm3.org_1   | 2022-08-15 20:22:13,873 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2022-08-15 20:22:13,875 [pool-16-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072 does not exist. Creating ...
scm3.org_1   | 2022-08-15 20:22:13,942 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/in_use.lock acquired by nodename 7@scm3.org
scm3.org_1   | 2022-08-15 20:22:13,979 [pool-16-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072 has been successfully formatted.
scm3.org_1   | 2022-08-15 20:22:13,983 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm3.org_1   | 2022-08-15 20:22:13,986 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2022-08-15 20:22:13,995 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2022-08-15 20:22:13,995 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-08-15 20:22:13,997 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm3.org_1   | 2022-08-15 20:22:14,141 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-08-15 20:22:14,154 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2022-08-15 20:22:14,155 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm3.org_1   | 2022-08-15 20:22:14,160 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072
scm3.org_1   | 2022-08-15 20:22:14,161 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2022-08-15 20:22:14,161 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm3.org_1   | 2022-08-15 20:22:14,162 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-08-15 20:22:14,163 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm3.org_1   | 2022-08-15 20:22:14,163 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2022-08-15 20:22:14,164 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm3.org_1   | 2022-08-15 20:22:14,164 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2022-08-15 20:22:14,165 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2022-08-15 20:21:50,458 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2022-08-15 20:21:50,459 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm2.org_1   | 2022-08-15 20:21:50,459 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm2.org_1   | 2022-08-15 20:21:50,459 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-08-15 20:21:50,459 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-08-15 20:21:50,460 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2022-08-15 20:21:50,501 [pool-16-thread-1] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2022-08-15 20:21:50,501 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-08-15 20:21:50,519 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2022-08-15 20:21:50,524 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm2.org_1   | 2022-08-15 20:21:50,526 [pool-16-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072 does not exist. Creating ...
scm2.org_1   | 2022-08-15 20:21:50,546 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/in_use.lock acquired by nodename 7@scm2.org
scm2.org_1   | 2022-08-15 20:21:50,583 [pool-16-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072 has been successfully formatted.
scm2.org_1   | 2022-08-15 20:21:50,587 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm2.org_1   | 2022-08-15 20:21:50,593 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2022-08-15 20:21:50,618 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm2.org_1   | 2022-08-15 20:21:50,630 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-08-15 20:21:50,636 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm2.org_1   | 2022-08-15 20:21:50,883 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-08-15 20:21:50,899 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2022-08-15 20:21:50,916 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2022-08-15 20:21:50,940 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072
scm2.org_1   | 2022-08-15 20:21:50,945 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2022-08-15 20:21:50,945 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2022-08-15 20:21:50,946 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-08-15 20:21:50,954 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm2.org_1   | 2022-08-15 20:21:50,955 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2022-08-15 20:21:50,956 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2022-08-15 20:21:50,956 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2022-08-15 20:21:50,957 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2022-08-15 20:21:50,986 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2022-08-15 20:21:50,988 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm2.org_1   | 2022-08-15 20:21:50,992 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2022-08-15 20:21:51,013 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-08-15 20:21:51,015 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-08-15 20:21:51,033 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2022-08-15 20:21:51,036 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2022-08-15 20:21:51,041 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2022-08-15 20:21:51,043 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2022-08-15 20:21:51,049 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2022-08-15 20:21:51,062 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2022-08-15 20:21:51,235 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2022-08-15 20:21:51,236 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm2.org_1   | 2022-08-15 20:21:51,248 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm2.org_1   | 2022-08-15 20:21:51,249 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm2.org_1   | 2022-08-15 20:21:51,256 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm2.org_1   | 2022-08-15 20:21:51,266 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2022-08-15 20:21:51,267 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2022-08-15 20:21:51,267 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2022-08-15 20:21:51,802 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm2.org_1   | 2022-08-15 20:21:52,172 [main] INFO reflections.Reflections: Reflections took 270 ms to scan 3 urls, producing 109 keys and 246 values 
scm2.org_1   | 2022-08-15 20:21:52,488 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:26:19,059 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49872
recon_1      | 2022-08-15 20:26:19,089 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36120
recon_1      | 2022-08-15 20:26:19,153 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:26:19,181 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:26:19,200 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50070
recon_1      | 2022-08-15 20:26:19,236 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:26:49,078 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49974
recon_1      | 2022-08-15 20:26:49,131 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36220
recon_1      | 2022-08-15 20:26:49,134 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:26:49,201 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:26:49,203 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50166
recon_1      | 2022-08-15 20:26:49,247 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:26:59,819 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 58 milliseconds to process 0 existing database records.
recon_1      | 2022-08-15 20:26:59,860 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 41 milliseconds for processing 2 containers.
recon_1      | 2022-08-15 20:27:00,068 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-08-15 20:27:00,079 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 47 milliseconds.
recon_1      | 2022-08-15 20:27:14,390 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:27:14,390 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:27:14,439 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1        | 2022-08-15 20:34:10,262 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:10,384 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:10,408 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:11,072 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:11,075 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:11,078 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:11,081 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:11,763 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:11,767 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:12,449 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:12,452 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:12,455 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:13,133 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:13,145 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:13,830 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:13,832 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:13,836 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:14,810 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40195
om1_1        | 2022-08-15 20:34:14,822 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:34:17,627 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55990
om1_1        | 2022-08-15 20:34:17,644 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:34:21,464 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:21,471 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:21,499 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1197578926 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:34:22,204 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:22,206 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:22,209 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:22,352 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:23,042 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:23,044 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:23,047 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:23,050 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:23,717 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:23,720 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:24,408 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:24,414 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:24,417 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:25,091 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:25,095 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:25,097 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:25,792 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:25,794 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:25,801 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1197578926, Key:thereisnosuchfile.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
scm3.org_1   | 2022-08-15 20:22:14,177 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm3.org_1   | 2022-08-15 20:22:14,184 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm3.org_1   | 2022-08-15 20:22:14,185 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2022-08-15 20:22:14,198 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-08-15 20:22:14,198 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-08-15 20:22:14,202 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm3.org_1   | 2022-08-15 20:22:14,205 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm3.org_1   | 2022-08-15 20:22:14,208 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm3.org_1   | 2022-08-15 20:22:14,209 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2022-08-15 20:22:14,210 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2022-08-15 20:22:14,214 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | 2022-08-15 20:22:14,362 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2022-08-15 20:22:14,363 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm3.org_1   | 2022-08-15 20:22:14,363 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm3.org_1   | 2022-08-15 20:22:14,363 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm3.org_1   | 2022-08-15 20:22:14,364 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm3.org_1   | 2022-08-15 20:22:14,366 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2022-08-15 20:22:14,367 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2022-08-15 20:22:14,368 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm3.org_1   | 2022-08-15 20:22:14,758 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm3.org_1   | 2022-08-15 20:22:15,063 [main] INFO reflections.Reflections: Reflections took 250 ms to scan 3 urls, producing 109 keys and 246 values 
scm3.org_1   | 2022-08-15 20:22:15,248 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm3.org_1   | 2022-08-15 20:22:15,248 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2022-08-15 20:22:15,258 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2022-08-15 20:22:15,269 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm3.org_1   | 2022-08-15 20:22:15,391 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | 2022-08-15 20:22:15,426 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2022-08-15 20:22:15,428 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2022-08-15 20:22:15,449 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2022-08-15 20:22:15,590 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm3.org_1   | 2022-08-15 20:22:15,594 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2022-08-15 20:22:15,604 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm3.org_1   | 2022-08-15 20:22:15,608 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2022-08-15 20:22:15,629 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm3.org_1   | 2022-08-15 20:22:15,630 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm3.org_1   | 2022-08-15 20:22:15,640 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm3.org_1   | 2022-08-15 20:22:15,644 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm3.org_1   | 2022-08-15 20:22:15,749 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm3.org_1   | 2022-08-15 20:22:15,809 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm3.org_1   | 2022-08-15 20:22:15,879 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-08-15 20:22:15,901 [main] INFO UnderReplicatedQueueThread: Starting UnderReplicatedQueueThread Service.
scm3.org_1   | 2022-08-15 20:22:15,906 [main] INFO ha.SCMServiceManager: Registering service UnderReplicatedQueueThread.
scm3.org_1   | 2022-08-15 20:22:15,908 [main] INFO OverReplicatedQueueThread: Starting OverReplicatedQueueThread Service.
scm3.org_1   | 2022-08-15 20:22:15,909 [main] INFO ha.SCMServiceManager: Registering service OverReplicatedQueueThread.
scm3.org_1   | 2022-08-15 20:22:15,910 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2022-08-15 20:22:15,934 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2022-08-15 20:22:15,920 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-15 20:22:15,943 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:22:15,947 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-08-15 20:22:16,041 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | 2022-08-15 20:22:16,127 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-08-15 20:22:16,200 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm3.org_1   | 2022-08-15 20:22:17,855 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-08-15 20:22:17,873 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-08-15 20:22:17,880 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2022-08-15 20:21:52,489 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2022-08-15 20:21:52,497 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm2.org_1   | 2022-08-15 20:21:52,504 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2022-08-15 20:21:52,670 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2022-08-15 20:21:52,703 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2022-08-15 20:21:52,712 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm2.org_1   | 2022-08-15 20:21:52,737 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2022-08-15 20:21:52,938 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2022-08-15 20:21:52,954 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm2.org_1   | 2022-08-15 20:21:52,987 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2022-08-15 20:21:52,995 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2022-08-15 20:21:52,999 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm2.org_1   | 2022-08-15 20:21:53,020 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm2.org_1   | 2022-08-15 20:21:53,045 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm2.org_1   | 2022-08-15 20:21:53,046 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm2.org_1   | 2022-08-15 20:21:53,180 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2022-08-15 20:21:53,239 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2022-08-15 20:21:53,393 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2022-08-15 20:21:53,440 [main] INFO UnderReplicatedQueueThread: Starting UnderReplicatedQueueThread Service.
scm2.org_1   | 2022-08-15 20:21:53,448 [main] INFO ha.SCMServiceManager: Registering service UnderReplicatedQueueThread.
scm2.org_1   | 2022-08-15 20:21:53,452 [main] INFO OverReplicatedQueueThread: Starting OverReplicatedQueueThread Service.
scm2.org_1   | 2022-08-15 20:21:53,448 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-15 20:21:53,459 [main] INFO ha.SCMServiceManager: Registering service OverReplicatedQueueThread.
scm2.org_1   | 2022-08-15 20:21:53,459 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm2.org_1   | 2022-08-15 20:21:53,479 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm2.org_1   | 2022-08-15 20:21:53,484 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:21:53,494 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-08-15 20:21:53,612 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm2.org_1   | 2022-08-15 20:21:53,740 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-08-15 20:21:53,845 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm2.org_1   | 2022-08-15 20:21:56,180 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-08-15 20:21:56,206 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-08-15 20:21:56,224 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2022-08-15 20:21:56,395 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-08-15 20:21:56,446 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-08-15 20:21:56,488 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2022-08-15 20:21:56,620 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-08-15 20:21:56,645 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-08-15 20:21:56,652 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm2.org_1   | 2022-08-15 20:21:57,151 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm2.org_1   | 2022-08-15 20:21:57,164 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm2.org_1   | Container Balancer status:
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        false
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                                                Value
scm2.org_1   | Threshold                                          10
scm2.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm2.org_1   | Max Size to Move per Iteration                     500GB
scm2.org_1   | Max Size Entering Target per Iteration             26GB
scm2.org_1   | Max Size Leaving Source per Iteration              26GB
scm2.org_1   | 
scm2.org_1   | 2022-08-15 20:21:57,165 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-08-15 20:21:57,165 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm2.org_1   | 2022-08-15 20:21:57,198 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2022-08-15 20:21:57,219 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2022-08-15 20:21:57,221 [3fa27e21-96df-4954-913e-c2b6f8845795-impl-thread1] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: start with initializing state, conf=-1: [], old=null
scm2.org_1   | 2022-08-15 20:21:57,224 [3fa27e21-96df-4954-913e-c2b6f8845795-impl-thread1] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: changes role from      null to FOLLOWER at term 0 for startInitializing
scm2.org_1   | 2022-08-15 20:21:57,229 [3fa27e21-96df-4954-913e-c2b6f8845795-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D1FD779EF072,id=3fa27e21-96df-4954-913e-c2b6f8845795
scm3.org_1   | 2022-08-15 20:22:17,936 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-08-15 20:22:17,943 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-08-15 20:22:17,956 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2022-08-15 20:22:18,028 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-08-15 20:22:18,227 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-08-15 20:22:18,262 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm3.org_1   | 2022-08-15 20:22:18,446 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm3.org_1   | 2022-08-15 20:22:18,446 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | Container Balancer status:
scm3.org_1   | Key                            Value
scm3.org_1   | Running                        false
scm3.org_1   | Container Balancer Configuration values:
scm3.org_1   | Key                                                Value
scm3.org_1   | Threshold                                          10
scm3.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm3.org_1   | Max Size to Move per Iteration                     500GB
scm3.org_1   | Max Size Entering Target per Iteration             26GB
scm3.org_1   | Max Size Leaving Source per Iteration              26GB
scm3.org_1   | 
scm3.org_1   | 2022-08-15 20:22:18,447 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-08-15 20:22:18,447 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm3.org_1   | 2022-08-15 20:22:18,459 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2022-08-15 20:22:18,461 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm3.org_1   | 2022-08-15 20:22:18,462 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-impl-thread1] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: start with initializing state, conf=-1: [], old=null
scm3.org_1   | 2022-08-15 20:22:18,467 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-impl-thread1] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2022-08-15 20:22:18,468 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D1FD779EF072,id=b7365c8d-2724-48d2-bef1-0dcca965a3a4
scm3.org_1   | 2022-08-15 20:22:18,477 [Listener at 0.0.0.0/9860] INFO server.RaftServer: b7365c8d-2724-48d2-bef1-0dcca965a3a4: start RPC server
scm3.org_1   | 2022-08-15 20:22:18,587 [Listener at 0.0.0.0/9860] INFO server.GrpcService: b7365c8d-2724-48d2-bef1-0dcca965a3a4: GrpcService started, listening on 9894
scm3.org_1   | 2022-08-15 20:22:18,622 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$471/0x0000000840557040@7b5e1b16] INFO util.JvmPauseMonitor: JvmPauseMonitor-b7365c8d-2724-48d2-bef1-0dcca965a3a4: Started
scm3.org_1   | 2022-08-15 20:22:18,655 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2022-08-15 20:22:23,161 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: receive installSnapshot: 17440e9e-0b34-4cd8-8102-cb903e52057d->b7365c8d-2724-48d2-bef1-0dcca965a3a4#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2022-08-15 20:22:23,197 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm3.org_1   | 2022-08-15 20:22:23,197 [grpc-default-executor-0] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: change Leader from null to 17440e9e-0b34-4cd8-8102-cb903e52057d at term 2 for installSnapshot, leader elected after 9213ms
scm3.org_1   | 2022-08-15 20:22:23,252 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: Received notification to install snapshot at index 0
scm3.org_1   | 2022-08-15 20:22:23,265 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm3.org_1   | 2022-08-15 20:22:24,217 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "17440e9e-0b34-4cd8-8102-cb903e52057d"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "3fa27e21-96df-4954-913e-c2b6f8845795"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-08-15 20:22:24,222 [grpc-default-executor-0] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: set configuration 9: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-15 20:22:24,253 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: reply installSnapshot: 17440e9e-0b34-4cd8-8102-cb903e52057d<-b7365c8d-2724-48d2-bef1-0dcca965a3a4#0:FAIL-t0,ALREADY_INSTALLED
scm3.org_1   | 2022-08-15 20:22:24,340 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: b7365c8d-2724-48d2-bef1-0dcca965a3a4: Completed INSTALL_SNAPSHOT, lastRequest: 17440e9e-0b34-4cd8-8102-cb903e52057d->b7365c8d-2724-48d2-bef1-0dcca965a3a4#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2022-08-15 20:22:24,489 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread1] INFO impl.RoleInfo: b7365c8d-2724-48d2-bef1-0dcca965a3a4: start b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-FollowerState
scm3.org_1   | 2022-08-15 20:22:24,504 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread1] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm3.org_1   | 2022-08-15 20:22:24,528 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread1] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: inconsistency entries. Reply:17440e9e-0b34-4cd8-8102-cb903e52057d<-b7365c8d-2724-48d2-bef1-0dcca965a3a4#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-08-15 20:22:24,555 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread2] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:27:19,188 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50070
recon_1      | 2022-08-15 20:27:19,216 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36316
recon_1      | 2022-08-15 20:27:19,242 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50266
recon_1      | 2022-08-15 20:27:19,248 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:27:19,329 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:27:19,360 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:27:49,054 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50178
recon_1      | 2022-08-15 20:27:49,080 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36428
recon_1      | 2022-08-15 20:27:49,084 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:27:49,129 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:27:49,184 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50374
recon_1      | 2022-08-15 20:27:49,211 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:28:14,443 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:28:14,443 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:28:14,509 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
scm2.org_1   | 2022-08-15 20:21:57,239 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 3fa27e21-96df-4954-913e-c2b6f8845795: start RPC server
scm2.org_1   | 2022-08-15 20:21:57,520 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 3fa27e21-96df-4954-913e-c2b6f8845795: GrpcService started, listening on 9894
scm2.org_1   | 2022-08-15 20:21:57,540 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$471/0x0000000840557040@543b855] INFO util.JvmPauseMonitor: JvmPauseMonitor-3fa27e21-96df-4954-913e-c2b6f8845795: Started
scm2.org_1   | 2022-08-15 20:21:57,550 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2022-08-15 20:21:59,495 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: receive installSnapshot: 17440e9e-0b34-4cd8-8102-cb903e52057d->3fa27e21-96df-4954-913e-c2b6f8845795#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2022-08-15 20:21:59,522 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2022-08-15 20:21:59,522 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: change Leader from null to 17440e9e-0b34-4cd8-8102-cb903e52057d at term 2 for installSnapshot, leader elected after 8935ms
scm2.org_1   | 2022-08-15 20:21:59,529 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: Received notification to install snapshot at index 0
scm2.org_1   | 2022-08-15 20:21:59,532 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm2.org_1   | 2022-08-15 20:21:59,773 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "17440e9e-0b34-4cd8-8102-cb903e52057d"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-08-15 20:21:59,775 [grpc-default-executor-0] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: set configuration 1: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-15 20:21:59,788 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: reply installSnapshot: 17440e9e-0b34-4cd8-8102-cb903e52057d<-3fa27e21-96df-4954-913e-c2b6f8845795#0:FAIL-t0,ALREADY_INSTALLED
scm2.org_1   | 2022-08-15 20:21:59,832 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 3fa27e21-96df-4954-913e-c2b6f8845795: Completed INSTALL_SNAPSHOT, lastRequest: 17440e9e-0b34-4cd8-8102-cb903e52057d->3fa27e21-96df-4954-913e-c2b6f8845795#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2022-08-15 20:21:59,901 [3fa27e21-96df-4954-913e-c2b6f8845795-server-thread1] INFO impl.RoleInfo: 3fa27e21-96df-4954-913e-c2b6f8845795: start 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-FollowerState
scm2.org_1   | 2022-08-15 20:21:59,910 [3fa27e21-96df-4954-913e-c2b6f8845795-server-thread1] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2022-08-15 20:21:59,913 [3fa27e21-96df-4954-913e-c2b6f8845795-server-thread1] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: inconsistency entries. Reply:17440e9e-0b34-4cd8-8102-cb903e52057d<-3fa27e21-96df-4954-913e-c2b6f8845795#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-08-15 20:21:59,932 [3fa27e21-96df-4954-913e-c2b6f8845795-server-thread2] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2022-08-15 20:21:59,933 [3fa27e21-96df-4954-913e-c2b6f8845795-server-thread2] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: inconsistency entries. Reply:17440e9e-0b34-4cd8-8102-cb903e52057d<-3fa27e21-96df-4954-913e-c2b6f8845795#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-08-15 20:22:00,004 [3fa27e21-96df-4954-913e-c2b6f8845795-server-thread2] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: set configuration 0: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-15 20:22:00,027 [3fa27e21-96df-4954-913e-c2b6f8845795-server-thread2] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: set configuration 1: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-15 20:22:00,038 [3fa27e21-96df-4954-913e-c2b6f8845795-server-thread2] INFO segmented.SegmentedRaftLogWorker: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-SegmentedRaftLogWorker: Starting segment from index:0
scm2.org_1   | 2022-08-15 20:22:00,126 [3fa27e21-96df-4954-913e-c2b6f8845795-server-thread2] INFO segmented.SegmentedRaftLogWorker: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm2.org_1   | 2022-08-15 20:22:00,241 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/current/log_inprogress_0
scm2.org_1   | 2022-08-15 20:22:00,257 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/current/log_inprogress_0 to /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/current/log_0-0
scm2.org_1   | 2022-08-15 20:22:00,301 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/current/log_inprogress_1
scm2.org_1   | 2022-08-15 20:22:00,326 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:22:00,332 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2022-08-15 20:22:00,332 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-08-15 20:22:00,333 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2022-08-15 20:22:00,346 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-08-15 20:22:00,357 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:34:26,478 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:26,483 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:26,486 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:27,176 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:27,184 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:27,189 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:27,285 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:27,994 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:27,998 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:28,001 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:28,004 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:28,681 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:28,688 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:28,699 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1197578926, Key:ozone-test-4339809727/deletetestapidir/key=value/.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:34:29,392 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:29,396 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:29,398 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:29,404 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:30,096 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:30,099 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:30,800 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:30,804 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:30,808 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:30,952 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:31,640 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:31,645 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:31,648 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:31,651 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:32,343 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:32,346 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:32,356 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-1197578926, Key:ozone-test-4339809727/deletetestapiprefix/key=value/file.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
scm2.org_1   | 2022-08-15 20:22:00,513 [3fa27e21-96df-4954-913e-c2b6f8845795-server-thread2] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: set configuration 7: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-08-15 20:22:00,576 [3fa27e21-96df-4954-913e-c2b6f8845795-server-thread2] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: set configuration 9: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-15 20:22:00,708 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:22:00,709 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm2.org_1   | 2022-08-15 20:22:00,709 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm2.org_1   | 2022-08-15 20:22:00,905 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:22:00,938 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-D1FD779EF072:[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-08-15 20:22:00,940 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2022-08-15 20:22:00,949 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm2.org_1   | 2022-08-15 20:22:00,951 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm2.org_1   | 2022-08-15 20:22:01,302 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2022-08-15 20:22:01,379 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2022-08-15 20:22:01,379 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2022-08-15 20:22:02,297 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2022-08-15 20:22:02,298 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-08-15 20:22:02,299 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2022-08-15 20:22:02,533 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2022-08-15 20:22:02,538 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2022-08-15 20:22:02,539 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-08-15 20:22:02,564 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2022-08-15 20:22:02,751 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2022-08-15 20:22:02,759 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-08-15 20:22:02,759 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2022-08-15 20:22:02,760 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2022-08-15 20:22:02,966 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-08-15 20:22:02,966 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-08-15 20:22:02,966 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2022-08-15 20:22:03,532 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 838496351631 on Scm Bootstrap Node 3fa27e21-96df-4954-913e-c2b6f8845795
scm2.org_1   | 2022-08-15 20:22:03,542 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 3fa27e21-96df-4954-913e-c2b6f8845795
scm2.org_1   | 2022-08-15 20:22:03,593 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2e2b1310] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm2.org_1   | 2022-08-15 20:22:03,639 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2022-08-15 20:22:03,645 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm2.org_1   | 2022-08-15 20:22:03,647 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2022-08-15 20:22:03,773 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @22823ms to org.eclipse.jetty.util.log.Slf4jLog
scm2.org_1   | 2022-08-15 20:22:04,112 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2022-08-15 20:22:04,140 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2022-08-15 20:22:04,225 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm2.org_1   | 2022-08-15 20:22:04,225 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2022-08-15 20:22:04,226 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm2.org_1   | 2022-08-15 20:22:04,229 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm2.org_1   | 2022-08-15 20:22:04,352 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2022-08-15 20:22:04,358 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm2.org_1   | 2022-08-15 20:22:04,490 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2022-08-15 20:22:04,490 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2022-08-15 20:22:04,501 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm1.org_1   | 2022-08-15 20:36:12,317 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:36:16,656 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36306
scm1.org_1   | 2022-08-15 20:36:16,677 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:36:19,110 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49634
scm1.org_1   | 2022-08-15 20:36:19,161 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55454
scm1.org_1   | 2022-08-15 20:36:19,162 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:36:19,178 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:36:21,030 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36334
scm1.org_1   | 2022-08-15 20:36:21,050 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:36:24,905 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59324
scm1.org_1   | 2022-08-15 20:36:24,943 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:36:25,153 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36346
scm1.org_1   | 2022-08-15 20:36:25,168 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:36:28,887 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 3 milliseconds for processing 3 containers.
scm1.org_1   | 2022-08-15 20:36:28,926 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:36:28,926 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:36:29,718 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36358
scm1.org_1   | 2022-08-15 20:36:29,754 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:36:33,916 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36380
scm1.org_1   | 2022-08-15 20:36:33,934 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:36:34,127 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #2
scm1.org_1   | 2022-08-15 20:36:37,981 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36392
scm1.org_1   | 2022-08-15 20:36:38,003 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:36:42,314 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36396
scm1.org_1   | 2022-08-15 20:36:42,340 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:36:49,065 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55552
scm1.org_1   | 2022-08-15 20:36:49,099 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49726
scm1.org_1   | 2022-08-15 20:36:49,109 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:36:49,132 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:36:50,170 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59418
scm1.org_1   | 2022-08-15 20:36:50,183 [FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm1.org_1   | 2022-08-15 20:36:50,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:36:50,317 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33379
scm1.org_1   | 2022-08-15 20:36:50,323 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:36:56,532 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36450
scm1.org_1   | 2022-08-15 20:36:56,553 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:36:58,926 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:34:33,031 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:33,040 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:33,043 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:33,049 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:33,729 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:33,736 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:34,443 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:34,446 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:38,289 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56104
om1_1        | 2022-08-15 20:34:38,305 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:34:42,022 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:42,026 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:42,037 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6614062836 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:34:42,744 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:42,747 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:42,750 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:42,893 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:43,592 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:43,597 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:44,258 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:44,261 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:44,942 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:44,948 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:45,691 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:45,694 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:49,588 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56166
om1_1        | 2022-08-15 20:34:49,605 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:34:53,256 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:53,261 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:53,277 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4509533375 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:34:54,024 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:54,029 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:54,032 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:54,184 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:54,880 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:54,883 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:54,886 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:54,985 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:55,683 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:55,685 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
scm2.org_1   | 2022-08-15 20:22:04,577 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-08-15 20:22:04,596 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1f3b8bfe{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2022-08-15 20:22:04,601 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7a506493{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2022-08-15 20:22:04,911 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-08-15 20:22:04,962 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3d97b0a{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-3535627200013690934/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm2.org_1   | 2022-08-15 20:22:05,009 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@399dc033{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm2.org_1   | 2022-08-15 20:22:05,009 [Listener at 0.0.0.0/9860] INFO server.Server: Started @24059ms
scm2.org_1   | 2022-08-15 20:22:05,014 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2022-08-15 20:22:05,014 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2022-08-15 20:22:05,016 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm2.org_1   | 2022-08-15 20:22:07,710 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:22:25,860 [3fa27e21-96df-4954-913e-c2b6f8845795-server-thread2] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: set configuration 13: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, b7365c8d-2724-48d2-bef1-0dcca965a3a4|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-08-15 20:22:25,936 [3fa27e21-96df-4954-913e-c2b6f8845795-server-thread2] INFO server.RaftServer$Division: 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072: set configuration 15: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, b7365c8d-2724-48d2-bef1-0dcca965a3a4|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-15 20:22:49,525 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:22:49,901 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:22:52,885 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:22:59,518 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:23:02,651 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:23:03,547 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:23:19,107 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37216
scm2.org_1   | 2022-08-15 20:23:19,193 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:23:19,551 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45748
scm2.org_1   | 2022-08-15 20:23:19,704 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:23:21,886 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45558
scm2.org_1   | 2022-08-15 20:23:21,954 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:23:24,324 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e2584860-2683-4862-8eba-daf2ea0fcaee
scm2.org_1   | 2022-08-15 20:23:24,362 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931151845995, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-08-15 20:23:24,614 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-08-15 20:23:24,618 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm2.org_1   | 2022-08-15 20:23:24,641 [IPC Server handler 19 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/11946e6e-1ab1-47b6-94a8-e6dbe917e210
scm2.org_1   | 2022-08-15 20:23:24,665 [IPC Server handler 19 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931661290961, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-08-15 20:23:24,668 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-08-15 20:23:24,737 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2022-08-15 20:36:58,928 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:37:03,884 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36464
scm1.org_1   | 2022-08-15 20:37:03,913 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:37:03,914 [IPC Server handler 7 on default port 9860] INFO ipc.Server: IPC Server handler 7 on default port 9860, call Call#0 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.116:36464
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1822)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getContainer(SCMClientProtocolServer.java:223)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:693)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:406)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:215)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-08-15 20:37:07,834 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:49184
scm1.org_1   | 2022-08-15 20:37:07,857 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:37:08,260 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36478
scm1.org_1   | 2022-08-15 20:37:08,265 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:37:08,265 [IPC Server handler 24 on default port 9860] INFO ipc.Server: IPC Server handler 24 on default port 9860, call Call#1 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.116:36478
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1822)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.allocateContainer(SCMClientProtocolServer.java:203)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.allocateContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:682)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:398)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:215)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-08-15 20:37:11,958 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36482
scm1.org_1   | 2022-08-15 20:37:11,984 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:37:16,175 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36496
scm1.org_1   | 2022-08-15 20:37:16,197 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:37:20,134 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36508
scm1.org_1   | 2022-08-15 20:37:20,157 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:37:20,220 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49820
scm1.org_1   | 2022-08-15 20:37:20,265 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:37:20,342 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59504
scm1.org_1   | 2022-08-15 20:37:20,354 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:37:20,361 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55676
scm1.org_1   | 2022-08-15 20:37:20,388 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:37:24,641 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36536
scm1.org_1   | 2022-08-15 20:37:24,665 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:37:28,354 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36548
scm1.org_1   | 2022-08-15 20:37:28,373 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:37:28,927 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:37:28,928 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:37:32,557 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36566
scm1.org_1   | 2022-08-15 20:37:32,581 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:37:36,638 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36574
scm1.org_1   | 2022-08-15 20:37:36,654 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:37:40,602 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36588
scm1.org_1   | 2022-08-15 20:37:40,626 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:37:44,605 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36602
scm1.org_1   | 2022-08-15 20:37:44,622 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:37:50,233 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49926
scm1.org_1   | 2022-08-15 20:37:50,296 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59612
scm1.org_1   | 2022-08-15 20:37:50,298 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:37:50,370 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55780
scm2.org_1   | 2022-08-15 20:23:25,365 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8115b5cd-243e-460c-8d63-8e6307b8cda8, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:24.678Z[UTC]].
scm2.org_1   | 2022-08-15 20:23:25,408 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:23:25,652 [IPC Server handler 22 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
scm2.org_1   | 2022-08-15 20:23:25,698 [IPC Server handler 22 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 934681712113, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-08-15 20:23:25,697 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f3e347f8-57d4-4c72-b323-3754be4def15, Nodes: 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:25.182Z[UTC]].
scm2.org_1   | 2022-08-15 20:23:25,704 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-08-15 20:23:25,708 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:23:25,738 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm2.org_1   | 2022-08-15 20:23:25,738 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2022-08-15 20:23:25,743 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2022-08-15 20:23:25,744 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-08-15 20:23:25,800 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2022-08-15 20:23:25,801 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-08-15 20:23:25,976 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d9c5810d-5123-4bc2-bd6e-bc27d48f5863, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:25.733Z[UTC]].
scm2.org_1   | 2022-08-15 20:23:25,986 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:23:26,249 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4e74fa7e-554b-49cb-895a-4beb5c69c54e, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:25.974Z[UTC]].
scm2.org_1   | 2022-08-15 20:23:26,260 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:23:26,481 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ee87d8de-c101-4564-aff4-e153e5671e57, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:26.205Z[UTC]].
scm2.org_1   | 2022-08-15 20:23:26,492 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:23:28,460 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f3e347f8-57d4-4c72-b323-3754be4def15, Nodes: 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:11946e6e-1ab1-47b6-94a8-e6dbe917e210, CreationTimestamp2022-08-15T20:23:25.182Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-15 20:22:24,564 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread2] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: inconsistency entries. Reply:17440e9e-0b34-4cd8-8102-cb903e52057d<-b7365c8d-2724-48d2-bef1-0dcca965a3a4#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-08-15 20:22:24,589 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread1] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: set configuration 0: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-15 20:22:24,603 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread1] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: set configuration 1: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-15 20:22:24,605 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread1] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: set configuration 7: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-08-15 20:22:24,623 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread1] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: set configuration 9: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-15 20:22:24,681 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread1] INFO segmented.SegmentedRaftLogWorker: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-SegmentedRaftLogWorker: Starting segment from index:0
scm3.org_1   | 2022-08-15 20:22:24,849 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread1] INFO segmented.SegmentedRaftLogWorker: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm3.org_1   | 2022-08-15 20:22:24,928 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread2] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: set configuration 0: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-15 20:22:24,943 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread2] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: set configuration 1: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-15 20:22:24,944 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread2] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: set configuration 7: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-08-15 20:22:24,944 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread2] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: set configuration 9: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-15 20:22:25,467 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/current/log_inprogress_0
scm3.org_1   | 2022-08-15 20:22:25,505 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/current/log_inprogress_0 to /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/current/log_0-0
scm3.org_1   | 2022-08-15 20:22:25,622 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9b83354a-0b87-41d3-bfcc-d1fd779ef072/current/log_inprogress_1
scm3.org_1   | 2022-08-15 20:22:25,684 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:22:25,692 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm3.org_1   | 2022-08-15 20:22:25,704 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-08-15 20:22:25,705 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2022-08-15 20:22:25,760 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-08-15 20:22:25,808 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm3.org_1   | 2022-08-15 20:22:25,811 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$471/0x0000000840557040@7b5e1b16] WARN util.JvmPauseMonitor: JvmPauseMonitor-b7365c8d-2724-48d2-bef1-0dcca965a3a4: Detected pause in JVM or host machine (eg GC): pause of approximately 100324060ns. No GCs detected.
scm3.org_1   | 2022-08-15 20:22:25,999 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread2] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: set configuration 13: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, b7365c8d-2724-48d2-bef1-0dcca965a3a4|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-08-15 20:22:26,084 [b7365c8d-2724-48d2-bef1-0dcca965a3a4-server-thread2] INFO server.RaftServer$Division: b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072: set configuration 15: [17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, b7365c8d-2724-48d2-bef1-0dcca965a3a4|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-15 20:22:26,322 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-D1FD779EF072:[17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 3fa27e21-96df-4954-913e-c2b6f8845795|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, b7365c8d-2724-48d2-bef1-0dcca965a3a4|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-08-15 20:22:26,569 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2022-08-15 20:22:26,814 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2022-08-15 20:22:26,814 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2022-08-15 20:37:50,388 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:37:50,408 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:37:51,314 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36640
scm1.org_1   | 2022-08-15 20:37:51,330 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:37:51,348 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 523955ed-13ce-47e3-8bf8-7fe3e7378640, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-08-15T20:37:51.333Z[UTC]].
scm1.org_1   | 2022-08-15 20:37:55,286 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36644
scm1.org_1   | 2022-08-15 20:37:55,309 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:37:58,927 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:37:58,929 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:37:59,457 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36656
scm1.org_1   | 2022-08-15 20:37:59,474 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:38:03,334 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36668
scm1.org_1   | 2022-08-15 20:38:03,359 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2022-08-15 20:23:28,884 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:23:29,776 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d9c5810d-5123-4bc2-bd6e-bc27d48f5863, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, CreationTimestamp2022-08-15T20:23:25.733Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-08-15 20:23:29,934 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:23:29,979 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-15 20:23:30,670 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-15 20:23:35,144 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-15 20:23:35,712 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-15 20:23:39,267 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-15 20:23:40,124 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45838
scm2.org_1   | 2022-08-15 20:23:40,226 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:23:41,327 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-15 20:23:44,511 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ee87d8de-c101-4564-aff4-e153e5671e57, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, CreationTimestamp2022-08-15T20:23:26.205Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-08-15 20:23:44,512 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-15 20:23:44,565 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-15 20:23:56,481 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45884
scm2.org_1   | 2022-08-15 20:23:56,658 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:23:56,659 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8115b5cd-243e-460c-8d63-8e6307b8cda8, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e2584860-2683-4862-8eba-daf2ea0fcaee, CreationTimestamp2022-08-15T20:23:24.678Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-08-15 20:23:56,661 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-15 20:23:56,662 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm2.org_1   | 2022-08-15 20:23:56,662 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm2.org_1   | 2022-08-15 20:23:56,662 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm2.org_1   | 2022-08-15 20:23:56,662 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-08-15 20:23:56,662 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
om1_1        | 2022-08-15 20:34:55,689 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:55,800 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:56,483 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:56,486 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:56,490 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:56,494 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:57,184 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:57,187 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:57,190 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:57,211 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:57,226 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:57,238 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-4509533375, Key:ozone-test-3363941668/multidelete/key=value/f4.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-15 20:34:57,949 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:57,952 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:57,959 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:34:57,964 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:02,009 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56206
om1_1        | 2022-08-15 20:35:02,028 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:35:05,663 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:05,668 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:05,674 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8409873988 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:35:06,373 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:06,376 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:06,380 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:06,520 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:07,241 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:07,243 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:07,246 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:07,249 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:07,926 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:07,932 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:07,942 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:07,979 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:08,673 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:08,675 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:08,678 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:08,681 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:09,369 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
scm1.org_1   | 2022-08-15 20:38:07,278 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36672
scm1.org_1   | 2022-08-15 20:38:07,309 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:38:11,305 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36684
scm1.org_1   | 2022-08-15 20:38:11,333 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:38:15,259 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36698
scm1.org_1   | 2022-08-15 20:38:15,298 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:38:19,371 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36702
scm1.org_1   | 2022-08-15 20:38:19,396 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:38:19,410 [IPC Server handler 25 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 523955ed-13ce-47e3-8bf8-7fe3e7378640, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-08-15T20:37:51.333Z[UTC]] moved to CLOSED state
scm1.org_1   | 2022-08-15 20:38:20,278 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50022
scm1.org_1   | 2022-08-15 20:38:20,294 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:38:20,356 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55874
scm1.org_1   | 2022-08-15 20:38:20,365 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59706
scm1.org_1   | 2022-08-15 20:38:20,389 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:38:20,399 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:38:20,415 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40525
scm1.org_1   | 2022-08-15 20:38:20,418 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:38:23,536 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36738
scm1.org_1   | 2022-08-15 20:38:23,565 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:38:28,928 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:38:28,929 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:38:30,364 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36752
scm1.org_1   | 2022-08-15 20:38:30,388 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:38:34,533 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36774
scm1.org_1   | 2022-08-15 20:38:34,553 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:38:39,256 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36790
scm1.org_1   | 2022-08-15 20:38:39,263 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:38:39,264 [IPC Server handler 24 on default port 9860] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
scm1.org_1   | 2022-08-15 20:38:39,268 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
scm1.org_1   | 2022-08-15 20:38:43,845 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36796
scm1.org_1   | 2022-08-15 20:38:43,876 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:38:47,985 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36812
scm1.org_1   | 2022-08-15 20:38:47,990 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:38:47,990 [IPC Server handler 0 on default port 9860] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2022-08-15 20:38:48,040 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 24 milliseconds for processing 3 containers.
scm1.org_1   | 2022-08-15 20:38:50,230 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50140
scm1.org_1   | 2022-08-15 20:38:50,263 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59820
scm3.org_1   | 2022-08-15 20:22:27,162 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:22:27,197 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2022-08-15 20:22:27,199 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2022-08-15 20:22:27,370 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:22:27,419 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:22:27,827 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2022-08-15 20:22:27,932 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm3.org_1   | 2022-08-15 20:22:27,932 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm3.org_1   | 2022-08-15 20:22:29,764 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2022-08-15 20:22:29,790 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-08-15 20:22:29,794 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   | 2022-08-15 20:22:30,532 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   | 2022-08-15 20:22:30,532 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2022-08-15 20:22:30,533 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-08-15 20:22:30,533 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2022-08-15 20:22:31,276 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2022-08-15 20:22:31,277 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-08-15 20:22:31,324 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2022-08-15 20:22:31,329 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2022-08-15 20:22:32,062 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-08-15 20:22:32,082 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-08-15 20:22:32,084 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2022-08-15 20:22:33,066 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 838496351631 on Scm Bootstrap Node b7365c8d-2724-48d2-bef1-0dcca965a3a4
scm3.org_1   | 2022-08-15 20:22:33,159 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node b7365c8d-2724-48d2-bef1-0dcca965a3a4
scm3.org_1   | 2022-08-15 20:22:33,295 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5331a22c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2022-08-15 20:22:33,682 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm3.org_1   | 2022-08-15 20:22:33,682 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2022-08-15 20:22:33,684 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2022-08-15 20:22:33,953 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @25509ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2022-08-15 20:22:35,094 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2022-08-15 20:22:35,190 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2022-08-15 20:22:35,200 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2022-08-15 20:22:35,209 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2022-08-15 20:22:35,211 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2022-08-15 20:22:35,230 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2022-08-15 20:22:35,581 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2022-08-15 20:22:35,591 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm3.org_1   | 2022-08-15 20:22:36,080 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2022-08-15 20:22:36,080 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2022-08-15 20:22:36,102 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm3.org_1   | 2022-08-15 20:22:36,305 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-08-15 20:22:36,319 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2bb7229e{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2022-08-15 20:22:36,351 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6b13f456{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2022-08-15 20:22:37,221 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-08-15 20:22:37,318 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6aa909cb{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-1207396644654691317/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2022-08-15 20:22:37,384 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@ad7d724{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm2.org_1   | 2022-08-15 20:24:09,917 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 4e74fa7e-554b-49cb-895a-4beb5c69c54e, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:e2584860-2683-4862-8eba-daf2ea0fcaee, CreationTimestamp2022-08-15T20:23:25.974Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-08-15 20:24:11,372 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37410
scm2.org_1   | 2022-08-15 20:24:11,413 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:24:14,568 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45742
scm2.org_1   | 2022-08-15 20:24:14,628 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:24:39,981 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46008
scm2.org_1   | 2022-08-15 20:24:40,020 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:24:41,350 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37502
scm2.org_1   | 2022-08-15 20:24:41,379 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:24:44,555 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45834
scm2.org_1   | 2022-08-15 20:24:44,594 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:24:52,518 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm2.org_1   | 2022-08-15 20:24:56,640 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46076
scm2.org_1   | 2022-08-15 20:24:56,848 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:24:57,226 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45882
scm2.org_1   | 2022-08-15 20:24:57,309 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:24:57,396 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37564
scm2.org_1   | 2022-08-15 20:24:57,446 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:25:19,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37632
scm2.org_1   | 2022-08-15 20:25:19,247 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:25:19,289 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:45960
scm2.org_1   | 2022-08-15 20:25:19,319 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46168
scm2.org_1   | 2022-08-15 20:25:19,403 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:25:19,424 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:25:49,165 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37726
scm2.org_1   | 2022-08-15 20:25:49,302 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46272
scm2.org_1   | 2022-08-15 20:25:49,343 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46058
scm2.org_1   | 2022-08-15 20:25:49,394 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:25:49,489 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:25:49,564 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:26:19,225 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46150
scm2.org_1   | 2022-08-15 20:26:19,242 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37820
scm2.org_1   | 2022-08-15 20:26:19,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:26:19,282 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:26:19,294 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46358
scm2.org_1   | 2022-08-15 20:26:19,334 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:26:49,072 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37916
scm2.org_1   | 2022-08-15 20:26:49,128 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46248
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:28:19,108 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50268
recon_1      | 2022-08-15 20:28:19,144 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36518
recon_1      | 2022-08-15 20:28:19,145 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:28:19,174 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50464
recon_1      | 2022-08-15 20:28:19,208 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:28:19,232 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:28:49,087 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36620
recon_1      | 2022-08-15 20:28:49,126 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50368
recon_1      | 2022-08-15 20:28:49,129 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:28:49,141 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:28:49,157 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50562
recon_1      | 2022-08-15 20:28:49,177 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:29:14,511 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:29:14,512 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:29:14,568 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
scm1.org_1   | 2022-08-15 20:38:50,280 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:38:50,295 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:38:50,363 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55992
scm1.org_1   | 2022-08-15 20:38:50,388 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:38:52,305 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36850
scm1.org_1   | 2022-08-15 20:38:52,324 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:38:58,929 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:38:58,929 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:38:59,261 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36864
scm1.org_1   | 2022-08-15 20:38:59,284 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:39:04,164 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36876
scm1.org_1   | 2022-08-15 20:39:04,184 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:39:08,167 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36888
scm1.org_1   | 2022-08-15 20:39:08,201 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:39:14,883 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36902
scm1.org_1   | 2022-08-15 20:39:14,905 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:39:20,243 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50224
scm1.org_1   | 2022-08-15 20:39:20,300 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59908
scm1.org_1   | 2022-08-15 20:39:20,318 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:39:20,346 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:39:20,430 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56074
scm1.org_1   | 2022-08-15 20:39:20,477 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:39:28,930 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:39:28,930 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:39:31,046 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:53514
scm1.org_1   | 2022-08-15 20:39:31,053 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:39:38,314 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:35626
scm1.org_1   | 2022-08-15 20:39:38,333 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:39:38,673 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37498
scm1.org_1   | 2022-08-15 20:39:38,682 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:39:40,875 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59982
scm1.org_1   | 2022-08-15 20:39:40,888 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:39:40,905 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37023
scm1.org_1   | 2022-08-15 20:39:40,916 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:39:45,179 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37522
scm1.org_1   | 2022-08-15 20:39:45,205 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:39:49,309 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37526
scm3.org_1   | 2022-08-15 20:22:37,386 [Listener at 0.0.0.0/9860] INFO server.Server: Started @28942ms
scm3.org_1   | 2022-08-15 20:22:37,420 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2022-08-15 20:22:37,420 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2022-08-15 20:22:37,428 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm3.org_1   | 2022-08-15 20:22:38,964 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$471/0x0000000840557040@7b5e1b16] WARN util.JvmPauseMonitor: JvmPauseMonitor-b7365c8d-2724-48d2-bef1-0dcca965a3a4: Detected pause in JVM or host machine (eg GC): pause of approximately 255488278ns.
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=353ms
scm3.org_1   | 2022-08-15 20:22:49,563 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:22:49,905 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:22:52,900 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:22:59,573 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:23:02,645 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:23:03,493 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:23:19,193 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59116
scm3.org_1   | 2022-08-15 20:23:19,288 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:23:19,476 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32890
scm3.org_1   | 2022-08-15 20:23:19,670 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:23:21,931 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52038
scm3.org_1   | 2022-08-15 20:23:22,025 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:23:24,436 [IPC Server handler 7 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e2584860-2683-4862-8eba-daf2ea0fcaee
scm3.org_1   | 2022-08-15 20:23:24,528 [IPC Server handler 7 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931151845995, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-08-15 20:23:24,595 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-08-15 20:23:24,654 [IPC Server handler 75 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/11946e6e-1ab1-47b6-94a8-e6dbe917e210
scm3.org_1   | 2022-08-15 20:23:24,689 [IPC Server handler 75 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 931661290961, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-08-15 20:23:24,696 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-08-15 20:23:24,696 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2022-08-15 20:23:24,726 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm3.org_1   | 2022-08-15 20:23:25,427 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8115b5cd-243e-460c-8d63-8e6307b8cda8, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:24.678Z[UTC]].
scm3.org_1   | 2022-08-15 20:23:25,451 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:23:25,553 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f3e347f8-57d4-4c72-b323-3754be4def15, Nodes: 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:25.182Z[UTC]].
scm3.org_1   | 2022-08-15 20:23:25,568 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:23:25,634 [IPC Server handler 75 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f
scm3.org_1   | 2022-08-15 20:23:25,659 [IPC Server handler 75 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 934681712113, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-08-15 20:23:25,703 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:29:19,066 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50464
recon_1      | 2022-08-15 20:29:19,127 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36714
recon_1      | 2022-08-15 20:29:19,149 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:29:19,154 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:29:19,184 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50654
recon_1      | 2022-08-15 20:29:19,215 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:29:49,085 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50560
recon_1      | 2022-08-15 20:29:49,121 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36812
recon_1      | 2022-08-15 20:29:49,153 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:29:49,170 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50756
recon_1      | 2022-08-15 20:29:49,191 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-08-15 20:23:25,711 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm3.org_1   | 2022-08-15 20:23:25,720 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm3.org_1   | 2022-08-15 20:23:25,705 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-08-15 20:23:25,721 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-08-15 20:23:25,734 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm3.org_1   | 2022-08-15 20:23:25,743 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-08-15 20:23:25,953 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d9c5810d-5123-4bc2-bd6e-bc27d48f5863, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:25.733Z[UTC]].
scm3.org_1   | 2022-08-15 20:23:25,970 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:23:26,285 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4e74fa7e-554b-49cb-895a-4beb5c69c54e, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:25.974Z[UTC]].
scm3.org_1   | 2022-08-15 20:23:26,289 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:23:26,362 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ee87d8de-c101-4564-aff4-e153e5671e57, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-15T20:23:26.205Z[UTC]].
scm3.org_1   | 2022-08-15 20:23:26,365 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:23:28,484 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f3e347f8-57d4-4c72-b323-3754be4def15, Nodes: 11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:11946e6e-1ab1-47b6-94a8-e6dbe917e210, CreationTimestamp2022-08-15T20:23:25.182Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-15 20:23:28,896 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:23:29,809 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d9c5810d-5123-4bc2-bd6e-bc27d48f5863, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, CreationTimestamp2022-08-15T20:23:25.733Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-15 20:23:29,933 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:23:30,022 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-15 20:23:30,693 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-15 20:23:35,161 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-15 20:23:35,710 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-15 20:23:39,257 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om1_1        | 2022-08-15 20:35:09,372 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:10,160 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:10,164 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:10,887 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:10,890 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:11,612 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:11,615 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:12,331 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:12,334 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:13,009 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:13,012 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:13,744 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:13,747 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:14,469 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:14,472 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:14,859 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41359
om1_1        | 2022-08-15 20:35:14,871 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:35:15,201 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:15,204 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:15,927 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:15,930 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:16,639 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:16,642 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:17,354 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:17,356 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:18,071 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:18,073 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:18,788 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:18,791 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:19,641 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:19,644 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:20,318 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:20,324 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:24,248 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56308
om1_1        | 2022-08-15 20:35:24,271 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:35:28,035 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:28,039 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 3827109c74716331b0e34d0b05d0f983a7b2ce58408bd11eafa378d0448b1ad6
om1_1        | 2022-08-15 20:35:28,045 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2278251128 of layout LEGACY in volume: s3v
om1_1        | 2022-08-15 20:35:43,559 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56364
om1_1        | 2022-08-15 20:35:43,588 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:36:14,932 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43965
om1_1        | 2022-08-15 20:36:14,937 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:37:14,979 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34675
recon_1      | 2022-08-15 20:29:49,231 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:30:14,571 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:30:14,571 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:30:14,636 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:30:19,024 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50654
recon_1      | 2022-08-15 20:30:19,128 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:30:19,161 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36904
recon_1      | 2022-08-15 20:30:19,186 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50854
recon_1      | 2022-08-15 20:30:19,196 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 2022-08-15 20:37:14,989 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:38:15,034 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42243
om1_1        | 2022-08-15 20:38:15,043 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:39:15,077 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46699
om1_1        | 2022-08-15 20:39:15,091 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:39:30,423 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:57078
om1_1        | 2022-08-15 20:39:30,446 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:40:15,156 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39969
om1_1        | 2022-08-15 20:40:15,158 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:41:15,201 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38041
om1_1        | 2022-08-15 20:41:15,209 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:42:15,250 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33307
om1_1        | 2022-08-15 20:42:15,257 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-15 20:43:15,300 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35883
om1_1        | 2022-08-15 20:43:15,304 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2022-08-15 20:39:49,338 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:39:50,239 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50334
scm1.org_1   | 2022-08-15 20:39:50,255 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:39:50,381 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56176
scm1.org_1   | 2022-08-15 20:39:50,407 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:39:53,451 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37554
scm1.org_1   | 2022-08-15 20:39:53,479 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:39:57,633 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37566
scm1.org_1   | 2022-08-15 20:39:57,654 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:39:58,168 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:53618
scm1.org_1   | 2022-08-15 20:39:58,172 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-15 20:39:58,930 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:39:58,930 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:40:01,826 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37572
scm1.org_1   | 2022-08-15 20:40:01,850 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:40:06,046 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37584
scm1.org_1   | 2022-08-15 20:40:06,069 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:40:10,036 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37596
scm1.org_1   | 2022-08-15 20:40:10,058 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:40:10,868 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60072
scm1.org_1   | 2022-08-15 20:40:10,912 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:40:14,296 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37616
scm1.org_1   | 2022-08-15 20:40:14,320 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:40:18,562 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37622
scm1.org_1   | 2022-08-15 20:40:18,580 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:40:18,761 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO container.CloseContainerEventHandler: Close container Event triggered for container : #1
scm1.org_1   | 2022-08-15 20:40:20,221 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50432
scm1.org_1   | 2022-08-15 20:40:20,235 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:40:20,329 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56274
scm1.org_1   | 2022-08-15 20:40:20,387 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:40:22,700 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37650
scm1.org_1   | 2022-08-15 20:40:22,720 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:40:26,667 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37662
scm1.org_1   | 2022-08-15 20:40:26,689 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:40:28,930 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:40:28,931 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:40:40,494 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37692
scm1.org_1   | 2022-08-15 20:40:40,512 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2022-08-15 20:26:49,143 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:26:49,195 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46462
scm2.org_1   | 2022-08-15 20:26:49,204 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:26:49,248 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:26:53,452 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-15 20:27:19,189 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38012
scm2.org_1   | 2022-08-15 20:27:19,223 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46346
scm2.org_1   | 2022-08-15 20:27:19,244 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46556
scm2.org_1   | 2022-08-15 20:27:19,258 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:27:19,338 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:27:19,368 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:27:49,062 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38122
scm2.org_1   | 2022-08-15 20:27:49,195 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:27:49,210 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46452
scm2.org_1   | 2022-08-15 20:27:49,236 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46668
scm2.org_1   | 2022-08-15 20:27:49,251 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:27:49,264 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:28:19,104 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38212
scm2.org_1   | 2022-08-15 20:28:19,192 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:28:19,241 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46546
scm2.org_1   | 2022-08-15 20:28:19,261 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46758
scm2.org_1   | 2022-08-15 20:28:19,263 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:28:19,295 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:28:49,070 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38316
scm2.org_1   | 2022-08-15 20:28:49,128 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:28:49,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46642
scm2.org_1   | 2022-08-15 20:28:49,184 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46858
scm2.org_1   | 2022-08-15 20:28:49,184 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:28:49,206 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:29:19,065 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38408
scm2.org_1   | 2022-08-15 20:29:19,145 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:29:19,164 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46738
scm2.org_1   | 2022-08-15 20:29:19,173 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:46952
scm2.org_1   | 2022-08-15 20:29:19,211 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:29:19,223 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:29:49,120 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38508
scm2.org_1   | 2022-08-15 20:29:49,136 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46836
scm2.org_1   | 2022-08-15 20:29:49,151 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47050
scm3.org_1   | 2022-08-15 20:23:40,156 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:32980
scm3.org_1   | 2022-08-15 20:23:40,231 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:23:41,327 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-15 20:23:44,497 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ee87d8de-c101-4564-aff4-e153e5671e57, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f, CreationTimestamp2022-08-15T20:23:26.205Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-15 20:23:44,499 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-15 20:23:44,563 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-15 20:23:56,506 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33020
scm3.org_1   | 2022-08-15 20:23:56,670 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:23:56,671 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8115b5cd-243e-460c-8d63-8e6307b8cda8, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e2584860-2683-4862-8eba-daf2ea0fcaee, CreationTimestamp2022-08-15T20:23:24.678Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-15 20:23:56,675 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-15 20:23:56,675 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm3.org_1   | 2022-08-15 20:23:56,675 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm3.org_1   | 2022-08-15 20:23:56,675 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm3.org_1   | 2022-08-15 20:23:56,675 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-08-15 20:23:56,675 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2022-08-15 20:24:09,938 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 4e74fa7e-554b-49cb-895a-4beb5c69c54e, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}11946e6e-1ab1-47b6-94a8-e6dbe917e210{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:e2584860-2683-4862-8eba-daf2ea0fcaee, CreationTimestamp2022-08-15T20:23:25.974Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-15 20:24:11,346 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59310
scm3.org_1   | 2022-08-15 20:24:11,365 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:24:14,578 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52224
scm3.org_1   | 2022-08-15 20:24:14,619 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:24:39,980 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33144
scm3.org_1   | 2022-08-15 20:24:40,020 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:24:41,340 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59396
scm3.org_1   | 2022-08-15 20:24:41,369 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:24:44,551 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52316
scm3.org_1   | 2022-08-15 20:24:44,600 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:40:40,881 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60168
scm1.org_1   | 2022-08-15 20:40:40,899 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:40:41,904 [FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm1.org_1   | 2022-08-15 20:40:41,937 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56334
scm1.org_1   | 2022-08-15 20:40:41,990 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50508
scm1.org_1   | 2022-08-15 20:40:41,993 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:40:42,033 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:40:54,642 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37738
scm1.org_1   | 2022-08-15 20:40:54,675 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:40:58,931 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:40:58,931 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:41:01,411 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37756
scm1.org_1   | 2022-08-15 20:41:01,428 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:41:01,428 [IPC Server handler 76 on default port 9860] INFO ipc.Server: IPC Server handler 76 on default port 9860, call Call#0 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.117:37756
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1822)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getContainer(SCMClientProtocolServer.java:223)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:693)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:406)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:215)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-08-15 20:41:05,697 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:35898
scm1.org_1   | 2022-08-15 20:41:05,717 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-15 20:41:06,022 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37770
scm1.org_1   | 2022-08-15 20:41:06,031 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:41:06,031 [IPC Server handler 46 on default port 9860] INFO ipc.Server: IPC Server handler 46 on default port 9860, call Call#1 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from 172.25.0.117:37770
scm1.org_1   | org.apache.hadoop.security.AccessControlException: Access denied for user testuser2/scm@EXAMPLE.COM. Superuser privilege is required.
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.checkAdminAccess(StorageContainerManager.java:1822)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.allocateContainer(SCMClientProtocolServer.java:203)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.allocateContainer(StorageContainerLocationProtocolServerSideTranslatorPB.java:682)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:398)
scm1.org_1   | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:215)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java:62732)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 2022-08-15 20:29:49,175 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:29:49,181 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:29:49,195 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:30:19,056 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38602
scm2.org_1   | 2022-08-15 20:30:19,122 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:46934
scm2.org_1   | 2022-08-15 20:30:19,133 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:30:19,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47142
scm2.org_1   | 2022-08-15 20:30:19,167 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:30:19,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:30:49,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38726
scm2.org_1   | 2022-08-15 20:30:49,155 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47058
scm2.org_1   | 2022-08-15 20:30:49,162 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:30:49,179 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47274
scm2.org_1   | 2022-08-15 20:30:49,190 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:30:49,228 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:31:19,055 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38966
scm2.org_1   | 2022-08-15 20:31:19,141 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:31:19,186 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47294
scm2.org_1   | 2022-08-15 20:31:19,197 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47506
scm2.org_1   | 2022-08-15 20:31:19,209 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:31:19,219 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:31:49,111 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47412
scm2.org_1   | 2022-08-15 20:31:49,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39082
scm2.org_1   | 2022-08-15 20:31:49,197 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47622
scm2.org_1   | 2022-08-15 20:31:49,274 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:31:49,300 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:31:49,301 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:31:53,452 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-15 20:32:19,069 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39192
scm2.org_1   | 2022-08-15 20:32:19,113 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47518
scm2.org_1   | 2022-08-15 20:32:19,148 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47734
scm2.org_1   | 2022-08-15 20:32:19,163 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:32:19,170 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:32:19,184 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:32:49,112 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39300
scm2.org_1   | 2022-08-15 20:32:49,152 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47838
scm2.org_1   | 2022-08-15 20:32:49,196 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-08-15 20:30:19,235 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:30:49,033 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50786
recon_1      | 2022-08-15 20:30:49,078 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37034
recon_1      | 2022-08-15 20:30:49,115 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50978
recon_1      | 2022-08-15 20:30:49,134 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:30:49,145 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:30:49,198 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:31:14,638 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:31:14,639 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:31:14,684 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
scm3.org_1   | 2022-08-15 20:24:52,503 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm3.org_1   | 2022-08-15 20:24:56,626 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33212
scm3.org_1   | 2022-08-15 20:24:56,849 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:24:57,188 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52360
scm3.org_1   | 2022-08-15 20:24:57,292 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:24:57,391 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59460
scm3.org_1   | 2022-08-15 20:24:57,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:25:19,142 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59524
scm3.org_1   | 2022-08-15 20:25:19,193 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:25:19,221 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52440
scm3.org_1   | 2022-08-15 20:25:19,343 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33310
scm3.org_1   | 2022-08-15 20:25:19,379 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:25:19,426 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:25:49,269 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59622
scm3.org_1   | 2022-08-15 20:25:49,344 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52544
scm3.org_1   | 2022-08-15 20:25:49,430 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:25:49,495 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:25:49,516 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33408
scm3.org_1   | 2022-08-15 20:25:49,589 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:26:19,155 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59714
scm3.org_1   | 2022-08-15 20:26:19,177 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52632
scm3.org_1   | 2022-08-15 20:26:19,221 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:26:19,288 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33500
scm3.org_1   | 2022-08-15 20:26:19,291 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:26:19,335 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:26:49,084 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59816
scm3.org_1   | 2022-08-15 20:26:49,165 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52728
scm3.org_1   | 2022-08-15 20:26:49,183 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:26:49,192 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33600
scm3.org_1   | 2022-08-15 20:26:49,207 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:26:49,220 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:27:15,935 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-15 20:27:19,198 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59912
scm3.org_1   | 2022-08-15 20:27:19,224 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52828
scm3.org_1   | 2022-08-15 20:27:19,262 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33692
scm3.org_1   | 2022-08-15 20:27:19,262 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:27:19,326 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-08-15 20:41:10,234 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37782
scm1.org_1   | 2022-08-15 20:41:10,253 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:41:11,900 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56418
scm1.org_1   | 2022-08-15 20:41:11,967 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60268
scm1.org_1   | 2022-08-15 20:41:11,994 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50600
scm1.org_1   | 2022-08-15 20:41:11,998 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:41:12,024 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:41:12,040 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:41:14,737 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37818
scm1.org_1   | 2022-08-15 20:41:14,759 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:41:18,931 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37824
scm1.org_1   | 2022-08-15 20:41:18,969 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:41:23,230 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37836
scm1.org_1   | 2022-08-15 20:41:23,253 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:41:27,296 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37848
scm1.org_1   | 2022-08-15 20:41:27,323 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:41:28,718 [BackgroundPipelineScrubberThread] INFO pipeline.PipelineManagerImpl: Scrubbing pipeline: id: PipelineID=523955ed-13ce-47e3-8bf8-7fe3e7378640 since it stays at CLOSED stage.
scm1.org_1   | 2022-08-15 20:41:28,736 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 523955ed-13ce-47e3-8bf8-7fe3e7378640, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-08-15T20:37:51.333Z[UTC]] removed.
scm1.org_1   | 2022-08-15 20:41:28,931 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:41:28,931 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:41:31,538 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37852
scm1.org_1   | 2022-08-15 20:41:31,556 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:41:35,733 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37874
scm1.org_1   | 2022-08-15 20:41:35,753 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:41:39,945 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37886
scm1.org_1   | 2022-08-15 20:41:39,979 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:41:41,895 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56522
scm1.org_1   | 2022-08-15 20:41:41,939 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50704
scm1.org_1   | 2022-08-15 20:41:41,964 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:41:41,972 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:41:41,979 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60378
scm1.org_1   | 2022-08-15 20:41:42,032 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:32:49,198 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:32:49,222 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47630
scm2.org_1   | 2022-08-15 20:32:49,263 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:33:19,097 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47776
scm2.org_1   | 2022-08-15 20:33:19,134 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:47988
scm2.org_1   | 2022-08-15 20:33:19,148 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39444
scm2.org_1   | 2022-08-15 20:33:19,170 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:33:19,205 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:33:19,216 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:33:49,133 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:47930
scm2.org_1   | 2022-08-15 20:33:49,134 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39604
scm2.org_1   | 2022-08-15 20:33:49,176 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:33:49,181 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48144
scm2.org_1   | 2022-08-15 20:33:49,206 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:33:49,217 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:34:19,113 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39730
scm2.org_1   | 2022-08-15 20:34:19,119 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48060
scm2.org_1   | 2022-08-15 20:34:19,146 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:34:19,191 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:34:19,214 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48272
scm2.org_1   | 2022-08-15 20:34:19,238 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:34:49,046 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39870
scm2.org_1   | 2022-08-15 20:34:49,112 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:34:49,159 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48200
scm2.org_1   | 2022-08-15 20:34:49,188 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48416
scm2.org_1   | 2022-08-15 20:34:49,189 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:34:49,198 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:35:19,056 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40006
scm2.org_1   | 2022-08-15 20:35:19,116 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48340
scm2.org_1   | 2022-08-15 20:35:19,142 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:35:19,169 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48548
scm2.org_1   | 2022-08-15 20:35:19,169 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:35:19,216 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:35:49,080 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40112
scm2.org_1   | 2022-08-15 20:35:49,121 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:35:49,168 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48442
scm2.org_1   | 2022-08-15 20:35:49,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48654
scm2.org_1   | 2022-08-15 20:35:49,196 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:27:19,368 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:27:49,065 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60024
scm3.org_1   | 2022-08-15 20:27:49,176 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:27:49,183 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52940
scm3.org_1   | 2022-08-15 20:27:49,208 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33802
scm3.org_1   | 2022-08-15 20:27:49,221 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:27:49,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:28:19,121 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60114
scm3.org_1   | 2022-08-15 20:28:19,185 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:28:19,218 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53024
scm3.org_1   | 2022-08-15 20:28:19,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33894
scm3.org_1   | 2022-08-15 20:28:19,269 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:28:19,288 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:28:49,204 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53132
scm3.org_1   | 2022-08-15 20:28:49,209 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60216
scm3.org_1   | 2022-08-15 20:28:49,216 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:28:49,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:28:49,249 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34000
scm3.org_1   | 2022-08-15 20:28:49,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:29:19,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60304
scm3.org_1   | 2022-08-15 20:29:19,139 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53218
scm3.org_1   | 2022-08-15 20:29:19,156 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:29:19,166 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34088
scm3.org_1   | 2022-08-15 20:29:19,186 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:29:19,224 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:29:49,209 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60402
scm3.org_1   | 2022-08-15 20:29:49,213 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53324
scm3.org_1   | 2022-08-15 20:29:49,234 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:29:49,251 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34192
scm3.org_1   | 2022-08-15 20:29:49,257 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:29:49,288 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:30:19,069 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60502
scm3.org_1   | 2022-08-15 20:30:19,132 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53416
scm3.org_1   | 2022-08-15 20:30:19,134 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:30:19,186 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34284
scm3.org_1   | 2022-08-15 20:30:19,196 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:30:19,222 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:30:49,058 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60626
scm3.org_1   | 2022-08-15 20:30:49,132 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53540
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:31:19,084 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51018
recon_1      | 2022-08-15 20:31:19,144 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:31:19,196 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37270
recon_1      | 2022-08-15 20:31:19,199 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51212
recon_1      | 2022-08-15 20:31:19,236 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:31:19,241 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:31:49,080 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51138
recon_1      | 2022-08-15 20:31:49,207 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37396
recon_1      | 2022-08-15 20:31:49,303 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:31:49,307 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51328
recon_1      | 2022-08-15 20:31:49,340 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:31:49,364 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:31:59,862 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1      | 2022-08-15 20:31:59,867 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 4 milliseconds for processing 2 containers.
recon_1      | 2022-08-15 20:32:00,119 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-08-15 20:32:00,122 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 33 milliseconds.
recon_1      | 2022-08-15 20:32:14,692 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:32:14,692 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:32:14,738 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
scm3.org_1   | 2022-08-15 20:30:49,135 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:30:49,146 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:30:49,168 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34412
scm3.org_1   | 2022-08-15 20:30:49,218 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:31:19,074 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60860
scm3.org_1   | 2022-08-15 20:31:19,123 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:31:19,187 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53774
scm3.org_1   | 2022-08-15 20:31:19,242 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:31:19,251 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34648
scm3.org_1   | 2022-08-15 20:31:19,273 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:31:49,170 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60984
scm3.org_1   | 2022-08-15 20:31:49,193 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34764
scm3.org_1   | 2022-08-15 20:31:49,291 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53908
scm3.org_1   | 2022-08-15 20:31:49,301 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:31:49,328 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:31:49,394 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:32:15,935 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-15 20:32:19,086 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32856
scm3.org_1   | 2022-08-15 20:32:19,088 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54000
scm3.org_1   | 2022-08-15 20:32:19,117 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:32:19,178 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:32:19,196 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34868
scm3.org_1   | 2022-08-15 20:32:19,206 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:32:49,093 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32964
scm3.org_1   | 2022-08-15 20:32:49,110 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:32:49,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34976
scm3.org_1   | 2022-08-15 20:32:49,189 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:32:49,201 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54112
scm3.org_1   | 2022-08-15 20:32:49,271 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:33:19,135 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33108
scm3.org_1   | 2022-08-15 20:33:19,152 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54258
scm3.org_1   | 2022-08-15 20:33:19,158 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:33:19,180 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35124
scm3.org_1   | 2022-08-15 20:33:19,217 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:33:19,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:33:49,121 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54416
scm3.org_1   | 2022-08-15 20:33:49,135 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33266
scm3.org_1   | 2022-08-15 20:33:49,154 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35286
scm2.org_1   | 2022-08-15 20:35:49,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:35:52,486 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 1481bf08-d4dd-442f-9fa2-0fe0347d9a1f, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-08-15T20:35:52.440Z[UTC]].
scm2.org_1   | 2022-08-15 20:36:19,088 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48524
scm2.org_1   | 2022-08-15 20:36:19,098 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40196
scm2.org_1   | 2022-08-15 20:36:19,142 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:36:19,170 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:36:24,896 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48752
scm2.org_1   | 2022-08-15 20:36:24,911 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:36:49,110 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48622
scm2.org_1   | 2022-08-15 20:36:49,122 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40292
scm2.org_1   | 2022-08-15 20:36:49,126 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:36:49,144 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:36:50,143 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48842
scm2.org_1   | 2022-08-15 20:36:50,177 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm2.org_1   | 2022-08-15 20:36:50,181 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 2
scm2.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072 is not the leader 17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:696)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:661)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:800)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$12(RaftServerImpl.java:783)
scm2.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$13(RaftServerImpl.java:783)
scm2.org_1   | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm2.org_1   | 2022-08-15 20:36:50,263 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:36:53,453 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-15 20:37:20,226 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48720
scm2.org_1   | 2022-08-15 20:37:20,275 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:37:20,294 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:48930
scm2.org_1   | 2022-08-15 20:37:20,326 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40408
scm2.org_1   | 2022-08-15 20:37:20,332 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:37:20,346 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:37:50,223 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48826
scm2.org_1   | 2022-08-15 20:37:50,284 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49036
scm2.org_1   | 2022-08-15 20:37:50,290 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:37:50,353 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40520
scm2.org_1   | 2022-08-15 20:37:50,397 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:37:50,401 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:41:44,451 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37914
scm1.org_1   | 2022-08-15 20:41:44,470 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:41:51,514 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37938
scm1.org_1   | 2022-08-15 20:41:51,532 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:41:51,540 [17440e9e-0b34-4cd8-8102-cb903e52057d@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ce604df5-9e75-4196-8248-caae6aec7781, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-08-15T20:41:51.534Z[UTC]].
scm1.org_1   | 2022-08-15 20:41:55,784 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37942
scm1.org_1   | 2022-08-15 20:41:55,803 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:41:58,931 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:41:58,933 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:41:59,952 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37954
scm1.org_1   | 2022-08-15 20:41:59,975 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:42:00,158 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34951
scm1.org_1   | 2022-08-15 20:42:00,169 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:42:04,225 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37966
scm1.org_1   | 2022-08-15 20:42:04,248 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:42:08,188 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:37970
scm1.org_1   | 2022-08-15 20:42:08,217 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:42:11,912 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56614
scm1.org_1   | 2022-08-15 20:42:11,948 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60464
scm1.org_1   | 2022-08-15 20:42:11,968 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:42:11,971 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50796
scm1.org_1   | 2022-08-15 20:42:12,009 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:42:12,016 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:42:12,514 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38006
scm1.org_1   | 2022-08-15 20:42:12,548 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:42:16,815 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38020
scm1.org_1   | 2022-08-15 20:42:16,834 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:32:19,063 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37496
recon_1      | 2022-08-15 20:32:19,087 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51242
recon_1      | 2022-08-15 20:32:19,152 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:32:19,154 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51438
recon_1      | 2022-08-15 20:32:19,169 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:32:19,191 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:32:49,092 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51350
recon_1      | 2022-08-15 20:32:49,147 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51548
recon_1      | 2022-08-15 20:32:49,180 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:32:49,187 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37600
recon_1      | 2022-08-15 20:32:49,194 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:32:49,245 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:33:14,739 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:33:14,739 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:33:14,786 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
scm1.org_1   | 2022-08-15 20:42:21,078 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38032
scm1.org_1   | 2022-08-15 20:42:21,101 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:42:21,110 [IPC Server handler 19 on default port 9860] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ce604df5-9e75-4196-8248-caae6aec7781, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-08-15T20:41:51.534Z[UTC]] moved to CLOSED state
scm1.org_1   | 2022-08-15 20:42:25,117 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38036
scm1.org_1   | 2022-08-15 20:42:25,145 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:42:28,932 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:42:28,937 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm2.org_1   | 2022-08-15 20:37:51,357 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 523955ed-13ce-47e3-8bf8-7fe3e7378640, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-08-15T20:37:51.333Z[UTC]].
scm2.org_1   | 2022-08-15 20:38:20,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:48920
scm2.org_1   | 2022-08-15 20:38:20,291 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:38:20,318 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49132
scm2.org_1   | 2022-08-15 20:38:20,347 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40618
scm2.org_1   | 2022-08-15 20:38:20,361 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:38:20,392 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:38:38,479 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52124
scm2.org_1   | 2022-08-15 20:38:38,501 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2022-08-15 20:38:39,031 [IPC Server handler 1 on default port 9860] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
scm2.org_1   | 2022-08-15 20:38:39,034 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
scm2.org_1   | 2022-08-15 20:38:47,774 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52146
scm2.org_1   | 2022-08-15 20:38:47,793 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2022-08-15 20:38:47,794 [IPC Server handler 83 on default port 9860] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2022-08-15 20:38:47,799 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-15 20:38:50,230 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49030
scm2.org_1   | 2022-08-15 20:38:50,279 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:38:50,294 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49244
scm2.org_1   | 2022-08-15 20:38:50,331 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40724
scm2.org_1   | 2022-08-15 20:38:50,333 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:38:50,345 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:39:20,240 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49124
scm2.org_1   | 2022-08-15 20:39:20,288 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49334
scm2.org_1   | 2022-08-15 20:39:20,318 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:39:20,332 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:39:20,420 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40818
scm2.org_1   | 2022-08-15 20:39:20,488 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:39:40,902 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49402
scm2.org_1   | 2022-08-15 20:39:40,932 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:39:50,217 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49232
scm2.org_1   | 2022-08-15 20:39:50,225 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:39:50,354 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:40920
scm2.org_1   | 2022-08-15 20:39:50,410 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:40:10,891 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49500
scm2.org_1   | 2022-08-15 20:40:10,932 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:40:20,205 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49328
scm2.org_1   | 2022-08-15 20:40:20,221 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:33:19,060 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37746
recon_1      | 2022-08-15 20:33:19,140 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:33:19,192 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51500
recon_1      | 2022-08-15 20:33:19,198 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51694
recon_1      | 2022-08-15 20:33:19,234 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:33:19,266 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:33:49,113 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37908
recon_1      | 2022-08-15 20:33:49,118 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51656
recon_1      | 2022-08-15 20:33:49,169 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:33:49,182 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51850
recon_1      | 2022-08-15 20:33:49,205 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:33:49,243 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:34:14,788 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:34:14,789 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:34:14,836 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
scm2.org_1   | 2022-08-15 20:40:20,337 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41014
scm2.org_1   | 2022-08-15 20:40:20,383 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:40:40,886 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49594
scm2.org_1   | 2022-08-15 20:40:40,909 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:40:41,904 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm2.org_1   | 2022-08-15 20:40:41,905 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 1
scm2.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server 3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072 is not the leader 17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:696)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:661)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:800)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$12(RaftServerImpl.java:783)
scm2.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
scm2.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$13(RaftServerImpl.java:783)
scm2.org_1   | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm2.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm2.org_1   | 2022-08-15 20:40:41,924 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41076
scm2.org_1   | 2022-08-15 20:40:41,979 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:40:42,006 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49404
scm2.org_1   | 2022-08-15 20:40:42,031 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:41:12,070 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41162
scm2.org_1   | 2022-08-15 20:41:12,074 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49696
scm2.org_1   | 2022-08-15 20:41:12,078 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:41:12,087 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:41:12,105 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49500
scm2.org_1   | 2022-08-15 20:41:12,117 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:41:28,763 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 523955ed-13ce-47e3-8bf8-7fe3e7378640, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-08-15T20:37:51.333Z[UTC]] removed.
scm2.org_1   | 2022-08-15 20:41:41,968 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49796
scm2.org_1   | 2022-08-15 20:41:42,041 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49602
scm2.org_1   | 2022-08-15 20:41:42,044 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:41:42,060 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41266
scm2.org_1   | 2022-08-15 20:41:42,061 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:41:42,068 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:41:51,570 [3fa27e21-96df-4954-913e-c2b6f8845795@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ce604df5-9e75-4196-8248-caae6aec7781, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-08-15T20:41:51.534Z[UTC]].
scm2.org_1   | 2022-08-15 20:42:12,059 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49694
scm2.org_1   | 2022-08-15 20:42:12,063 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41358
scm1.org_1   | 2022-08-15 20:42:32,245 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38050
scm1.org_1   | 2022-08-15 20:42:32,273 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:42:36,113 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38072
scm1.org_1   | 2022-08-15 20:42:36,145 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:42:40,102 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38088
scm1.org_1   | 2022-08-15 20:42:40,112 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:42:40,113 [IPC Server handler 19 on default port 9860] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
scm1.org_1   | 2022-08-15 20:42:40,114 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
scm1.org_1   | 2022-08-15 20:42:41,963 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60582
scm1.org_1   | 2022-08-15 20:42:41,966 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50908
scm1.org_1   | 2022-08-15 20:42:41,967 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:42:41,976 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56726
scm1.org_1   | 2022-08-15 20:42:41,983 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:42:41,985 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:42:44,157 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38118
scm1.org_1   | 2022-08-15 20:42:44,176 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:42:48,484 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38134
scm1.org_1   | 2022-08-15 20:42:48,488 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:42:48,489 [IPC Server handler 64 on default port 9860] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2022-08-15 20:42:48,507 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 4 containers.
scm1.org_1   | 2022-08-15 20:42:52,389 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38148
scm1.org_1   | 2022-08-15 20:42:52,406 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:42:58,937 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:42:58,938 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-15 20:42:59,456 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38162
scm1.org_1   | 2022-08-15 20:42:59,485 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:43:03,617 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38174
scm1.org_1   | 2022-08-15 20:43:03,643 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:43:07,595 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38178
scm1.org_1   | 2022-08-15 20:43:07,616 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-15 20:43:11,918 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60676
scm1.org_1   | 2022-08-15 20:43:11,946 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56824
scm1.org_1   | 2022-08-15 20:43:11,989 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51010
scm1.org_1   | 2022-08-15 20:43:12,007 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:43:12,026 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:43:12,045 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-15 20:43:14,903 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:38216
scm1.org_1   | 2022-08-15 20:43:14,923 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:34:19,070 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51782
recon_1      | 2022-08-15 20:34:19,076 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38036
recon_1      | 2022-08-15 20:34:19,092 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:34:19,154 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51982
recon_1      | 2022-08-15 20:34:19,184 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:34:19,210 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:34:49,023 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51922
recon_1      | 2022-08-15 20:34:49,091 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38178
recon_1      | 2022-08-15 20:34:49,108 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:34:49,118 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:34:49,151 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52122
recon_1      | 2022-08-15 20:34:49,197 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:35:14,837 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:35:14,837 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:35:14,896 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
scm3.org_1   | 2022-08-15 20:33:49,172 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:33:49,182 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:33:49,206 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:34:19,104 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33398
scm3.org_1   | 2022-08-15 20:34:19,130 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54542
scm3.org_1   | 2022-08-15 20:34:19,139 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35410
scm3.org_1   | 2022-08-15 20:34:19,143 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:34:19,183 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:34:19,209 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:34:49,053 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33538
scm3.org_1   | 2022-08-15 20:34:49,109 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:34:49,149 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54686
scm3.org_1   | 2022-08-15 20:34:49,172 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:34:49,187 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35552
scm3.org_1   | 2022-08-15 20:34:49,199 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:35:19,069 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54822
scm3.org_1   | 2022-08-15 20:35:19,150 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33674
scm3.org_1   | 2022-08-15 20:35:19,151 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:35:19,152 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35690
scm3.org_1   | 2022-08-15 20:35:19,200 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:35:19,211 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:35:49,067 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33776
scm3.org_1   | 2022-08-15 20:35:49,094 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:35:49,137 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54922
scm3.org_1   | 2022-08-15 20:35:49,179 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35790
scm3.org_1   | 2022-08-15 20:35:49,188 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:35:49,232 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:35:52,475 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 1481bf08-d4dd-442f-9fa2-0fe0347d9a1f, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-08-15T20:35:52.440Z[UTC]].
scm3.org_1   | 2022-08-15 20:36:19,101 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33864
scm3.org_1   | 2022-08-15 20:36:19,104 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55006
scm3.org_1   | 2022-08-15 20:36:19,138 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:36:19,174 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:36:24,886 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35888
scm3.org_1   | 2022-08-15 20:36:24,905 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:36:49,068 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55108
scm2.org_1   | 2022-08-15 20:42:12,065 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:42:12,073 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49890
scm2.org_1   | 2022-08-15 20:42:12,076 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:42:12,082 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:42:39,908 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:55556
scm2.org_1   | 2022-08-15 20:42:39,926 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2022-08-15 20:42:39,927 [IPC Server handler 1 on default port 9860] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
scm2.org_1   | 2022-08-15 20:42:39,929 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
scm2.org_1   | 2022-08-15 20:42:42,002 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:49998
scm2.org_1   | 2022-08-15 20:42:42,018 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41468
scm2.org_1   | 2022-08-15 20:42:42,021 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:42:42,023 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:42:42,042 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49804
scm2.org_1   | 2022-08-15 20:42:42,048 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:42:48,231 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:55602
scm2.org_1   | 2022-08-15 20:42:48,254 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm2.org_1   | 2022-08-15 20:42:48,256 [IPC Server handler 0 on default port 9860] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2022-08-15 20:42:48,269 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-15 20:43:11,933 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41568
scm2.org_1   | 2022-08-15 20:43:12,021 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:43:12,084 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50096
scm2.org_1   | 2022-08-15 20:43:12,100 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:49902
scm2.org_1   | 2022-08-15 20:43:12,103 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-15 20:43:12,114 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:35:19,118 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38310
recon_1      | 2022-08-15 20:35:19,125 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52064
recon_1      | 2022-08-15 20:35:19,148 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:35:19,186 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52260
recon_1      | 2022-08-15 20:35:19,191 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:35:19,225 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:35:49,050 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52162
recon_1      | 2022-08-15 20:35:49,064 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:35:49,130 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38414
recon_1      | 2022-08-15 20:35:49,182 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52360
recon_1      | 2022-08-15 20:35:49,190 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:35:49,224 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-08-15 20:36:49,086 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:36:49,098 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33960
scm3.org_1   | 2022-08-15 20:36:49,138 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:36:50,153 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35984
scm3.org_1   | 2022-08-15 20:36:50,184 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm3.org_1   | 2022-08-15 20:36:50,212 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 2
scm3.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072 is not the leader 17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:696)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:661)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:800)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$12(RaftServerImpl.java:783)
scm3.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$13(RaftServerImpl.java:783)
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm3.org_1   | 2022-08-15 20:36:50,263 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:37:15,936 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-15 20:37:20,247 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55202
scm3.org_1   | 2022-08-15 20:37:20,282 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:37:20,331 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36072
scm3.org_1   | 2022-08-15 20:37:20,339 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34078
scm3.org_1   | 2022-08-15 20:37:20,351 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:37:20,379 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:37:50,216 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55308
scm3.org_1   | 2022-08-15 20:37:50,282 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36172
scm3.org_1   | 2022-08-15 20:37:50,285 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:37:50,360 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34180
scm3.org_1   | 2022-08-15 20:37:50,389 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:37:50,416 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:37:51,357 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 523955ed-13ce-47e3-8bf8-7fe3e7378640, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-08-15T20:37:51.333Z[UTC]].
scm3.org_1   | 2022-08-15 20:38:20,206 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55406
scm3.org_1   | 2022-08-15 20:38:20,282 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:38:20,320 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36274
scm3.org_1   | 2022-08-15 20:38:20,345 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34280
scm3.org_1   | 2022-08-15 20:38:20,358 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:38:20,385 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:38:39,292 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45510
recon_1      | 2022-08-15 20:35:54,879 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: New container #3 got from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-08-15 20:35:54,927 [FixedThreadPoolWithAffinityExecutor-8-0] WARN scm.ReconContainerManager: Pipeline PipelineID=1481bf08-d4dd-442f-9fa2-0fe0347d9a1f not found. Cannot add container #3
recon_1      | 2022-08-15 20:35:54,928 [FixedThreadPoolWithAffinityExecutor-8-0] WARN scm.ReconIncrementalContainerReportHandler: Container 3 not found!
recon_1      | 2022-08-15 20:36:14,897 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:36:14,897 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:36:14,957 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:36:19,061 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52248
recon_1      | 2022-08-15 20:36:19,084 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38500
recon_1      | 2022-08-15 20:36:19,139 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-08-15 20:38:39,299 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2022-08-15 20:38:39,904 [IPC Server handler 93 on default port 9860] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
scm3.org_1   | 2022-08-15 20:38:39,907 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
scm3.org_1   | 2022-08-15 20:38:48,017 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:45532
scm3.org_1   | 2022-08-15 20:38:48,028 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2022-08-15 20:38:48,029 [IPC Server handler 95 on default port 9860] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-08-15 20:38:48,044 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-15 20:38:50,255 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55520
scm3.org_1   | 2022-08-15 20:38:50,310 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:38:50,350 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36388
scm3.org_1   | 2022-08-15 20:38:50,360 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34394
scm3.org_1   | 2022-08-15 20:38:50,362 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:38:50,382 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:39:20,226 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55606
scm3.org_1   | 2022-08-15 20:39:20,298 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36472
scm3.org_1   | 2022-08-15 20:39:20,316 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:39:20,372 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:39:20,412 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34480
scm3.org_1   | 2022-08-15 20:39:20,458 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:39:40,894 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36538
scm3.org_1   | 2022-08-15 20:39:40,912 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:39:50,215 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55718
scm3.org_1   | 2022-08-15 20:39:50,238 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:39:50,339 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34584
scm3.org_1   | 2022-08-15 20:39:50,394 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:40:10,866 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36636
scm3.org_1   | 2022-08-15 20:40:10,923 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:40:20,204 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55816
scm3.org_1   | 2022-08-15 20:40:20,219 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:40:20,338 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34684
scm3.org_1   | 2022-08-15 20:40:20,378 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:40:40,869 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36736
scm3.org_1   | 2022-08-15 20:40:40,899 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:40:41,914 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
scm3.org_1   | 2022-08-15 20:40:41,915 [FixedThreadPoolWithAffinityExecutor-0-0] ERROR container.IncrementalContainerReportHandler: Exception while processing ICR for container 1
scm3.org_1   | org.apache.ratis.protocol.exceptions.NotLeaderException: Server b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072 is not the leader 17440e9e-0b34-4cd8-8102-cb903e52057d|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:696)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:661)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:800)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$12(RaftServerImpl.java:783)
scm3.org_1   | 	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:115)
recon_1      | 2022-08-15 20:36:19,154 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:36:24,923 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52458
recon_1      | 2022-08-15 20:36:24,940 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:36:49,040 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52350
recon_1      | 2022-08-15 20:36:49,092 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38600
recon_1      | 2022-08-15 20:36:49,114 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:36:49,124 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:36:50,015 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: Container #2 has state OPEN, but given state is CLOSING.
recon_1      | 2022-08-15 20:36:50,156 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52554
recon_1      | 2022-08-15 20:36:50,215 [FixedThreadPoolWithAffinityExecutor-0-0] INFO container.IncrementalContainerReportHandler: Moving container #2 to CLOSED state, datanode ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
recon_1      | 2022-08-15 20:36:50,262 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:36:50,334 [FixedThreadPoolWithAffinityExecutor-8-0] WARN scm.ReconContainerManager: Pipeline PipelineID=1481bf08-d4dd-442f-9fa2-0fe0347d9a1f not found. Cannot add container #3
recon_1      | 2022-08-15 20:36:50,334 [FixedThreadPoolWithAffinityExecutor-8-0] ERROR container.ContainerReportHandler: Received container report for an unknown container 3 from datanode e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
recon_1      | 2022-08-15 20:36:59,869 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds to process 0 existing database records.
recon_1      | 2022-08-15 20:36:59,874 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 4 milliseconds for processing 2 containers.
recon_1      | 2022-08-15 20:37:00,132 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-08-15 20:37:00,135 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=1481bf08-d4dd-442f-9fa2-0fe0347d9a1f from SCM.
recon_1      | 2022-08-15 20:37:00,137 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 1481bf08-d4dd-442f-9fa2-0fe0347d9a1f, Nodes: e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-08-15T20:35:52.440Z[UTC]].
recon_1      | 2022-08-15 20:37:00,138 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 10 milliseconds.
recon_1      | 2022-08-15 20:37:14,958 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:37:14,959 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:37:15,010 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
scm3.org_1   | 	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$13(RaftServerImpl.java:783)
scm3.org_1   | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm3.org_1   | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm3.org_1   | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm3.org_1   | 2022-08-15 20:40:41,995 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34744
scm3.org_1   | 2022-08-15 20:40:42,004 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:40:42,017 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55890
scm3.org_1   | 2022-08-15 20:40:42,035 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:41:11,944 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34826
scm3.org_1   | 2022-08-15 20:41:11,964 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36832
scm3.org_1   | 2022-08-15 20:41:11,987 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55982
scm3.org_1   | 2022-08-15 20:41:12,001 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:41:12,012 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:41:12,031 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:41:28,745 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Pipeline Pipeline[ Id: 523955ed-13ce-47e3-8bf8-7fe3e7378640, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:CLOSED, leaderId:, CreationTimestamp2022-08-15T20:37:51.333Z[UTC]] removed.
scm3.org_1   | 2022-08-15 20:41:41,994 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56084
scm3.org_1   | 2022-08-15 20:41:41,998 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36934
scm3.org_1   | 2022-08-15 20:41:42,005 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:41:42,024 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34928
scm3.org_1   | 2022-08-15 20:41:42,027 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:41:42,039 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:41:51,543 [b7365c8d-2724-48d2-bef1-0dcca965a3a4@group-D1FD779EF072-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ce604df5-9e75-4196-8248-caae6aec7781, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-08-15T20:41:51.534Z[UTC]].
scm3.org_1   | 2022-08-15 20:42:11,907 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37032
scm3.org_1   | 2022-08-15 20:42:11,913 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35020
scm3.org_1   | 2022-08-15 20:42:11,917 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:42:11,978 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56180
scm3.org_1   | 2022-08-15 20:42:12,006 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:42:12,013 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:42:40,130 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:48166
scm3.org_1   | 2022-08-15 20:42:40,133 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2022-08-15 20:42:40,134 [IPC Server handler 94 on default port 9860] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
scm3.org_1   | 2022-08-15 20:42:40,135 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
scm3.org_1   | 2022-08-15 20:42:41,997 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35132
scm3.org_1   | 2022-08-15 20:42:42,001 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37142
scm3.org_1   | 2022-08-15 20:42:42,016 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:37:20,210 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38690
recon_1      | 2022-08-15 20:37:20,249 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:37:20,324 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52636
recon_1      | 2022-08-15 20:37:20,347 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:37:20,356 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52464
recon_1      | 2022-08-15 20:37:20,387 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:37:50,218 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38796
recon_1      | 2022-08-15 20:37:50,275 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52746
recon_1      | 2022-08-15 20:37:50,290 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:37:50,358 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52570
recon_1      | 2022-08-15 20:37:50,386 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:37:50,405 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:38:15,013 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:38:15,014 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:38:15,057 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
scm3.org_1   | 2022-08-15 20:42:42,022 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:42:42,028 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56290
scm3.org_1   | 2022-08-15 20:42:42,036 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:42:48,514 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:48212
scm3.org_1   | 2022-08-15 20:42:48,519 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm3.org_1   | 2022-08-15 20:42:48,520 [IPC Server handler 49 on default port 9860] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-08-15 20:42:48,522 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-15 20:43:11,916 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35230
scm3.org_1   | 2022-08-15 20:43:11,979 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56384
scm3.org_1   | 2022-08-15 20:43:11,980 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:43:12,016 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37240
scm3.org_1   | 2022-08-15 20:43:12,038 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-15 20:43:12,053 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:38:20,228 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38892
recon_1      | 2022-08-15 20:38:20,291 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:38:20,312 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52838
recon_1      | 2022-08-15 20:38:20,343 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52670
recon_1      | 2022-08-15 20:38:20,383 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:38:20,401 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:38:20,421 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: Successfully added container #3 to Recon.
recon_1      | 2022-08-15 20:38:50,226 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39006
recon_1      | 2022-08-15 20:38:50,268 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52954
recon_1      | 2022-08-15 20:38:50,280 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:38:50,295 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:38:50,349 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52780
recon_1      | 2022-08-15 20:38:50,369 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:39:15,057 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:39:15,057 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:39:15,128 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:39:20,232 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39092
recon_1      | 2022-08-15 20:39:20,375 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53044
recon_1      | 2022-08-15 20:39:20,383 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:39:20,385 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:39:20,476 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52870
recon_1      | 2022-08-15 20:39:20,493 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:39:40,874 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53108
recon_1      | 2022-08-15 20:39:40,892 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:39:40,893 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: New container #4 got from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-08-15 20:39:40,925 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: Successfully added container #4 to Recon.
recon_1      | 2022-08-15 20:39:50,197 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39204
recon_1      | 2022-08-15 20:39:50,240 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:39:50,348 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52970
recon_1      | 2022-08-15 20:39:50,405 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:40:10,864 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53206
recon_1      | 2022-08-15 20:40:10,910 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:40:15,129 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:40:15,129 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:40:15,179 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor55.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:40:20,194 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39304
recon_1      | 2022-08-15 20:40:20,221 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:40:20,326 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53070
recon_1      | 2022-08-15 20:40:20,383 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:40:21,180 [FixedThreadPoolWithAffinityExecutor-8-0] INFO scm.ReconContainerManager: Container #1 has state OPEN, but given state is CLOSING.
recon_1      | 2022-08-15 20:40:40,846 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53300
recon_1      | 2022-08-15 20:40:40,854 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:40:41,899 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53128
recon_1      | 2022-08-15 20:40:41,944 [FixedThreadPoolWithAffinityExecutor-8-0] INFO container.IncrementalContainerReportHandler: Moving container #1 to CLOSED state, datanode e2584860-2683-4862-8eba-daf2ea0fcaee{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
recon_1      | 2022-08-15 20:40:41,972 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39382
recon_1      | 2022-08-15 20:40:41,979 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:40:42,028 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:41:11,974 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53212
recon_1      | 2022-08-15 20:41:11,989 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39470
recon_1      | 2022-08-15 20:41:11,993 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53402
recon_1      | 2022-08-15 20:41:12,003 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:41:12,032 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:41:12,041 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:41:15,180 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:41:15,181 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:41:15,229 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor55.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:41:41,943 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39578
recon_1      | 2022-08-15 20:41:41,952 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53506
recon_1      | 2022-08-15 20:41:41,990 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53318
recon_1      | 2022-08-15 20:41:41,991 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:41:42,019 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:41:42,052 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:41:59,876 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1      | 2022-08-15 20:41:59,880 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 4 milliseconds for processing 4 containers.
recon_1      | 2022-08-15 20:42:00,177 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 6 pipelines in house.
recon_1      | 2022-08-15 20:42:00,191 [PipelineSyncTask] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=ce604df5-9e75-4196-8248-caae6aec7781 from SCM.
recon_1      | 2022-08-15 20:42:00,194 [PipelineSyncTask] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ce604df5-9e75-4196-8248-caae6aec7781, Nodes: ff5a91df-08e6-4e6e-bd06-f5ce7e1e035f{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: STANDALONE/ONE, State:OPEN, leaderId:, CreationTimestamp2022-08-15T20:41:51.534Z[UTC]].
recon_1      | 2022-08-15 20:42:00,196 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 51 milliseconds.
recon_1      | 2022-08-15 20:42:11,914 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53410
recon_1      | 2022-08-15 20:42:11,939 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53596
recon_1      | 2022-08-15 20:42:11,982 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:42:12,001 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39666
recon_1      | 2022-08-15 20:42:12,006 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:42:12,014 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:42:15,230 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:42:15,230 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:42:15,275 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor55.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-15 20:42:41,883 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53524
recon_1      | 2022-08-15 20:42:41,912 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53708
recon_1      | 2022-08-15 20:42:41,932 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:42:41,965 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:42:41,971 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39782
recon_1      | 2022-08-15 20:42:41,997 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:43:11,939 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53620
recon_1      | 2022-08-15 20:43:11,962 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39880
recon_1      | 2022-08-15 20:43:11,988 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:53810
recon_1      | 2022-08-15 20:43:11,993 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:43:11,997 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:43:12,041 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-15 20:43:15,277 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-15 20:43:15,277 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-15 20:43:15,326 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor55.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
