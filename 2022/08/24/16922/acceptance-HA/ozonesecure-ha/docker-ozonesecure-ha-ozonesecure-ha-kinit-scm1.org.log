Attaching to ozonesecure-ha_kdc_1, ozonesecure-ha_s3g_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_datanode2_1, ozonesecure-ha_scm3.org_1, ozonesecure-ha_om2_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_om1_1, ozonesecure-ha_recon_1, ozonesecure-ha_om3_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_kms_1
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2022-08-24 20:57:37,349 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = 527bfc57601e/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
datanode1_1  | STARTUP_MSG:   java = 11.0.14.1
datanode1_1  | ************************************************************/
datanode1_1  | 2022-08-24 20:57:37,412 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2022-08-24 20:57:37,758 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2022-08-24 20:57:38,340 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2022-08-24 20:57:39,173 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2022-08-24 20:57:39,173 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2022-08-24 20:57:39,801 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:527bfc57601e ip:172.25.0.102
datanode1_1  | 2022-08-24 20:57:42,420 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2022-08-24 20:57:43,265 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2022-08-24 20:57:43,267 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2022-08-24 20:57:45,153 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2022-08-24 20:57:45,168 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2022-08-24 20:57:45,168 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2022-08-24 20:57:45,170 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2022-08-24 20:57:49,504 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2022-08-24 20:57:49,604 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:527bfc57601e
datanode1_1  | 2022-08-24 20:57:49,604 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2022-08-24 20:57:49,621 [main] ERROR client.DNCertificateClient: Invalid domain 527bfc57601e
datanode1_1  | 2022-08-24 20:57:49,622 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@527bfc57601e
datanode1_1  | 2022-08-24 20:57:53,816 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2022-08-24 20:57:53,910 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2022-08-24 20:57:53,923 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-1170009537688.crt.
datanode1_1  | 2022-08-24 20:57:53,950 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/1250283857425.crt.
datanode1_1  | 2022-08-24 20:57:53,954 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2022-08-24 20:57:54,048 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode1_1  | 2022-08-24 20:57:54,880 [main] INFO reflections.Reflections: Reflections took 626 ms to scan 2 urls, producing 90 keys and 199 values 
datanode1_1  | 2022-08-24 20:57:55,293 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode1_1  | 2022-08-24 20:57:56,263 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2022-08-24 20:57:56,363 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode1_1  | 2022-08-24 20:57:56,376 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2022-08-24 20:57:56,410 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2022-08-24 20:57:56,596 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2022-08-24 20:57:56,761 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-08-24 20:57:56,778 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2022-08-24 20:57:56,786 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2022-08-24 20:57:56,786 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2022-08-24 20:57:56,799 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2022-08-24 20:57:57,097 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2022-08-24 20:57:57,100 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2022-08-24 20:58:01,820 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode1_1  | 2022-08-24 20:58:02,618 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-08-24 20:58:02,828 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2022-08-24 20:58:04,204 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2022-08-24 20:58:04,268 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2022-08-24 20:58:04,286 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2022-08-24 20:58:04,306 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2022-08-24 20:58:04,328 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-08-24 20:58:04,341 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2022-08-24 20:58:04,342 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-08-24 20:58:04,530 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode1_1  | 2022-08-24 20:58:04,531 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode1_1  | 2022-08-24 20:58:10,304 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2022-08-24 20:57:37,683 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = 7541e863c794/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
datanode2_1  | STARTUP_MSG:   java = 11.0.14.1
datanode2_1  | ************************************************************/
datanode2_1  | 2022-08-24 20:57:37,725 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2022-08-24 20:57:37,990 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2022-08-24 20:57:38,563 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2022-08-24 20:57:39,447 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2022-08-24 20:57:39,447 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2022-08-24 20:57:40,163 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:7541e863c794 ip:172.25.0.103
datanode2_1  | 2022-08-24 20:57:42,570 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2022-08-24 20:57:43,329 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2022-08-24 20:57:43,333 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2022-08-24 20:57:45,202 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2022-08-24 20:57:45,204 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2022-08-24 20:57:45,204 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2022-08-24 20:57:45,209 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2022-08-24 20:57:51,083 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2022-08-24 20:57:51,235 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:7541e863c794
datanode2_1  | 2022-08-24 20:57:51,235 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2022-08-24 20:57:51,276 [main] ERROR client.DNCertificateClient: Invalid domain 7541e863c794
datanode2_1  | 2022-08-24 20:57:51,278 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@7541e863c794
datanode2_1  | 2022-08-24 20:57:55,999 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2022-08-24 20:57:56,104 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/1252176017931.crt.
datanode2_1  | 2022-08-24 20:57:56,125 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2022-08-24 20:57:56,130 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-1170009537688.crt.
datanode2_1  | 2022-08-24 20:57:56,130 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2022-08-24 20:57:56,174 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode2_1  | 2022-08-24 20:57:57,288 [main] INFO reflections.Reflections: Reflections took 812 ms to scan 2 urls, producing 90 keys and 199 values 
datanode2_1  | 2022-08-24 20:57:57,845 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode2_1  | 2022-08-24 20:57:58,958 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2022-08-24 20:57:59,037 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode2_1  | 2022-08-24 20:57:59,041 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2022-08-24 20:57:59,076 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2022-08-24 20:57:59,253 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2022-08-24 20:57:59,402 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-08-24 20:57:59,412 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2022-08-24 20:57:59,429 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2022-08-24 20:57:59,431 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2022-08-24 20:57:59,441 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode2_1  | 2022-08-24 20:57:59,638 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2022-08-24 20:57:59,660 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2022-08-24 20:58:04,799 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode2_1  | 2022-08-24 20:58:06,374 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-08-24 20:58:06,758 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2022-08-24 20:58:07,680 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2022-08-24 20:58:07,681 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2022-08-24 20:58:07,685 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2022-08-24 20:58:07,685 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2022-08-24 20:58:07,690 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-24 20:58:07,691 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2022-08-24 20:58:07,694 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-08-24 20:58:07,765 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode2_1  | 2022-08-24 20:58:07,770 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode2_1  | 2022-08-24 20:58:13,267 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | 2022-08-24 20:58:13,286 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode2_1  | 2022-08-24 20:58:13,286 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2022-08-24 20:58:10,357 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode1_1  | 2022-08-24 20:58:10,359 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode1_1  | 2022-08-24 20:58:10,372 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-08-24 20:58:10,373 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-08-24 20:58:10,393 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-08-24 20:58:10,871 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode1_1  | 2022-08-24 20:58:11,732 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode1_1  | 2022-08-24 20:58:11,749 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode1_1  | 2022-08-24 20:58:12,068 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2022-08-24 20:58:12,069 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2022-08-24 20:58:12,069 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2022-08-24 20:58:12,357 [main] INFO util.log: Logging initialized @44821ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2022-08-24 20:58:12,876 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2022-08-24 20:58:12,911 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2022-08-24 20:58:12,912 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2022-08-24 20:58:12,913 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2022-08-24 20:58:12,913 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2022-08-24 20:58:12,939 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2022-08-24 20:58:13,130 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2022-08-24 20:58:13,131 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode1_1  | 2022-08-24 20:58:13,296 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2022-08-24 20:58:13,296 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2022-08-24 20:58:13,312 [main] INFO server.session: node0 Scavenging every 600000ms
datanode1_1  | 2022-08-24 20:58:13,469 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-08-24 20:58:13,477 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3285c141{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2022-08-24 20:58:13,493 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@105e8710{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2022-08-24 20:58:14,103 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-08-24 20:58:14,183 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5629e904{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-10486414816961446588/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2022-08-24 20:58:14,238 [main] INFO server.AbstractConnector: Started ServerConnector@44b99f09{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2022-08-24 20:58:14,238 [main] INFO server.Server: Started @46703ms
datanode1_1  | 2022-08-24 20:58:14,262 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2022-08-24 20:58:14,262 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2022-08-24 20:58:14,267 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2022-08-24 20:58:14,297 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode3_1  | 2022-08-24 20:57:37,259 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = 84533d7fcdfb/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
datanode3_1  | STARTUP_MSG:   java = 11.0.14.1
datanode3_1  | ************************************************************/
datanode3_1  | 2022-08-24 20:57:37,355 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2022-08-24 20:57:37,698 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2022-08-24 20:57:38,281 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2022-08-24 20:57:39,332 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2022-08-24 20:57:39,332 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2022-08-24 20:57:40,017 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:84533d7fcdfb ip:172.25.0.104
datanode3_1  | 2022-08-24 20:57:42,621 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2022-08-24 20:57:43,513 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2022-08-24 20:57:43,514 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2022-08-24 20:57:45,345 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2022-08-24 20:57:45,387 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2022-08-24 20:57:45,387 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2022-08-24 20:57:45,397 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2022-08-24 20:57:51,236 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2022-08-24 20:57:51,284 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:84533d7fcdfb
datanode3_1  | 2022-08-24 20:57:51,306 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2022-08-24 20:57:51,308 [main] ERROR client.DNCertificateClient: Invalid domain 84533d7fcdfb
datanode3_1  | 2022-08-24 20:57:51,318 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@84533d7fcdfb
datanode3_1  | 2022-08-24 20:57:56,021 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2022-08-24 20:57:56,097 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/1252470207979.crt.
datanode3_1  | 2022-08-24 20:57:56,112 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2022-08-24 20:57:56,162 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-1170009537688.crt.
datanode3_1  | 2022-08-24 20:57:56,162 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2022-08-24 20:57:56,298 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode3_1  | 2022-08-24 20:57:57,065 [main] INFO reflections.Reflections: Reflections took 576 ms to scan 2 urls, producing 90 keys and 199 values 
datanode3_1  | 2022-08-24 20:57:57,522 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode3_1  | 2022-08-24 20:57:58,569 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2022-08-24 20:57:58,669 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode3_1  | 2022-08-24 20:57:58,709 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2022-08-24 20:57:58,710 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2022-08-24 20:57:58,915 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2022-08-24 20:57:59,037 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-08-24 20:57:59,067 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2022-08-24 20:57:59,073 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2022-08-24 20:57:59,077 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2022-08-24 20:57:59,078 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2022-08-24 20:57:59,383 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2022-08-24 20:57:59,397 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2022-08-24 20:58:04,149 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode3_1  | 2022-08-24 20:58:05,266 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-08-24 20:58:05,560 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2022-08-24 20:58:06,454 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2022-08-24 20:58:06,462 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2022-08-24 20:58:06,474 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2022-08-24 20:58:06,475 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2022-08-24 20:58:06,492 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-24 20:58:06,502 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2022-08-24 20:58:06,503 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-08-24 20:58:06,685 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode3_1  | 2022-08-24 20:58:06,723 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode3_1  | 2022-08-24 20:58:12,571 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2022-08-24 20:58:14,492 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@15e4cb02] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2022-08-24 20:58:14,903 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2022-08-24 20:58:14,943 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode1_1  | 2022-08-24 20:58:19,265 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe/DS-635b1fae-35ed-4b7f-9fd3-e301cf0d2023/container.db for volume DS-635b1fae-35ed-4b7f-9fd3-e301cf0d2023
datanode1_1  | 2022-08-24 20:58:19,279 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe/DS-635b1fae-35ed-4b7f-9fd3-e301cf0d2023/container.db for volume DS-635b1fae-35ed-4b7f-9fd3-e301cf0d2023
datanode1_1  | 2022-08-24 20:58:19,296 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2022-08-24 20:58:19,306 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2022-08-24 20:58:19,641 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
datanode1_1  | 2022-08-24 20:58:19,778 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.RaftServer: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start RPC server
datanode1_1  | 2022-08-24 20:58:19,785 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: GrpcService started, listening on 9856
datanode1_1  | 2022-08-24 20:58:19,796 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: GrpcService started, listening on 9857
datanode1_1  | 2022-08-24 20:58:19,800 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: GrpcService started, listening on 9858
datanode1_1  | 2022-08-24 20:58:19,807 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2 is started using port 9858 for RATIS
datanode1_1  | 2022-08-24 20:58:19,808 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2 is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2022-08-24 20:58:19,808 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2 is started using port 9856 for RATIS_SERVER
datanode1_1  | 2022-08-24 20:58:19,812 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$392/0x00000008405e6840@5d32fa05] INFO util.JvmPauseMonitor: JvmPauseMonitor-8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: Started
datanode1_1  | 2022-08-24 20:58:19,866 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-08-24 20:58:19,866 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-08-24 20:58:31,087 [grpc-default-executor-0] INFO server.RaftServer: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: addNew group-C4A4D57205B6:[8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] returns group-C4A4D57205B6:java.util.concurrent.CompletableFuture@3c83aa0b[Not completed]
datanode1_1  | 2022-08-24 20:58:31,126 [pool-23-thread-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: new RaftServerImpl for group-C4A4D57205B6:[8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-08-24 20:58:31,150 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-08-24 20:58:31,168 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-08-24 20:58:31,168 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-08-24 20:58:31,168 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-08-24 20:58:31,168 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-08-24 20:58:31,168 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-08-24 20:58:31,214 [pool-23-thread-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6: ConfigurationManager, init=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-08-24 20:58:31,214 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-08-24 20:58:31,227 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-08-24 20:58:31,228 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-08-24 20:58:31,239 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6 does not exist. Creating ...
datanode1_1  | 2022-08-24 20:58:31,270 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6/in_use.lock acquired by nodename 7@527bfc57601e
datanode1_1  | 2022-08-24 20:58:31,288 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6 has been successfully formatted.
datanode1_1  | 2022-08-24 20:58:31,343 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-C4A4D57205B6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-08-24 20:58:31,369 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-08-24 20:58:31,371 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-08-24 20:58:31,450 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-08-24 20:58:31,450 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-08-24 20:58:31,451 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-08-24 20:58:31,487 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-24 20:58:31,532 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-08-24 20:58:31,532 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-08-24 20:58:31,577 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6
datanode1_1  | 2022-08-24 20:58:31,577 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-08-24 20:58:31,599 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-08-24 20:58:31,600 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-24 20:58:31,600 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-08-24 20:58:31,600 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-08-24 20:58:31,601 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-08-24 20:58:31,601 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-08-24 20:58:31,606 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-08-24 20:58:31,635 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-08-24 20:58:31,635 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-08-24 20:58:31,635 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-08-24 20:58:31,695 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-24 20:58:31,695 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-24 20:58:13,287 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-08-24 20:58:13,288 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-08-24 20:58:13,292 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-08-24 20:58:13,939 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode2_1  | 2022-08-24 20:58:14,985 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-08-24 20:58:14,998 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-08-24 20:58:15,365 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2022-08-24 20:58:15,365 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2022-08-24 20:58:15,365 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2022-08-24 20:58:15,515 [main] INFO util.log: Logging initialized @48078ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2022-08-24 20:58:16,095 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2022-08-24 20:58:16,121 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2022-08-24 20:58:16,130 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2022-08-24 20:58:16,130 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2022-08-24 20:58:16,130 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2022-08-24 20:58:16,145 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2022-08-24 20:58:16,366 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2022-08-24 20:58:16,369 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode2_1  | 2022-08-24 20:58:16,614 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2022-08-24 20:58:16,614 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2022-08-24 20:58:16,624 [main] INFO server.session: node0 Scavenging every 600000ms
datanode2_1  | 2022-08-24 20:58:16,974 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-08-24 20:58:16,985 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3c48bbf3{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2022-08-24 20:58:16,994 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@65f8933b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2022-08-24 20:58:17,804 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-08-24 20:58:17,908 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2fedfff1{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-8278154911044981037/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2022-08-24 20:58:17,999 [main] INFO server.AbstractConnector: Started ServerConnector@349504d5{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2022-08-24 20:58:18,010 [main] INFO server.Server: Started @50573ms
datanode2_1  | 2022-08-24 20:58:18,027 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
kdc_1        | Aug 24 20:56:10 kdc krb5kdc[9](info): Loaded
kdc_1        | Aug 24 20:56:10 kdc krb5kdc[9](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
datanode3_1  | 2022-08-24 20:58:12,595 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode3_1  | 2022-08-24 20:58:12,596 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode3_1  | 2022-08-24 20:58:12,596 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-08-24 20:58:12,596 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-08-24 20:58:18,027 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
kdc_1        | Aug 24 20:56:10 kdc krb5kdc[9](info): setting up network...
kdc_1        | Aug 24 20:56:10 kdc krb5kdc[9](info): setsockopt(8,IPV6_V6ONLY,1) worked
datanode1_1  | 2022-08-24 20:58:31,714 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-08-24 20:58:31,714 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-08-24 20:58:31,715 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-08-24 20:58:12,611 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-08-24 20:58:13,090 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode3_1  | 2022-08-24 20:58:13,869 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-08-24 20:58:13,882 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-08-24 20:58:14,214 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2022-08-24 20:58:14,214 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2022-08-24 20:58:14,214 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2022-08-24 20:58:14,365 [main] INFO util.log: Logging initialized @46639ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2022-08-24 20:58:15,003 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2022-08-24 20:58:15,048 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2022-08-24 20:58:15,051 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2022-08-24 20:58:15,051 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2022-08-24 20:58:15,051 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2022-08-24 20:58:15,073 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2022-08-24 20:58:18,035 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2022-08-24 20:58:18,077 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode2_1  | 2022-08-24 20:58:18,263 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6076fc2b] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2022-08-24 20:58:18,648 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2022-08-24 20:58:18,707 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode2_1  | 2022-08-24 20:58:21,383 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe/DS-185ef141-3f9b-474d-ab56-95b24aa08b54/container.db for volume DS-185ef141-3f9b-474d-ab56-95b24aa08b54
datanode2_1  | 2022-08-24 20:58:21,456 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe/DS-185ef141-3f9b-474d-ab56-95b24aa08b54/container.db for volume DS-185ef141-3f9b-474d-ab56-95b24aa08b54
datanode2_1  | 2022-08-24 20:58:21,460 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
kdc_1        | Aug 24 20:56:10 kdc krb5kdc[9](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Aug 24 20:56:10 kdc krb5kdc[9](info): set up 4 sockets
kdc_1        | Aug 24 20:56:10 kdc krb5kdc[9](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Aug 24 20:56:12 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374572, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:56:17 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374577, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:56:21 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.114: ISSUE: authtime 1661374581, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:56:24 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.115: ISSUE: authtime 1661374584, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:56:35 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1661374595, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:56:41 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1661374601, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:56:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1661374584, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:56:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1661374595, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:56:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374577, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:56:54 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374614, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode2_1  | 2022-08-24 20:58:21,466 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2022-08-24 20:58:21,797 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 55f25964-0507-4416-bd5f-134f8268daba
datanode2_1  | 2022-08-24 20:58:21,949 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: 55f25964-0507-4416-bd5f-134f8268daba: start RPC server
datanode2_1  | 2022-08-24 20:58:21,966 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 55f25964-0507-4416-bd5f-134f8268daba: GrpcService started, listening on 9856
datanode2_1  | 2022-08-24 20:58:21,968 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 55f25964-0507-4416-bd5f-134f8268daba: GrpcService started, listening on 9857
datanode2_1  | 2022-08-24 20:58:21,975 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 55f25964-0507-4416-bd5f-134f8268daba: GrpcService started, listening on 9858
datanode3_1  | 2022-08-24 20:58:15,311 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2022-08-24 20:58:15,326 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode3_1  | 2022-08-24 20:58:15,528 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2022-08-24 20:58:15,528 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2022-08-24 20:58:15,529 [main] INFO server.session: node0 Scavenging every 660000ms
datanode3_1  | 2022-08-24 20:58:15,695 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-08-24 20:58:15,721 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1912ba29{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2022-08-24 20:58:15,724 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@13198b8e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2022-08-24 20:58:16,167 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-08-24 20:58:16,237 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@45dbbb97{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-5549054497979789158/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2022-08-24 20:58:21,988 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 55f25964-0507-4416-bd5f-134f8268daba is started using port 9858 for RATIS
datanode2_1  | 2022-08-24 20:58:21,988 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 55f25964-0507-4416-bd5f-134f8268daba is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2022-08-24 20:58:21,996 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 55f25964-0507-4416-bd5f-134f8268daba is started using port 9856 for RATIS_SERVER
datanode2_1  | 2022-08-24 20:58:21,997 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$393/0x00000008405d8840@3d20f98e] INFO util.JvmPauseMonitor: JvmPauseMonitor-55f25964-0507-4416-bd5f-134f8268daba: Started
datanode2_1  | 2022-08-24 20:58:22,090 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-08-24 20:58:22,092 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-08-24 20:58:25,457 [Command processor thread] INFO server.RaftServer: 55f25964-0507-4416-bd5f-134f8268daba: addNew group-2337C26F5C0C:[55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-2337C26F5C0C:java.util.concurrent.CompletableFuture@6d356bfe[Not completed]
datanode2_1  | 2022-08-24 20:58:25,563 [pool-23-thread-1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba: new RaftServerImpl for group-2337C26F5C0C:[55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-08-24 20:58:25,583 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-08-24 20:58:25,584 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-08-24 20:58:25,598 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-08-24 20:58:25,598 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-08-24 20:58:25,601 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-08-24 20:58:25,601 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-08-24 20:58:25,633 [pool-23-thread-1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C: ConfigurationManager, init=-1: [55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-08-24 20:58:25,634 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-08-24 20:58:25,658 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-08-24 20:58:25,659 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-08-24 20:58:25,660 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/e5375211-a7a5-4dcb-a220-2337c26f5c0c does not exist. Creating ...
datanode2_1  | 2022-08-24 20:58:25,698 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/e5375211-a7a5-4dcb-a220-2337c26f5c0c/in_use.lock acquired by nodename 6@7541e863c794
datanode2_1  | 2022-08-24 20:58:25,726 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/e5375211-a7a5-4dcb-a220-2337c26f5c0c has been successfully formatted.
kdc_1        | Aug 24 20:57:01 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1661374621, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:57:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374614, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:57:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374628, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:57:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1661374621, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:57:14 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1661374634, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:57:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1661374634, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:57:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374628, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode3_1  | 2022-08-24 20:58:16,290 [main] INFO server.AbstractConnector: Started ServerConnector@297bbd41{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2022-08-24 20:58:16,290 [main] INFO server.Server: Started @48564ms
datanode3_1  | 2022-08-24 20:58:16,296 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2022-08-24 20:58:16,296 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2022-08-24 20:58:16,299 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2022-08-24 20:58:31,715 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-08-24 20:58:31,716 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-08-24 20:58:31,717 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-08-24 20:58:31,942 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-08-24 20:58:31,955 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-08-24 20:58:31,956 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-08-24 20:58:31,958 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-08-24 20:58:31,959 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-08-24 20:58:31,962 [pool-23-thread-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6: start as a follower, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-24 20:58:31,968 [pool-23-thread-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-08-24 20:58:31,972 [pool-23-thread-1] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6-FollowerState
datanode1_1  | 2022-08-24 20:58:31,990 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C4A4D57205B6,id=8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
datanode1_1  | 2022-08-24 20:58:33,214 [grpc-default-executor-0] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6: receive requestVote(ELECTION, 55f25964-0507-4416-bd5f-134f8268daba, group-C4A4D57205B6, 1, (t:0, i:0))
datanode1_1  | 2022-08-24 20:58:33,247 [grpc-default-executor-0] INFO impl.VoteContext: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6-FOLLOWER: accept ELECTION from 55f25964-0507-4416-bd5f-134f8268daba: our priority 0 <= candidate's priority 1
datanode1_1  | 2022-08-24 20:58:33,248 [grpc-default-executor-0] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:55f25964-0507-4416-bd5f-134f8268daba
datanode1_1  | 2022-08-24 20:58:33,248 [grpc-default-executor-0] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: shutdown 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6-FollowerState
datanode1_1  | 2022-08-24 20:58:33,249 [grpc-default-executor-0] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6-FollowerState
datanode1_1  | 2022-08-24 20:58:33,249 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6-FollowerState] INFO impl.FollowerState: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6-FollowerState was interrupted
datanode1_1  | 2022-08-24 20:58:33,257 [grpc-default-executor-0] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6 replies to ELECTION vote request: 55f25964-0507-4416-bd5f-134f8268daba<-8a3aa5b1-7501-4e35-bc9c-199b5d065ff2#0:OK-t1. Peer's state: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6:t1, leader=null, voted=55f25964-0507-4416-bd5f-134f8268daba, raftlog=8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-24 20:58:33,787 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C4A4D57205B6 with new leaderId: 55f25964-0507-4416-bd5f-134f8268daba
datanode1_1  | 2022-08-24 20:58:33,788 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2-server-thread1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6: change Leader from null to 55f25964-0507-4416-bd5f-134f8268daba at term 1 for appendEntries, leader elected after 2419ms
datanode1_1  | 2022-08-24 20:58:33,907 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2-server-thread1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6: set configuration 0: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-24 20:58:33,957 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2-server-thread1] INFO segmented.SegmentedRaftLogWorker: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-08-24 20:58:34,481 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-C4A4D57205B6-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6/current/log_inprogress_0
datanode1_1  | 2022-08-24 20:58:38,174 [grpc-default-executor-0] INFO server.RaftServer: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: addNew group-069052B7AC42:[8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] returns group-069052B7AC42:java.util.concurrent.CompletableFuture@63eccc59[Not completed]
datanode1_1  | 2022-08-24 20:58:38,176 [pool-23-thread-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: new RaftServerImpl for group-069052B7AC42:[8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-08-24 20:58:38,180 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-08-24 20:58:38,182 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-08-24 20:58:38,182 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-08-24 20:58:38,182 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-08-24 20:58:38,182 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-08-24 20:58:38,183 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-08-24 20:58:38,183 [pool-23-thread-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: ConfigurationManager, init=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-08-24 20:58:38,183 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-08-24 20:58:38,183 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-08-24 20:58:38,183 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-08-24 20:58:38,184 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42 does not exist. Creating ...
datanode1_1  | 2022-08-24 20:58:38,191 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42/in_use.lock acquired by nodename 7@527bfc57601e
datanode1_1  | 2022-08-24 20:58:38,196 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42 has been successfully formatted.
datanode1_1  | 2022-08-24 20:58:38,199 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-069052B7AC42: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-08-24 20:58:38,201 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-08-24 20:58:38,204 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-08-24 20:58:38,211 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-08-24 20:58:38,211 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-08-24 20:58:38,213 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-08-24 20:58:38,213 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-24 20:58:38,214 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-08-24 20:58:38,220 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-08-24 20:58:38,220 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42
datanode1_1  | 2022-08-24 20:58:38,220 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-08-24 20:58:38,220 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-08-24 20:58:38,220 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-24 20:58:25,753 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-2337C26F5C0C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-08-24 20:58:25,754 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-08-24 20:58:25,826 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-08-24 20:58:25,879 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-08-24 20:58:25,887 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-24 20:58:25,888 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-08-24 20:58:26,121 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-24 20:58:26,183 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-08-24 20:58:26,198 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-08-24 20:58:26,224 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/e5375211-a7a5-4dcb-a220-2337c26f5c0c
datanode2_1  | 2022-08-24 20:58:26,240 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-08-24 20:58:26,241 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-08-24 20:58:26,250 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-24 20:58:26,250 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-08-24 20:58:26,251 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-08-24 20:58:26,252 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-08-24 20:58:26,265 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-08-24 20:58:26,267 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
kdc_1        | Aug 24 20:57:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374640, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode3_1  | 2022-08-24 20:58:16,340 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode3_1  | 2022-08-24 20:58:16,471 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a03ead7] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2022-08-24 20:58:17,178 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2022-08-24 20:58:17,539 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
kdc_1        | Aug 24 20:57:20 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1661374640, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:57:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374640, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:57:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1661374640, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:57:30 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374650, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:57:43 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1661374663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:57:43 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1661374663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:57:43 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1661374663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:57:46 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1661374666, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:57:47 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1661374667, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:57:47 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1661374667, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:57:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1661374666, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:57:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1661374667, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:57:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1661374667, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:57:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1661374663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:57:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1661374663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:57:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1661374663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:57:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374650, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:58:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374684, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode3_1  | 2022-08-24 20:58:19,832 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe/DS-f4c13615-763b-40dd-8ed5-f443e7fb9395/container.db for volume DS-f4c13615-763b-40dd-8ed5-f443e7fb9395
datanode3_1  | 2022-08-24 20:58:19,838 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe/DS-f4c13615-763b-40dd-8ed5-f443e7fb9395/container.db for volume DS-f4c13615-763b-40dd-8ed5-f443e7fb9395
datanode3_1  | 2022-08-24 20:58:19,853 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2022-08-24 20:58:19,861 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2022-08-24 20:58:20,000 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 635159ec-b87e-4c18-a398-f9f404aae830
datanode3_1  | 2022-08-24 20:58:20,095 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.RaftServer: 635159ec-b87e-4c18-a398-f9f404aae830: start RPC server
datanode3_1  | 2022-08-24 20:58:20,105 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 635159ec-b87e-4c18-a398-f9f404aae830: GrpcService started, listening on 9856
datanode3_1  | 2022-08-24 20:58:20,110 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 635159ec-b87e-4c18-a398-f9f404aae830: GrpcService started, listening on 9857
datanode3_1  | 2022-08-24 20:58:20,111 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 635159ec-b87e-4c18-a398-f9f404aae830: GrpcService started, listening on 9858
datanode3_1  | 2022-08-24 20:58:20,131 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 635159ec-b87e-4c18-a398-f9f404aae830 is started using port 9858 for RATIS
datanode3_1  | 2022-08-24 20:58:20,131 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 635159ec-b87e-4c18-a398-f9f404aae830 is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2022-08-24 20:58:20,133 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 635159ec-b87e-4c18-a398-f9f404aae830 is started using port 9856 for RATIS_SERVER
datanode3_1  | 2022-08-24 20:58:20,134 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$392/0x00000008405e6840@1bab559d] INFO util.JvmPauseMonitor: JvmPauseMonitor-635159ec-b87e-4c18-a398-f9f404aae830: Started
datanode3_1  | 2022-08-24 20:58:20,185 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-08-24 20:58:20,186 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-08-24 20:58:35,045 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: 635159ec-b87e-4c18-a398-f9f404aae830: Failed requestVote 55f25964-0507-4416-bd5f-134f8268daba->635159ec-b87e-4c18-a398-f9f404aae830#0
datanode3_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 635159ec-b87e-4c18-a398-f9f404aae830: group-C4A4D57205B6 not found.
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:148)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:347)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:356)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:351)
datanode3_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:603)
datanode3_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode3_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:382)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:340)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:866)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode3_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | Sleeping for 5 seconds
kdc_1        | Aug 24 20:58:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1661374663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Aug 24 20:58:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1661374663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
datanode1_1  | 2022-08-24 20:58:38,220 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-08-24 20:58:38,220 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | 2022-08-24 20:58:26,314 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-08-24 20:58:26,329 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-08-24 20:58:26,329 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-08-24 20:58:26,379 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-24 20:58:26,379 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-24 20:58:26,404 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-08-24 20:58:26,419 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-08-24 20:58:26,420 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-08-24 20:58:26,438 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode3_1  | 2022-08-24 20:58:35,207 [grpc-default-executor-0] INFO server.RaftServer: 635159ec-b87e-4c18-a398-f9f404aae830: addNew group-C4A4D57205B6:[8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] returns group-C4A4D57205B6:java.util.concurrent.CompletableFuture@27679593[Not completed]
datanode3_1  | 2022-08-24 20:58:35,265 [pool-23-thread-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830: new RaftServerImpl for group-C4A4D57205B6:[8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-08-24 20:58:35,279 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-08-24 20:58:35,296 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-08-24 20:58:35,297 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-08-24 20:58:26,443 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-08-24 20:58:26,446 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-08-24 20:58:26,751 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-24 20:58:26,777 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-08-24 20:58:26,777 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-08-24 20:58:26,777 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-08-24 20:58:26,778 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-08-24 20:58:26,779 [pool-23-thread-1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C: start as a follower, conf=-1: [55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-08-24 20:58:26,796 [pool-23-thread-1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-08-24 20:58:26,798 [pool-23-thread-1] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-FollowerState
datanode1_1  | 2022-08-24 20:58:38,220 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-08-24 20:58:38,221 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-08-24 20:58:38,221 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-08-24 20:58:38,224 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-08-24 20:58:38,229 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-08-24 20:58:38,229 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-08-24 20:58:38,231 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-24 20:58:38,232 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-24 20:58:38,272 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-08-24 20:58:38,278 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-08-24 20:58:38,278 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-08-24 20:58:38,279 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-08-24 20:58:38,279 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-08-24 20:58:38,279 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-08-24 20:58:35,297 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-08-24 20:58:35,297 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-08-24 20:58:35,297 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-08-24 20:58:35,339 [pool-23-thread-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-C4A4D57205B6: ConfigurationManager, init=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-08-24 20:58:35,349 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-08-24 20:58:35,365 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2022-08-24 20:56:19,614 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
recon_1      | STARTUP_MSG:   java = 11.0.14.1
datanode2_1  | 2022-08-24 20:58:26,813 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2337C26F5C0C,id=55f25964-0507-4416-bd5f-134f8268daba
datanode2_1  | 2022-08-24 20:58:26,889 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=e5375211-a7a5-4dcb-a220-2337c26f5c0c
datanode2_1  | 2022-08-24 20:58:26,890 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=e5375211-a7a5-4dcb-a220-2337c26f5c0c.
datanode2_1  | 2022-08-24 20:58:26,891 [Command processor thread] INFO server.RaftServer: 55f25964-0507-4416-bd5f-134f8268daba: addNew group-C4A4D57205B6:[8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] returns group-C4A4D57205B6:java.util.concurrent.CompletableFuture@23b60dfd[Not completed]
datanode2_1  | 2022-08-24 20:58:26,894 [pool-23-thread-1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba: new RaftServerImpl for group-C4A4D57205B6:[8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-08-24 20:58:26,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-08-24 20:58:26,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-08-24 20:58:26,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-08-24 20:58:26,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-08-24 20:58:26,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-08-24 20:58:26,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-08-24 20:58:38,284 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-08-24 20:58:38,305 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-08-24 20:58:38,306 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-08-24 20:58:38,309 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-08-24 20:58:38,315 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-08-24 20:58:38,315 [pool-23-thread-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: start as a follower, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-24 20:58:38,316 [pool-23-thread-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-08-24 20:58:35,365 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-08-24 20:58:35,375 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6 does not exist. Creating ...
datanode3_1  | 2022-08-24 20:58:35,411 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6/in_use.lock acquired by nodename 9@84533d7fcdfb
datanode3_1  | 2022-08-24 20:58:35,480 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6 has been successfully formatted.
datanode3_1  | 2022-08-24 20:58:35,599 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-C4A4D57205B6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-08-24 20:58:35,610 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-08-24 20:58:35,612 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-08-24 20:58:35,776 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-08-24 20:58:35,776 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-24 20:58:35,777 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-08-24 20:58:38,316 [pool-23-thread-1] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState
datanode1_1  | 2022-08-24 20:58:38,317 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-069052B7AC42,id=8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
datanode1_1  | 2022-08-24 20:58:41,866 [grpc-default-executor-0] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: receive requestVote(ELECTION, 55f25964-0507-4416-bd5f-134f8268daba, group-069052B7AC42, 1, (t:0, i:0))
datanode1_1  | 2022-08-24 20:58:41,867 [grpc-default-executor-0] INFO impl.VoteContext: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FOLLOWER: reject ELECTION from 55f25964-0507-4416-bd5f-134f8268daba: our priority 1 > candidate's priority 0
datanode1_1  | 2022-08-24 20:58:41,867 [grpc-default-executor-0] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:55f25964-0507-4416-bd5f-134f8268daba
datanode1_1  | 2022-08-24 20:58:41,867 [grpc-default-executor-0] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: shutdown 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState
datanode1_1  | 2022-08-24 20:58:41,867 [grpc-default-executor-0] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState
datanode1_1  | 2022-08-24 20:58:41,868 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState was interrupted
datanode1_1  | 2022-08-24 20:58:41,872 [grpc-default-executor-0] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42 replies to ELECTION vote request: 55f25964-0507-4416-bd5f-134f8268daba<-8a3aa5b1-7501-4e35-bc9c-199b5d065ff2#0:FAIL-t1. Peer's state: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42:t1, leader=null, voted=null, raftlog=8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-24 20:58:46,981 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5113803830ns, electionTimeout:5112ms
datanode1_1  | 2022-08-24 20:58:46,982 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: shutdown 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState
datanode1_1  | 2022-08-24 20:58:46,982 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode1_1  | 2022-08-24 20:58:46,984 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-08-24 20:58:46,984 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection1
datanode1_1  | 2022-08-24 20:58:46,996 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection1] INFO impl.LeaderElection: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for -1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-24 20:58:46,999 [grpc-default-executor-0] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: receive requestVote(ELECTION, 55f25964-0507-4416-bd5f-134f8268daba, group-069052B7AC42, 2, (t:0, i:0))
datanode1_1  | 2022-08-24 20:58:46,999 [grpc-default-executor-0] INFO impl.VoteContext: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-CANDIDATE: reject ELECTION from 55f25964-0507-4416-bd5f-134f8268daba: already has voted for 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2 at current term 2
datanode1_1  | 2022-08-24 20:58:46,999 [grpc-default-executor-0] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42 replies to ELECTION vote request: 55f25964-0507-4416-bd5f-134f8268daba<-8a3aa5b1-7501-4e35-bc9c-199b5d065ff2#0:FAIL-t2. Peer's state: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42:t2, leader=null, voted=8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, raftlog=8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-08-24 20:57:37,965 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-08-24 20:57:38,033 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | Sleeping for 5 seconds
om3_1        | 2022-08-24 20:57:44,251 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-08-24 20:57:46,286 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-08-24 20:57:46,713 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-08-24 20:57:46,713 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-08-24 20:57:46,722 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-08-24 20:57:48,033 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-08-24 20:57:48,042 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-08-24 20:57:48,089 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
kdc_1        | Aug 24 20:58:20 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1661374663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Aug 24 20:58:21 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1661374701, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-08-24 20:57:37,738 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-08-24 20:57:37,824 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | ************************************************************/
recon_1      | 2022-08-24 20:56:19,659 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2022-08-24 20:58:26,910 [pool-23-thread-1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6: ConfigurationManager, init=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-08-24 20:58:26,911 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-08-24 20:58:26,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-08-24 20:58:26,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-08-24 20:58:26,912 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6 does not exist. Creating ...
datanode2_1  | 2022-08-24 20:58:26,915 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6/in_use.lock acquired by nodename 6@7541e863c794
datanode2_1  | 2022-08-24 20:58:26,926 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6 has been successfully formatted.
datanode2_1  | 2022-08-24 20:58:26,926 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-C4A4D57205B6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-08-24 20:58:26,926 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-08-24 20:58:26,926 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-08-24 20:58:26,927 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-08-24 20:58:26,927 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-24 20:58:26,927 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-08-24 20:58:26,929 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-24 20:58:26,929 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-08-24 20:58:26,929 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
kdc_1        | Aug 24 20:58:23 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1661374703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
recon_1      | 2022-08-24 20:56:21,678 [main] INFO reflections.Reflections: Reflections took 197 ms to scan 1 urls, producing 16 keys and 48 values 
recon_1      | 2022-08-24 20:56:23,884 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2022-08-24 20:56:23,991 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2022-08-24 20:56:24,431 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-08-24 20:57:43,679 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-08-24 20:57:45,428 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-08-24 20:57:45,861 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-08-24 20:57:45,861 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-08-24 20:57:45,861 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-08-24 20:57:47,136 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
kdc_1        | Aug 24 20:58:24 kdc krb5kdc[9](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1661374704, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:58:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1661374701, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:58:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1661374704, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:58:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1661374703, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode3_1  | 2022-08-24 20:58:35,823 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-24 20:58:35,944 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-08-24 20:58:35,965 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-08-24 20:58:36,006 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 635159ec-b87e-4c18-a398-f9f404aae830@group-C4A4D57205B6-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6
datanode3_1  | 2022-08-24 20:58:36,011 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-08-24 20:58:36,014 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
kdc_1        | Aug 24 20:58:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374684, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:58:37 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374717, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:58:50 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1661374584, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1      | 2022-08-24 20:56:24,432 [main] INFO recon.ReconServer: Recon login successful.
recon_1      | 2022-08-24 20:56:24,434 [main] INFO recon.ReconServer: Initializing secure Recon.
recon_1      | 2022-08-24 20:56:25,535 [main] ERROR client.ReconCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
recon_1      | 2022-08-24 20:56:25,552 [main] INFO client.ReconCertificateClient: Certificate client init case: 0
recon_1      | 2022-08-24 20:56:25,553 [main] INFO client.ReconCertificateClient: Creating keypair for client as keypair and certificate not found.
recon_1      | 2022-08-24 20:56:27,408 [main] INFO recon.ReconServer: Init response: GETCERT
recon_1      | 2022-08-24 20:56:27,447 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.115,host:recon
recon_1      | 2022-08-24 20:56:27,447 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
recon_1      | 2022-08-24 20:56:27,451 [main] ERROR client.ReconCertificateClient: Invalid domain recon
recon_1      | 2022-08-24 20:56:27,716 [main] INFO recon.ReconServer: Creating CSR for Recon.
recon_1      | 2022-08-24 20:56:30,542 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:56:32,544 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:56:34,546 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:56:36,548 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:56:38,549 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:56:40,550 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:56:42,552 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:56:44,553 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:56:46,932 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:4c4be219-e818-4409-b18c-c29dce22a660 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1      | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1      | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
recon_1      | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:56:48,933 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:56:50,935 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:56:53,675 [main] INFO recon.ReconServer: Successfully stored SCM signed certificate, case:GETCERT.
recon_1      | 2022-08-24 20:56:54,720 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-08-24 20:56:56,320 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
kdc_1        | Aug 24 20:58:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374717, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 24 20:58:54 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374734, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:58:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374734, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om1_1        | 2022-08-24 20:57:47,137 [main] INFO om.OzoneManager: Ozone Manager login successful.
datanode3_1  | 2022-08-24 20:58:36,015 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
kdc_1        | Aug 24 20:59:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
om1_1        | 2022-08-24 20:57:47,257 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode3_1  | 2022-08-24 20:58:36,021 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
kdc_1        | Aug 24 20:59:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
om1_1        | 2022-08-24 20:57:47,947 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-08-24 20:57:50,105 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2022-08-24 20:57:52,916 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2022-08-24 20:57:52,925 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2022-08-24 20:57:52,931 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2022-08-24 20:57:56,635 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2022-08-24 20:57:56,801 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2022-08-24 20:57:56,820 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2022-08-24 20:57:56,823 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2022-08-24 20:57:56,844 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-08-24 20:57:56,850 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-08-24 20:57:56,850 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-08-24 20:57:56,858 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-08-24 20:57:56,860 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:4c4be219-e818-4409-b18c-c29dce22a660,clusterId:CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe,subject:om1
om1_1        | 2022-08-24 20:57:57,636 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
datanode3_1  | 2022-08-24 20:58:36,021 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-08-24 20:58:36,029 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-08-24 20:58:36,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-08-24 20:58:36,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-08-24 20:58:36,061 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-08-24 20:58:36,070 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-08-24 20:58:36,071 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-08-24 20:58:36,097 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 635159ec-b87e-4c18-a398-f9f404aae830@group-C4A4D57205B6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-24 20:58:36,101 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 635159ec-b87e-4c18-a398-f9f404aae830@group-C4A4D57205B6-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-24 20:58:36,125 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-08-24 20:58:36,133 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-08-24 20:58:36,134 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-08-24 20:58:36,150 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-08-24 20:58:36,151 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-08-24 20:58:36,152 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-08-24 20:58:36,291 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-08-24 20:58:36,306 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-08-24 20:58:36,306 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-08-24 20:58:36,308 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-08-24 20:58:36,308 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-08-24 20:58:36,326 [pool-23-thread-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-C4A4D57205B6: start as a follower, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-24 20:58:36,327 [pool-23-thread-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-C4A4D57205B6: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-08-24 20:58:36,328 [pool-23-thread-1] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: start 635159ec-b87e-4c18-a398-f9f404aae830@group-C4A4D57205B6-FollowerState
datanode3_1  | 2022-08-24 20:58:36,348 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C4A4D57205B6,id=635159ec-b87e-4c18-a398-f9f404aae830
datanode3_1  | 2022-08-24 20:58:37,176 [635159ec-b87e-4c18-a398-f9f404aae830-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C4A4D57205B6 with new leaderId: 55f25964-0507-4416-bd5f-134f8268daba
datanode3_1  | 2022-08-24 20:58:37,177 [635159ec-b87e-4c18-a398-f9f404aae830-server-thread1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-C4A4D57205B6: change Leader from null to 55f25964-0507-4416-bd5f-134f8268daba at term 1 for appendEntries, leader elected after 1567ms
datanode3_1  | 2022-08-24 20:58:37,180 [635159ec-b87e-4c18-a398-f9f404aae830-server-thread1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-C4A4D57205B6: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode3_1  | 2022-08-24 20:58:37,236 [635159ec-b87e-4c18-a398-f9f404aae830-server-thread1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-C4A4D57205B6: inconsistency entries. Reply:55f25964-0507-4416-bd5f-134f8268daba<-635159ec-b87e-4c18-a398-f9f404aae830#4:FAIL-t0,INCONSISTENCY,nextIndex=0,followerCommit=-1
datanode3_1  | 2022-08-24 20:58:37,310 [635159ec-b87e-4c18-a398-f9f404aae830-server-thread1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-C4A4D57205B6: set configuration 0: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-24 20:58:37,454 [grpc-default-executor-1] INFO server.RaftServer: 635159ec-b87e-4c18-a398-f9f404aae830: addNew group-069052B7AC42:[8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] returns group-069052B7AC42:java.util.concurrent.CompletableFuture@1aa5dda0[Not completed]
datanode3_1  | 2022-08-24 20:58:37,467 [pool-23-thread-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830: new RaftServerImpl for group-069052B7AC42:[8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-08-24 20:58:37,471 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-08-24 20:58:37,471 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-08-24 20:58:37,472 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-08-24 20:58:37,472 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-08-24 20:58:37,472 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-08-24 20:58:37,474 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-08-24 20:58:37,475 [pool-23-thread-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: ConfigurationManager, init=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-08-24 20:58:48,487 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection1] INFO impl.LeaderElection: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode1_1  | 2022-08-24 20:58:48,498 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection1] INFO impl.LeaderElection:   Response 0: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2<-55f25964-0507-4416-bd5f-134f8268daba#0:FAIL-t2
datanode2_1  | 2022-08-24 20:58:26,930 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6
kdc_1        | Aug 24 20:59:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 20:59:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 20:59:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 20:59:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 20:59:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 20:59:25 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 20:59:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 20:59:34 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 20:59:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 20:59:48 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 20:59:53 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:00:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:00:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:00:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:00:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:00:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:00:16 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:00:30 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:00:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:00:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:00:43 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:00:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:00:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:00:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:01:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:01:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:01:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2022-08-24 20:58:26,930 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-08-24 20:58:48,500 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection1] INFO impl.LeaderElection:   Response 1: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2<-635159ec-b87e-4c18-a398-f9f404aae830#0:FAIL-t2
datanode1_1  | 2022-08-24 20:58:48,501 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection1] INFO impl.LeaderElection: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection1 ELECTION round 0: result REJECTED
datanode1_1  | 2022-08-24 20:58:48,502 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode1_1  | 2022-08-24 20:58:48,502 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection1] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: shutdown 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection1
datanode1_1  | 2022-08-24 20:58:48,503 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection1] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState
datanode1_1  | 2022-08-24 20:58:52,176 [grpc-default-executor-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: receive requestVote(ELECTION, 55f25964-0507-4416-bd5f-134f8268daba, group-069052B7AC42, 3, (t:0, i:0))
datanode1_1  | 2022-08-24 20:58:52,176 [grpc-default-executor-1] INFO impl.VoteContext: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FOLLOWER: reject ELECTION from 55f25964-0507-4416-bd5f-134f8268daba: our priority 1 > candidate's priority 0
datanode1_1  | 2022-08-24 20:58:52,177 [grpc-default-executor-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:55f25964-0507-4416-bd5f-134f8268daba
datanode1_1  | 2022-08-24 20:58:52,177 [grpc-default-executor-1] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: shutdown 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState
datanode1_1  | 2022-08-24 20:58:52,177 [grpc-default-executor-1] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState
datanode1_1  | 2022-08-24 20:58:52,177 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState was interrupted
datanode1_1  | 2022-08-24 20:58:52,187 [grpc-default-executor-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42 replies to ELECTION vote request: 55f25964-0507-4416-bd5f-134f8268daba<-8a3aa5b1-7501-4e35-bc9c-199b5d065ff2#0:FAIL-t3. Peer's state: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42:t3, leader=null, voted=null, raftlog=8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-24 20:58:53,187 [grpc-default-executor-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: receive requestVote(ELECTION, 635159ec-b87e-4c18-a398-f9f404aae830, group-069052B7AC42, 3, (t:0, i:0))
datanode1_1  | 2022-08-24 20:58:53,187 [grpc-default-executor-1] INFO impl.VoteContext: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FOLLOWER: reject ELECTION from 635159ec-b87e-4c18-a398-f9f404aae830: our priority 1 > candidate's priority 0
datanode1_1  | 2022-08-24 20:58:53,187 [grpc-default-executor-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:635159ec-b87e-4c18-a398-f9f404aae830
datanode1_1  | 2022-08-24 20:58:53,187 [grpc-default-executor-1] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: shutdown 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState
datanode1_1  | 2022-08-24 20:58:53,187 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState was interrupted
datanode1_1  | 2022-08-24 20:58:53,187 [grpc-default-executor-1] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState
datanode2_1  | 2022-08-24 20:58:26,930 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-08-24 20:58:26,930 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-24 20:58:26,930 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-08-24 20:58:26,930 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-08-24 20:58:26,930 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-08-24 20:58:26,930 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-08-24 20:58:26,930 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-08-24 20:58:26,934 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-08-24 20:58:26,978 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-08-24 20:58:26,978 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-08-24 20:58:26,979 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-24 20:58:27,004 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-24 20:58:27,026 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-08-24 20:58:27,026 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-08-24 20:58:27,026 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-08-24 20:58:27,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-08-24 20:58:27,032 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-08-24 20:58:27,032 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-08-24 20:58:27,033 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-24 20:58:27,033 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-08-24 20:58:27,034 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-08-24 20:58:27,035 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-08-24 20:58:27,035 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-08-24 20:58:27,036 [pool-23-thread-1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6: start as a follower, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2022-08-24 20:58:27,036 [pool-23-thread-1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-08-24 20:58:27,036 [pool-23-thread-1] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-FollowerState
datanode2_1  | 2022-08-24 20:58:27,036 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C4A4D57205B6,id=55f25964-0507-4416-bd5f-134f8268daba
datanode2_1  | 2022-08-24 20:58:27,082 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=0fca26ca-dda5-4802-a36e-c4a4d57205b6
datanode2_1  | 2022-08-24 20:58:31,883 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-FollowerState] INFO impl.FollowerState: 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5085321419ns, electionTimeout:5070ms
datanode2_1  | 2022-08-24 20:58:31,883 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-FollowerState] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: shutdown 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-FollowerState
datanode2_1  | 2022-08-24 20:58:31,883 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-FollowerState] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-08-24 20:58:31,886 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-24 20:58:31,887 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-FollowerState] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1
datanode2_1  | 2022-08-24 20:58:31,903 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-08-24 20:58:31,905 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2022-08-24 20:58:31,909 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: shutdown 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1
datanode2_1  | 2022-08-24 20:58:31,911 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-08-24 20:58:31,914 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-2337C26F5C0C with new leaderId: 55f25964-0507-4416-bd5f-134f8268daba
datanode2_1  | 2022-08-24 20:58:31,915 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C: change Leader from null to 55f25964-0507-4416-bd5f-134f8268daba at term 1 for becomeLeader, leader elected after 6160ms
datanode2_1  | 2022-08-24 20:58:31,968 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-08-24 20:58:31,981 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-08-24 20:58:31,990 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-08-24 20:58:32,009 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-08-24 20:58:32,010 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-08-24 20:58:32,011 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-08-24 20:58:32,035 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-08-24 20:58:32,041 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-08-24 20:58:32,049 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderStateImpl
datanode2_1  | 2022-08-24 20:58:32,121 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2022-08-24 20:57:48,677 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-08-24 20:57:50,993 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2022-08-24 20:57:54,115 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2022-08-24 20:57:54,115 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2022-08-24 20:57:54,117 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2022-08-24 20:57:59,316 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2022-08-24 20:57:59,571 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2022-08-24 20:57:59,426 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe;layoutVersion=3
om1_1        | 2022-08-24 20:57:59,610 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-08-24 20:58:09,202 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-08-24 20:58:09,269 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-08-24 20:58:14,769 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-08-24 20:58:17,106 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-08-24 20:58:17,978 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-08-24 20:58:17,981 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-08-24 20:58:18,000 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-08-24 20:58:18,104 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-08-24 20:58:18,708 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om1_1        | 2022-08-24 20:58:20,228 [main] INFO reflections.Reflections: Reflections took 894 ms to scan 1 urls, producing 113 keys and 334 values [using 2 cores]
om1_1        | 2022-08-24 20:58:21,697 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-08-24 20:58:21,711 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-08-24 20:58:21,711 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-08-24 20:58:24,110 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-08-24 20:58:24,412 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-08-24 20:58:28,409 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2022-08-24 20:58:29,063 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/1256322444158.crt.
om1_1        | 2022-08-24 20:58:29,092 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2022-08-24 20:57:59,584 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2022-08-24 20:57:59,601 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2022-08-24 20:57:59,612 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-08-24 20:57:59,614 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-08-24 20:57:59,615 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-08-24 20:57:59,617 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-08-24 20:57:59,620 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:4c4be219-e818-4409-b18c-c29dce22a660,clusterId:CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe,subject:om3
om3_1        | 2022-08-24 20:58:00,662 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2022-08-24 20:58:02,153 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe;layoutVersion=3
om3_1        | 2022-08-24 20:58:02,338 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2022-08-24 20:56:22,184 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1        | 2022-08-24 20:56:22,184 [main] INFO s3.Gateway: S3Gateway login successful.
s3g_1        | 2022-08-24 20:56:22,463 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2022-08-24 20:56:22,464 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2022-08-24 20:56:22,464 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2022-08-24 20:56:22,560 [main] INFO util.log: Logging initialized @6155ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2022-08-24 20:56:23,068 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2022-08-24 20:56:23,103 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2022-08-24 20:56:23,105 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2022-08-24 20:56:23,105 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2022-08-24 20:56:23,105 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2022-08-24 20:56:23,108 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
datanode1_1  | 2022-08-24 20:58:53,202 [grpc-default-executor-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42 replies to ELECTION vote request: 635159ec-b87e-4c18-a398-f9f404aae830<-8a3aa5b1-7501-4e35-bc9c-199b5d065ff2#0:FAIL-t3. Peer's state: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42:t3, leader=null, voted=null, raftlog=8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-24 20:58:53,709 [pool-23-thread-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: new RaftServerImpl for group-71CDB3C1BBAB:[8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-08-24 20:58:53,713 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-08-24 20:58:53,714 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-08-24 20:58:53,714 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-08-24 20:58:53,714 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-08-24 20:58:53,714 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-08-24 20:58:53,714 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-08-24 20:58:53,715 [pool-23-thread-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB: ConfigurationManager, init=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-08-24 20:58:53,715 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-08-24 20:58:53,718 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
kdc_1        | Aug 24 21:01:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:01:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2022-08-24 20:56:57,065 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-08-24 20:56:57,093 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2022-08-24 20:56:57,106 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2022-08-24 20:56:59,098 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2022-08-24 20:56:59,098 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2022-08-24 20:56:59,098 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2022-08-24 20:56:59,130 [main] INFO util.log: Logging initialized @43617ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2022-08-24 20:56:59,473 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2022-08-24 20:56:59,514 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2022-08-24 20:56:59,515 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2022-08-24 20:56:59,516 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2022-08-24 20:56:59,516 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2022-08-24 20:56:59,519 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
kdc_1        | Aug 24 21:01:14 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:01:18 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:01:22 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:01:22 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374882, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:01:26 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374882, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:01:29 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374882, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:01:30 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374890, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:01:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374890, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:01:37 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374890, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:01:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374890, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:01:49 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374890, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:01:51 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374911, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:01:54 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374911, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:02:01 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374911, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:02:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:02:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:02:04 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374924, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:02:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374924, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:02:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374924, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:02:12 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374932, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:02:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374932, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:02:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374932, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:02:20 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374940, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:02:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374940, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:02:24 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374944, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:02:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374944, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:02:28 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374948, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1        | 2022-08-24 20:56:23,455 [main] INFO s3.Gateway: STARTUP_MSG: 
datanode1_1  | 2022-08-24 20:58:53,718 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-08-24 20:58:53,719 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/f0d2bb84-a865-4722-a590-71cdb3c1bbab does not exist. Creating ...
om3_1        | 2022-08-24 20:58:11,582 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-08-24 20:58:11,655 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-08-24 20:58:17,545 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-08-24 20:58:20,179 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.2.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
s3g_1        | STARTUP_MSG:   java = 11.0.14.1
s3g_1        | ************************************************************/
s3g_1        | 2022-08-24 20:56:23,474 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2022-08-24 20:56:23,563 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2022-08-24 20:56:23,927 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 2022-08-24 20:56:24,354 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 2022-08-24 20:56:24,354 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1        | 2022-08-24 20:56:24,445 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2022-08-24 20:56:24,455 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
s3g_1        | 2022-08-24 20:56:24,539 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2022-08-24 20:56:24,546 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2022-08-24 20:56:24,547 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1        | 2022-08-24 20:56:24,577 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2022-08-24 20:56:24,599 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@72f46e16{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2022-08-24 20:56:24,610 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2416a51{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2022-08-24 20:56:29,893 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Aug 24, 2022 8:56:31 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2022-08-24 20:56:31,675 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4eb1943b{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-13672196544398019834/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2022-08-24 20:56:31,713 [main] INFO server.AbstractConnector: Started ServerConnector@6691490c{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2022-08-24 20:56:31,713 [main] INFO server.Server: Started @15309ms
s3g_1        | 2022-08-24 20:56:31,726 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2022-08-24 20:56:31,726 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2022-08-24 20:56:31,727 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1        | 2022-08-24 21:04:32,249 [qtp864326906-22] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
s3g_1        | 2022-08-24 21:04:32,274 [qtp864326906-22] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
s3g_1        | 2022-08-24 21:04:32,294 [qtp864326906-22] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
s3g_1        | 2022-08-24 21:04:33,939 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8166617629, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:04:39,525 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4164878180, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:04:40,377 [qtp864326906-21] WARN impl.MetricsSystemImpl: S3Gateway metrics system already initialized!
s3g_1        | 2022-08-24 21:04:40,650 [qtp864326906-21] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 2022-08-24 21:04:54,011 [qtp864326906-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0970255710, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:04:54,513 [qtp864326906-23] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-ypmpvjoaev, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:01,905 [qtp864326906-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-dvkabsedjt, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:11,578 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3304228662, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:12,147 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6346790541, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:12,721 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-7884169516, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:13,323 [qtp864326906-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-7884169516, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:14,708 [qtp864326906-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4696656892, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:24,219 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5953658177, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:24,794 [qtp864326906-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0264810494, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:31,595 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8426919085, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:38,203 [qtp864326906-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9156506742, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | Aug 24, 2022 9:05:43 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
datanode1_1  | 2022-08-24 20:58:53,723 [Command processor thread] INFO server.RaftServer: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: addNew group-71CDB3C1BBAB:[8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-71CDB3C1BBAB:java.util.concurrent.CompletableFuture@5a66d4f9[Not completed]
datanode1_1  | 2022-08-24 20:58:53,728 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/f0d2bb84-a865-4722-a590-71cdb3c1bbab/in_use.lock acquired by nodename 7@527bfc57601e
datanode1_1  | 2022-08-24 20:58:53,744 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/f0d2bb84-a865-4722-a590-71cdb3c1bbab has been successfully formatted.
datanode3_1  | 2022-08-24 20:58:37,476 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-08-24 20:58:37,476 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-08-24 20:58:37,478 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-08-24 20:58:37,481 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42 does not exist. Creating ...
datanode3_1  | 2022-08-24 20:58:37,504 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42/in_use.lock acquired by nodename 9@84533d7fcdfb
datanode3_1  | 2022-08-24 20:58:37,521 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42 has been successfully formatted.
datanode3_1  | 2022-08-24 20:58:37,522 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-069052B7AC42: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-08-24 20:58:53,773 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-71CDB3C1BBAB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-08-24 20:58:53,776 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-08-24 20:58:53,778 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-08-24 20:58:53,779 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-08-24 20:58:53,782 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-24 20:58:37,528 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-08-24 20:58:37,528 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-08-24 20:58:37,528 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-08-24 20:58:37,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-24 20:58:37,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-08-24 20:58:37,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-24 20:58:37,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-08-24 20:58:37,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-08-24 20:58:53,830 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-08-24 20:58:53,831 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
recon_1      | 2022-08-24 20:56:59,699 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2022-08-24 20:57:00,224 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
om1_1        | 2022-08-24 20:58:29,115 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1170009537688.crt.
om1_1        | 2022-08-24 20:58:29,288 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-08-24 20:58:30,095 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-08-24 20:58:30,124 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-08-24 20:58:31,368 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om1_1        | 2022-08-24 20:58:31,420 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2022-08-24 20:58:31,420 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2022-08-24 20:58:31,888 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om1_1        | 2022-08-24 20:58:32,571 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-08-24 20:58:32,571 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2022-08-24 20:58:32,660 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2022-08-24 20:58:33,578 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2022-08-24 20:58:33,714 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-08-24 20:58:53,834 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-08-24 20:58:53,834 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-08-24 20:58:53,834 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/f0d2bb84-a865-4722-a590-71cdb3c1bbab
datanode1_1  | 2022-08-24 20:58:53,834 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-08-24 20:58:53,834 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-08-24 20:58:53,834 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-24 20:58:53,835 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-08-24 20:58:53,835 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-08-24 20:58:53,835 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-08-24 20:58:53,835 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-08-24 20:57:37,143 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-08-24 20:57:37,193 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-08-24 20:57:43,409 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-08-24 20:57:45,543 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-08-24 20:57:46,105 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-08-24 20:57:46,106 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-08-24 20:57:46,138 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-08-24 20:57:47,684 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-08-24 20:57:47,684 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-08-24 20:57:47,697 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-08-24 20:57:48,501 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-08-24 20:57:50,948 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2022-08-24 20:57:53,756 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2022-08-24 20:57:53,757 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2022-08-24 20:57:53,758 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2022-08-24 20:57:59,487 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2022-08-24 20:57:59,721 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2022-08-24 20:57:59,742 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2022-08-24 20:57:59,751 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2022-08-24 20:57:59,758 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
recon_1      | 2022-08-24 20:57:00,250 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2022-08-24 20:57:00,253 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTaskWithFSO with controller.
recon_1      | 2022-08-24 20:57:00,278 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2022-08-24 20:57:01,613 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-08-24 20:57:02,145 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-08-24 20:57:02,290 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2022-08-24 20:57:02,296 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2022-08-24 20:57:02,458 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-08-24 20:57:02,777 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
recon_1      | 2022-08-24 20:57:03,040 [main] INFO reflections.Reflections: Reflections took 248 ms to scan 3 urls, producing 110 keys and 247 values 
recon_1      | 2022-08-24 20:57:03,261 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2022-08-24 20:57:03,381 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2022-08-24 20:57:03,417 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2022-08-24 20:57:03,432 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2022-08-24 20:57:03,657 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1      | 2022-08-24 20:57:03,751 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2022-08-24 20:57:03,766 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2022-08-24 20:57:03,872 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 2022-08-24 20:57:04,104 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2022-08-24 20:57:04,104 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2022-08-24 20:57:04,281 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2022-08-24 20:57:04,342 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2022-08-24 20:57:04,342 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2022-08-24 20:57:04,974 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2022-08-24 20:57:04,981 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
recon_1      | 2022-08-24 20:57:05,129 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2022-08-24 20:57:05,129 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2022-08-24 20:57:05,131 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1      | 2022-08-24 20:57:05,165 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-08-24 20:57:05,169 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@589a82af{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2022-08-24 20:58:37,529 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42
datanode3_1  | 2022-08-24 20:58:37,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-08-24 20:58:37,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-08-24 20:58:37,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-24 20:58:37,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-08-24 20:58:37,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-08-24 20:58:37,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-08-24 20:58:37,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-08-24 20:58:32,141 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-FollowerState] INFO impl.FollowerState: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5105467975ns, electionTimeout:5097ms
datanode2_1  | 2022-08-24 20:58:32,178 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-FollowerState] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: shutdown 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-FollowerState
datanode2_1  | 2022-08-24 20:58:32,181 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-FollowerState] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
kdc_1        | Aug 24 21:02:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374948, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:02:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374948, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:02:40 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374948, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:02:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374948, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:02:47 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374948, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:02:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374948, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2022-08-24 20:58:32,181 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-24 20:58:32,186 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-FollowerState] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2
datanode2_1  | 2022-08-24 20:58:32,229 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2022-08-24 20:58:32,254 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-LeaderElection1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C: set configuration 0: [55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-08-24 20:58:33,230 [55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 55f25964-0507-4416-bd5f-134f8268daba@group-2337C26F5C0C-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/e5375211-a7a5-4dcb-a220-2337c26f5c0c/current/log_inprogress_0
datanode2_1  | 2022-08-24 20:58:33,309 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-08-24 20:58:33,310 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO impl.LeaderElection:   Response 0: 55f25964-0507-4416-bd5f-134f8268daba<-8a3aa5b1-7501-4e35-bc9c-199b5d065ff2#0:OK-t1
datanode2_1  | 2022-08-24 20:58:33,311 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2 ELECTION round 0: result PASSED
om3_1        | 2022-08-24 20:58:20,708 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-08-24 20:58:20,708 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
datanode1_1  | 2022-08-24 20:58:53,835 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-08-24 20:58:53,873 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-08-24 20:58:53,906 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-08-24 20:58:53,906 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-08-24 20:58:53,910 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-24 20:58:53,910 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-24 20:58:53,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-08-24 20:58:53,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-08-24 20:58:53,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-08-24 20:58:53,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-08-24 20:58:53,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-08-24 20:58:53,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-08-24 20:58:53,932 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-08-24 20:58:53,932 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-08-24 20:58:53,932 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-08-24 20:58:53,933 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-08-24 20:58:53,933 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-08-24 20:58:53,933 [pool-23-thread-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB: start as a follower, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-08-24 20:58:53,933 [pool-23-thread-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2022-08-24 20:58:20,719 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-08-24 20:58:20,813 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-08-24 20:58:21,201 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om3_1        | 2022-08-24 20:58:23,347 [main] INFO reflections.Reflections: Reflections took 1352 ms to scan 1 urls, producing 113 keys and 334 values [using 2 cores]
om3_1        | 2022-08-24 20:58:24,619 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-08-24 20:58:24,619 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-08-24 20:58:24,638 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-08-24 20:58:26,417 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-08-24 20:58:26,631 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-08-24 20:58:30,325 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2022-08-24 20:58:31,004 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2022-08-24 20:58:31,022 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1170009537688.crt.
om3_1        | 2022-08-24 20:58:31,040 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/1258968497864.crt.
om3_1        | 2022-08-24 20:58:31,245 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-08-24 20:58:32,036 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-08-24 20:58:32,042 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-08-24 20:58:34,192 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om3_1        | 2022-08-24 20:58:34,266 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2022-08-24 20:58:34,266 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2022-08-24 20:58:34,953 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om3_1        | 2022-08-24 20:58:35,448 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-08-24 20:58:35,473 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2022-08-24 20:58:35,562 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2022-08-24 20:58:36,157 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2022-08-24 20:58:36,225 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-08-24 20:58:36,367 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om3:9872, om1:9872, om2:9872
om3_1        | 2022-08-24 20:58:36,407 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2022-08-24 20:58:38,389 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2022-08-24 20:58:38,917 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2022-08-24 20:58:38,919 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-08-24 20:58:38,926 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2022-08-24 20:58:38,926 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-08-24 20:58:38,927 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-08-24 20:58:38,928 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2022-08-24 20:58:38,939 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-08-24 20:58:38,939 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2022-08-24 20:58:38,940 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2022-08-24 20:58:39,019 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om3_1        | 2022-08-24 20:58:39,027 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om3_1        | 2022-08-24 20:58:41,156 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2022-08-24 20:58:41,174 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om3_1        | 2022-08-24 20:58:41,178 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om3_1        | 2022-08-24 20:58:41,180 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-08-24 20:58:41,180 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-08-24 20:58:41,194 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-08-24 20:58:41,227 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@3d5e1b83[Not completed]
om3_1        | 2022-08-24 20:58:41,227 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2022-08-24 20:58:41,320 [pool-27-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om3_1        | 2022-08-24 20:58:41,340 [main] INFO om.OzoneManager: Creating RPC Server
om3_1        | 2022-08-24 20:58:41,353 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2022-08-24 20:58:41,354 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2022-08-24 20:58:41,355 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2022-08-24 20:58:41,355 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-08-24 20:58:41,355 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-08-24 20:58:41,359 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2022-08-24 20:58:41,371 [pool-27-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2022-08-24 20:58:41,385 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-08-24 20:58:41,388 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2022-08-24 20:58:41,409 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1        | 2022-08-24 20:58:41,411 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2022-08-24 20:58:41,536 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 9@om3
om3_1        | 2022-08-24 20:58:41,640 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2022-08-24 20:58:34,090 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om1:9872, om3:9872, om2:9872
om1_1        | 2022-08-24 20:58:34,175 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
datanode3_1  | 2022-08-24 20:58:37,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-08-24 20:58:37,547 [635159ec-b87e-4c18-a398-f9f404aae830-server-thread1] INFO segmented.SegmentedRaftLogWorker: 635159ec-b87e-4c18-a398-f9f404aae830@group-C4A4D57205B6-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-08-24 20:58:37,624 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-08-24 20:58:37,712 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-08-24 20:58:37,735 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-08-24 20:58:37,738 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-24 20:58:37,751 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-24 20:58:37,766 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-08-24 20:58:37,771 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-08-24 20:58:37,771 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
kdc_1        | Aug 24 21:02:52 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374972, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:02:55 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374972, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:02:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374972, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:03:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:03:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:03:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374972, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:03:07 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374972, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:03:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374988, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:03:08 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374988, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:03:11 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374988, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:03:12 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374992, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:03:12 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374992, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:03:15 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374992, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:03:16 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374996, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:03:16 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661374996, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:03:19 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374996, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:03:23 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661374996, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:03:24 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375004, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:03:27 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375004, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:03:31 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375004, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:03:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375004, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:03:39 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375004, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:03:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375019, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:03:42 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375019, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:03:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375019, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:03:52 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375019, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:03:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375035, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:03:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375035, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:04:02 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375035, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:04:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:04:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:04:06 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375035, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:04:07 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375047, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:04:10 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375047, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:04:14 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375047, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:04:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375047, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:04:26 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375066, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:04:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375066, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om1_1        | 2022-08-24 20:58:35,954 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2022-08-24 20:58:36,429 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2022-08-24 20:58:36,439 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
datanode2_1  | 2022-08-24 20:58:33,318 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: shutdown 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2
datanode2_1  | 2022-08-24 20:58:33,318 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-08-24 20:58:33,318 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C4A4D57205B6 with new leaderId: 55f25964-0507-4416-bd5f-134f8268daba
datanode2_1  | 2022-08-24 20:58:33,322 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6: change Leader from null to 55f25964-0507-4416-bd5f-134f8268daba at term 1 for becomeLeader, leader elected after 6391ms
datanode2_1  | 2022-08-24 20:58:33,324 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-08-24 20:58:33,325 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-08-24 20:58:33,326 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-08-24 20:58:33,356 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-08-24 20:58:33,367 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-08-24 20:58:33,372 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-08-24 20:58:33,378 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-08-24 20:58:33,378 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-08-24 20:58:33,466 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-08-24 20:58:33,467 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-24 20:58:33,467 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-08-24 20:58:33,501 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-08-24 20:58:33,520 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-08-24 20:58:33,520 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-24 20:58:33,522 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-08-24 20:58:33,523 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-24 20:58:33,524 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-08-24 20:58:33,524 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-08-24 20:58:33,524 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-08-24 20:58:33,524 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-24 20:58:33,540 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderStateImpl
datanode2_1  | 2022-08-24 20:58:33,583 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-08-24 20:58:33,592 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6/current/log_inprogress_0
datanode2_1  | 2022-08-24 20:58:33,647 [55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6-LeaderElection2] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6: set configuration 0: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
om1_1        | 2022-08-24 20:58:36,439 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2022-08-24 20:58:36,440 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-08-24 20:58:36,441 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-08-24 20:58:36,471 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2022-08-24 20:58:36,483 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-08-24 20:58:36,485 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2022-08-24 20:58:36,490 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode3_1  | 2022-08-24 20:58:37,772 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-08-24 20:58:37,774 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om1_1        | 2022-08-24 20:58:36,620 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om1_1        | 2022-08-24 20:58:36,621 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
recon_1      | 2022-08-24 20:57:05,170 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7a0eb939{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2022-08-24 20:57:05,775 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
datanode1_1  | 2022-08-24 20:58:53,933 [pool-23-thread-1] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-FollowerState
datanode1_1  | 2022-08-24 20:58:53,934 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-71CDB3C1BBAB,id=8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
datanode1_1  | 2022-08-24 20:58:53,976 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=f0d2bb84-a865-4722-a590-71cdb3c1bbab
datanode1_1  | 2022-08-24 20:58:53,977 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=f0d2bb84-a865-4722-a590-71cdb3c1bbab.
datanode1_1  | 2022-08-24 20:58:57,411 [grpc-default-executor-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: receive requestVote(ELECTION, 55f25964-0507-4416-bd5f-134f8268daba, group-069052B7AC42, 4, (t:0, i:0))
datanode1_1  | 2022-08-24 20:58:57,411 [grpc-default-executor-1] INFO impl.VoteContext: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FOLLOWER: reject ELECTION from 55f25964-0507-4416-bd5f-134f8268daba: our priority 1 > candidate's priority 0
datanode1_1  | 2022-08-24 20:58:57,411 [grpc-default-executor-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:55f25964-0507-4416-bd5f-134f8268daba
datanode1_1  | 2022-08-24 20:58:57,412 [grpc-default-executor-1] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: shutdown 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState
datanode1_1  | 2022-08-24 20:58:57,412 [grpc-default-executor-1] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState
datanode1_1  | 2022-08-24 20:58:57,412 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState was interrupted
datanode1_1  | 2022-08-24 20:58:57,430 [grpc-default-executor-1] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42 replies to ELECTION vote request: 55f25964-0507-4416-bd5f-134f8268daba<-8a3aa5b1-7501-4e35-bc9c-199b5d065ff2#0:FAIL-t4. Peer's state: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42:t4, leader=null, voted=null, raftlog=8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-24 20:58:37,774 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-08-24 20:58:37,776 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-08-24 20:58:37,780 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om1_1        | 2022-08-24 20:58:39,267 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2022-08-24 20:58:39,275 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om1_1        | 2022-08-24 20:58:39,280 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om1_1        | 2022-08-24 20:58:39,285 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-08-24 20:58:39,286 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-08-24 20:58:39,292 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-08-24 20:58:39,351 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@466d87a1[Not completed]
om1_1        | 2022-08-24 20:58:39,354 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2022-08-24 20:58:39,437 [pool-27-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2022-08-24 20:58:39,439 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2022-08-24 20:58:39,446 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2022-08-24 20:58:39,446 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2022-08-24 20:58:39,448 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-08-24 20:58:39,448 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-08-24 20:58:39,449 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2022-08-24 20:58:39,551 [main] INFO om.OzoneManager: Creating RPC Server
recon_1      | 2022-08-24 20:57:05,780 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-08-24 20:57:08,603 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5e8990ee{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-511467443322529528/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1      | 2022-08-24 20:57:08,612 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@77da2881{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1      | 2022-08-24 20:57:08,614 [Listener at 0.0.0.0/9891] INFO server.Server: Started @53100ms
recon_1      | 2022-08-24 20:57:08,622 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1      | 2022-08-24 20:57:08,622 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1      | 2022-08-24 20:57:08,623 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1      | 2022-08-24 20:57:08,623 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1      | 2022-08-24 20:57:08,634 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1      | 2022-08-24 20:57:08,648 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1      | 2022-08-24 20:57:08,650 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1      | 2022-08-24 20:57:08,650 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-08-24 20:57:08,666 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1      | 2022-08-24 20:57:08,667 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1      | 2022-08-24 20:57:09,161 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1      | 2022-08-24 20:57:09,161 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
om2_1        | 2022-08-24 20:57:59,774 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-08-24 20:57:59,774 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-08-24 20:57:59,780 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-08-24 20:57:59,782 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:4c4be219-e818-4409-b18c-c29dce22a660,clusterId:CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe,subject:om2
om2_1        | 2022-08-24 20:58:00,826 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2022-08-24 20:58:02,175 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe;layoutVersion=3
om2_1        | 2022-08-24 20:58:02,398 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-08-24 20:58:11,202 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-08-24 20:58:11,249 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-08-24 20:58:17,233 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-08-24 20:58:20,056 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-08-24 20:58:20,300 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-08-24 20:58:20,300 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-08-24 20:58:20,301 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
datanode3_1  | 2022-08-24 20:58:37,799 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-08-24 20:58:37,799 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-08-24 20:58:37,801 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-08-24 20:58:37,803 [pool-23-thread-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: start as a follower, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-24 20:58:37,804 [pool-23-thread-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-08-24 20:58:37,806 [pool-23-thread-1] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: start 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState
datanode3_1  | 2022-08-24 20:58:37,821 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-069052B7AC42,id=635159ec-b87e-4c18-a398-f9f404aae830
datanode3_1  | 2022-08-24 20:58:37,961 [635159ec-b87e-4c18-a398-f9f404aae830@group-C4A4D57205B6-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 635159ec-b87e-4c18-a398-f9f404aae830@group-C4A4D57205B6-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0fca26ca-dda5-4802-a36e-c4a4d57205b6/current/log_inprogress_0
datanode3_1  | 2022-08-24 20:58:41,861 [grpc-default-executor-0] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: receive requestVote(ELECTION, 55f25964-0507-4416-bd5f-134f8268daba, group-069052B7AC42, 1, (t:0, i:0))
datanode3_1  | 2022-08-24 20:58:41,863 [grpc-default-executor-0] INFO impl.VoteContext: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FOLLOWER: accept ELECTION from 55f25964-0507-4416-bd5f-134f8268daba: our priority 0 <= candidate's priority 0
datanode3_1  | 2022-08-24 20:58:41,863 [grpc-default-executor-0] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:55f25964-0507-4416-bd5f-134f8268daba
datanode3_1  | 2022-08-24 20:58:41,864 [grpc-default-executor-0] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: shutdown 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState
datanode3_1  | 2022-08-24 20:58:41,864 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState was interrupted
datanode3_1  | 2022-08-24 20:58:41,869 [grpc-default-executor-0] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: start 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState
datanode3_1  | 2022-08-24 20:58:41,879 [grpc-default-executor-0] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42 replies to ELECTION vote request: 55f25964-0507-4416-bd5f-134f8268daba<-635159ec-b87e-4c18-a398-f9f404aae830#0:OK-t1. Peer's state: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42:t1, leader=null, voted=55f25964-0507-4416-bd5f-134f8268daba, raftlog=635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-24 20:58:46,954 [grpc-default-executor-0] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: receive requestVote(ELECTION, 55f25964-0507-4416-bd5f-134f8268daba, group-069052B7AC42, 2, (t:0, i:0))
datanode3_1  | 2022-08-24 20:58:46,954 [grpc-default-executor-0] INFO impl.VoteContext: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FOLLOWER: accept ELECTION from 55f25964-0507-4416-bd5f-134f8268daba: our priority 0 <= candidate's priority 0
datanode3_1  | 2022-08-24 20:58:46,955 [grpc-default-executor-0] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:55f25964-0507-4416-bd5f-134f8268daba
datanode3_1  | 2022-08-24 20:58:46,955 [grpc-default-executor-0] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: shutdown 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState
datanode3_1  | 2022-08-24 20:58:46,955 [grpc-default-executor-0] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: start 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState
datanode3_1  | 2022-08-24 20:58:46,955 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState was interrupted
datanode3_1  | 2022-08-24 20:58:46,957 [grpc-default-executor-0] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42 replies to ELECTION vote request: 55f25964-0507-4416-bd5f-134f8268daba<-635159ec-b87e-4c18-a398-f9f404aae830#0:OK-t2. Peer's state: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42:t2, leader=null, voted=55f25964-0507-4416-bd5f-134f8268daba, raftlog=635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-24 20:58:48,394 [grpc-default-executor-0] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: receive requestVote(ELECTION, 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, group-069052B7AC42, 2, (t:0, i:0))
datanode3_1  | 2022-08-24 20:58:48,394 [grpc-default-executor-0] INFO impl.VoteContext: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FOLLOWER: reject ELECTION from 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: already has voted for 55f25964-0507-4416-bd5f-134f8268daba at current term 2
datanode3_1  | 2022-08-24 20:58:48,395 [grpc-default-executor-0] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42 replies to ELECTION vote request: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2<-635159ec-b87e-4c18-a398-f9f404aae830#0:FAIL-t2. Peer's state: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42:t2, leader=null, voted=55f25964-0507-4416-bd5f-134f8268daba, raftlog=635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-24 20:58:52,032 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5075760662ns, electionTimeout:5074ms
datanode3_1  | 2022-08-24 20:58:52,033 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: shutdown 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState
datanode3_1  | 2022-08-24 20:58:52,033 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode3_1  | 2022-08-24 20:58:52,036 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-08-24 20:58:52,036 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: start 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-LeaderElection1
datanode3_1  | 2022-08-24 20:58:52,046 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-LeaderElection1] INFO impl.LeaderElection: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-LeaderElection1 ELECTION round 0: submit vote requests at term 3 for -1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-24 20:58:52,213 [grpc-default-executor-0] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: receive requestVote(ELECTION, 55f25964-0507-4416-bd5f-134f8268daba, group-069052B7AC42, 3, (t:0, i:0))
datanode3_1  | 2022-08-24 20:58:52,214 [grpc-default-executor-0] INFO impl.VoteContext: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-CANDIDATE: reject ELECTION from 55f25964-0507-4416-bd5f-134f8268daba: already has voted for 635159ec-b87e-4c18-a398-f9f404aae830 at current term 3
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-08-24 20:56:23,949 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-08-24 20:56:24,003 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-08-24 20:56:24,283 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-24 20:56:24,443 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-08-24 20:56:24,488 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-08-24 20:56:24,763 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-08-24 20:56:35,439 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
datanode1_1  | 2022-08-24 20:58:59,064 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-FollowerState] INFO impl.FollowerState: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5131127459ns, electionTimeout:5130ms
datanode1_1  | 2022-08-24 20:58:59,065 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-FollowerState] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: shutdown 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-FollowerState
datanode1_1  | 2022-08-24 20:58:59,065 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-FollowerState] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-08-24 20:58:59,065 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-08-24 20:58:59,065 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-FollowerState] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2
datanode1_1  | 2022-08-24 20:58:59,068 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO impl.LeaderElection: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-08-24 20:58:59,068 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO impl.LeaderElection: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2022-08-24 20:58:59,069 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: shutdown 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2
datanode1_1  | 2022-08-24 20:58:59,069 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2022-08-24 20:58:59,069 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-71CDB3C1BBAB with new leaderId: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
datanode1_1  | 2022-08-24 20:58:59,069 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB: change Leader from null to 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2 at term 1 for becomeLeader, leader elected after 5292ms
datanode1_1  | 2022-08-24 20:58:59,080 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-08-24 20:58:59,095 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-08-24 20:58:59,097 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-08-24 20:58:59,102 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-08-24 20:58:59,106 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-08-24 20:58:59,106 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
datanode2_1  | 2022-08-24 20:58:36,536 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=0fca26ca-dda5-4802-a36e-c4a4d57205b6.
datanode2_1  | 2022-08-24 20:58:36,536 [Command processor thread] INFO server.RaftServer: 55f25964-0507-4416-bd5f-134f8268daba: addNew group-069052B7AC42:[8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] returns group-069052B7AC42:java.util.concurrent.CompletableFuture@25a217c5[Not completed]
datanode2_1  | 2022-08-24 20:58:36,538 [pool-23-thread-1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba: new RaftServerImpl for group-069052B7AC42:[8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-08-24 20:58:36,539 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-08-24 20:58:36,539 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-08-24 20:58:36,539 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-08-24 20:58:36,539 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-08-24 20:58:36,539 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-08-24 20:58:36,539 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-08-24 20:58:36,539 [pool-23-thread-1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: ConfigurationManager, init=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-08-24 20:58:36,539 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-08-24 20:58:36,539 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-08-24 20:58:36,539 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-08-24 20:58:36,540 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42 does not exist. Creating ...
datanode2_1  | 2022-08-24 20:58:36,554 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42/in_use.lock acquired by nodename 6@7541e863c794
datanode2_1  | 2022-08-24 20:58:36,566 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42 has been successfully formatted.
datanode2_1  | 2022-08-24 20:58:36,628 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-069052B7AC42: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-08-24 20:58:36,628 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-08-24 20:58:36,628 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-08-24 20:58:36,628 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-08-24 20:58:36,628 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-24 20:58:36,628 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-08-24 20:58:36,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-24 20:58:36,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-08-24 20:58:36,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-08-24 20:58:36,629 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42
datanode2_1  | 2022-08-24 20:58:36,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-08-24 20:58:36,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-08-24 20:58:36,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-24 20:58:36,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-08-24 20:58:36,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-08-24 20:58:36,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-08-24 20:58:36,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-08-24 20:58:36,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-08-24 20:58:36,639 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-08-24 20:58:36,639 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om1_1        | 2022-08-24 20:58:39,594 [pool-27-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2022-08-24 20:58:39,605 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-08-24 20:58:39,609 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
s3g_1        | MultiException stack 1 of 1
s3g_1        | javax.ws.rs.WebApplicationException: The authorization header you provided is invalid.
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.wrapOS3Exception(OzoneClientProducer.java:141)
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:102)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1        | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1        | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1        | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-08-24 20:56:35,450 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-08-24 20:56:35,536 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-08-24 20:56:35,566 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-08-24 20:56:35,566 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-08-24 20:56:35,610 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-08-24 20:56:35,611 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-08-24 20:56:35,774 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-08-24 20:56:35,774 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-08-24 20:56:35,828 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2022-08-24 20:56:38,009 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-24 20:56:40,011 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-24 20:56:42,013 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-24 20:56:44,016 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-24 20:56:46,025 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-24 20:56:48,169 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:4c4be219-e818-4409-b18c-c29dce22a660 is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 2022-08-24 20:57:09,166 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1      | 2022-08-24 20:57:09,167 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1      | 2022-08-24 20:57:09,262 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1      | 2022-08-24 20:57:09,541 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1      | 2022-08-24 20:57:09,546 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1      | 2022-08-24 20:57:09,567 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1      | 2022-08-24 20:57:09,567 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1      | 2022-08-24 20:57:09,581 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-08-24 20:57:09,592 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 27 milliseconds.
recon_1      | 2022-08-24 20:57:28,667 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 20:57:28,667 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 20:57:28,937 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:28,945 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2022-08-24 20:58:39,616 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1        | 2022-08-24 20:58:39,631 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2022-08-24 20:58:39,681 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@om1
kdc_1        | Aug 24 21:04:33 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.114: ISSUE: authtime 1661374581, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:04:34 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375074, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:04:36 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375074, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:04:48 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375088, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:04:51 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375088, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:05:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:05:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:05:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375105, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:05:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375105, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:05:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375105, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:05:18 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375118, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:05:21 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375118, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:05:26 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375126, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:05:28 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375126, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:05:32 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375132, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:05:35 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375132, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:05:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375132, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:05:43 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375143, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:05:46 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375143, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:05:55 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375155, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:05:58 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375155, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:06:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:06:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:07:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:07:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:07:21 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375241, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:07:24 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375241, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:07:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375259, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:07:41 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375259, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:07:57 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375277, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:07:59 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375277, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:08:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
om1_1        | 2022-08-24 20:58:39,813 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2022-08-24 20:58:39,827 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2022-08-24 20:58:39,846 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2022-08-24 20:58:39,913 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2022-08-24 20:58:39,926 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-08-24 20:58:39,929 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om1_1        | 2022-08-24 20:58:40,148 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-08-24 20:56:24,798 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-08-24 20:56:24,816 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2022-08-24 20:56:27,363 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2022-08-24 20:56:27,374 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2022-08-24 20:56:27,380 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2022-08-24 20:56:30,060 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2022-08-24 20:56:32,325 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-08-24 20:56:32,326 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-08-24 20:56:32,510 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-08-24 20:56:32,513 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-08-24 20:56:32,514 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:4c4be219-e818-4409-b18c-c29dce22a660,clusterId:CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe,subject:scm-sub@scm1.org
scm1.org_1   | 2022-08-24 20:56:32,639 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2022-08-24 20:56:32,798 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-08-24 20:56:32,883 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-08-24 20:56:32,883 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-24 20:56:32,884 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-08-24 20:56:32,884 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-24 20:56:32,884 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-24 20:56:32,885 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-08-24 20:56:32,890 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-24 20:56:32,890 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
datanode1_1  | 2022-08-24 20:58:59,111 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-08-24 20:58:59,114 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-08-24 20:58:59,116 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderStateImpl
datanode1_1  | 2022-08-24 20:58:59,128 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-08-24 20:58:59,129 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/f0d2bb84-a865-4722-a590-71cdb3c1bbab/current/log_inprogress_0
datanode1_1  | 2022-08-24 20:58:59,138 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB-LeaderElection2] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-71CDB3C1BBAB: set configuration 0: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-08-24 20:59:02,581 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5169370505ns, electionTimeout:5138ms
datanode1_1  | 2022-08-24 20:59:02,581 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: shutdown 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState
datanode1_1  | 2022-08-24 20:59:02,581 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
datanode1_1  | 2022-08-24 20:59:02,582 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-08-24 20:59:02,582 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-FollowerState] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3
datanode1_1  | 2022-08-24 20:59:02,589 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO impl.LeaderElection: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3 ELECTION round 0: submit vote requests at term 5 for -1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-24 20:59:02,615 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO impl.LeaderElection: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode1_1  | 2022-08-24 20:59:02,615 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO impl.LeaderElection:   Response 0: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2<-635159ec-b87e-4c18-a398-f9f404aae830#0:OK-t5
datanode1_1  | 2022-08-24 20:59:02,615 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO impl.LeaderElection: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3 ELECTION round 0: result PASSED
datanode1_1  | 2022-08-24 20:59:02,615 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: shutdown 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3
datanode1_1  | 2022-08-24 20:59:02,616 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: changes role from CANDIDATE to LEADER at term 5 for changeToLeader
datanode1_1  | 2022-08-24 20:59:02,616 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-069052B7AC42 with new leaderId: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
datanode1_1  | 2022-08-24 20:59:02,616 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: change Leader from null to 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2 at term 5 for becomeLeader, leader elected after 24414ms
datanode1_1  | 2022-08-24 20:59:02,616 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-08-24 20:59:02,617 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-08-24 20:59:02,617 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-08-24 20:59:02,617 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-08-24 20:59:02,617 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-08-24 20:59:02,618 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-08-24 20:59:02,618 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
om1_1        | 2022-08-24 20:58:40,315 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2022-08-24 20:58:40,322 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2022-08-24 20:58:40,366 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2022-08-24 20:58:40,382 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-08-24 20:58:40,383 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2022-08-24 20:58:40,384 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-08-24 20:58:40,403 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2022-08-24 20:58:40,407 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2022-08-24 20:58:40,415 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2022-08-24 20:58:40,421 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2022-08-24 20:58:40,421 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2022-08-24 20:58:40,555 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2022-08-24 20:58:40,595 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om1_1        | 2022-08-24 20:58:40,596 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1        | 2022-08-24 20:58:40,637 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2022-08-24 20:58:40,637 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2022-08-24 20:58:40,690 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2022-08-24 20:58:40,722 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2022-08-24 20:58:40,726 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2022-08-24 20:58:40,727 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2022-08-24 20:58:40,747 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2022-08-24 20:58:40,756 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2022-08-24 20:58:41,067 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-08-24 20:58:41,098 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om1_1        | 2022-08-24 20:58:41,099 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om1_1        | 2022-08-24 20:58:41,102 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om1_1        | 2022-08-24 20:58:41,102 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om1_1        | 2022-08-24 20:58:41,953 [main] INFO reflections.Reflections: Reflections took 2115 ms to scan 8 urls, producing 23 keys and 517 values [using 2 cores]
om1_1        | 2022-08-24 20:58:43,049 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2022-08-24 20:58:43,105 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2022-08-24 20:58:46,897 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2022-08-24 20:57:30,946 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 3 failover attempts. Trying to failover immediately.
om2_1        | 2022-08-24 20:58:20,344 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
recon_1      | 2022-08-24 20:57:30,948 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 4 failover attempts. Trying to failover immediately.
om2_1        | 2022-08-24 20:58:20,512 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om2_1        | 2022-08-24 20:58:22,440 [main] INFO reflections.Reflections: Reflections took 1172 ms to scan 1 urls, producing 113 keys and 334 values [using 2 cores]
scm3.org_1   | Sleeping for 5 seconds
scm3.org_1   | Waiting for the service scm2.org:9894
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-08-24 20:57:13,570 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1        | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1        | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
recon_1      | 2022-08-24 20:57:30,949 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:57:32,954 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 6 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:32,954 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 7 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:32,955 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:57:34,956 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 9 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:34,957 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 10 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:34,958 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
datanode3_1  | 2022-08-24 20:58:52,214 [grpc-default-executor-0] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42 replies to ELECTION vote request: 55f25964-0507-4416-bd5f-134f8268daba<-635159ec-b87e-4c18-a398-f9f404aae830#0:FAIL-t3. Peer's state: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42:t3, leader=null, voted=635159ec-b87e-4c18-a398-f9f404aae830, raftlog=635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-24 20:58:53,279 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-LeaderElection1] INFO impl.LeaderElection: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-LeaderElection1: ELECTION REJECTED received 1 response(s) and 0 exception(s):
om2_1        | 2022-08-24 20:58:24,238 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-08-24 20:58:24,238 [main] INFO om.OzoneManager: Ozone Manager login successful.
s3g_1        | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
datanode3_1  | 2022-08-24 20:58:53,294 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-LeaderElection1] INFO impl.LeaderElection:   Response 0: 635159ec-b87e-4c18-a398-f9f404aae830<-8a3aa5b1-7501-4e35-bc9c-199b5d065ff2#0:FAIL-t3
datanode3_1  | 2022-08-24 20:58:53,294 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-LeaderElection1] INFO impl.LeaderElection: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-LeaderElection1 ELECTION round 0: result REJECTED
datanode3_1  | 2022-08-24 20:58:53,326 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-LeaderElection1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode3_1  | 2022-08-24 20:58:53,326 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-LeaderElection1] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: shutdown 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-LeaderElection1
datanode3_1  | 2022-08-24 20:58:53,327 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-LeaderElection1] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: start 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState
datanode3_1  | 2022-08-24 20:58:53,650 [Command processor thread] INFO server.RaftServer: 635159ec-b87e-4c18-a398-f9f404aae830: addNew group-A4F4EAFA6589:[635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-A4F4EAFA6589:java.util.concurrent.CompletableFuture@7e4a4e1b[Not completed]
datanode3_1  | 2022-08-24 20:58:53,657 [pool-23-thread-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830: new RaftServerImpl for group-A4F4EAFA6589:[635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
om2_1        | 2022-08-24 20:58:24,238 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-08-24 20:58:26,362 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-08-24 20:58:26,733 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-08-24 20:58:30,626 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1        | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
om3_1        | 2022-08-24 20:58:41,662 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2022-08-24 20:58:41,672 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2022-08-24 20:58:41,751 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2022-08-24 20:58:41,767 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-08-24 20:58:41,769 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om3_1        | 2022-08-24 20:58:42,010 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-08-24 20:58:42,085 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2022-08-24 20:58:42,088 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
recon_1      | 2022-08-24 20:57:36,959 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 12 failover attempts. Trying to failover immediately.
om2_1        | 2022-08-24 20:58:31,359 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
s3g_1        | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
recon_1      | 2022-08-24 20:57:36,961 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 13 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:36,962 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:57:38,971 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 15 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:38,973 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 16 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:38,973 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:57:40,975 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 18 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:40,976 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 19 failover attempts. Trying to failover immediately.
om2_1        | 2022-08-24 20:58:31,391 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1170009537688.crt.
om2_1        | 2022-08-24 20:58:31,400 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/1259130466725.crt.
om2_1        | 2022-08-24 20:58:31,592 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-08-24 20:58:32,437 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-08-24 20:58:32,456 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-08-24 20:58:34,091 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om2_1        | 2022-08-24 20:58:34,166 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2022-08-24 20:58:34,167 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2022-08-24 20:58:34,809 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om2_1        | 2022-08-24 20:58:35,305 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-08-24 20:58:35,309 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2022-08-24 20:58:35,389 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2022-08-24 20:58:35,835 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2022-08-24 20:58:35,961 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-08-24 20:58:36,145 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om2:9872, om1:9872, om3:9872
om2_1        | 2022-08-24 20:58:36,217 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2022-08-24 20:58:37,731 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2022-08-24 20:58:38,241 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2022-08-24 20:58:38,265 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-08-24 20:58:38,265 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-08-24 20:56:32,891 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-08-24 20:56:32,901 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2022-08-24 20:56:32,902 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2022-08-24 20:56:33,067 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-08-24 20:56:33,069 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm3.org_1   | 2022-08-24 20:57:13,594 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2022-08-24 20:58:36,639 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-08-24 20:58:36,640 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-24 20:58:36,640 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-24 20:58:36,649 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-08-24 20:58:36,649 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-08-24 20:58:36,649 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-08-24 20:58:36,649 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-08-24 20:58:36,649 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-08-24 20:58:36,649 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-08-24 20:58:36,650 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-24 20:58:36,650 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-08-24 20:58:36,650 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-08-24 20:58:36,650 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-08-24 20:58:36,650 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-08-24 20:58:36,650 [pool-23-thread-1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: start as a follower, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2022-08-24 20:58:36,650 [pool-23-thread-1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-08-24 20:58:36,650 [pool-23-thread-1] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState
datanode2_1  | 2022-08-24 20:58:36,659 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-069052B7AC42,id=55f25964-0507-4416-bd5f-134f8268daba
datanode2_1  | 2022-08-24 20:58:36,695 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=a574462d-c45e-4fde-830b-069052b7ac42
datanode2_1  | 2022-08-24 20:58:37,285 [grpc-default-executor-0] INFO leader.FollowerInfo: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830: nextIndex: updateUnconditionally 1 -> 0
datanode2_1  | 2022-08-24 20:58:38,345 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=a574462d-c45e-4fde-830b-069052b7ac42.
datanode2_1  | 2022-08-24 20:58:41,845 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5194475766ns, electionTimeout:5185ms
datanode2_1  | 2022-08-24 20:58:41,845 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: shutdown 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState
datanode2_1  | 2022-08-24 20:58:41,846 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:874)
s3g_1        | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1        | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1        | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:127)
om3_1        | 2022-08-24 20:58:42,117 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2022-08-24 20:58:42,127 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2022-08-24 20:58:42,131 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2022-08-24 20:58:42,136 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-08-24 20:58:42,153 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2022-08-24 20:58:42,153 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2022-08-24 20:58:42,157 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2022-08-24 20:58:42,158 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1        | 2022-08-24 20:58:42,158 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2022-08-24 20:58:42,234 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-24 20:56:50,176 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-24 20:56:52,276 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2022-08-24 20:57:13,875 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode3_1  | 2022-08-24 20:58:53,686 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-08-24 20:58:53,686 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-08-24 20:58:53,692 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-08-24 20:58:53,696 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-08-24 20:58:53,703 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-08-24 20:56:33,070 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2022-08-24 20:56:33,070 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-08-24 20:56:33,070 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-08-24 20:56:33,074 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-08-24 20:56:33,080 [main] INFO server.RaftServer: 4c4be219-e818-4409-b18c-c29dce22a660: addNew group-CC84B7B042FE:[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|priority:0] returns group-CC84B7B042FE:java.util.concurrent.CompletableFuture@433c6abb[Not completed]
scm1.org_1   | 2022-08-24 20:56:33,102 [pool-2-thread-1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660: new RaftServerImpl for group-CC84B7B042FE:[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-08-24 20:56:33,103 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-08-24 20:56:33,103 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-08-24 20:56:33,104 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-08-24 20:56:33,104 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-08-24 20:56:33,104 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-08-24 20:56:33,104 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-08-24 20:56:33,110 [pool-2-thread-1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: ConfigurationManager, init=-1: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
recon_1      | 2022-08-24 20:57:40,976 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 20 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:57:42,978 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 21 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:42,979 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 22 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:42,981 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 23 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:57:44,984 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 24 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:44,988 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 25 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:44,991 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 26 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:57:46,992 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 27 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:46,993 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 28 failover attempts. Trying to failover immediately.
scm3.org_1   | 2022-08-24 20:57:13,935 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
om1_1        | 2022-08-24 20:58:46,961 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2022-08-24 20:57:46,994 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 29 failover attempts. Trying to failover after sleeping for 2000ms.
kdc_1        | Aug 24 21:08:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:08:05 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375285, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:08:08 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375285, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:09:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:09:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:10:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
scm2.org_1   | 2022-08-24 20:56:52,718 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm2.org_1   | 2022-08-24 20:56:52,718 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2022-08-24 20:56:52,719 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm2.org_1   | 2022-08-24 20:56:53,150 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2022-08-24 20:56:53,203 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2022-08-24 20:56:53,204 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2022-08-24 20:56:53,206 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:9c76dfff-1a89-47d1-a1fa-c42b1e1bf147,clusterId:CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe,subject:scm-sub@scm2.org
scm2.org_1   | 2022-08-24 20:56:56,122 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
datanode1_1  | 2022-08-24 20:59:02,618 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-08-24 20:59:02,672 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2022-08-24 20:59:02,674 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-08-24 20:59:02,675 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2022-08-24 20:59:02,701 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2022-08-24 20:59:02,701 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
scm3.org_1   | 2022-08-24 20:57:13,935 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
datanode1_1  | 2022-08-24 20:59:02,706 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-08-24 20:59:02,718 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2022-08-24 20:59:02,718 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-24 20:58:53,703 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-08-24 20:58:53,704 [pool-23-thread-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589: ConfigurationManager, init=-1: [635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-08-24 20:58:53,704 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-08-24 20:58:53,704 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-08-24 20:58:53,704 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-08-24 20:58:53,704 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6149d847-7841-4389-9c66-a4f4eafa6589 does not exist. Creating ...
kdc_1        | Aug 24 21:10:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:11:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:69)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:103)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:46)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:53)
s3g_1        | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:129)
s3g_1        | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
s3g_1        | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:46)
s3g_1        | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
om3_1        | 2022-08-24 20:58:42,295 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om3_1        | 2022-08-24 20:58:42,298 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2022-08-24 20:58:42,467 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
datanode3_1  | 2022-08-24 20:58:53,725 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6149d847-7841-4389-9c66-a4f4eafa6589/in_use.lock acquired by nodename 9@84533d7fcdfb
datanode3_1  | 2022-08-24 20:58:53,731 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6149d847-7841-4389-9c66-a4f4eafa6589 has been successfully formatted.
datanode3_1  | 2022-08-24 20:58:53,733 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-A4F4EAFA6589: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-08-24 20:58:53,735 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
kdc_1        | Aug 24 21:11:03 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:12:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:12:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:13:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:13:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
om1_1        | 2022-08-24 20:58:46,961 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
datanode1_1  | 2022-08-24 20:59:02,718 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2022-08-24 20:59:02,718 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2022-08-24 20:59:02,719 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-08-24 20:59:02,719 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-08-24 20:59:02,749 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO impl.RoleInfo: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: start 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderStateImpl
datanode1_1  | 2022-08-24 20:59:02,750 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-08-24 20:59:02,751 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42/current/log_inprogress_0
om3_1        | 2022-08-24 20:58:42,469 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2022-08-24 20:58:42,503 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2022-08-24 20:58:42,520 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2022-08-24 20:58:42,527 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2022-08-24 20:58:42,528 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2022-08-24 20:58:42,548 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2022-08-24 20:58:42,557 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2022-08-24 20:58:42,996 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-08-24 20:58:38,265 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
scm2.org_1   | 2022-08-24 20:56:56,150 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe, SCMID 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147
scm2.org_1   | 2022-08-24 20:56:56,151 [main] INFO server.StorageContainerManager: Primary SCM Node ID 4c4be219-e818-4409-b18c-c29dce22a660
scm2.org_1   | 2022-08-24 20:56:56,230 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-08-24 20:56:59,323 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
datanode2_1  | 2022-08-24 20:58:41,846 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2022-08-24 20:58:47,266 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2022-08-24 20:58:47,267 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2022-08-24 20:58:47,278 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-24 20:58:47,282 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2022-08-24 20:58:47,284 [om1-impl-thread1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-08-24 20:58:47,312 [om1-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2022-08-24 20:58:47,328 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2022-08-24 20:58:47,625 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2022-08-24 20:58:47,660 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2022-08-24 20:58:47,660 [Listener at om1/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
kdc_1        | Aug 24 21:13:11 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375591, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode1_1  | 2022-08-24 20:59:02,760 [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42-LeaderElection3] INFO server.RaftServer$Division: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2@group-069052B7AC42: set configuration 0: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-24 20:59:38,642 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:1256322444158.
datanode2_1  | 2022-08-24 20:58:41,846 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection3
recon_1      | 2022-08-24 20:57:48,995 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 30 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:48,999 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 31 failover attempts. Trying to failover immediately.
s3g_1        | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
s3g_1        | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
s3g_1        | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
om3_1        | 2022-08-24 20:58:43,024 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om3_1        | 2022-08-24 20:58:43,025 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm2.org_1   | /************************************************************
kdc_1        | Aug 24 21:13:17 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375591, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 24 21:13:39 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375619, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:13:44 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661375619, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1      | 2022-08-24 20:57:49,006 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 32 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:57:51,011 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 33 failover attempts. Trying to failover immediately.
scm1.org_1   | 2022-08-24 20:56:33,110 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-08-24 20:56:33,113 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-08-24 20:56:33,114 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-08-24 20:56:33,115 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe does not exist. Creating ...
scm1.org_1   | 2022-08-24 20:56:33,129 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/in_use.lock acquired by nodename 91@scm1.org
scm1.org_1   | 2022-08-24 20:56:33,134 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe has been successfully formatted.
scm1.org_1   | 2022-08-24 20:56:33,138 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
recon_1      | 2022-08-24 20:57:51,012 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 34 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:51,013 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 35 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 2022-08-24 20:58:43,029 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om3_1        | 2022-08-24 20:58:43,029 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om2_1        | 2022-08-24 20:58:38,265 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-08-24 20:58:38,266 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2022-08-24 20:58:38,288 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-08-24 20:57:14,053 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-08-24 20:57:14,053 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
recon_1      | 2022-08-24 20:57:53,014 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 36 failover attempts. Trying to failover immediately.
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
om2_1        | 2022-08-24 20:58:38,290 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2022-08-24 20:58:38,293 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-08-24 20:58:38,382 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om2_1        | 2022-08-24 20:58:38,383 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om2_1        | 2022-08-24 20:58:40,459 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2022-08-24 20:58:40,483 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om2_1        | 2022-08-24 20:58:40,484 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om2_1        | 2022-08-24 20:58:40,484 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-08-24 20:58:40,489 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-08-24 20:58:40,504 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-08-24 20:58:40,539 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@12300573[Not completed]
om2_1        | 2022-08-24 20:58:40,540 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2022-08-24 20:58:40,663 [pool-27-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2022-08-24 20:58:40,722 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2022-08-24 20:58:40,741 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2022-08-24 20:58:40,742 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2022-08-24 20:58:40,744 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-08-24 20:58:40,744 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-08-24 20:58:40,746 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2022-08-24 20:58:40,746 [main] INFO om.OzoneManager: Creating RPC Server
om2_1        | 2022-08-24 20:58:40,814 [pool-27-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2022-08-24 20:58:40,815 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-08-24 20:58:40,910 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2022-08-24 20:58:40,918 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2022-08-24 20:58:40,944 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2022-08-24 20:58:41,042 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@om2
om2_1        | 2022-08-24 20:58:41,162 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2022-08-24 20:58:41,177 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2022-08-24 20:58:41,182 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2022-08-24 20:58:41,349 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2022-08-24 20:58:41,349 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-08-24 20:58:41,354 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om2_1        | 2022-08-24 20:58:41,500 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-08-24 20:58:41,674 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2022-08-24 20:58:41,675 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2022-08-24 20:58:41,717 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2022-08-24 20:58:41,721 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-08-24 20:58:41,730 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2022-08-24 20:58:41,738 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-08-24 20:58:41,741 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2022-08-24 20:58:41,742 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2022-08-24 20:58:41,743 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2022-08-24 20:58:41,751 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2022-08-24 20:58:41,764 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2022-08-24 20:58:41,901 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2022-08-24 20:58:41,919 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om2_1        | 2022-08-24 20:58:41,922 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1        | 2022-08-24 20:58:42,008 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2022-08-24 20:58:42,018 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-24 20:58:53,743 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-08-24 20:58:53,745 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2022-08-24 20:57:14,424 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2022-08-24 20:56:33,141 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-08-24 20:56:33,160 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-08-24 20:56:33,161 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-24 20:56:33,162 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2022-08-24 20:56:33,172 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-08-24 20:56:33,311 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-08-24 20:56:33,317 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-08-24 20:56:33,317 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-08-24 20:56:33,322 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe
scm1.org_1   | 2022-08-24 20:56:33,322 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-08-24 20:56:33,322 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-08-24 20:56:33,323 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-08-24 20:56:33,323 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-08-24 20:56:33,323 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-08-24 20:56:33,324 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-08-24 20:56:33,324 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-08-24 20:56:33,325 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-08-24 20:56:33,332 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-08-24 20:56:33,332 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2022-08-24 20:56:33,333 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-08-24 20:56:33,337 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-08-24 20:56:33,337 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-08-24 20:56:33,340 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-08-24 20:56:33,341 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-08-24 20:56:33,341 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-08-24 20:56:33,342 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-08-24 20:56:33,343 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-08-24 20:56:33,343 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-08-24 20:56:33,374 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-08-24 20:56:33,374 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2022-08-24 20:56:33,375 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2022-08-24 20:56:33,375 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2022-08-24 20:56:33,376 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2022-08-24 20:56:33,378 [4c4be219-e818-4409-b18c-c29dce22a660-impl-thread1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: start as a follower, conf=-1: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-08-24 20:56:33,379 [4c4be219-e818-4409-b18c-c29dce22a660-impl-thread1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2022-08-24 20:56:33,380 [4c4be219-e818-4409-b18c-c29dce22a660-impl-thread1] INFO impl.RoleInfo: 4c4be219-e818-4409-b18c-c29dce22a660: start 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState
scm1.org_1   | 2022-08-24 20:56:33,387 [4c4be219-e818-4409-b18c-c29dce22a660-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CC84B7B042FE,id=4c4be219-e818-4409-b18c-c29dce22a660
scm1.org_1   | 2022-08-24 20:56:33,393 [main] INFO server.RaftServer: 4c4be219-e818-4409-b18c-c29dce22a660: start RPC server
scm1.org_1   | 2022-08-24 20:56:33,441 [main] INFO server.GrpcService: 4c4be219-e818-4409-b18c-c29dce22a660: GrpcService started, listening on 9894
scm1.org_1   | 2022-08-24 20:56:33,444 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$354/0x000000084031f040@6ed922e1] INFO util.JvmPauseMonitor: JvmPauseMonitor-4c4be219-e818-4409-b18c-c29dce22a660: Started
scm1.org_1   | 2022-08-24 20:56:38,520 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState] INFO impl.FollowerState: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5140513576ns, electionTimeout:5126ms
scm1.org_1   | 2022-08-24 20:56:38,522 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState] INFO impl.RoleInfo: 4c4be219-e818-4409-b18c-c29dce22a660: shutdown 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
s3g_1        | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
datanode3_1  | 2022-08-24 20:58:53,748 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-24 20:58:53,754 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-08-24 20:58:53,772 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
recon_1      | 2022-08-24 20:57:53,015 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 37 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:53,016 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 38 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:57:55,017 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 39 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:55,018 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 40 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:55,019 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 41 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:57:57,020 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 42 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:57,021 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 43 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:57,022 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 44 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:57:59,023 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 45 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:59,024 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 46 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:57:59,025 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 47 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:01,027 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 48 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:01,028 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 49 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:01,029 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 50 failover attempts. Trying to failover after sleeping for 2000ms.
scm3.org_1   | 2022-08-24 20:57:14,424 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-08-24 20:57:14,583 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2022-08-24 20:57:15,276 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2022-08-24 20:57:16,130 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm3.org_1   | 2022-08-24 20:57:16,130 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2022-08-24 20:57:16,131 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm3.org_1   | 2022-08-24 20:57:17,176 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm3.org_1   | 2022-08-24 20:57:17,200 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2022-08-24 20:57:17,200 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2022-08-24 20:57:17,203 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:32d0e816-7836-4618-b71b-8792003f2e21,clusterId:CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe,subject:scm-sub@scm3.org
datanode3_1  | 2022-08-24 20:58:53,778 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-08-24 20:58:53,778 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-08-24 20:58:41,854 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection3] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2022-08-24 20:58:41,876 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection3] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection3: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-08-24 20:58:41,877 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection3] INFO impl.LeaderElection:   Response 0: 55f25964-0507-4416-bd5f-134f8268daba<-8a3aa5b1-7501-4e35-bc9c-199b5d065ff2#0:FAIL-t1
datanode2_1  | 2022-08-24 20:58:41,877 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection3] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection3 ELECTION round 0: result REJECTED
datanode3_1  | 2022-08-24 20:58:53,778 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/6149d847-7841-4389-9c66-a4f4eafa6589
datanode3_1  | 2022-08-24 20:58:53,778 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-08-24 20:56:59,329 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-08-24 20:56:59,504 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-08-24 20:56:59,635 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-08-24 20:56:59,657 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-08-24 20:56:59,759 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-08-24 20:56:59,763 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-08-24 20:57:01,184 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2022-08-24 20:57:01,455 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2022-08-24 20:57:01,468 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm2.org_1   | 2022-08-24 20:57:01,470 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/1191314964846.crt.
scm2.org_1   | 2022-08-24 20:57:01,817 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-08-24 20:57:01,817 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-08-24 20:57:01,919 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-08-24 20:57:02,294 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-08-24 20:57:02,816 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2022-08-24 20:57:02,816 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm2.org_1   | 2022-08-24 20:57:02,975 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2022-08-24 20:57:03,065 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:9c76dfff-1a89-47d1-a1fa-c42b1e1bf147
scm2.org_1   | 2022-08-24 20:57:03,334 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2022-08-24 20:58:41,882 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection3] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode2_1  | 2022-08-24 20:58:41,882 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection3] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: shutdown 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection3
datanode2_1  | 2022-08-24 20:58:41,884 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection3] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState
datanode2_1  | 2022-08-24 20:58:46,947 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5062812176ns, electionTimeout:5033ms
om1_1        | 2022-08-24 20:58:47,669 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2022-08-24 20:58:47,669 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-08-24 20:58:47,688 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$452/0x00000008405b2040@babef5e] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2022-08-24 20:58:47,689 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1        | 2022-08-24 20:58:47,689 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2022-08-24 20:58:47,934 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2022-08-24 20:58:47,936 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2022-08-24 20:58:47,936 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om1_1        | 2022-08-24 20:58:48,101 [Listener at om1/9862] INFO util.log: Logging initialized @47257ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2022-08-24 20:58:48,838 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2022-08-24 20:58:48,855 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2022-08-24 20:58:48,864 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2022-08-24 20:58:48,868 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2022-08-24 20:58:48,868 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2022-08-24 20:58:48,871 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2022-08-24 20:58:49,004 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2022-08-24 20:58:49,010 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om1_1        | 2022-08-24 20:58:49,140 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2022-08-24 20:58:49,149 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2022-08-24 20:58:49,151 [Listener at om1/9862] INFO server.session: node0 Scavenging every 660000ms
om1_1        | 2022-08-24 20:58:49,196 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-08-24 20:58:49,199 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b4c8fa9{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2022-08-24 20:58:49,203 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@ab8d6a6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2022-08-24 20:58:49,659 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-08-24 20:58:49,707 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@21ebf946{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-17034070444388012618/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
scm3.org_1   | 2022-08-24 20:57:17,573 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2022-08-24 20:57:17,581 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe, SCMID 32d0e816-7836-4618-b71b-8792003f2e21
scm3.org_1   | 2022-08-24 20:57:17,581 [main] INFO server.StorageContainerManager: Primary SCM Node ID 4c4be219-e818-4409-b18c-c29dce22a660
scm3.org_1   | 2022-08-24 20:57:17,609 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-08-24 20:57:18,941 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-08-24 20:57:18,954 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-08-24 20:57:19,042 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-08-24 20:57:19,118 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-08-24 20:57:19,138 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-08-24 20:57:19,213 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-08-24 20:57:19,230 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-08-24 20:57:20,113 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2022-08-24 20:57:20,300 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2022-08-24 20:57:20,308 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2022-08-24 20:57:20,311 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/1214845521971.crt.
scm3.org_1   | 2022-08-24 20:57:20,465 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-08-24 20:57:20,465 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-08-24 20:57:20,520 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-08-24 20:57:20,745 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-08-24 20:57:21,277 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm3.org_1   | 2022-08-24 20:57:21,277 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm3.org_1   | 2022-08-24 20:57:21,393 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2022-08-24 20:57:21,441 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:32d0e816-7836-4618-b71b-8792003f2e21
scm3.org_1   | 2022-08-24 20:57:21,592 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm3.org_1   | 2022-08-24 20:57:21,735 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm3.org_1   | 2022-08-24 20:57:21,738 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-08-24 20:57:21,739 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
datanode3_1  | 2022-08-24 20:58:53,778 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-08-24 20:58:53,779 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-24 20:58:53,795 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-08-24 20:58:53,795 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-08-24 20:58:53,795 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-08-24 20:58:53,795 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-08-24 20:58:53,795 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-08-24 20:58:53,862 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-08-24 20:58:53,943 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-08-24 20:58:53,943 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-08-24 20:58:53,948 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-24 20:58:53,948 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-24 20:58:53,952 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-08-24 20:58:53,982 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-08-24 20:58:53,982 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-08-24 20:58:53,982 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-08-24 20:58:53,983 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-08-24 20:58:53,983 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-08-24 20:58:53,994 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-08-24 20:58:54,004 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-08-24 20:58:54,005 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
datanode2_1  | 2022-08-24 20:58:46,948 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: shutdown 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState
datanode2_1  | 2022-08-24 20:58:46,948 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode2_1  | 2022-08-24 20:58:46,948 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-24 20:58:46,948 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection4
datanode2_1  | 2022-08-24 20:58:46,950 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection4] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection4 ELECTION round 0: submit vote requests at term 2 for -1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2022-08-24 20:58:47,003 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection4] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection4: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2022-08-24 20:58:47,015 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection4] INFO impl.LeaderElection:   Response 0: 55f25964-0507-4416-bd5f-134f8268daba<-8a3aa5b1-7501-4e35-bc9c-199b5d065ff2#0:FAIL-t2
datanode2_1  | 2022-08-24 20:58:47,015 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection4] INFO impl.LeaderElection:   Response 1: 55f25964-0507-4416-bd5f-134f8268daba<-635159ec-b87e-4c18-a398-f9f404aae830#0:OK-t2
datanode2_1  | 2022-08-24 20:58:47,016 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection4] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection4 ELECTION round 0: result REJECTED
datanode2_1  | 2022-08-24 20:58:47,016 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection4] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode2_1  | 2022-08-24 20:58:47,016 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection4] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: shutdown 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection4
datanode2_1  | 2022-08-24 20:58:47,017 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection4] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState
datanode2_1  | 2022-08-24 20:58:48,423 [grpc-default-executor-0] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: receive requestVote(ELECTION, 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, group-069052B7AC42, 2, (t:0, i:0))
datanode2_1  | 2022-08-24 20:58:48,436 [grpc-default-executor-0] INFO impl.VoteContext: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FOLLOWER: reject ELECTION from 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: already has voted for 55f25964-0507-4416-bd5f-134f8268daba at current term 2
datanode2_1  | 2022-08-24 20:58:48,440 [grpc-default-executor-0] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42 replies to ELECTION vote request: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2<-55f25964-0507-4416-bd5f-134f8268daba#0:FAIL-t2. Peer's state: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42:t2, leader=null, voted=55f25964-0507-4416-bd5f-134f8268daba, raftlog=55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2022-08-24 20:58:52,169 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5151931755ns, electionTimeout:5125ms
datanode2_1  | 2022-08-24 20:58:52,169 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: shutdown 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState
kdc_1        | Aug 24 21:13:49 kdc krb5kdc[9](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375629, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 24 21:13:49 kdc krb5kdc[9](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661375629, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
kdc_1        | Aug 24 21:14:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 24 21:14:04 kdc krb5kdc[9](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om1@EXAMPLE.COM, Server not found in Kerberos database
recon_1      | 2022-08-24 20:58:03,031 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 51 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:03,033 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 52 failover attempts. Trying to failover immediately.
om3_1        | 2022-08-24 20:58:43,613 [main] INFO reflections.Reflections: Reflections took 1939 ms to scan 8 urls, producing 23 keys and 517 values [using 2 cores]
om3_1        | 2022-08-24 20:58:44,415 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2022-08-24 20:58:44,468 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2022-08-24 20:58:48,093 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2022-08-24 20:58:48,172 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2022-08-24 20:58:48,172 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2022-08-24 20:58:48,424 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2022-08-24 20:58:48,435 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
recon_1      | 2022-08-24 20:58:03,033 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 53 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:05,035 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 54 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:05,036 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 55 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:05,037 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 56 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:07,038 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 57 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:07,039 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 58 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:07,039 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 59 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 2022-08-24 20:58:48,459 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-24 20:58:48,470 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2022-08-24 20:58:48,471 [om3-impl-thread1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-08-24 20:58:48,497 [om3-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2022-08-24 20:58:48,520 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2022-08-24 20:58:48,686 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2022-08-24 20:58:48,699 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$452/0x00000008405b2040@43cd2f26] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2022-08-24 20:58:48,700 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2022-08-24 20:58:48,702 [Listener at om3/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
recon_1      | 2022-08-24 20:58:09,041 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 60 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:09,042 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 61 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:09,043 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 62 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:11,045 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 63 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:11,046 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 64 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:11,050 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 65 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:13,051 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 66 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:13,053 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 67 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:13,053 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 68 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:15,055 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 69 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:15,057 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 70 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:15,058 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 71 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:16,912 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36712
recon_1      | 2022-08-24 20:58:16,942 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 20:58:17,063 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 72 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:17,075 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 73 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:17,079 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 74 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:19,091 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 75 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:19,096 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 76 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:19,098 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 77 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:19,114 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56934
datanode2_1  | 2022-08-24 20:58:52,169 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode2_1  | 2022-08-24 20:58:52,169 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-24 20:58:52,169 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection5
datanode2_1  | 2022-08-24 20:58:52,172 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection5] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection5 ELECTION round 0: submit vote requests at term 3 for -1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2022-08-24 20:58:52,195 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection5] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection5: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-08-24 20:58:52,195 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection5] INFO impl.LeaderElection:   Response 0: 55f25964-0507-4416-bd5f-134f8268daba<-8a3aa5b1-7501-4e35-bc9c-199b5d065ff2#0:FAIL-t3
datanode2_1  | 2022-08-24 20:58:52,195 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection5] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection5 ELECTION round 0: result REJECTED
datanode2_1  | 2022-08-24 20:58:52,195 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection5] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode2_1  | 2022-08-24 20:58:52,195 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection5] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: shutdown 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection5
datanode2_1  | 2022-08-24 20:58:52,196 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection5] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState
datanode2_1  | 2022-08-24 20:58:53,213 [grpc-default-executor-0] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: receive requestVote(ELECTION, 635159ec-b87e-4c18-a398-f9f404aae830, group-069052B7AC42, 3, (t:0, i:0))
datanode2_1  | 2022-08-24 20:58:53,218 [grpc-default-executor-0] INFO impl.VoteContext: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FOLLOWER: reject ELECTION from 635159ec-b87e-4c18-a398-f9f404aae830: already has voted for 55f25964-0507-4416-bd5f-134f8268daba at current term 3
datanode2_1  | 2022-08-24 20:58:53,218 [grpc-default-executor-0] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42 replies to ELECTION vote request: 635159ec-b87e-4c18-a398-f9f404aae830<-55f25964-0507-4416-bd5f-134f8268daba#0:FAIL-t3. Peer's state: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42:t3, leader=null, voted=55f25964-0507-4416-bd5f-134f8268daba, raftlog=55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2022-08-24 20:58:57,400 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5204447727ns, electionTimeout:5193ms
datanode2_1  | 2022-08-24 20:58:57,400 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: shutdown 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState
datanode2_1  | 2022-08-24 20:58:57,400 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode2_1  | 2022-08-24 20:58:57,400 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-24 20:58:57,400 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection6
datanode3_1  | 2022-08-24 20:58:54,005 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-08-24 20:58:54,005 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-08-24 20:58:54,005 [pool-23-thread-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589: start as a follower, conf=-1: [635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-08-24 20:58:54,005 [pool-23-thread-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-08-24 20:58:54,005 [pool-23-thread-1] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: start 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-FollowerState
datanode3_1  | 2022-08-24 20:58:54,020 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A4F4EAFA6589,id=635159ec-b87e-4c18-a398-f9f404aae830
datanode3_1  | 2022-08-24 20:58:54,089 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=6149d847-7841-4389-9c66-a4f4eafa6589
datanode3_1  | 2022-08-24 20:58:54,148 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=6149d847-7841-4389-9c66-a4f4eafa6589.
datanode3_1  | 2022-08-24 20:58:57,417 [grpc-default-executor-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: receive requestVote(ELECTION, 55f25964-0507-4416-bd5f-134f8268daba, group-069052B7AC42, 4, (t:0, i:0))
datanode3_1  | 2022-08-24 20:58:57,417 [grpc-default-executor-1] INFO impl.VoteContext: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FOLLOWER: accept ELECTION from 55f25964-0507-4416-bd5f-134f8268daba: our priority 0 <= candidate's priority 0
datanode3_1  | 2022-08-24 20:58:57,417 [grpc-default-executor-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:55f25964-0507-4416-bd5f-134f8268daba
datanode3_1  | 2022-08-24 20:58:57,417 [grpc-default-executor-1] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: shutdown 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState
datanode3_1  | 2022-08-24 20:58:57,418 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState was interrupted
datanode3_1  | 2022-08-24 20:58:57,418 [grpc-default-executor-1] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: start 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState
datanode3_1  | 2022-08-24 20:58:57,420 [grpc-default-executor-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42 replies to ELECTION vote request: 55f25964-0507-4416-bd5f-134f8268daba<-635159ec-b87e-4c18-a398-f9f404aae830#0:OK-t4. Peer's state: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42:t4, leader=null, voted=55f25964-0507-4416-bd5f-134f8268daba, raftlog=635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-24 20:58:59,134 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-FollowerState] INFO impl.FollowerState: 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5128075836ns, electionTimeout:5113ms
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
scm2.org_1   | 2022-08-24 20:57:03,553 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2022-08-24 20:58:48,704 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2022-08-24 20:58:48,704 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-08-24 20:58:48,707 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1        | 2022-08-24 20:58:48,725 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2022-08-24 20:58:48,824 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2022-08-24 20:58:48,824 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2022-08-24 20:58:48,824 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2022-08-24 20:58:48,936 [Listener at om3/9862] INFO util.log: Logging initialized @45780ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2022-08-24 20:58:49,323 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2022-08-24 20:58:49,360 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2022-08-24 20:58:49,367 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2022-08-24 20:58:49,368 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2022-08-24 20:58:49,368 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2022-08-24 20:58:49,377 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2022-08-24 20:58:49,506 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2022-08-24 20:58:49,511 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om3_1        | 2022-08-24 20:58:49,727 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2022-08-24 20:58:49,734 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2022-08-24 20:58:49,739 [Listener at om3/9862] INFO server.session: node0 Scavenging every 660000ms
om1_1        | 2022-08-24 20:58:49,763 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@2fe12b04{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2022-08-24 20:58:49,770 [Listener at om1/9862] INFO server.Server: Started @48926ms
om1_1        | 2022-08-24 20:58:49,781 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2022-08-24 20:58:49,781 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2022-08-24 20:58:49,783 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
scm2.org_1   | 2022-08-24 20:57:03,553 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-08-24 20:57:03,553 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm2.org_1   | 2022-08-24 20:57:03,553 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-08-24 20:57:03,566 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-08-24 20:57:03,566 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm2.org_1   | 2022-08-24 20:57:03,568 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-08-24 20:57:03,575 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm2.org_1   | 2022-08-24 20:57:03,592 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2022-08-24 20:57:03,646 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
om1_1        | 2022-08-24 20:58:49,812 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2022-08-24 20:58:49,831 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2022-08-24 20:58:49,987 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om1_1        | 2022-08-24 20:58:50,288 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41245
om1_1        | 2022-08-24 20:58:50,299 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 20:58:50,388 [Listener at om1/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om1_1        | 2022-08-24 20:58:50,437 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1415d4ca] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2022-08-24 20:56:38,522 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm1.org_1   | 2022-08-24 20:56:38,525 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-08-24 20:56:38,525 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState] INFO impl.RoleInfo: 4c4be219-e818-4409-b18c-c29dce22a660: start 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1
scm1.org_1   | 2022-08-24 20:56:38,529 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO impl.LeaderElection: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-08-24 20:56:38,530 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO impl.LeaderElection: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2022-08-24 20:56:38,530 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO impl.RoleInfo: 4c4be219-e818-4409-b18c-c29dce22a660: shutdown 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1
scm1.org_1   | 2022-08-24 20:56:38,530 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm1.org_1   | 2022-08-24 20:56:38,531 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: change Leader from null to 4c4be219-e818-4409-b18c-c29dce22a660 at term 1 for becomeLeader, leader elected after 5393ms
scm1.org_1   | 2022-08-24 20:56:38,536 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-08-24 20:56:38,540 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-08-24 20:56:38,540 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-08-24 20:56:38,545 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm2.org_1   | 2022-08-24 20:57:03,647 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm2.org_1   | 2022-08-24 20:57:04,922 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm2.org_1   | 2022-08-24 20:57:04,924 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm2.org_1   | 2022-08-24 20:57:04,925 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm2.org_1   | 2022-08-24 20:57:04,925 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-08-24 20:57:04,925 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-08-24 20:57:04,928 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-08-24 20:57:04,958 [main] INFO server.RaftServer: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147: addNew group-CC84B7B042FE:[] returns group-CC84B7B042FE:java.util.concurrent.CompletableFuture@52a7928a[Not completed]
scm2.org_1   | 2022-08-24 20:57:05,041 [pool-16-thread-1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147: new RaftServerImpl for group-CC84B7B042FE:[] with SCMStateMachine:uninitialized
scm2.org_1   | 2022-08-24 20:57:05,048 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2022-08-24 20:57:05,049 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm2.org_1   | 2022-08-24 20:57:05,049 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm2.org_1   | 2022-08-24 20:57:05,049 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-08-24 20:57:05,049 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-08-24 20:57:05,049 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2022-08-24 20:57:05,059 [pool-16-thread-1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2022-08-24 20:57:05,059 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-08-24 20:57:05,069 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2022-08-24 20:57:05,069 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm2.org_1   | 2022-08-24 20:57:05,071 [pool-16-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe does not exist. Creating ...
scm2.org_1   | 2022-08-24 20:57:05,093 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/in_use.lock acquired by nodename 7@scm2.org
scm2.org_1   | 2022-08-24 20:57:05,127 [pool-16-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe has been successfully formatted.
scm2.org_1   | 2022-08-24 20:57:05,129 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm2.org_1   | 2022-08-24 20:57:05,131 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2022-08-24 20:57:05,147 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm2.org_1   | 2022-08-24 20:57:05,148 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-08-24 20:57:05,149 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm2.org_1   | 2022-08-24 20:57:05,290 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-08-24 20:57:05,309 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2022-08-24 20:57:05,323 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2022-08-24 20:57:05,332 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe
scm2.org_1   | 2022-08-24 20:57:05,338 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2022-08-24 20:57:05,338 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2022-08-24 20:57:05,339 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-08-24 20:57:05,340 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm2.org_1   | 2022-08-24 20:57:05,340 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2022-08-24 20:57:05,341 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2022-08-24 20:57:05,341 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2022-08-24 20:57:05,341 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2022-08-24 20:57:05,356 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2022-08-24 20:57:05,357 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm2.org_1   | 2022-08-24 20:57:05,357 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2022-08-24 20:57:05,361 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-08-24 20:57:05,370 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-08-24 20:57:05,373 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2022-08-24 20:58:42,070 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2022-08-24 20:58:42,071 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2022-08-24 20:58:42,071 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2022-08-24 20:58:42,072 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2022-08-24 20:58:42,073 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
recon_1      | 2022-08-24 20:58:19,272 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 20:58:20,606 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41160
recon_1      | 2022-08-24 20:58:20,666 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 20:58:20,932 [IPC Server handler 3 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
recon_1      | 2022-08-24 20:58:20,959 [IPC Server handler 3 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1250283857425, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:20,996 [IPC Server handler 18 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/635159ec-b87e-4c18-a398-f9f404aae830
recon_1      | 2022-08-24 20:58:21,013 [IPC Server handler 18 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252470207979, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:21,101 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 78 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:21,106 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 79 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:21,107 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 80 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:21,298 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 635159ec-b87e-4c18-a398-f9f404aae830 to Node DB.
recon_1      | 2022-08-24 20:58:21,305 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2 to Node DB.
recon_1      | 2022-08-24 20:58:22,521 [IPC Server handler 83 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-24 20:58:22,559 [IPC Server handler 95 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/55f25964-0507-4416-bd5f-134f8268daba
recon_1      | 2022-08-24 20:58:22,559 [IPC Server handler 95 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252176017931, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:22,582 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 55f25964-0507-4416-bd5f-134f8268daba to Node DB.
recon_1      | 2022-08-24 20:58:22,622 [IPC Server handler 98 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:139)
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:126)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor.parseSignature(AWSSignatureProcessor.java:86)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor$Proxy$_$$_WeldClientProxy.parseSignature(Unknown Source)
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:81)
s3g_1        | 	... 114 more
om1_1        | 2022-08-24 20:58:52,499 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5215131703ns, electionTimeout:5162ms
om1_1        | 2022-08-24 20:58:52,500 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-08-24 20:58:52,500 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2022-08-24 20:58:52,503 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2022-08-24 20:58:52,503 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1        | 2022-08-24 20:58:52,519 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-24 20:58:55,803 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-08-24 20:58:55,810 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om1 at current term 1
om1_1        | 2022-08-24 20:58:55,836 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-24 20:58:55,941 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-08-24 20:58:55,946 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om1 at current term 1
om1_1        | 2022-08-24 20:58:55,946 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-24 20:58:55,998 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om1_1        | 2022-08-24 20:58:55,999 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om3#0:FAIL-t1
om1_1        | 2022-08-24 20:58:56,000 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om1<-om2#0:FAIL-t1
om1_1        | 2022-08-24 20:58:56,000 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om1_1        | 2022-08-24 20:58:56,003 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om1_1        | 2022-08-24 20:58:56,003 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1        | 2022-08-24 20:58:56,004 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-08-24 20:58:59,860 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40752
om1_1        | 2022-08-24 20:58:59,885 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 20:59:01,041 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5037262198ns, electionTimeout:5008ms
om1_1        | 2022-08-24 20:59:01,042 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-08-24 20:59:01,042 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om1_1        | 2022-08-24 20:59:01,048 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2022-08-24 20:59:01,048 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection2
om1_1        | 2022-08-24 20:59:01,060 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-24 20:59:01,108 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
om1_1        | 2022-08-24 20:59:01,108 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 0: om1<-om2#0:OK-t2
om1_1        | 2022-08-24 20:59:01,108 [om1@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection2 ELECTION round 0: result PASSED
om1_1        | 2022-08-24 20:59:01,109 [om1@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection2
om1_1        | 2022-08-24 20:59:01,109 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
om1_1        | 2022-08-24 20:59:01,109 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om1 at term 2 for becomeLeader, leader elected after 21281ms
om1_1        | 2022-08-24 20:59:01,125 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om1_1        | 2022-08-24 20:59:01,136 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2022-08-24 20:59:01,136 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-08-24 20:59:01,141 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om1_1        | 2022-08-24 20:59:01,141 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om1_1        | 2022-08-24 20:59:01,143 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om1_1        | 2022-08-24 20:59:01,155 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1        | 2022-08-24 20:59:01,158 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om1_1        | 2022-08-24 20:59:01,184 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2022-08-24 20:59:01,184 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-08-24 20:59:01,184 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2022-08-24 20:59:01,187 [om1@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode3_1  | 2022-08-24 20:58:59,134 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-FollowerState] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: shutdown 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-FollowerState
datanode3_1  | 2022-08-24 20:58:59,134 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-FollowerState] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-08-24 20:58:59,134 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-08-24 20:58:59,134 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-FollowerState] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: start 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2
datanode3_1  | 2022-08-24 20:58:59,151 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO impl.LeaderElection: 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-08-24 20:58:59,153 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO impl.LeaderElection: 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2022-08-24 20:58:59,153 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: shutdown 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2
datanode3_1  | 2022-08-24 20:58:59,153 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-08-24 20:58:59,154 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A4F4EAFA6589 with new leaderId: 635159ec-b87e-4c18-a398-f9f404aae830
scm2.org_1   | 2022-08-24 20:57:05,373 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
datanode3_1  | 2022-08-24 20:58:59,158 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589: change Leader from null to 635159ec-b87e-4c18-a398-f9f404aae830 at term 1 for becomeLeader, leader elected after 5418ms
datanode3_1  | 2022-08-24 20:58:59,180 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-08-24 20:58:59,188 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-08-24 20:58:59,188 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-08-24 20:58:59,207 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-08-24 20:58:59,207 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
recon_1      | 2022-08-24 20:58:23,117 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 81 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:23,130 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 82 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:23,135 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 83 failover attempts. Trying to failover after sleeping for 2000ms.
s3g_1        | 
scm2.org_1   | 2022-08-24 20:57:05,374 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2022-08-24 20:57:05,375 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-08-24 20:58:57,407 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection6] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection6 ELECTION round 0: submit vote requests at term 4 for -1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2022-08-24 20:58:57,446 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection6] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection6: ELECTION REJECTED received 2 response(s) and 0 exception(s):
scm3.org_1   | 2022-08-24 20:57:21,739 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-08-24 20:57:21,740 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-08-24 20:57:21,742 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm3.org_1   | 2022-08-24 20:57:21,744 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1      | 2022-08-24 20:58:24,339 [IPC Server handler 34 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-24 20:58:25,136 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 84 failover attempts. Trying to failover immediately.
s3g_1        | 
s3g_1        | 2022-08-24 21:05:52,824 [qtp864326906-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg4, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm2.org_1   | 2022-08-24 20:57:05,376 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2022-08-24 20:57:05,376 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-08-24 20:58:57,447 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection6] INFO impl.LeaderElection:   Response 0: 55f25964-0507-4416-bd5f-134f8268daba<-8a3aa5b1-7501-4e35-bc9c-199b5d065ff2#0:FAIL-t4
datanode2_1  | 2022-08-24 20:58:57,447 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection6] INFO impl.LeaderElection:   Response 1: 55f25964-0507-4416-bd5f-134f8268daba<-635159ec-b87e-4c18-a398-f9f404aae830#0:OK-t4
datanode2_1  | 2022-08-24 20:58:57,447 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection6] INFO impl.LeaderElection: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection6 ELECTION round 0: result REJECTED
scm1.org_1   | 2022-08-24 20:56:38,546 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-08-24 20:56:38,560 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
recon_1      | 2022-08-24 20:58:25,138 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 85 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:25,139 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 86 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:25,803 [IPC Server handler 18 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-24 20:58:25,806 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=e5375211-a7a5-4dcb-a220-2337c26f5c0c. Trying to get from SCM.
datanode3_1  | 2022-08-24 20:58:59,208 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-08-24 20:58:59,217 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
om3_1        | 2022-08-24 20:58:49,806 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-08-24 20:58:49,825 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@278b0a4d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2022-08-24 20:57:05,488 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2022-08-24 20:57:21,747 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
datanode3_1  | 2022-08-24 20:58:59,218 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-08-24 20:58:59,223 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: start 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderStateImpl
scm1.org_1   | 2022-08-24 20:56:38,570 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-08-24 20:56:38,573 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-08-24 20:56:38,578 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO impl.RoleInfo: 4c4be219-e818-4409-b18c-c29dce22a660: start 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderStateImpl
om2_1        | 2022-08-24 20:58:42,073 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2022-08-24 20:58:42,507 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-08-24 20:58:59,238 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-08-24 20:58:59,254 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-LeaderElection2] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589: set configuration 0: [635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-08-24 20:58:59,254 [635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 635159ec-b87e-4c18-a398-f9f404aae830@group-A4F4EAFA6589-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6149d847-7841-4389-9c66-a4f4eafa6589/current/log_inprogress_0
scm3.org_1   | 2022-08-24 20:57:21,748 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2022-08-24 20:57:21,784 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm3.org_1   | 2022-08-24 20:57:21,785 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm3.org_1   | 2022-08-24 20:57:22,811 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | 2022-08-24 20:59:02,598 [grpc-default-executor-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: receive requestVote(ELECTION, 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, group-069052B7AC42, 5, (t:0, i:0))
datanode3_1  | 2022-08-24 20:59:02,598 [grpc-default-executor-1] INFO impl.VoteContext: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FOLLOWER: accept ELECTION from 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: our priority 0 <= candidate's priority 1
datanode3_1  | 2022-08-24 20:59:02,598 [grpc-default-executor-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
datanode3_1  | 2022-08-24 20:59:02,598 [grpc-default-executor-1] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: shutdown 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState
recon_1      | 2022-08-24 20:58:25,941 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: e5375211-a7a5-4dcb-a220-2337c26f5c0c, Nodes: 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:22.680Z[UTC]] to Recon pipeline metadata.
s3g_1        | 2022-08-24 21:05:52,824 [qtp864326906-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg0, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:52,825 [qtp864326906-77] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg2, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:52,826 [qtp864326906-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg7, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:52,828 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg5, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:52,831 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg3, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm3.org_1   | 2022-08-24 20:57:22,823 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode3_1  | 2022-08-24 20:59:02,598 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState was interrupted
datanode3_1  | 2022-08-24 20:59:02,599 [grpc-default-executor-1] INFO impl.RoleInfo: 635159ec-b87e-4c18-a398-f9f404aae830: start 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-FollowerState
datanode3_1  | 2022-08-24 20:59:02,604 [grpc-default-executor-1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42 replies to ELECTION vote request: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2<-635159ec-b87e-4c18-a398-f9f404aae830#0:OK-t5. Peer's state: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42:t5, leader=null, voted=8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, raftlog=635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-24 20:56:38,597 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2022-08-24 20:56:38,631 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: set configuration 0: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-24 20:56:38,659 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/current/log_inprogress_0
om2_1        | 2022-08-24 20:58:42,508 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om2_1        | 2022-08-24 20:58:42,508 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
recon_1      | 2022-08-24 20:58:26,126 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e5375211-a7a5-4dcb-a220-2337c26f5c0c, Nodes: 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:22.680Z[UTC]].
recon_1      | 2022-08-24 20:58:26,147 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=e5375211-a7a5-4dcb-a220-2337c26f5c0c reported by 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252176017931, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:26,147 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e5375211-a7a5-4dcb-a220-2337c26f5c0c, Nodes: 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:22.680Z[UTC]] moved to OPEN state
recon_1      | 2022-08-24 20:58:26,974 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=0fca26ca-dda5-4802-a36e-c4a4d57205b6. Trying to get from SCM.
datanode2_1  | 2022-08-24 20:58:57,448 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection6] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode2_1  | 2022-08-24 20:58:57,449 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection6] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: shutdown 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection6
datanode2_1  | 2022-08-24 20:58:57,449 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-LeaderElection6] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState
datanode2_1  | 2022-08-24 20:59:02,605 [grpc-default-executor-0] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: receive requestVote(ELECTION, 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, group-069052B7AC42, 5, (t:0, i:0))
datanode2_1  | 2022-08-24 20:59:02,606 [grpc-default-executor-0] INFO impl.VoteContext: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FOLLOWER: accept ELECTION from 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2: our priority 0 <= candidate's priority 1
datanode2_1  | 2022-08-24 20:59:02,606 [grpc-default-executor-0] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
om2_1        | 2022-08-24 20:58:42,509 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om2_1        | 2022-08-24 20:58:42,509 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om2_1        | 2022-08-24 20:58:43,246 [main] INFO reflections.Reflections: Reflections took 2071 ms to scan 8 urls, producing 23 keys and 517 values [using 2 cores]
om2_1        | 2022-08-24 20:58:44,091 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2022-08-24 20:58:44,140 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2022-08-24 20:58:47,382 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2022-08-24 20:58:49,826 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2e7b57b3{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | 2022-08-24 20:58:50,180 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-08-24 20:58:50,213 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1aec9516{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-6132591144448437777/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2022-08-24 20:58:50,230 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@6b3d3a9a{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
datanode2_1  | 2022-08-24 20:59:02,606 [grpc-default-executor-0] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: shutdown 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState
datanode2_1  | 2022-08-24 20:59:02,606 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState] INFO impl.FollowerState: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState was interrupted
datanode2_1  | 2022-08-24 20:59:02,607 [grpc-default-executor-0] INFO impl.RoleInfo: 55f25964-0507-4416-bd5f-134f8268daba: start 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-FollowerState
om2_1        | 2022-08-24 20:58:47,523 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2022-08-24 20:58:47,523 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2022-08-24 20:58:47,741 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2022-08-24 20:58:47,770 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om3_1        | 2022-08-24 20:58:50,231 [Listener at om3/9862] INFO server.Server: Started @47075ms
om3_1        | 2022-08-24 20:58:50,254 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2022-08-24 20:58:50,254 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2022-08-24 20:57:22,824 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm3.org_1   | 2022-08-24 20:57:22,825 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-08-24 20:57:22,834 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-08-24 20:59:02,611 [grpc-default-executor-0] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42 replies to ELECTION vote request: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2<-55f25964-0507-4416-bd5f-134f8268daba#0:OK-t5. Peer's state: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42:t5, leader=null, voted=8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, raftlog=55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-SegmentedRaftLog:OPENED:c-1, conf=-1: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0], old=null
datanode2_1  | 2022-08-24 20:59:02,828 [55f25964-0507-4416-bd5f-134f8268daba-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-069052B7AC42 with new leaderId: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
datanode2_1  | 2022-08-24 20:59:02,829 [55f25964-0507-4416-bd5f-134f8268daba-server-thread1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: change Leader from null to 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2 at term 5 for appendEntries, leader elected after 26200ms
datanode2_1  | 2022-08-24 20:59:02,924 [55f25964-0507-4416-bd5f-134f8268daba-server-thread1] INFO server.RaftServer$Division: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42: set configuration 0: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
om2_1        | 2022-08-24 20:58:47,782 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-24 20:58:50,256 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
scm1.org_1   | 2022-08-24 20:56:39,445 [main] INFO server.RaftServer: 4c4be219-e818-4409-b18c-c29dce22a660: close
scm1.org_1   | 2022-08-24 20:56:39,446 [main] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: shutdown
scm1.org_1   | 2022-08-24 20:56:39,447 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CC84B7B042FE,id=4c4be219-e818-4409-b18c-c29dce22a660
scm3.org_1   | 2022-08-24 20:57:22,846 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-08-24 20:57:22,873 [main] INFO server.RaftServer: 32d0e816-7836-4618-b71b-8792003f2e21: addNew group-CC84B7B042FE:[] returns group-CC84B7B042FE:java.util.concurrent.CompletableFuture@52a7928a[Not completed]
scm3.org_1   | 2022-08-24 20:57:22,941 [pool-16-thread-1] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21: new RaftServerImpl for group-CC84B7B042FE:[] with SCMStateMachine:uninitialized
om2_1        | 2022-08-24 20:58:47,783 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2022-08-24 20:58:47,785 [om2-impl-thread1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-08-24 20:58:47,795 [om2-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2022-08-24 20:58:47,799 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om3_1        | 2022-08-24 20:58:50,274 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2022-08-24 20:58:50,283 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
datanode2_1  | 2022-08-24 20:59:02,924 [55f25964-0507-4416-bd5f-134f8268daba-server-thread1] INFO segmented.SegmentedRaftLogWorker: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-08-24 20:59:02,928 [55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 55f25964-0507-4416-bd5f-134f8268daba@group-069052B7AC42-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42/current/log_inprogress_0
datanode2_1  | 2022-08-24 20:59:37,303 [java.util.concurrent.ThreadPoolExecutor$Worker@2f72872b[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5,entriesCount=1,lastEntry=(t:1, i:0)
datanode2_1  | 2022-08-24 20:59:38,946 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:1256322444158.
scm1.org_1   | 2022-08-24 20:56:39,447 [main] INFO impl.RoleInfo: 4c4be219-e818-4409-b18c-c29dce22a660: shutdown 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderStateImpl
scm1.org_1   | 2022-08-24 20:56:39,452 [main] INFO impl.PendingRequests: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-PendingRequests: sendNotLeaderResponses
om3_1        | 2022-08-24 20:58:50,652 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om3_1        | 2022-08-24 20:58:50,791 [Listener at om3/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
scm3.org_1   | 2022-08-24 20:57:22,949 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | 2022-08-24 20:57:22,950 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2022-08-24 20:57:22,950 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-08-24 20:56:39,454 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO impl.StateMachineUpdater: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2022-08-24 20:56:39,455 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO impl.StateMachineUpdater: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2022-08-24 20:56:39,455 [main] INFO impl.StateMachineUpdater: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2022-08-24 20:56:39,470 [main] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: closes. applyIndex: 0
om3_1        | 2022-08-24 20:58:50,821 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@968ebd0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2022-08-24 20:58:51,654 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36017
om3_1        | 2022-08-24 20:58:51,667 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-24 20:58:53,662 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5191049024ns, electionTimeout:5167ms
om3_1        | 2022-08-24 20:58:53,673 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om2_1        | 2022-08-24 20:58:48,018 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2022-08-24 20:58:48,023 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$452/0x00000008405b2040@129a9d88] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2022-08-24 20:58:48,025 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2022-08-24 20:58:48,025 [Listener at om2/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-08-24 21:00:55,988 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=267,entriesCount=1,lastEntry=(t:1, i:1)
datanode2_1  | 2022-08-24 21:00:55,998 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=268,entriesCount=1,lastEntry=(t:1, i:2)
datanode2_1  | 2022-08-24 21:00:56,094 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=270,entriesCount=1,lastEntry=(t:1, i:3)
s3g_1        | 2022-08-24 21:05:52,830 [qtp864326906-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg8, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:52,830 [qtp864326906-74] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg9, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:52,830 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg6, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:52,845 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg1, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
scm3.org_1   | 2022-08-24 20:57:22,955 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-08-24 20:57:22,956 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-08-24 20:57:22,956 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2022-08-24 20:59:01,188 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-08-24 20:59:01,188 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-08-24 20:59:01,192 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1        | 2022-08-24 20:59:01,192 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1      | 2022-08-24 20:58:27,011 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-08-24 20:58:27,023 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]].
recon_1      | 2022-08-24 20:58:27,034 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=0fca26ca-dda5-4802-a36e-c4a4d57205b6 reported by 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252176017931, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:27,140 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 87 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:27,141 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 88 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:27,142 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 89 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:29,143 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 90 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:29,146 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 91 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:29,149 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 92 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:31,152 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 93 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:31,153 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 94 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:31,154 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 95 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:31,350 [IPC Server handler 34 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-24 20:58:31,351 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=0fca26ca-dda5-4802-a36e-c4a4d57205b6 reported by 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1250283857425, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:31,951 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=0fca26ca-dda5-4802-a36e-c4a4d57205b6 reported by 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252176017931, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:33,155 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 96 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:33,158 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 97 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:33,158 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 98 failover attempts. Trying to failover after sleeping for 2000ms.
scm1.org_1   | 2022-08-24 20:56:39,471 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm1.org_1   | 2022-08-24 20:56:39,473 [main] INFO segmented.SegmentedRaftLogWorker: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker close()
scm1.org_1   | 2022-08-24 20:56:39,475 [main] INFO server.GrpcService: 4c4be219-e818-4409-b18c-c29dce22a660: shutdown server with port 9894 now
scm1.org_1   | 2022-08-24 20:56:39,481 [main] INFO server.GrpcService: 4c4be219-e818-4409-b18c-c29dce22a660: shutdown server with port 9894 successfully
scm1.org_1   | 2022-08-24 20:56:39,482 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$354/0x000000084031f040@6ed922e1] INFO util.JvmPauseMonitor: JvmPauseMonitor-4c4be219-e818-4409-b18c-c29dce22a660: Stopped
datanode2_1  | 2022-08-24 21:00:56,217 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=271,entriesCount=1,lastEntry=(t:1, i:4)
datanode2_1  | 2022-08-24 21:01:45,621 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=418,entriesCount=1,lastEntry=(t:1, i:5)
om3_1        | 2022-08-24 20:58:53,678 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2022-08-24 20:58:53,693 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2022-08-24 20:58:53,693 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1        | 2022-08-24 20:58:53,755 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-24 20:58:55,882 [grpc-default-executor-3] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-08-24 20:58:55,888 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-08-24 20:58:48,026 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2022-08-24 20:58:48,030 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-08-24 20:59:02,800 [635159ec-b87e-4c18-a398-f9f404aae830-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-069052B7AC42 with new leaderId: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
datanode3_1  | 2022-08-24 20:59:02,800 [635159ec-b87e-4c18-a398-f9f404aae830-server-thread1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: change Leader from null to 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2 at term 5 for appendEntries, leader elected after 25271ms
datanode3_1  | 2022-08-24 20:59:02,893 [635159ec-b87e-4c18-a398-f9f404aae830-server-thread1] INFO server.RaftServer$Division: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42: set configuration 0: [8a3aa5b1-7501-4e35-bc9c-199b5d065ff2|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 55f25964-0507-4416-bd5f-134f8268daba|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0, 635159ec-b87e-4c18-a398-f9f404aae830|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-24 20:59:02,895 [635159ec-b87e-4c18-a398-f9f404aae830-server-thread1] INFO segmented.SegmentedRaftLogWorker: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-08-24 20:59:02,896 [635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 635159ec-b87e-4c18-a398-f9f404aae830@group-069052B7AC42-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a574462d-c45e-4fde-830b-069052b7ac42/current/log_inprogress_0
datanode3_1  | 2022-08-24 20:59:38,783 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:1256322444158.
scm3.org_1   | 2022-08-24 20:57:22,968 [pool-16-thread-1] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2022-08-24 20:57:22,970 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-08-24 20:57:22,973 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm3.org_1   | 2022-08-24 20:57:22,978 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2022-08-24 20:57:22,979 [pool-16-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe does not exist. Creating ...
scm3.org_1   | 2022-08-24 20:57:23,006 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/in_use.lock acquired by nodename 6@scm3.org
scm3.org_1   | 2022-08-24 20:57:23,031 [pool-16-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe has been successfully formatted.
scm3.org_1   | 2022-08-24 20:57:23,036 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm3.org_1   | 2022-08-24 20:57:23,043 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2022-08-24 20:57:23,050 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2022-08-24 20:57:23,052 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-08-24 20:57:23,053 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-08-24 21:01:45,631 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=419,entriesCount=1,lastEntry=(t:1, i:6)
datanode2_1  | 2022-08-24 21:01:45,647 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=420,entriesCount=1,lastEntry=(t:1, i:7)
datanode2_1  | 2022-08-24 21:01:45,659 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=421,entriesCount=1,lastEntry=(t:1, i:8)
datanode2_1  | 2022-08-24 21:02:43,658 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=644,entriesCount=1,lastEntry=(t:1, i:9)
datanode2_1  | 2022-08-24 21:02:43,658 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=645,entriesCount=1,lastEntry=(t:1, i:10)
om2_1        | 2022-08-24 20:58:48,034 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1        | 2022-08-24 20:58:48,103 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2022-08-24 20:58:48,334 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2022-08-24 20:58:48,334 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2022-08-24 20:58:48,338 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2022-08-24 20:58:48,466 [Listener at om2/9862] INFO util.log: Logging initialized @45277ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2022-08-24 20:58:48,885 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2022-08-24 20:58:48,908 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2022-08-24 20:58:48,922 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2022-08-24 20:58:48,925 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2022-08-24 21:05:52,949 [qtp864326906-76] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg12, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,010 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg10, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,016 [qtp864326906-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg17, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,023 [qtp864326906-79] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg14, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,020 [qtp864326906-77] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg16, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,017 [qtp864326906-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg11, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,044 [qtp864326906-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg15, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,053 [qtp864326906-76] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg13, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,056 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg20, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,074 [qtp864326906-74] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg18, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,181 [qtp864326906-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg26, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,189 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg25, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,193 [qtp864326906-79] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg27, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,194 [qtp864326906-80] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg19, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,202 [qtp864326906-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg24, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,213 [qtp864326906-77] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg22, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,216 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg21, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,224 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg23, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,235 [qtp864326906-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg28, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,276 [qtp864326906-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg29, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,354 [qtp864326906-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg32, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,356 [qtp864326906-76] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg30, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,366 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg31, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,451 [qtp864326906-80] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg36, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,465 [qtp864326906-77] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg35, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,468 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg34, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,474 [qtp864326906-74] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg33, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,504 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg39, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,524 [qtp864326906-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg40, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,539 [qtp864326906-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg43, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,539 [qtp864326906-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg38, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,590 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg46, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,524 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg42, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,538 [qtp864326906-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg41, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,525 [qtp864326906-76] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg37, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,594 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg45, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,639 [qtp864326906-80] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg47, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,642 [qtp864326906-74] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg44, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,650 [qtp864326906-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg49, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,679 [qtp864326906-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg50, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,693 [qtp864326906-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg51, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,697 [qtp864326906-76] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg52, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,739 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg56, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,745 [qtp864326906-77] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg48, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,747 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg53, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,773 [qtp864326906-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg54, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,783 [qtp864326906-80] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg57, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,787 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg55, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,803 [qtp864326906-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg59, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,811 [qtp864326906-74] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg58, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,880 [qtp864326906-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg60, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,888 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg61, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,910 [qtp864326906-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg62, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,912 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg66, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,913 [qtp864326906-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg63, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,916 [qtp864326906-76] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg64, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,922 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg65, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,986 [qtp864326906-79] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg67, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:53,988 [qtp864326906-80] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg68, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,086 [qtp864326906-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg70, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,088 [qtp864326906-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg69, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,098 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg75, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,099 [qtp864326906-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg76, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,099 [qtp864326906-77] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg77, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,138 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg72, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,139 [qtp864326906-74] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg71, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,144 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg74, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,139 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg73, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,205 [qtp864326906-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg78, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,214 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg80, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,210 [qtp864326906-76] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg79, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,274 [qtp864326906-80] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg81, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,354 [qtp864326906-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg84, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om1_1        | 2022-08-24 20:59:01,192 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1        | 2022-08-24 20:59:01,192 [om1@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1        | 2022-08-24 20:59:01,192 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
scm1.org_1   | 2022-08-24 20:56:39,483 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-24 20:56:39,486 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-9f87aeec-f613-42f5-8bb5-cc84b7b042fe; layoutVersion=4; scmId=4c4be219-e818-4409-b18c-c29dce22a660
scm1.org_1   | 2022-08-24 20:56:39,499 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm1.org_1   | ************************************************************/
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-08-24 20:56:41,112 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | 2022-08-24 20:57:05,498 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om1_1        | 2022-08-24 20:59:01,192 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-08-24 20:59:01,194 [om1@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderStateImpl
om3_1        | 2022-08-24 20:58:55,889 [grpc-default-executor-3] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om3 at current term 1
om3_1        | 2022-08-24 20:58:55,961 [grpc-default-executor-3] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-24 20:58:55,961 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om3 at current term 1
datanode2_1  | 2022-08-24 21:02:43,683 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=646,entriesCount=1,lastEntry=(t:1, i:11)
datanode2_1  | 2022-08-24 21:02:43,695 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=647,entriesCount=1,lastEntry=(t:1, i:12)
datanode2_1  | 2022-08-24 21:05:41,395 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=876,entriesCount=1,lastEntry=(t:1, i:13)
datanode2_1  | 2022-08-24 21:05:41,395 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=877,entriesCount=1,lastEntry=(t:1, i:14)
datanode2_1  | 2022-08-24 21:05:41,396 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=878,entriesCount=1,lastEntry=(t:1, i:15)
datanode2_1  | 2022-08-24 21:05:41,405 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=879,entriesCount=1,lastEntry=(t:1, i:16)
datanode2_1  | 2022-08-24 21:05:43,852 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1053,entriesCount=1,lastEntry=(t:1, i:17)
datanode2_1  | 2022-08-24 21:05:43,863 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1054,entriesCount=1,lastEntry=(t:1, i:18)
datanode2_1  | 2022-08-24 21:05:43,864 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1055,entriesCount=1,lastEntry=(t:1, i:19)
datanode2_1  | 2022-08-24 21:05:43,891 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1058,entriesCount=1,lastEntry=(t:1, i:20)
scm2.org_1   | 2022-08-24 20:57:05,499 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm2.org_1   | 2022-08-24 20:57:05,499 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm2.org_1   | 2022-08-24 20:57:05,499 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm2.org_1   | 2022-08-24 20:57:05,502 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2022-08-24 20:57:05,502 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2022-08-24 20:57:05,503 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2022-08-24 20:57:05,771 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm2.org_1   | 2022-08-24 20:57:06,061 [main] INFO reflections.Reflections: Reflections took 235 ms to scan 3 urls, producing 110 keys and 247 values 
scm2.org_1   | 2022-08-24 20:57:06,198 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
om1_1        | 2022-08-24 20:59:01,220 [om1@group-562213E44849-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2022-08-24 20:59:01,273 [om1@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2022-08-24 20:59:01,429 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2022-08-24 20:58:55,967 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-24 20:58:56,014 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om3_1        | 2022-08-24 20:58:56,020 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:FAIL-t1
om2_1        | 2022-08-24 20:58:48,926 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2022-08-24 20:58:48,940 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2022-08-24 20:58:49,136 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2022-08-24 20:58:49,145 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om2_1        | 2022-08-24 20:58:49,285 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2022-08-24 20:58:49,290 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2022-08-24 20:58:49,292 [Listener at om2/9862] INFO server.session: node0 Scavenging every 600000ms
om2_1        | 2022-08-24 20:58:49,385 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-08-24 20:58:49,398 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@40bb73ff{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2022-08-24 20:58:49,399 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@56cdf69b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2022-08-24 20:58:49,799 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-08-24 20:58:49,867 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@253e74c2{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-5790862401230762842/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2022-08-24 20:58:49,922 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@713b2ee9{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2022-08-24 20:58:49,923 [Listener at om2/9862] INFO server.Server: Started @46734ms
om2_1        | 2022-08-24 20:58:49,930 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2022-08-24 20:58:49,930 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2022-08-24 20:58:49,936 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2022-08-24 20:58:49,961 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2022-08-24 20:58:49,937 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2022-08-24 20:58:50,225 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om2_1        | 2022-08-24 20:58:50,525 [Listener at om2/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om2_1        | 2022-08-24 20:58:50,583 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@67e38ad7] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2022-08-24 20:58:51,046 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37829
om2_1        | 2022-08-24 20:58:51,065 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-24 20:58:52,869 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5084062962ns, electionTimeout:5054ms
scm3.org_1   | 2022-08-24 20:57:23,211 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-08-24 20:57:23,232 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2022-08-24 20:57:23,232 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm3.org_1   | 2022-08-24 20:57:23,237 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe
scm3.org_1   | 2022-08-24 20:57:23,238 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2022-08-24 20:57:23,238 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm3.org_1   | 2022-08-24 20:57:23,239 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-08-24 20:57:23,240 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm3.org_1   | 2022-08-24 20:57:23,240 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2022-08-24 20:57:23,241 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm3.org_1   | 2022-08-24 20:57:23,241 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2022-08-24 20:57:23,241 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2022-08-24 20:59:01,738 [om1@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1        | [id: "om1"
om1_1        | address: "om1:9872"
om1_1        | , id: "om3"
om1_1        | address: "om3:9872"
om1_1        | , id: "om2"
om1_1        | address: "om2:9872"
om1_1        | ]
om1_1        | 2022-08-24 20:59:16,889 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40754
om1_1        | 2022-08-24 20:59:16,914 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 20:59:21,383 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40756
om1_1        | 2022-08-24 20:59:21,396 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 20:59:25,635 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40758
om1_1        | 2022-08-24 20:59:25,650 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 20:59:30,035 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40760
om1_1        | 2022-08-24 20:59:30,054 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 20:59:34,507 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40762
om1_1        | 2022-08-24 20:59:34,517 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 20:59:35,154 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om1_1        | 2022-08-24 20:59:35,346 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om1_1        | 2022-08-24 20:59:43,853 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40764
om1_1        | 2022-08-24 20:59:43,869 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 20:59:44,345 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40766
om1_1        | 2022-08-24 20:59:44,358 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 20:59:48,644 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40768
om1_1        | 2022-08-24 20:59:48,666 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-24 20:58:56,020 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om3<-om2#0:FAIL-t1
om3_1        | 2022-08-24 20:58:56,021 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om3_1        | 2022-08-24 20:58:56,024 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om3_1        | 2022-08-24 20:58:56,025 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om3_1        | 2022-08-24 20:58:56,026 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
recon_1      | 2022-08-24 20:58:33,345 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=0fca26ca-dda5-4802-a36e-c4a4d57205b6 reported by 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252176017931, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:35,159 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 99 failover attempts. Trying to failover immediately.
scm2.org_1   | 2022-08-24 20:57:06,202 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2022-08-24 20:57:06,209 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
datanode2_1  | 2022-08-24 21:05:48,006 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1234,entriesCount=1,lastEntry=(t:1, i:21)
datanode2_1  | 2022-08-24 21:05:48,010 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1235,entriesCount=1,lastEntry=(t:1, i:22)
datanode2_1  | 2022-08-24 21:05:48,020 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1236,entriesCount=1,lastEntry=(t:1, i:23)
datanode2_1  | 2022-08-24 21:05:48,021 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1237,entriesCount=1,lastEntry=(t:1, i:24)
datanode2_1  | 2022-08-24 21:05:54,612 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1255,entriesCount=1,lastEntry=(t:1, i:25)
datanode2_1  | 2022-08-24 21:05:54,622 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1256,entriesCount=1,lastEntry=(t:1, i:26)
datanode2_1  | 2022-08-24 21:05:54,630 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1257,entriesCount=1,lastEntry=(t:1, i:27)
datanode2_1  | 2022-08-24 21:05:54,630 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1258,entriesCount=1,lastEntry=(t:1, i:28)
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/20c45aee396f2e104367bfb3370d85938febb766 ; compiled by 'runner' on 2022-08-24T20:33Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
recon_1      | 2022-08-24 20:58:35,161 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 100 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:35,161 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 101 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:35,667 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56936
recon_1      | 2022-08-24 20:58:35,694 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 20:58:35,695 [IPC Server handler 18 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-24 20:58:35,696 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=0fca26ca-dda5-4802-a36e-c4a4d57205b6 reported by 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252470207979, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:35,696 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]] moved to OPEN state
recon_1      | 2022-08-24 20:58:36,588 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=a574462d-c45e-4fde-830b-069052b7ac42. Trying to get from SCM.
recon_1      | 2022-08-24 20:58:36,597 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: a574462d-c45e-4fde-830b-069052b7ac42, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:23.363Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-08-24 20:58:36,599 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a574462d-c45e-4fde-830b-069052b7ac42, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:23.363Z[UTC]].
recon_1      | 2022-08-24 20:58:36,600 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a574462d-c45e-4fde-830b-069052b7ac42 reported by 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252176017931, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:37,163 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 102 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:37,164 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 103 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:37,165 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 104 failover attempts. Trying to failover after sleeping for 2000ms.
om3_1        | 2022-08-24 20:58:59,981 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:47974
om3_1        | 2022-08-24 20:58:59,983 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2022-08-24 20:57:06,211 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2022-08-24 20:57:06,306 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2022-08-24 20:57:06,333 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-08-24 20:56:41,126 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-08-24 20:56:41,212 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-24 20:56:41,276 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-08-24 20:56:41,303 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-08-24 20:56:41,343 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-08-24 20:56:41,343 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-08-24 20:56:41,762 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
om3_1        | 2022-08-24 20:59:01,070 [grpc-default-executor-3] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 2, (t:0, i:~))
om3_1        | 2022-08-24 20:59:01,072 [grpc-default-executor-3] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om3_1        | 2022-08-24 20:59:01,074 [grpc-default-executor-3] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om1
om3_1        | 2022-08-24 20:59:01,077 [grpc-default-executor-3] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-08-24 20:59:01,077 [grpc-default-executor-3] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-08-24 20:59:01,077 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState was interrupted
scm3.org_1   | 2022-08-24 20:57:23,249 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm3.org_1   | 2022-08-24 20:57:23,250 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm3.org_1   | 2022-08-24 20:57:23,251 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2022-08-24 20:57:23,260 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-08-24 20:57:23,260 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-08-24 20:57:23,263 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm3.org_1   | 2022-08-24 20:57:23,265 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm3.org_1   | 2022-08-24 20:57:23,265 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm3.org_1   | 2022-08-24 20:57:23,266 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2022-08-24 20:57:23,267 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2022-08-24 20:57:23,268 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2022-08-24 20:57:06,339 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm2.org_1   | 2022-08-24 20:57:06,356 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2022-08-24 20:57:06,465 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2022-08-24 20:57:06,474 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm2.org_1   | 2022-08-24 20:57:06,484 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2022-08-24 20:57:06,484 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2022-08-24 20:57:06,487 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm2.org_1   | 2022-08-24 20:57:06,510 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm2.org_1   | 2022-08-24 20:57:06,516 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm2.org_1   | 2022-08-24 20:57:06,520 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm2.org_1   | 2022-08-24 20:57:06,578 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2022-08-24 20:57:06,617 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2022-08-24 20:57:06,698 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2022-08-24 20:57:06,727 [main] INFO UnderReplicatedQueueThread: Starting UnderReplicatedQueueThread Service.
scm2.org_1   | 2022-08-24 20:57:06,735 [main] INFO ha.SCMServiceManager: Registering service UnderReplicatedQueueThread.
scm2.org_1   | 2022-08-24 20:57:06,736 [main] INFO OverReplicatedQueueThread: Starting OverReplicatedQueueThread Service.
scm2.org_1   | 2022-08-24 20:57:06,737 [main] INFO ha.SCMServiceManager: Registering service OverReplicatedQueueThread.
scm2.org_1   | 2022-08-24 20:57:06,737 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
datanode2_1  | 2022-08-24 21:05:55,792 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1363,entriesCount=1,lastEntry=(t:1, i:29)
datanode2_1  | 2022-08-24 21:05:55,808 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1364,entriesCount=1,lastEntry=(t:1, i:30)
datanode2_1  | 2022-08-24 21:05:55,812 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1365,entriesCount=1,lastEntry=(t:1, i:31)
datanode2_1  | 2022-08-24 21:05:55,820 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1366,entriesCount=1,lastEntry=(t:1, i:32)
datanode2_1  | 2022-08-24 21:05:58,884 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1600,entriesCount=1,lastEntry=(t:1, i:33)
datanode2_1  | 2022-08-24 21:05:58,891 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1601,entriesCount=1,lastEntry=(t:1, i:34)
datanode2_1  | 2022-08-24 21:05:59,003 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1602,entriesCount=1,lastEntry=(t:1, i:35)
datanode2_1  | 2022-08-24 21:05:59,093 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1609,entriesCount=1,lastEntry=(t:1, i:36)
datanode2_1  | 2022-08-24 21:05:59,204 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1619,entriesCount=1,lastEntry=(t:1, i:37)
datanode2_1  | 2022-08-24 21:05:59,231 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1622,entriesCount=1,lastEntry=(t:1, i:38)
datanode2_1  | 2022-08-24 21:05:59,406 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1635,entriesCount=1,lastEntry=(t:1, i:39)
datanode2_1  | 2022-08-24 21:05:59,432 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1638,entriesCount=1,lastEntry=(t:1, i:40)
datanode2_1  | 2022-08-24 21:05:59,436 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1639,entriesCount=1,lastEntry=(t:1, i:41)
datanode2_1  | 2022-08-24 21:07:06,235 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1792,entriesCount=1,lastEntry=(t:1, i:42)
datanode2_1  | 2022-08-24 21:07:06,265 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1793,entriesCount=1,lastEntry=(t:1, i:43)
datanode2_1  | 2022-08-24 21:07:06,273 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1794,entriesCount=1,lastEntry=(t:1, i:44)
datanode2_1  | 2022-08-24 21:07:06,291 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1795,entriesCount=1,lastEntry=(t:1, i:45)
datanode2_1  | 2022-08-24 21:07:21,260 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2007,entriesCount=1,lastEntry=(t:1, i:46)
datanode2_1  | 2022-08-24 21:07:21,270 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2008,entriesCount=1,lastEntry=(t:1, i:47)
datanode2_1  | 2022-08-24 21:07:21,278 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2009,entriesCount=1,lastEntry=(t:1, i:48)
datanode2_1  | 2022-08-24 21:07:21,290 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2011,entriesCount=1,lastEntry=(t:1, i:49)
datanode2_1  | 2022-08-24 21:07:24,133 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2225,entriesCount=1,lastEntry=(t:1, i:50)
datanode2_1  | 2022-08-24 21:07:24,136 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2226,entriesCount=1,lastEntry=(t:1, i:51)
datanode2_1  | 2022-08-24 21:07:24,145 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2227,entriesCount=1,lastEntry=(t:1, i:52)
datanode2_1  | 2022-08-24 21:07:24,157 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2228,entriesCount=1,lastEntry=(t:1, i:53)
datanode2_1  | 2022-08-24 21:07:30,576 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2405,entriesCount=1,lastEntry=(t:1, i:54)
om3_1        | 2022-08-24 20:59:01,094 [grpc-default-executor-3] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:OK-t2. Peer's state: om3@group-562213E44849:t2, leader=null, voted=om1, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-24 20:59:01,336 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om1 at term 2 for appendEntries, leader elected after 19674ms
om3_1        | 2022-08-24 20:59:01,444 [om3-server-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2022-08-24 20:59:01,531 [om3-server-thread1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2022-08-24 20:59:01,742 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2022-08-24 20:59:04,513 [om3@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
scm1.org_1   | 2022-08-24 20:56:41,856 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2022-08-24 20:56:41,859 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/1170009537688.crt.
scm1.org_1   | 2022-08-24 20:56:41,865 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2022-08-24 20:56:41,969 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2022-08-24 20:56:41,969 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2022-08-24 20:56:42,015 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-24 20:56:42,149 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-24 20:56:42,402 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm1.org_1   | 2022-08-24 20:56:42,402 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm1.org_1   | 2022-08-24 20:56:42,454 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-08-24 20:56:42,472 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:4c4be219-e818-4409-b18c-c29dce22a660
scm1.org_1   | 2022-08-24 20:56:42,560 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-08-24 20:56:42,623 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
recon_1      | 2022-08-24 20:58:37,690 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a574462d-c45e-4fde-830b-069052b7ac42 reported by 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252470207979, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:38,274 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a574462d-c45e-4fde-830b-069052b7ac42 reported by 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1250283857425, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:39,166 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 105 failover attempts. Trying to failover immediately.
om2_1        | 2022-08-24 20:58:52,879 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
scm3.org_1   | 2022-08-24 20:57:23,311 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2022-08-24 20:57:23,312 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm3.org_1   | 2022-08-24 20:57:23,313 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm3.org_1   | 2022-08-24 20:57:23,313 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm3.org_1   | 2022-08-24 20:57:23,313 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm3.org_1   | 2022-08-24 20:57:23,355 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2022-08-24 20:57:23,356 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2022-08-24 20:57:23,356 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | [id: "om1"
om3_1        | address: "om1:9872"
om3_1        | , id: "om3"
om3_1        | address: "om3:9872"
om3_1        | , id: "om2"
om3_1        | address: "om2:9872"
om3_1        | ]
om2_1        | 2022-08-24 20:58:52,888 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2022-08-24 20:58:52,891 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2022-08-24 20:58:52,891 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1        | 2022-08-24 20:58:52,967 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
recon_1      | 2022-08-24 20:58:39,167 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 106 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:39,169 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 107 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:41,171 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 108 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:41,172 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 109 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:41,173 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 110 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:50,929 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 111 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:51,537 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
om1_1        | 2022-08-24 20:59:49,157 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40770
om1_1        | 2022-08-24 20:59:49,161 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 20:59:49,186 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om1_1        | 2022-08-24 20:59:53,750 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40772
om1_1        | 2022-08-24 20:59:53,775 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:00:02,005 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40774
om1_1        | 2022-08-24 21:00:02,019 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:00:03,363 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35245
om1_1        | 2022-08-24 21:00:03,371 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:00:06,733 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40776
om1_1        | 2022-08-24 21:00:06,749 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:00:07,261 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40778
om1_1        | 2022-08-24 21:00:07,265 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:00:07,285 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om1_1        | 2022-08-24 21:00:11,688 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40780
om1_1        | 2022-08-24 21:00:11,698 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:00:16,149 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40782
om1_1        | 2022-08-24 21:00:16,166 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:00:30,904 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40784
om1_1        | 2022-08-24 21:00:30,920 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:00:31,565 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:53130-source for user:testuser
om1_1        | 2022-08-24 21:00:35,178 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40786
om1_1        | 2022-08-24 21:00:35,199 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:00:35,775 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:53130-target for user:testuser
om1_1        | 2022-08-24 21:00:39,107 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40788
om1_1        | 2022-08-24 21:00:39,122 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:00:39,759 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 53130-source
om1_1        | 2022-08-24 21:00:43,293 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40790
om1_1        | 2022-08-24 21:00:43,307 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:00:51,655 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40792
om1_1        | 2022-08-24 21:00:51,681 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:00:52,281 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 53130-source
om1_1        | 2022-08-24 21:00:55,740 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40794
om1_1        | 2022-08-24 21:00:55,765 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:00:56,654 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 53130-target
om1_1        | 2022-08-24 21:00:59,844 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40798
om1_1        | 2022-08-24 21:00:59,887 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:01:00,343 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 53130-target
om1_1        | 2022-08-24 21:01:03,406 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46033
om1_1        | 2022-08-24 21:01:03,414 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:01:03,526 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40800
om1_1        | 2022-08-24 21:01:03,545 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:01:04,020 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 53130-target
om1_1        | 2022-08-24 21:01:07,276 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40802
om1_1        | 2022-08-24 21:01:07,292 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:01:11,141 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40804
om1_1        | 2022-08-24 21:01:11,153 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:01:14,839 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40806
om1_1        | 2022-08-24 21:01:14,856 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:01:18,365 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40808
om1_1        | 2022-08-24 21:01:18,386 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:01:22,305 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40810
om1_1        | 2022-08-24 21:01:22,324 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:01:26,186 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40812
om1_1        | 2022-08-24 21:01:26,345 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:01:26,817 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 53130-target
om1_1        | 2022-08-24 21:01:29,828 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40814
om1_1        | 2022-08-24 21:01:29,841 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:01:33,455 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40816
om1_1        | 2022-08-24 21:01:33,474 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:01:33,941 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 53130-target
scm2.org_1   | 2022-08-24 20:57:06,737 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-24 20:57:06,751 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm2.org_1   | 2022-08-24 20:57:06,756 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:57:06,759 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-08-24 20:57:06,817 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm2.org_1   | 2022-08-24 20:57:06,847 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-08-24 20:57:06,920 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm2.org_1   | 2022-08-24 20:57:09,073 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-08-24 20:57:09,106 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-08-24 20:57:09,130 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2022-08-24 20:57:09,215 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-08-24 20:57:09,226 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-08-24 20:57:09,230 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2022-08-24 20:57:09,350 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-08-24 20:57:09,449 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-08-24 20:57:09,454 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm2.org_1   | 2022-08-24 20:57:09,755 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm2.org_1   | 2022-08-24 20:57:09,766 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm2.org_1   | Container Balancer status:
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        false
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                                                Value
scm2.org_1   | Threshold                                          10
scm1.org_1   | 2022-08-24 20:56:42,624 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-24 20:56:42,624 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-08-24 20:56:42,625 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om2_1        | 2022-08-24 20:58:55,772 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-08-24 20:58:55,774 [grpc-default-executor-1] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om1: already has voted for om2 at current term 1
om2_1        | 2022-08-24 20:58:55,787 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-08-24 20:58:55,947 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-08-24 20:58:55,957 [grpc-default-executor-1] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om2 at current term 1
om2_1        | 2022-08-24 20:58:55,957 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-08-24 20:58:56,001 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om2_1        | 2022-08-24 20:58:56,001 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t1
om2_1        | 2022-08-24 20:58:56,001 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t1
om2_1        | 2022-08-24 20:58:56,002 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om2_1        | 2022-08-24 20:58:56,003 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om2_1        | 2022-08-24 20:58:56,003 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1        | 2022-08-24 20:58:56,004 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-08-24 20:58:59,933 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:48932
om2_1        | 2022-08-24 20:58:59,944 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-24 20:59:01,085 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 2, (t:0, i:~))
om2_1        | 2022-08-24 20:59:01,087 [grpc-default-executor-1] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: accept ELECTION from om1: our priority 0 <= candidate's priority 0
om2_1        | 2022-08-24 20:59:01,087 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om1
om2_1        | 2022-08-24 20:59:01,087 [grpc-default-executor-1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-08-24 20:59:01,087 [grpc-default-executor-1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-08-24 20:59:01,088 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState was interrupted
om2_1        | 2022-08-24 20:59:01,101 [grpc-default-executor-1] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:OK-t2. Peer's state: om2@group-562213E44849:t2, leader=null, voted=om1, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-08-24 20:59:01,334 [om2-server-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om1 at term 2 for appendEntries, leader elected after 20156ms
om2_1        | 2022-08-24 20:59:01,425 [om2-server-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2022-08-24 20:59:01,442 [om2-server-thread1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2022-08-24 20:59:01,649 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2022-08-24 20:59:04,406 [om2@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1        | [id: "om1"
om3_1        | 2022-08-24 20:59:35,288 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om3_1        | 2022-08-24 20:59:35,422 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om3_1        | 2022-08-24 20:59:49,183 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om3_1        | 2022-08-24 21:00:07,296 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om3_1        | 2022-08-24 21:00:31,569 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:53130-source for user:testuser
om3_1        | 2022-08-24 21:00:35,796 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:53130-target for user:testuser
om3_1        | 2022-08-24 21:00:39,762 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 53130-source
om3_1        | 2022-08-24 21:00:52,291 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 53130-source
om3_1        | 2022-08-24 21:00:56,659 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 53130-target
scm3.org_1   | 2022-08-24 20:57:23,619 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm3.org_1   | 2022-08-24 20:57:23,870 [main] INFO reflections.Reflections: Reflections took 187 ms to scan 3 urls, producing 110 keys and 247 values 
scm3.org_1   | 2022-08-24 20:57:24,066 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm1.org_1   | 2022-08-24 20:56:42,625 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-24 20:56:42,626 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-08-24 20:56:42,628 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-24 20:56:42,628 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2022-08-24 20:57:24,069 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2022-08-24 20:57:24,072 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2022-08-24 20:57:24,074 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2022-08-24 20:56:42,629 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-08-24 20:56:42,640 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2022-08-24 20:56:42,645 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2022-08-24 20:56:43,067 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-08-24 20:56:43,069 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm1.org_1   | 2022-08-24 20:56:43,069 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2022-08-24 20:56:43,070 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-08-24 20:56:43,070 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-08-24 20:56:43,072 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-08-24 20:56:43,074 [4c4be219-e818-4409-b18c-c29dce22a660-impl-thread1] INFO server.RaftServer: 4c4be219-e818-4409-b18c-c29dce22a660: found a subdirectory /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe
scm1.org_1   | 2022-08-24 20:56:43,080 [main] INFO server.RaftServer: 4c4be219-e818-4409-b18c-c29dce22a660: addNew group-CC84B7B042FE:[] returns group-CC84B7B042FE:java.util.concurrent.CompletableFuture@52a7928a[Not completed]
datanode2_1  | 2022-08-24 21:07:30,576 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2406,entriesCount=1,lastEntry=(t:1, i:55)
datanode2_1  | 2022-08-24 21:07:30,577 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2407,entriesCount=1,lastEntry=(t:1, i:56)
datanode2_1  | 2022-08-24 21:07:30,695 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2408,entriesCount=1,lastEntry=(t:1, i:57)
datanode2_1  | 2022-08-24 21:07:30,701 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2409,entriesCount=1,lastEntry=(t:1, i:58)
datanode2_1  | 2022-08-24 21:07:30,715 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2411,entriesCount=1,lastEntry=(t:1, i:59)
datanode2_1  | 2022-08-24 21:07:38,580 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2439,entriesCount=1,lastEntry=(t:1, i:60)
datanode2_1  | 2022-08-24 21:07:38,602 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2440,entriesCount=1,lastEntry=(t:1, i:61)
datanode2_1  | 2022-08-24 21:07:38,608 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2441,entriesCount=1,lastEntry=(t:1, i:62)
datanode2_1  | 2022-08-24 21:07:38,750 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2442,entriesCount=1,lastEntry=(t:1, i:63)
datanode2_1  | 2022-08-24 21:07:38,762 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2444,entriesCount=1,lastEntry=(t:1, i:64)
datanode2_1  | 2022-08-24 21:07:38,781 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2446,entriesCount=1,lastEntry=(t:1, i:65)
datanode2_1  | 2022-08-24 21:07:41,627 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2665,entriesCount=1,lastEntry=(t:1, i:66)
datanode2_1  | 2022-08-24 21:07:41,631 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2666,entriesCount=1,lastEntry=(t:1, i:67)
datanode2_1  | 2022-08-24 21:07:41,638 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2667,entriesCount=1,lastEntry=(t:1, i:68)
datanode2_1  | 2022-08-24 21:07:41,646 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2668,entriesCount=1,lastEntry=(t:1, i:69)
datanode2_1  | 2022-08-24 21:07:47,205 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2851,entriesCount=1,lastEntry=(t:1, i:70)
datanode2_1  | 2022-08-24 21:07:47,264 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2852,entriesCount=1,lastEntry=(t:1, i:71)
datanode2_1  | 2022-08-24 21:07:47,282 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2853,entriesCount=1,lastEntry=(t:1, i:72)
datanode2_1  | 2022-08-24 21:07:47,561 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2854,entriesCount=1,lastEntry=(t:1, i:73)
datanode2_1  | 2022-08-24 21:07:47,645 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2861,entriesCount=1,lastEntry=(t:1, i:74)
scm3.org_1   | 2022-08-24 20:57:24,137 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | 2022-08-24 20:57:24,152 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2022-08-24 20:57:24,154 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2022-08-24 20:57:24,168 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2022-08-24 20:57:24,260 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm3.org_1   | 2022-08-24 20:57:24,261 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2022-08-24 20:57:24,278 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm3.org_1   | 2022-08-24 20:57:24,284 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2022-08-24 20:57:24,298 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm3.org_1   | 2022-08-24 20:57:24,301 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm3.org_1   | 2022-08-24 20:57:24,313 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm3.org_1   | 2022-08-24 20:57:24,314 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm3.org_1   | 2022-08-24 20:57:24,384 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm3.org_1   | 2022-08-24 20:57:24,436 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm3.org_1   | 2022-08-24 20:57:24,543 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-08-24 20:57:24,578 [main] INFO UnderReplicatedQueueThread: Starting UnderReplicatedQueueThread Service.
scm3.org_1   | 2022-08-24 20:57:24,594 [main] INFO ha.SCMServiceManager: Registering service UnderReplicatedQueueThread.
scm3.org_1   | 2022-08-24 20:57:24,596 [main] INFO OverReplicatedQueueThread: Starting OverReplicatedQueueThread Service.
scm3.org_1   | 2022-08-24 20:57:24,596 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-24 20:57:24,597 [main] INFO ha.SCMServiceManager: Registering service OverReplicatedQueueThread.
scm3.org_1   | 2022-08-24 20:57:24,597 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2022-08-24 20:57:24,624 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
om3_1        | 2022-08-24 21:01:00,355 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 53130-target
om3_1        | 2022-08-24 21:01:04,031 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 53130-target
om3_1        | 2022-08-24 21:01:26,823 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 53130-target
om3_1        | 2022-08-24 21:01:33,950 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 53130-target
om3_1        | 2022-08-24 21:01:37,716 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 53130-source
om3_1        | 2022-08-24 21:02:56,642 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 53130-target
om3_1        | 2022-08-24 21:03:00,480 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:53130-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-24 21:03:04,353 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 53130-target
om3_1        | 2022-08-24 21:03:08,135 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:53130-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-24 21:03:28,068 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 53130-target
om3_1        | 2022-08-24 21:03:31,980 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 53130-target
om3_1        | 2022-08-24 21:03:35,795 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 53130-target
om3_1        | 2022-08-24 21:03:43,424 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 53130-target
scm1.org_1   | 2022-08-24 20:56:43,102 [pool-16-thread-1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660: new RaftServerImpl for group-CC84B7B042FE:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-08-24 20:56:43,103 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-08-24 20:56:43,103 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-08-24 20:56:43,103 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-08-24 20:56:43,104 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-08-24 20:56:43,104 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
scm2.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm2.org_1   | Max Size to Move per Iteration                     500GB
scm2.org_1   | Max Size Entering Target per Iteration             26GB
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 2022-08-24 20:56:43,104 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-08-24 20:56:43,109 [pool-16-thread-1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-08-24 20:56:43,110 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-08-24 20:56:43,112 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-08-24 20:56:43,112 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-08-24 20:56:43,119 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/in_use.lock acquired by nodename 6@scm1.org
scm1.org_1   | 2022-08-24 20:56:43,123 [pool-16-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=4c4be219-e818-4409-b18c-c29dce22a660} from /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/current/raft-meta
scm1.org_1   | 2022-08-24 20:56:43,147 [pool-16-thread-1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: set configuration 0: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-24 20:56:43,147 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-08-24 20:56:43,148 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-08-24 20:56:43,153 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-08-24 20:56:43,154 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-24 20:56:43,155 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2022-08-24 20:56:43,209 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-08-24 20:56:43,216 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-08-24 20:56:43,216 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-08-24 20:56:43,220 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe
scm1.org_1   | 2022-08-24 20:56:43,221 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-08-24 20:56:43,221 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-08-24 20:56:43,222 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-08-24 20:56:43,222 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-08-24 20:56:43,223 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-08-24 20:56:43,223 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-08-24 20:56:43,223 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-08-24 20:56:43,224 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-08-24 20:56:43,230 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | Max Size Leaving Source per Iteration              26GB
scm2.org_1   | 
scm2.org_1   | 2022-08-24 20:57:09,766 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-08-24 20:57:09,766 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm2.org_1   | 2022-08-24 20:57:09,793 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2022-08-24 20:57:09,810 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2022-08-24 20:57:09,817 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-impl-thread1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: start with initializing state, conf=-1: [], old=null
scm2.org_1   | 2022-08-24 20:57:09,822 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-impl-thread1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: changes role from      null to FOLLOWER at term 0 for startInitializing
scm2.org_1   | 2022-08-24 20:57:09,823 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CC84B7B042FE,id=9c76dfff-1a89-47d1-a1fa-c42b1e1bf147
scm2.org_1   | 2022-08-24 20:57:09,846 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147: start RPC server
scm2.org_1   | 2022-08-24 20:57:09,952 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147: GrpcService started, listening on 9894
scm2.org_1   | 2022-08-24 20:57:09,964 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2022-08-24 20:57:09,965 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$471/0x0000000840557040@322c70bc] INFO util.JvmPauseMonitor: JvmPauseMonitor-9c76dfff-1a89-47d1-a1fa-c42b1e1bf147: Started
scm2.org_1   | 2022-08-24 20:57:11,197 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: receive installSnapshot: 4c4be219-e818-4409-b18c-c29dce22a660->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2022-08-24 20:57:11,227 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2022-08-24 20:57:11,227 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: change Leader from null to 4c4be219-e818-4409-b18c-c29dce22a660 at term 2 for installSnapshot, leader elected after 6097ms
scm2.org_1   | 2022-08-24 20:57:11,229 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: Received notification to install snapshot at index 0
s3g_1        | 2022-08-24 21:05:54,366 [qtp864326906-77] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg85, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,366 [qtp864326906-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg82, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,368 [qtp864326906-76] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg88, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,369 [qtp864326906-20] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg86, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,372 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg89, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,374 [qtp864326906-74] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg83, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,380 [qtp864326906-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg90, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,382 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg87, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,503 [qtp864326906-80] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg91, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,509 [qtp864326906-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg97, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,542 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg96, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om2_1        | address: "om1:9872"
om2_1        | , id: "om3"
om2_1        | address: "om3:9872"
om2_1        | , id: "om2"
om2_1        | address: "om2:9872"
om2_1        | ]
om2_1        | 2022-08-24 20:59:35,258 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om2_1        | 2022-08-24 20:59:35,384 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om2_1        | 2022-08-24 20:59:49,202 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om2_1        | 2022-08-24 21:00:07,293 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om2_1        | 2022-08-24 21:00:31,592 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:53130-source for user:testuser
om2_1        | 2022-08-24 21:00:35,784 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:53130-target for user:testuser
om2_1        | 2022-08-24 21:00:39,769 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 53130-source
om2_1        | 2022-08-24 21:00:52,301 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 53130-source
om2_1        | 2022-08-24 21:00:56,676 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 53130-target
om2_1        | 2022-08-24 21:01:00,344 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 53130-target
om2_1        | 2022-08-24 21:01:04,028 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 53130-target
datanode2_1  | 2022-08-24 21:07:47,657 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2862,entriesCount=1,lastEntry=(t:1, i:75)
datanode2_1  | 2022-08-24 21:07:51,160 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2935,entriesCount=1,lastEntry=(t:1, i:76)
datanode2_1  | 2022-08-24 21:07:51,167 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2936,entriesCount=1,lastEntry=(t:1, i:77)
datanode2_1  | 2022-08-24 21:07:51,174 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2937,entriesCount=1,lastEntry=(t:1, i:78)
datanode2_1  | 2022-08-24 21:07:51,280 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2939,entriesCount=1,lastEntry=(t:1, i:79)
datanode2_1  | 2022-08-24 21:07:51,306 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2942,entriesCount=1,lastEntry=(t:1, i:80)
datanode2_1  | 2022-08-24 21:07:51,315 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2943,entriesCount=1,lastEntry=(t:1, i:81)
datanode2_1  | 2022-08-24 21:07:55,066 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3160,entriesCount=1,lastEntry=(t:1, i:82)
datanode2_1  | 2022-08-24 21:07:55,074 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3161,entriesCount=1,lastEntry=(t:1, i:83)
datanode2_1  | 2022-08-24 21:07:55,082 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3162,entriesCount=1,lastEntry=(t:1, i:84)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 112 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:52,066 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
scm3.org_1   | 2022-08-24 20:57:24,634 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:57:24,637 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-08-24 20:57:24,714 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | 2022-08-24 20:57:24,781 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-08-24 20:57:24,859 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm3.org_1   | 2022-08-24 20:57:26,018 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-08-24 20:57:26,035 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-08-24 20:57:26,040 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm3.org_1   | 2022-08-24 20:57:26,101 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-08-24 20:57:26,111 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-08-24 20:57:26,117 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2022-08-24 20:57:26,216 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-08-24 20:57:26,262 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-08-24 20:57:26,264 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm3.org_1   | 2022-08-24 20:57:26,529 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm3.org_1   | 2022-08-24 20:57:26,532 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | Container Balancer status:
scm3.org_1   | Key                            Value
scm3.org_1   | Running                        false
scm3.org_1   | Container Balancer Configuration values:
scm3.org_1   | Key                                                Value
s3g_1        | 2022-08-24 21:05:54,549 [qtp864326906-74] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg95, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
datanode2_1  | 2022-08-24 21:07:55,144 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3163,entriesCount=1,lastEntry=(t:1, i:85)
datanode2_1  | 2022-08-24 21:07:55,145 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3164,entriesCount=1,lastEntry=(t:1, i:86)
datanode2_1  | 2022-08-24 21:07:55,155 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3165,entriesCount=1,lastEntry=(t:1, i:87)
datanode2_1  | 2022-08-24 21:07:58,237 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3251,entriesCount=1,lastEntry=(t:1, i:88)
datanode2_1  | 2022-08-24 21:07:58,381 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3252,entriesCount=1,lastEntry=(t:1, i:89)
datanode2_1  | 2022-08-24 21:07:58,424 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3253,entriesCount=1,lastEntry=(t:1, i:90)
datanode2_1  | 2022-08-24 21:07:58,424 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3254,entriesCount=1,lastEntry=(t:1, i:91)
datanode2_1  | 2022-08-24 21:07:58,473 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3256,entriesCount=1,lastEntry=(t:1, i:92)
datanode2_1  | 2022-08-24 21:07:58,571 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3264,entriesCount=1,lastEntry=(t:1, i:93)
datanode2_1  | 2022-08-24 21:07:58,581 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3266,entriesCount=1,lastEntry=(t:1, i:94)
datanode2_1  | 2022-08-24 21:07:58,606 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3269,entriesCount=1,lastEntry=(t:1, i:95)
datanode2_1  | 2022-08-24 21:08:03,818 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3520,entriesCount=1,lastEntry=(t:1, i:96)
datanode2_1  | 2022-08-24 21:08:03,821 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3521,entriesCount=1,lastEntry=(t:1, i:97)
datanode2_1  | 2022-08-24 21:08:03,838 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3522,entriesCount=1,lastEntry=(t:1, i:98)
datanode2_1  | 2022-08-24 21:08:03,846 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3524,entriesCount=1,lastEntry=(t:1, i:99)
datanode2_1  | 2022-08-24 21:08:08,375 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3747,entriesCount=1,lastEntry=(t:1, i:100)
datanode2_1  | 2022-08-24 21:08:08,450 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3748,entriesCount=1,lastEntry=(t:1, i:101)
datanode2_1  | 2022-08-24 21:08:08,464 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3749,entriesCount=1,lastEntry=(t:1, i:102)
datanode2_1  | 2022-08-24 21:08:08,480 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3750,entriesCount=1,lastEntry=(t:1, i:103)
datanode2_1  | 2022-08-24 21:08:08,590 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3752,entriesCount=1,lastEntry=(t:1, i:104)
datanode2_1  | 2022-08-24 21:08:08,629 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3756,entriesCount=1,lastEntry=(t:1, i:105)
datanode2_1  | 2022-08-24 21:08:08,636 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3757,entriesCount=1,lastEntry=(t:1, i:106)
s3g_1        | 2022-08-24 21:05:54,551 [qtp864326906-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg93, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,548 [qtp864326906-77] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg98, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,564 [qtp864326906-76] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg99, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:05:54,577 [qtp864326906-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg92, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om3_1        | 2022-08-24 21:04:11,071 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 53130-target
om3_1        | 2022-08-24 21:04:14,789 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:53130-target
om3_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-24 21:04:33,984 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8166617629 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:04:39,558 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4164878180 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:04:54,035 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0970255710 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:04:54,539 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-ypmpvjoaev of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:01,946 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-dvkabsedjt of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:11,598 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3304228662 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:12,160 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6346790541 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:12,731 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7884169516 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:13,339 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-7884169516 in volume:s3v
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm2.org_1   | 2022-08-24 20:57:11,231 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm2.org_1   | 2022-08-24 20:57:11,433 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "4c4be219-e818-4409-b18c-c29dce22a660"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-08-24 20:57:11,441 [grpc-default-executor-0] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: set configuration 1: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-24 20:57:11,445 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: reply installSnapshot: 4c4be219-e818-4409-b18c-c29dce22a660<-9c76dfff-1a89-47d1-a1fa-c42b1e1bf147#0:FAIL-t0,ALREADY_INSTALLED
scm2.org_1   | 2022-08-24 20:57:11,467 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147: Completed INSTALL_SNAPSHOT, lastRequest: 4c4be219-e818-4409-b18c-c29dce22a660->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2022-08-24 20:57:11,542 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO impl.RoleInfo: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147: start 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-FollowerState
scm2.org_1   | 2022-08-24 20:57:11,547 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2022-08-24 20:57:11,549 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: inconsistency entries. Reply:4c4be219-e818-4409-b18c-c29dce22a660<-9c76dfff-1a89-47d1-a1fa-c42b1e1bf147#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-08-24 20:57:11,570 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2022-08-24 20:57:11,570 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: inconsistency entries. Reply:4c4be219-e818-4409-b18c-c29dce22a660<-9c76dfff-1a89-47d1-a1fa-c42b1e1bf147#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-08-24 20:57:11,580 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: set configuration 0: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-24 20:57:11,580 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: set configuration 1: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-24 20:57:11,601 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO segmented.SegmentedRaftLogWorker: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-SegmentedRaftLogWorker: Starting segment from index:0
s3g_1        | 2022-08-24 21:05:54,577 [qtp864326906-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg94, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:06:01,258 [qtp864326906-25] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6750200698, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:07:27,511 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5414616179, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:07:28,071 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-57355, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:07:44,708 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-3239440474, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:08:02,573 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8302286888, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:08:11,299 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0355249610, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:11:12,663 [qtp864326906-21] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #179 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:104)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:409)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:569)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:583)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:145)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:493)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:467)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:520)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:262)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om2_1        | 2022-08-24 21:01:26,829 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 53130-target
om2_1        | 2022-08-24 21:01:33,954 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 53130-target
om2_1        | 2022-08-24 21:01:37,715 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 53130-source
om2_1        | 2022-08-24 21:02:56,640 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 53130-target
om2_1        | 2022-08-24 21:03:00,485 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:53130-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 113 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:53,885 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56938
recon_1      | 2022-08-24 20:58:53,907 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 20:58:53,908 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a574462d-c45e-4fde-830b-069052b7ac42 reported by 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252470207979, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:53,909 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=6149d847-7841-4389-9c66-a4f4eafa6589. Trying to get from SCM.
recon_1      | 2022-08-24 20:58:54,046 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 6149d847-7841-4389-9c66-a4f4eafa6589, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:22.136Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-08-24 20:58:54,047 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6149d847-7841-4389-9c66-a4f4eafa6589, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:22.136Z[UTC]].
recon_1      | 2022-08-24 20:58:54,047 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=6149d847-7841-4389-9c66-a4f4eafa6589 reported by 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252470207979, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-08-24 20:56:43,231 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2022-08-24 20:56:43,238 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-08-24 20:56:43,260 [pool-16-thread-1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: set configuration 0: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-24 20:56:43,261 [pool-16-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/current/log_inprogress_0
scm1.org_1   | 2022-08-24 20:56:43,263 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-24 20:56:43,263 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-08-24 20:56:43,310 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-08-24 20:56:43,311 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-08-24 20:56:43,312 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-24 21:03:04,340 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 53130-target
om2_1        | 2022-08-24 21:03:08,127 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:53130-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 2022-08-24 21:01:37,155 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40818
om1_1        | 2022-08-24 21:01:37,170 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:01:37,710 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 53130-source
scm3.org_1   | Threshold                                          10
scm3.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm3.org_1   | Max Size to Move per Iteration                     500GB
scm3.org_1   | Max Size Entering Target per Iteration             26GB
scm3.org_1   | Max Size Leaving Source per Iteration              26GB
om1_1        | 2022-08-24 21:01:41,046 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40820
om1_1        | 2022-08-24 21:01:41,063 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:01:49,036 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40822
om1_1        | 2022-08-24 21:01:49,053 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:01:54,809 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40824
om1_1        | 2022-08-24 21:01:54,835 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm1.org_1   | 2022-08-24 20:56:43,312 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-08-24 20:56:43,313 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-08-24 20:56:43,314 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-08-24 20:56:43,363 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-08-24 20:56:43,364 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2022-08-24 20:56:43,364 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-08-24 21:08:08,638 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3758,entriesCount=1,lastEntry=(t:1, i:107)
datanode2_1  | 2022-08-24 21:08:28,771 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4015,entriesCount=1,lastEntry=(t:1, i:108)
datanode2_1  | 2022-08-24 21:08:28,773 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4016,entriesCount=1,lastEntry=(t:1, i:109)
datanode2_1  | 2022-08-24 21:08:28,778 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4018,entriesCount=1,lastEntry=(t:1, i:110)
datanode2_1  | 2022-08-24 21:08:28,790 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4020,entriesCount=1,lastEntry=(t:1, i:111)
datanode2_1  | 2022-08-24 21:08:33,835 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4264,entriesCount=1,lastEntry=(t:1, i:112)
datanode2_1  | 2022-08-24 21:08:33,847 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4265,entriesCount=1,lastEntry=(t:1, i:113)
datanode2_1  | 2022-08-24 21:08:33,859 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4266,entriesCount=1,lastEntry=(t:1, i:114)
datanode2_1  | 2022-08-24 21:08:33,879 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4267,entriesCount=1,lastEntry=(t:1, i:115)
datanode2_1  | 2022-08-24 21:08:45,374 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4503,entriesCount=1,lastEntry=(t:1, i:116)
datanode2_1  | 2022-08-24 21:08:45,382 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4504,entriesCount=1,lastEntry=(t:1, i:117)
datanode2_1  | 2022-08-24 21:08:45,382 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4505,entriesCount=1,lastEntry=(t:1, i:118)
datanode2_1  | 2022-08-24 21:08:45,388 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4506,entriesCount=1,lastEntry=(t:1, i:119)
datanode2_1  | 2022-08-24 21:08:50,144 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4591,entriesCount=1,lastEntry=(t:1, i:120)
datanode2_1  | 2022-08-24 21:08:50,144 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4592,entriesCount=1,lastEntry=(t:1, i:121)
datanode2_1  | 2022-08-24 21:08:50,148 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4593,entriesCount=1,lastEntry=(t:1, i:122)
datanode2_1  | 2022-08-24 21:08:50,171 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4595,entriesCount=1,lastEntry=(t:1, i:123)
datanode2_1  | 2022-08-24 21:09:11,956 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4710,entriesCount=1,lastEntry=(t:1, i:124)
datanode2_1  | 2022-08-24 21:09:11,957 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4711,entriesCount=1,lastEntry=(t:1, i:125)
datanode2_1  | 2022-08-24 21:09:11,963 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4712,entriesCount=1,lastEntry=(t:1, i:126)
datanode2_1  | 2022-08-24 21:09:11,967 [java.util.concurrent.ThreadPoolExecutor$Worker@4a4de0a0[State = -1, empty queue]] WARN server.GrpcLogAppender: 55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6->635159ec-b87e-4c18-a398-f9f404aae830-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4713,entriesCount=1,lastEntry=(t:1, i:127)
datanode2_1  | 2022-08-24 21:11:13,596 [null-request--thread5] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-9D90226B0BD8->55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6, cid=179, seq=0, Watch-ALL_COMMITTED(129), Message:<EMPTY>, reply=RaftClientReply:client-9D90226B0BD8->55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6, cid=179, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 179 and log index 129 is not yet replicated to ALL_COMMITTED, logIndex=129, commits[55f25964-0507-4416-bd5f-134f8268daba:c139, 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2:c139, 635159ec-b87e-4c18-a398-f9f404aae830:c127]
scm2.org_1   | 2022-08-24 20:57:11,627 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO segmented.SegmentedRaftLogWorker: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm2.org_1   | 2022-08-24 20:57:11,646 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread2] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: set configuration 7: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-08-24 20:57:11,652 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: set configuration 0: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-24 20:57:11,652 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: set configuration 1: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-24 20:57:11,653 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: set configuration 7: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-08-24 20:57:11,902 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/current/log_inprogress_0
scm2.org_1   | 2022-08-24 20:57:11,908 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/current/log_inprogress_0 to /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/current/log_0-0
scm2.org_1   | 2022-08-24 20:57:11,934 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/current/log_inprogress_1
scm2.org_1   | 2022-08-24 20:57:11,977 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 
scm3.org_1   | 2022-08-24 20:57:26,536 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-08-24 20:57:26,536 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm3.org_1   | 2022-08-24 20:57:26,568 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2022-08-24 20:57:26,576 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
om1_1        | 2022-08-24 21:02:01,209 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40826
om1_1        | 2022-08-24 21:02:01,231 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:03,472 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43607
om1_1        | 2022-08-24 21:02:03,482 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:07,132 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40828
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-24 21:05:14,719 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4696656892 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:24,237 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5953658177 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:24,807 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0264810494 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:25,953 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-1287075521 in volume:s3v
om3_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2498)
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2468)
om3_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-24 21:05:31,610 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8426919085 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:38,221 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9156506742 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:52,857 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg0 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-24 20:56:43,365 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2022-08-24 20:56:43,365 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2022-08-24 20:56:43,367 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2022-08-24 20:56:43,367 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2022-08-24 20:56:43,368 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2022-08-24 20:56:43,516 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm1.org_1   | 2022-08-24 20:56:43,647 [main] INFO reflections.Reflections: Reflections took 101 ms to scan 3 urls, producing 110 keys and 247 values 
scm1.org_1   | 2022-08-24 20:56:43,722 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm1.org_1   | 2022-08-24 20:56:43,722 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
recon_1      | 2022-08-24 20:58:54,047 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6149d847-7841-4389-9c66-a4f4eafa6589, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:635159ec-b87e-4c18-a398-f9f404aae830, CreationTimestamp2022-08-24T20:58:22.136Z[UTC]] moved to OPEN state
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-24 21:03:28,061 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 53130-target
om2_1        | 2022-08-24 21:03:31,985 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 53130-target
om2_1        | 2022-08-24 21:03:35,781 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 53130-target
om2_1        | 2022-08-24 21:03:43,419 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 53130-target
om2_1        | 2022-08-24 21:04:11,066 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 53130-target
om2_1        | 2022-08-24 21:04:14,767 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:53130-target
om2_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-24 21:04:33,976 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8166617629 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:04:39,551 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4164878180 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:04:54,025 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0970255710 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:04:54,539 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-ypmpvjoaev of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:01,916 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-dvkabsedjt of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:11,600 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3304228662 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:12,173 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6346790541 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:12,737 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7884169516 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:13,336 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-7884169516 in volume:s3v
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-24 21:05:14,735 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4696656892 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:24,241 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5953658177 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:24,811 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0264810494 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:25,956 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-1287075521 in volume:s3v
om2_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2498)
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2468)
om2_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
recon_1      | 2022-08-24 20:58:54,058 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36714
recon_1      | 2022-08-24 20:58:54,074 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 114 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:54,084 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 20:58:54,086 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=f0d2bb84-a865-4722-a590-71cdb3c1bbab. Trying to get from SCM.
recon_1      | 2022-08-24 20:58:54,095 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: f0d2bb84-a865-4722-a590-71cdb3c1bbab, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:21.661Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-08-24 20:58:54,097 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f0d2bb84-a865-4722-a590-71cdb3c1bbab, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:21.661Z[UTC]].
recon_1      | 2022-08-24 20:58:54,104 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=f0d2bb84-a865-4722-a590-71cdb3c1bbab reported by 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1250283857425, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:54,104 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f0d2bb84-a865-4722-a590-71cdb3c1bbab, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, CreationTimestamp2022-08-24T20:58:21.661Z[UTC]] moved to OPEN state
recon_1      | 2022-08-24 20:58:54,107 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a574462d-c45e-4fde-830b-069052b7ac42 reported by 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1250283857425, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:54,109 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 115 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:54,116 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 116 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:56,120 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 117 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:56,123 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
scm3.org_1   | 2022-08-24 20:57:26,577 [32d0e816-7836-4618-b71b-8792003f2e21-impl-thread1] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: start with initializing state, conf=-1: [], old=null
scm3.org_1   | 2022-08-24 20:57:26,578 [32d0e816-7836-4618-b71b-8792003f2e21-impl-thread1] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2022-08-24 20:57:26,582 [32d0e816-7836-4618-b71b-8792003f2e21-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CC84B7B042FE,id=32d0e816-7836-4618-b71b-8792003f2e21
scm3.org_1   | 2022-08-24 20:57:26,584 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 32d0e816-7836-4618-b71b-8792003f2e21: start RPC server
scm3.org_1   | 2022-08-24 20:57:26,742 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 32d0e816-7836-4618-b71b-8792003f2e21: GrpcService started, listening on 9894
om1_1        | 2022-08-24 21:02:07,148 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:11,305 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40830
om1_1        | 2022-08-24 21:02:11,323 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:15,423 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40832
om1_1        | 2022-08-24 21:02:15,436 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:19,290 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40834
om1_1        | 2022-08-24 21:02:19,313 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:23,221 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40836
scm2.org_1   | 2022-08-24 20:57:11,978 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2022-08-24 20:57:11,979 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-08-24 20:57:11,980 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2022-08-24 20:57:11,994 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm2.org_1   | 2022-08-24 20:57:12,003 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-08-24 20:57:12,151 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: set configuration 9: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-24 20:57:12,333 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-CC84B7B042FE:[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-08-24 20:57:12,350 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2022-08-24 20:57:12,355 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm2.org_1   | 2022-08-24 20:57:12,355 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm3.org_1   | 2022-08-24 20:57:26,770 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$468/0x0000000840560440@6ec9f664] INFO util.JvmPauseMonitor: JvmPauseMonitor-32d0e816-7836-4618-b71b-8792003f2e21: Started
scm3.org_1   | 2022-08-24 20:57:26,776 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm1.org_1   | 2022-08-24 20:56:43,726 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2022-08-24 20:56:43,727 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2022-08-24 20:56:43,801 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2022-08-24 20:56:43,815 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2022-08-24 20:56:43,816 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm1.org_1   | 2022-08-24 20:56:43,825 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm1.org_1   | 2022-08-24 20:56:43,877 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm1.org_1   | 2022-08-24 20:56:43,877 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm1.org_1   | 2022-08-24 20:56:43,883 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm1.org_1   | 2022-08-24 20:56:43,884 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm1.org_1   | 2022-08-24 20:56:43,886 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm1.org_1   | 2022-08-24 20:56:43,889 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm1.org_1   | 2022-08-24 20:56:43,894 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm1.org_1   | 2022-08-24 20:56:43,895 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm1.org_1   | 2022-08-24 20:56:43,931 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2022-08-24 20:56:43,953 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2022-08-24 20:56:43,999 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2022-08-24 20:56:44,025 [main] INFO UnderReplicatedQueueThread: Starting UnderReplicatedQueueThread Service.
scm1.org_1   | 2022-08-24 20:56:44,026 [main] INFO ha.SCMServiceManager: Registering service UnderReplicatedQueueThread.
scm1.org_1   | 2022-08-24 20:56:44,030 [main] INFO OverReplicatedQueueThread: Starting OverReplicatedQueueThread Service.
scm1.org_1   | 2022-08-24 20:56:44,029 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-08-24 20:56:44,031 [main] INFO ha.SCMServiceManager: Registering service OverReplicatedQueueThread.
scm1.org_1   | 2022-08-24 20:56:44,031 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2022-08-24 20:56:44,041 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2022-08-24 20:57:29,785 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: receive installSnapshot: 4c4be219-e818-4409-b18c-c29dce22a660->32d0e816-7836-4618-b71b-8792003f2e21#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2022-08-24 20:57:29,839 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm3.org_1   | 2022-08-24 20:57:29,839 [grpc-default-executor-0] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: change Leader from null to 4c4be219-e818-4409-b18c-c29dce22a660 at term 2 for installSnapshot, leader elected after 6803ms
scm3.org_1   | 2022-08-24 20:57:29,871 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: Received notification to install snapshot at index 0
scm3.org_1   | 2022-08-24 20:57:29,887 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm3.org_1   | 2022-08-24 20:57:30,636 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "4c4be219-e818-4409-b18c-c29dce22a660"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "9c76dfff-1a89-47d1-a1fa-c42b1e1bf147"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-08-24 20:57:30,643 [grpc-default-executor-0] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: set configuration 9: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-24 20:57:30,661 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: reply installSnapshot: 4c4be219-e818-4409-b18c-c29dce22a660<-32d0e816-7836-4618-b71b-8792003f2e21#0:FAIL-t0,ALREADY_INSTALLED
scm3.org_1   | 2022-08-24 20:57:30,694 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 32d0e816-7836-4618-b71b-8792003f2e21: Completed INSTALL_SNAPSHOT, lastRequest: 4c4be219-e818-4409-b18c-c29dce22a660->32d0e816-7836-4618-b71b-8792003f2e21#0-t2,notify:(t:1, i:0)
om1_1        | 2022-08-24 21:02:23,241 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:27,661 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40838
om1_1        | 2022-08-24 21:02:27,680 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:31,974 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40840
om1_1        | 2022-08-24 21:02:31,996 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:36,003 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40842
om1_1        | 2022-08-24 21:02:36,031 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:40,058 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40844
om1_1        | 2022-08-24 21:02:40,077 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:44,091 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40846
om1_1        | 2022-08-24 21:02:44,107 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:47,915 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40848
om1_1        | 2022-08-24 21:02:47,931 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:51,856 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40850
om1_1        | 2022-08-24 21:02:51,868 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:55,890 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40852
datanode2_1  | 2022-08-24 21:12:13,590 [null-request--thread5] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-50D7ECCEEBF5->55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6, cid=183, seq=0, Watch-ALL_COMMITTED(134), Message:<EMPTY>, reply=RaftClientReply:client-50D7ECCEEBF5->55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6, cid=183, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 183 and log index 134 is not yet replicated to ALL_COMMITTED, logIndex=134, commits[55f25964-0507-4416-bd5f-134f8268daba:c143, 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2:c143, 635159ec-b87e-4c18-a398-f9f404aae830:c127]
datanode2_1  | 2022-08-24 21:13:14,590 [null-request--thread5] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-98CAF5A3B0C5->55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6, cid=187, seq=0, Watch-ALL_COMMITTED(138), Message:<EMPTY>, reply=RaftClientReply:client-98CAF5A3B0C5->55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6, cid=187, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 187 and log index 138 is not yet replicated to ALL_COMMITTED, logIndex=138, commits[55f25964-0507-4416-bd5f-134f8268daba:c147, 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2:c147, 635159ec-b87e-4c18-a398-f9f404aae830:c127]
datanode2_1  | 2022-08-24 21:14:16,591 [null-request--thread5] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-58C688846B6D->55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6, cid=192, seq=0, Watch-ALL_COMMITTED(142), Message:<EMPTY>, reply=RaftClientReply:client-58C688846B6D->55f25964-0507-4416-bd5f-134f8268daba@group-C4A4D57205B6, cid=192, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 192 and log index 142 is not yet replicated to ALL_COMMITTED, logIndex=142, commits[55f25964-0507-4416-bd5f-134f8268daba:c151, 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2:c151, 635159ec-b87e-4c18-a398-f9f404aae830:c127]
scm2.org_1   | 2022-08-24 20:57:12,350 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:57:12,360 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm2.org_1   | 2022-08-24 20:57:12,360 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm2.org_1   | 2022-08-24 20:57:12,410 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:57:12,619 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2022-08-24 20:57:12,638 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2022-08-24 20:57:12,638 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2022-08-24 20:57:13,159 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2022-08-24 20:57:13,171 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-08-24 20:57:13,198 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2022-08-24 20:57:13,202 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2022-08-24 20:57:13,211 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2022-08-24 20:57:13,211 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-08-24 20:57:13,214 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2022-08-24 20:57:13,280 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2022-08-24 20:57:13,283 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-08-24 20:57:13,291 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2022-08-24 20:57:13,300 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2022-08-24 20:57:13,402 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-08-24 20:57:13,408 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-08-24 20:57:13,408 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2022-08-24 20:57:13,758 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147
scm2.org_1   | 2022-08-24 20:57:13,768 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1170009537688 on Scm Bootstrap Node 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147
scm2.org_1   | 2022-08-24 20:57:13,814 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7e47a922] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm2.org_1   | 2022-08-24 20:57:13,840 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2022-08-24 20:57:13,841 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm2.org_1   | 2022-08-24 20:57:13,846 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2022-08-24 20:57:13,914 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @17344ms to org.eclipse.jetty.util.log.Slf4jLog
scm2.org_1   | 2022-08-24 20:57:14,235 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2022-08-24 20:57:14,250 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2022-08-24 20:57:14,253 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm2.org_1   | 2022-08-24 20:57:14,253 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2022-08-24 21:05:52,860 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg2 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:52,885 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg4 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:52,887 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg5 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:52,899 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg3 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:52,900 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg1 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:52,941 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg7 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:52,951 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg8 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:52,987 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg6 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:52,989 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg9 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:52,992 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg12 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,067 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg10 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,073 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg11 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:02:55,906 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:02:56,635 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 53130-target
om1_1        | 2022-08-24 21:02:59,891 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40854
om1_1        | 2022-08-24 21:02:59,919 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:03:00,455 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:53130-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:03:03,540 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37663
om1_1        | 2022-08-24 21:03:03,543 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:03:03,763 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40856
om1_1        | 2022-08-24 21:03:03,778 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:03:04,332 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 53130-target
om1_1        | 2022-08-24 21:03:07,546 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40858
om1_1        | 2022-08-24 21:03:07,563 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:03:08,119 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:53130-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:03:11,508 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40860
om1_1        | 2022-08-24 21:03:11,531 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:03:15,967 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40862
om1_1        | 2022-08-24 21:03:15,993 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:03:16,545 [IPC Server handler 18 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket Volume:53130-target Bucket:unreadable-link 
om1_1        | 2022-08-24 21:03:19,737 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40864
scm3.org_1   | 2022-08-24 20:57:30,843 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread1] INFO impl.RoleInfo: 32d0e816-7836-4618-b71b-8792003f2e21: start 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-FollowerState
scm3.org_1   | 2022-08-24 20:57:30,871 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread1] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm3.org_1   | 2022-08-24 20:57:30,890 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread1] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: inconsistency entries. Reply:4c4be219-e818-4409-b18c-c29dce22a660<-32d0e816-7836-4618-b71b-8792003f2e21#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-08-24 20:57:30,940 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread2] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm3.org_1   | 2022-08-24 20:57:30,941 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread2] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: inconsistency entries. Reply:4c4be219-e818-4409-b18c-c29dce22a660<-32d0e816-7836-4618-b71b-8792003f2e21#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-08-24 20:57:30,967 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread1] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: set configuration 0: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-24 20:57:30,967 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread1] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: set configuration 1: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-24 20:57:30,968 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread1] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: set configuration 7: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-08-24 20:57:30,969 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread1] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: set configuration 9: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-24 20:57:30,973 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread1] INFO segmented.SegmentedRaftLogWorker: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-SegmentedRaftLogWorker: Starting segment from index:0
scm3.org_1   | 2022-08-24 20:57:31,115 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread1] INFO segmented.SegmentedRaftLogWorker: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm3.org_1   | 2022-08-24 20:57:31,128 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread2] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: set configuration 0: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-24 20:57:31,129 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread2] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: set configuration 1: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-24 20:57:31,129 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread2] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: set configuration 7: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-08-24 20:57:31,129 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread2] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: set configuration 9: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-24 20:57:31,395 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/current/log_inprogress_0
scm3.org_1   | 2022-08-24 20:57:31,406 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/current/log_inprogress_0 to /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/current/log_0-0
scm3.org_1   | 2022-08-24 20:57:31,550 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/current/log_inprogress_1
scm3.org_1   | 2022-08-24 20:57:31,606 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:57:31,606 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm3.org_1   | 2022-08-24 20:57:31,610 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-08-24 20:57:31,611 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2022-08-24 20:57:31,669 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-08-24 20:57:31,922 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm3.org_1   | 2022-08-24 20:57:32,190 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread2] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: set configuration 13: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 32d0e816-7836-4618-b71b-8792003f2e21|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-08-24 20:57:32,239 [32d0e816-7836-4618-b71b-8792003f2e21-server-thread2] INFO server.RaftServer$Division: 32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE: set configuration 15: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 32d0e816-7836-4618-b71b-8792003f2e21|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-24 20:57:32,341 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-CC84B7B042FE:[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 32d0e816-7836-4618-b71b-8792003f2e21|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-08-24 20:57:32,422 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2022-08-24 20:57:32,442 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2022-08-24 20:57:32,443 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm3.org_1   | 2022-08-24 20:57:32,627 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:57:32,637 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2022-08-24 20:57:32,637 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2022-08-24 20:57:32,892 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:57:32,902 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:57:33,346 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2022-08-24 20:57:33,437 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm3.org_1   | 2022-08-24 20:57:33,437 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm3.org_1   | 2022-08-24 20:57:35,249 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2022-08-24 20:57:35,261 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-08-24 20:57:35,658 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   | 2022-08-24 20:57:35,831 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   | 2022-08-24 20:57:35,833 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2022-08-24 20:57:35,842 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-08-24 20:57:35,842 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2022-08-24 20:57:35,965 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2022-08-24 20:57:35,976 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-08-24 20:57:35,987 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2022-08-24 20:57:35,988 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2022-08-24 20:57:36,349 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-08-24 20:57:36,349 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-08-24 20:57:36,349 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2022-08-24 20:57:37,151 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 32d0e816-7836-4618-b71b-8792003f2e21
scm3.org_1   | 2022-08-24 20:57:37,202 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1170009537688 on Scm Bootstrap Node 32d0e816-7836-4618-b71b-8792003f2e21
scm3.org_1   | 2022-08-24 20:57:37,301 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@618b147b] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2022-08-24 20:57:37,454 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm3.org_1   | 2022-08-24 20:57:37,474 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2022-08-24 20:57:37,475 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2022-08-24 20:57:37,686 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @19870ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2022-08-24 20:57:38,580 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2022-08-24 20:57:38,645 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2022-08-24 20:57:38,661 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2022-08-24 20:57:38,661 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2022-08-24 20:57:38,661 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2022-08-24 20:57:38,666 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2022-08-24 20:57:38,947 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2022-08-24 20:57:38,948 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm3.org_1   | 2022-08-24 20:57:39,259 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2022-08-24 20:57:39,273 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2022-08-24 20:57:39,279 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm3.org_1   | 2022-08-24 20:57:39,424 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-08-24 20:57:39,433 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@765d2d4d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2022-08-24 20:57:39,437 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@485996f7{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2022-08-24 20:57:40,216 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-08-24 20:57:40,331 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@41e35358{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-6072752928115646847/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2022-08-24 20:56:44,046 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:56:44,049 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-08-24 20:56:44,083 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-08-24 20:56:44,097 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-08-24 20:56:44,099 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 1170009537688 on primary SCM
scm1.org_1   | 2022-08-24 20:56:44,106 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm1.org_1   | 2022-08-24 20:56:44,138 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-08-24 20:56:44,174 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2022-08-24 20:56:44,931 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-08-24 20:56:44,948 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-08-24 20:56:44,949 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm1.org_1   | 2022-08-24 20:56:44,973 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-08-24 20:56:44,978 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-08-24 20:56:44,979 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2022-08-24 20:56:45,003 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
om3_1        | 2022-08-24 21:05:53,126 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg16 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,131 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg17 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,148 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg13 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,158 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg14 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,163 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg15 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,206 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg26 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,277 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg18 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,310 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg20 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,319 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg19 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,392 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg21 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,395 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg23 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,398 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg27 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,402 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg24 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,412 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg25 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,416 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg22 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,425 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg28 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,437 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg29 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,459 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg30 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,463 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg32 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,476 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg31 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,509 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg34 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,535 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg33 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,551 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg35 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,586 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg39 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,603 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg36 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,649 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg38 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,652 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg40 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,659 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg43 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,737 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg46 of layout LEGACY in volume: s3v
scm2.org_1   | 2022-08-24 20:57:14,255 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm2.org_1   | 2022-08-24 20:57:14,257 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm2.org_1   | 2022-08-24 20:57:14,318 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-24 21:05:31,607 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8426919085 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:38,232 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9156506742 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:52,932 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg0 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:52,939 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg2 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:52,947 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg4 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:52,988 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg5 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:52,990 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg3 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-24 20:56:45,011 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-08-24 20:56:45,011 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm1.org_1   | 2022-08-24 20:56:45,190 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm1.org_1   | 2022-08-24 20:56:45,190 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | Container Balancer status:
scm1.org_1   | Key                            Value
scm1.org_1   | Running                        false
scm1.org_1   | Container Balancer Configuration values:
scm1.org_1   | Key                                                Value
scm1.org_1   | Threshold                                          10
scm1.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm1.org_1   | Max Size to Move per Iteration                     500GB
scm1.org_1   | Max Size Entering Target per Iteration             26GB
scm1.org_1   | Max Size Leaving Source per Iteration              26GB
scm1.org_1   | 
scm1.org_1   | 2022-08-24 20:56:45,191 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #179 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
scm2.org_1   | 2022-08-24 20:57:14,322 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm2.org_1   | 2022-08-24 20:57:14,445 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2022-08-24 20:57:14,445 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2022-08-24 20:57:14,447 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm2.org_1   | 2022-08-24 20:57:14,468 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-08-24 20:57:14,484 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@737652a9{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2022-08-24 20:57:14,487 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@12f826c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2022-08-24 20:57:14,698 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-08-24 20:57:14,726 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3a6732bc{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-18141429428749468711/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm2.org_1   | 2022-08-24 20:57:14,750 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@2554bfa{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm2.org_1   | 2022-08-24 20:57:14,751 [Listener at 0.0.0.0/9860] INFO server.Server: Started @18180ms
om2_1        | 2022-08-24 21:05:52,995 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg1 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,015 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg7 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,028 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg8 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,103 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg6 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,107 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg9 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,130 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg12 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,143 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg10 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,151 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg11 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,752 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg37 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,761 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg42 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,768 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg41 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,771 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg45 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,790 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg47 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,795 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg49 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,800 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg44 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,806 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg50 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,819 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg51 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,832 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg56 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,833 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg53 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,848 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg48 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,858 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg52 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,874 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg54 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,897 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg55 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,920 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg57 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,949 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg58 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,967 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg59 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-24 20:56:45,191 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm1.org_1   | 2022-08-24 20:56:45,195 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm1.org_1   | 2022-08-24 20:56:45,196 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm1.org_1   | 2022-08-24 20:56:45,197 [4c4be219-e818-4409-b18c-c29dce22a660-impl-thread1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: start as a follower, conf=0: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-24 20:56:45,197 [4c4be219-e818-4409-b18c-c29dce22a660-impl-thread1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm1.org_1   | 2022-08-24 20:56:45,198 [4c4be219-e818-4409-b18c-c29dce22a660-impl-thread1] INFO impl.RoleInfo: 4c4be219-e818-4409-b18c-c29dce22a660: start 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState
scm1.org_1   | 2022-08-24 20:56:45,206 [4c4be219-e818-4409-b18c-c29dce22a660-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CC84B7B042FE,id=4c4be219-e818-4409-b18c-c29dce22a660
scm1.org_1   | 2022-08-24 20:56:45,214 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 4c4be219-e818-4409-b18c-c29dce22a660: start RPC server
scm1.org_1   | 2022-08-24 20:56:45,276 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 4c4be219-e818-4409-b18c-c29dce22a660: GrpcService started, listening on 9894
scm1.org_1   | 2022-08-24 20:56:45,282 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-08-24 20:56:45,282 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm1.org_1   | 2022-08-24 20:56:45,283 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2022-08-24 20:56:45,283 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2022-08-24 20:56:45,288 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$485/0x0000000840552840@320ca97c] INFO util.JvmPauseMonitor: JvmPauseMonitor-4c4be219-e818-4409-b18c-c29dce22a660: Started
scm1.org_1   | 2022-08-24 20:56:45,403 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2022-08-24 20:56:45,419 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2022-08-24 20:56:45,420 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2022-08-24 20:56:45,655 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
om1_1        | 2022-08-24 21:03:19,761 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:03:23,674 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40866
om1_1        | 2022-08-24 21:03:23,687 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:03:24,190 [IPC Server handler 15 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket Volume:53130-source Bucket:unreadable-bucket Key:
om1_1        | 2022-08-24 21:03:27,476 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40868
scm2.org_1   | 2022-08-24 20:57:14,761 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2022-08-24 20:57:14,761 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2022-08-24 20:57:14,763 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm2.org_1   | 2022-08-24 20:57:17,513 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:57:31,930 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: set configuration 13: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 32d0e816-7836-4618-b71b-8792003f2e21|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-08-24 20:57:32,007 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-server-thread1] INFO server.RaftServer$Division: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE: set configuration 15: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 32d0e816-7836-4618-b71b-8792003f2e21|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-24 20:57:53,111 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:57:55,004 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2022-08-24 21:05:53,190 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg16 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,198 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg17 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,214 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg13 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,221 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg14 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,234 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg15 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,241 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg26 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,338 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg18 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,344 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg20 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,348 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg19 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,381 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg21 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,389 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg23 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,402 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg27 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,411 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg24 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,416 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg25 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,430 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg22 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,440 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg28 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,442 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg29 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,450 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg30 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,459 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg32 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,471 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg31 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,512 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg34 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,528 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg33 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,555 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg35 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,571 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg39 of layout LEGACY in volume: s3v
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
om1_1        | 2022-08-24 21:03:27,499 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:03:28,051 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 53130-target
om1_1        | 2022-08-24 21:03:31,514 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40872
om1_1        | 2022-08-24 21:03:31,534 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:03:31,979 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 53130-target
om1_1        | 2022-08-24 21:03:35,202 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40874
om1_1        | 2022-08-24 21:03:35,220 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm2.org_1   | 2022-08-24 20:57:55,252 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:57:59,058 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:58:01,717 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:58:01,797 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:58:16,936 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34994
scm2.org_1   | 2022-08-24 20:58:16,988 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 20:58:19,001 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35446
scm2.org_1   | 2022-08-24 20:58:19,031 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 20:58:20,504 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37674
scm2.org_1   | 2022-08-24 20:58:20,589 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 20:58:20,947 [IPC Server handler 80 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/635159ec-b87e-4c18-a398-f9f404aae830
scm2.org_1   | 2022-08-24 20:58:20,970 [IPC Server handler 80 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252470207979, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-08-24 20:58:21,087 [IPC Server handler 65 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
scm2.org_1   | 2022-08-24 20:58:21,134 [IPC Server handler 65 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1250283857425, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-08-24 20:58:21,179 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-08-24 20:58:21,238 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-08-24 20:58:21,086 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm2.org_1   | 2022-08-24 20:58:21,290 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm2.org_1   | 2022-08-24 20:58:22,368 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f0d2bb84-a865-4722-a590-71cdb3c1bbab, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:21.661Z[UTC]].
scm2.org_1   | 2022-08-24 20:58:22,384 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:58:22,518 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6149d847-7841-4389-9c66-a4f4eafa6589, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:22.136Z[UTC]].
scm2.org_1   | 2022-08-24 20:58:22,537 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:58:22,582 [IPC Server handler 11 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/55f25964-0507-4416-bd5f-134f8268daba
scm2.org_1   | 2022-08-24 20:58:22,588 [IPC Server handler 11 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252176017931, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om1_1        | 2022-08-24 21:03:35,777 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 53130-target
om1_1        | 2022-08-24 21:03:39,136 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40876
om1_1        | 2022-08-24 21:03:39,149 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:03:42,851 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40878
om1_1        | 2022-08-24 21:03:42,868 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 2022-08-24 21:05:53,989 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg60 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:53,990 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg66 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,028 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg64 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,037 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg65 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,038 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg62 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,043 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg61 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,061 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg63 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,078 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg67 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,129 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg69 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,156 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg70 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,182 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg75 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,186 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg68 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,240 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg72 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,261 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg71 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,266 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg73 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,291 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg76 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,309 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg77 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,350 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg74 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,371 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg80 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,377 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg79 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,378 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg78 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,400 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg81 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,429 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg85 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,433 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg90 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,439 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg88 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,446 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg84 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,472 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg87 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,478 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg83 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,481 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg82 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,490 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg89 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,491 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg86 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,526 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg91 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,560 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg97 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,627 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg93 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,635 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg98 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,637 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg92 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,659 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg94 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,661 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg96 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:54,668 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg95 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:05:57,177 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg99 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:06:01,271 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6750200698 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:06:26,734 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-6750200698/ozone-test-2364806815/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om3_1        | 2022-08-24 21:06:26,739 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2364806815/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om3_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2364806815/multipartKey2. Entity too small.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-24 21:06:27,915 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om3_1        | partName: "etag1"
om3_1        | , partNumber: 2
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-08-24 21:06:27,932 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-24 21:06:28,517 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om3_1        | partName: "etag1"
s3g_1        | 	... 1 more
s3g_1        | 2022-08-24 21:11:12,673 [qtp864326906-21] INFO scm.XceiverClientRatis: Could not commit index 129 on pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]] to all the nodes. Server 635159ec-b87e-4c18-a398-f9f404aae830 has failed. Committed by majority.
s3g_1        | 2022-08-24 21:11:12,675 [qtp864326906-21] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 109611004723200054 bcsId: 129 on Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]]. Failed nodes: [635159ec-b87e-4c18-a398-f9f404aae830{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-08-24 21:12:12,944 [qtp864326906-77] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #183 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
scm1.org_1   | 2022-08-24 20:56:45,666 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-08-24 20:56:45,667 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm1.org_1   | 2022-08-24 20:56:45,686 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm1.org_1   | 2022-08-24 20:56:45,687 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm1.org_1   | 2022-08-24 20:56:45,690 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-08-24 20:56:45,690 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm1.org_1   | 2022-08-24 20:56:45,708 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2022-08-24 20:56:45,721 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-08-24 20:56:45,721 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2022-08-24 20:56:45,726 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2022-08-24 20:56:45,776 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@124e538e] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2022-08-24 20:56:45,787 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2022-08-24 20:56:45,787 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2022-08-24 20:56:45,788 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
om1_1        | 2022-08-24 21:03:43,417 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 53130-target
om1_1        | 2022-08-24 21:03:46,625 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40880
om1_1        | 2022-08-24 21:03:46,639 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:03:52,898 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40882
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 118 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:56,127 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
om1_1        | 2022-08-24 21:03:52,915 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:03:58,916 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40884
om1_1        | 2022-08-24 21:03:58,929 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:04:02,594 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40886
om1_1        | 2022-08-24 21:04:02,615 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:04:03,585 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35541
om1_1        | 2022-08-24 21:04:03,587 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:04:06,514 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40888
om1_1        | 2022-08-24 21:04:06,536 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:04:10,545 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40890
om2_1        | 2022-08-24 21:05:53,592 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg36 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,632 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg38 of layout LEGACY in volume: s3v
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:104)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:409)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:569)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:583)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:145)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:493)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:467)
om2_1        | 2022-08-24 21:05:53,638 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg40 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,653 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg43 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,673 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg46 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,688 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg37 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,692 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg42 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,695 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg41 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,725 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg45 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,742 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg47 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,753 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg49 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,758 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg44 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,773 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg50 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,816 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg51 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,863 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg56 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,866 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg53 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,875 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg48 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,876 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg52 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,885 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg54 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,902 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg55 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,903 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg57 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,966 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg58 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,972 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg59 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:53,994 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg60 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,013 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg66 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,026 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg64 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,033 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg65 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,039 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg62 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,045 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg61 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,048 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg63 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,068 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg67 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,116 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg69 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,151 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg70 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,162 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg75 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,174 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg68 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,209 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg72 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-24 20:56:45,809 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @5827ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2022-08-24 20:56:45,887 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm1.org_1   | 2022-08-24 20:56:45,894 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm1.org_1   | 2022-08-24 20:56:45,895 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2022-08-24 20:56:45,895 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm1.org_1   | 2022-08-24 20:56:45,895 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2022-08-24 20:56:45,897 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm1.org_1   | 2022-08-24 20:56:45,930 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2022-08-24 20:58:22,590 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-08-24 20:58:22,599 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm2.org_1   | 2022-08-24 20:58:22,599 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2022-08-24 20:58:22,608 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2022-08-24 20:58:22,608 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-08-24 20:58:22,635 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2022-08-24 20:58:22,636 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-08-24 20:58:23,228 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e5375211-a7a5-4dcb-a220-2337c26f5c0c, Nodes: 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:22.680Z[UTC]].
scm2.org_1   | 2022-08-24 20:58:23,229 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:58:23,518 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]].
scm2.org_1   | 2022-08-24 20:58:23,519 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om1_1        | 2022-08-24 21:04:10,559 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:04:11,054 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 53130-target
om1_1        | 2022-08-24 21:04:14,235 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40892
om1_1        | 2022-08-24 21:04:14,259 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:04:14,765 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:53130-target
om1_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:04:18,003 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40894
om1_1        | 2022-08-24 21:04:18,025 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:04:28,947 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40896
om1_1        | 2022-08-24 21:04:28,969 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:04:33,520 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:40549
om1_1        | 2022-08-24 21:04:33,538 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2022-08-24 20:57:40,403 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@7431f4b8{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2022-08-24 20:57:40,404 [Listener at 0.0.0.0/9860] INFO server.Server: Started @22588ms
scm3.org_1   | 2022-08-24 20:57:40,427 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2022-08-24 20:57:40,428 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:520)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 119 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:58,137 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
scm1.org_1   | 2022-08-24 20:56:45,931 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm1.org_1   | 2022-08-24 20:56:45,952 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm1.org_1   | 2022-08-24 20:56:45,953 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm1.org_1   | 2022-08-24 20:56:45,954 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm1.org_1   | 2022-08-24 20:56:45,972 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-08-24 20:56:45,978 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7854f2a2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm1.org_1   | 2022-08-24 20:56:45,979 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5aa7bb86{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | 2022-08-24 20:56:46,068 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-08-24 20:56:46,080 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@37edb7fa{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-5040544897756383968/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2022-08-24 20:56:46,088 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@79fc6651{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm1.org_1   | 2022-08-24 20:56:46,088 [Listener at 0.0.0.0/9860] INFO server.Server: Started @6106ms
scm1.org_1   | 2022-08-24 20:56:46,094 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm1.org_1   | 2022-08-24 20:56:46,094 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm1.org_1   | 2022-08-24 20:56:46,097 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2022-08-24 20:56:46,738 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45313
scm1.org_1   | 2022-08-24 20:56:46,761 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:56:46,917 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.25.0.115:45313
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:262)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
scm3.org_1   | 2022-08-24 20:57:40,434 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm3.org_1   | 2022-08-24 20:57:53,177 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:57:55,014 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:57:55,253 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:57:59,047 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:58:01,699 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:58:01,784 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:58:16,977 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37150
scm3.org_1   | 2022-08-24 20:58:17,137 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 20:58:18,390 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$468/0x0000000840560440@6ec9f664] WARN util.JvmPauseMonitor: JvmPauseMonitor-32d0e816-7836-4618-b71b-8792003f2e21: Detected pause in JVM or host machine (eg GC): pause of approximately 116626225ns.
scm3.org_1   | GC pool 'ParNew' had collection(s): count=1 time=139ms
scm3.org_1   | 2022-08-24 20:58:18,900 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39912
scm3.org_1   | 2022-08-24 20:58:19,002 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 20:58:20,507 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55512
scm3.org_1   | 2022-08-24 20:58:20,585 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 20:58:20,999 [IPC Server handler 52 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/635159ec-b87e-4c18-a398-f9f404aae830
scm3.org_1   | 2022-08-24 20:58:21,026 [IPC Server handler 52 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252470207979, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-08-24 20:58:21,058 [IPC Server handler 4 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
scm3.org_1   | 2022-08-24 20:58:21,107 [IPC Server handler 4 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1250283857425, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-08-24 20:58:21,177 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-08-24 20:58:21,202 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-08-24 20:58:21,219 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2022-08-24 20:58:21,283 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm3.org_1   | 2022-08-24 20:58:22,258 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f0d2bb84-a865-4722-a590-71cdb3c1bbab, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:21.661Z[UTC]].
scm3.org_1   | 2022-08-24 20:58:22,300 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:58:22,344 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6149d847-7841-4389-9c66-a4f4eafa6589, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:22.136Z[UTC]].
scm3.org_1   | 2022-08-24 20:58:22,377 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:58:22,590 [IPC Server handler 2 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/55f25964-0507-4416-bd5f-134f8268daba
scm3.org_1   | 2022-08-24 20:58:22,649 [IPC Server handler 2 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252176017931, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-08-24 20:58:22,656 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-08-24 20:58:22,692 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm3.org_1   | 2022-08-24 20:58:22,692 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm3.org_1   | 2022-08-24 20:58:22,696 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm3.org_1   | 2022-08-24 20:58:22,696 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om1_1        | 2022-08-24 21:04:33,873 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:33,963 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:33,974 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8166617629 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:04:36,546 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40898
om1_1        | 2022-08-24 21:04:36,564 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:04:39,523 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:39,527 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:39,533 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4164878180 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:04:40,111 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:40,118 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:40,138 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:43,225 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:43,814 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:43,818 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:43,822 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:45,671 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:46,222 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:46,228 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:46,236 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:46,245 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:46,819 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:46,826 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:46,831 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:46,834 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:47,370 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:47,374 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:47,378 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:47,383 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:47,943 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:47,950 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:47,961 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:48,172 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:48,745 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:48,749 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:48,753 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:48,756 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:51,132 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40900
om1_1        | 2022-08-24 21:04:51,151 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:04:54,006 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:54,013 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:54,021 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0970255710 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:04:54,509 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:54,515 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:54,524 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-ypmpvjoaev of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:04:54,550 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:54,560 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:54,564 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:55,683 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:55,722 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:55,725 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:55,729 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:58,187 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:58,218 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:58,222 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:58,226 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:58,359 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:58,402 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:58,407 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:58,421 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:58,536 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:58,550 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:58,619 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:58,622 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:58,634 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:04:58,652 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:00,698 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:00,706 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:00,814 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:00,845 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:00,970 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:00,977 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:00,980 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,045 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,050 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,066 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,132 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,135 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,162 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,734 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,806 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,845 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,858 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,902 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,906 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,914 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-dvkabsedjt of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:01,950 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,958 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:01,963 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,005 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,008 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,020 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,024 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,058 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,063 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,075 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,157 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,208 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,215 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,238 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
scm2.org_1   | 2022-08-24 20:58:23,531 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a574462d-c45e-4fde-830b-069052b7ac42, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:23.363Z[UTC]].
scm2.org_1   | 2022-08-24 20:58:23,542 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:58:25,965 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e5375211-a7a5-4dcb-a220-2337c26f5c0c, Nodes: 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:22.680Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-08-24 20:58:26,306 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:58:27,024 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-24 20:58:31,919 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-24 20:58:33,353 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-24 20:58:35,767 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35448
scm2.org_1   | 2022-08-24 20:58:35,856 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 20:58:35,862 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-08-24 20:58:35,897 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 20:58:36,593 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-24 20:58:36,594 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm2.org_1   | 2022-08-24 20:58:36,594 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm2.org_1   | 2022-08-24 20:58:36,594 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm2.org_1   | 2022-08-24 20:58:36,594 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-08-24 20:58:36,594 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm2.org_1   | 2022-08-24 20:58:53,961 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34996
scm2.org_1   | 2022-08-24 20:58:54,031 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 20:58:54,033 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f0d2bb84-a865-4722-a590-71cdb3c1bbab, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, CreationTimestamp2022-08-24T20:58:21.661Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-08-24 20:58:54,105 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35450
scm2.org_1   | 2022-08-24 20:58:54,187 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 20:58:54,190 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6149d847-7841-4389-9c66-a4f4eafa6589, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:635159ec-b87e-4c18-a398-f9f404aae830, CreationTimestamp2022-08-24T20:58:22.136Z[UTC]] moved to OPEN state
scm1.org_1   | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:4c4be219-e818-4409-b18c-c29dce22a660 is not the leader. Could not determine the leader node.
scm1.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-08-24 20:56:48,124 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:56956
scm1.org_1   | 2022-08-24 20:56:48,134 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 20:56:50,337 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState] INFO impl.FollowerState: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5139511419ns, electionTimeout:5131ms
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om2_1        | 2022-08-24 21:05:54,215 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg71 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,229 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg73 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,256 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg76 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,264 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg77 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,273 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg74 of layout LEGACY in volume: s3v
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 120 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:58,141 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
om2_1        | 2022-08-24 21:05:54,290 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg80 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,299 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg79 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,310 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg78 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,319 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg81 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,414 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg85 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,422 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg90 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,426 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg88 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,450 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg84 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,467 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg87 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,473 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg83 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,476 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg82 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,481 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg89 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,494 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg86 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,544 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg91 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,569 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg97 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,634 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg93 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,640 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg98 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,643 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg92 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,647 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg94 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,650 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg96 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:54,656 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg95 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:05:57,166 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg99 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:06:01,277 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6750200698 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:06:26,731 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-6750200698/ozone-test-2364806815/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1        | 2022-08-24 21:06:26,735 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2364806815/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om2_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2364806815/multipartKey2. Entity too small.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-24 21:06:27,919 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om2_1        | partName: "etag1"
om2_1        | , partNumber: 2
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-08-24 21:06:27,925 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-24 21:06:28,511 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1        | partName: "etag1"
om2_1        | , partNumber: 1
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-08-24 21:06:28,512 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2022-08-24 20:59:02,675 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a574462d-c45e-4fde-830b-069052b7ac42, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, CreationTimestamp2022-08-24T20:58:23.363Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-08-24 20:59:06,650 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37676
scm2.org_1   | 2022-08-24 20:59:06,690 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 20:59:29,245 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35452
scm2.org_1   | 2022-08-24 20:59:29,263 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 20:59:32,686 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34998
scm2.org_1   | 2022-08-24 20:59:32,730 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 20:59:35,855 [9c76dfff-1a89-47d1-a1fa-c42b1e1bf147@group-CC84B7B042FE-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm2.org_1   | 2022-08-24 20:59:36,650 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37678
scm2.org_1   | 2022-08-24 20:59:36,744 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 20:59:39,481 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35454
scm2.org_1   | 2022-08-24 20:59:39,543 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 20:59:56,163 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35456
scm2.org_1   | 2022-08-24 20:59:56,164 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35000
scm2.org_1   | 2022-08-24 20:59:56,272 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37680
scm2.org_1   | 2022-08-24 20:59:56,283 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 20:59:56,318 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 20:59:56,357 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:00:26,281 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35458
scm2.org_1   | 2022-08-24 21:00:26,307 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35002
scm1.org_1   | 2022-08-24 20:56:50,339 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState] INFO impl.RoleInfo: 4c4be219-e818-4409-b18c-c29dce22a660: shutdown 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState
scm1.org_1   | 2022-08-24 20:56:50,339 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm1.org_1   | 2022-08-24 20:56:50,341 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-08-24 20:56:50,341 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-FollowerState] INFO impl.RoleInfo: 4c4be219-e818-4409-b18c-c29dce22a660: start 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1
scm1.org_1   | 2022-08-24 20:56:50,353 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO impl.LeaderElection: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-24 20:56:50,354 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO impl.LeaderElection: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm1.org_1   | 2022-08-24 20:56:50,355 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO impl.RoleInfo: 4c4be219-e818-4409-b18c-c29dce22a660: shutdown 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1
scm1.org_1   | 2022-08-24 20:56:50,355 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm1.org_1   | 2022-08-24 20:56:50,355 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm3.org_1   | 2022-08-24 20:58:22,697 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm3.org_1   | 2022-08-24 20:58:22,701 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-08-24 20:58:23,253 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e5375211-a7a5-4dcb-a220-2337c26f5c0c, Nodes: 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:22.680Z[UTC]].
scm3.org_1   | 2022-08-24 20:58:23,254 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:58:23,381 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]].
scm3.org_1   | 2022-08-24 20:58:23,382 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | , partNumber: 1
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-08-24 21:06:28,518 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
scm1.org_1   | 2022-08-24 20:56:50,356 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm1.org_1   | 2022-08-24 20:56:50,357 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: change Leader from null to 4c4be219-e818-4409-b18c-c29dce22a660 at term 2 for becomeLeader, leader elected after 7208ms
scm1.org_1   | 2022-08-24 20:56:50,362 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-08-24 20:56:50,366 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-08-24 20:56:50,367 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-08-24 20:56:50,371 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm3.org_1   | 2022-08-24 20:58:23,472 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a574462d-c45e-4fde-830b-069052b7ac42, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:23.363Z[UTC]].
scm3.org_1   | 2022-08-24 20:58:23,472 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-24 20:58:25,974 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e5375211-a7a5-4dcb-a220-2337c26f5c0c, Nodes: 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:22.680Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-24 20:58:26,244 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 121 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:58:58,144 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
scm1.org_1   | 2022-08-24 20:56:50,371 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-08-24 20:56:50,372 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
scm3.org_1   | 2022-08-24 20:58:26,975 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-24 20:58:31,947 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-24 20:58:33,370 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-24 20:58:35,906 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-24 21:00:26,348 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37682
scm2.org_1   | 2022-08-24 21:00:26,392 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:00:26,425 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:00:26,444 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:00:56,210 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37684
scm2.org_1   | 2022-08-24 21:00:56,215 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35006
scm2.org_1   | 2022-08-24 21:00:56,241 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35460
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-24 21:06:32,353 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3-0579730d-1832-44a3-83a2-6b2a4197637a-108879884275417124-1
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-24 21:06:32,918 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3-0579730d-1832-44a3-83a2-6b2a4197637a-108879884275417124-2
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm3.org_1   | 2022-08-24 20:58:35,926 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39916
scm3.org_1   | 2022-08-24 20:58:35,971 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 20:58:35,975 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-24 20:58:35,975 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm3.org_1   | 2022-08-24 20:58:35,975 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm3.org_1   | 2022-08-24 20:58:35,975 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm3.org_1   | 2022-08-24 20:58:35,978 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-08-24 20:58:35,979 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2022-08-24 20:58:53,974 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37152
scm3.org_1   | 2022-08-24 20:58:54,019 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39918
scm3.org_1   | 2022-08-24 20:58:54,050 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 20:58:54,051 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f0d2bb84-a865-4722-a590-71cdb3c1bbab, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, CreationTimestamp2022-08-24T20:58:21.661Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-24 20:58:54,160 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 20:58:54,178 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6149d847-7841-4389-9c66-a4f4eafa6589, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:635159ec-b87e-4c18-a398-f9f404aae830, CreationTimestamp2022-08-24T20:58:22.136Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-24 20:59:02,664 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a574462d-c45e-4fde-830b-069052b7ac42, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, CreationTimestamp2022-08-24T20:58:23.363Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-24 20:59:06,666 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55514
scm3.org_1   | 2022-08-24 20:59:06,711 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 20:59:29,244 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39922
scm3.org_1   | 2022-08-24 20:59:29,261 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 20:59:32,669 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37154
scm3.org_1   | 2022-08-24 20:59:32,726 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 122 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:58:59,078 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a574462d-c45e-4fde-830b-069052b7ac42 reported by 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1250283857425, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:58:59,178 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a574462d-c45e-4fde-830b-069052b7ac42 reported by 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252470207979, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:59:00,148 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 2022-08-24 20:56:50,390 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-08-24 20:56:50,391 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-08-24 20:56:50,394 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO impl.RoleInfo: 4c4be219-e818-4409-b18c-c29dce22a660: start 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderStateImpl
scm1.org_1   | 2022-08-24 20:56:50,409 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm1.org_1   | 2022-08-24 20:56:50,413 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/current/log_inprogress_0 to /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/current/log_0-0
scm1.org_1   | 2022-08-24 20:56:50,429 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9f87aeec-f613-42f5-8bb5-cc84b7b042fe/current/log_inprogress_1
scm1.org_1   | 2022-08-24 20:56:50,430 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderElection1] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: set configuration 1: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-24 20:56:50,437 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm1.org_1   | 2022-08-24 20:56:50,439 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm1.org_1   | 2022-08-24 20:56:50,441 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:56:50,441 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2022-08-24 20:56:50,442 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-08-24 20:56:50,442 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2022-08-24 20:56:50,444 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-08-24 20:56:50,446 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2022-08-24 20:56:50,618 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33492
scm1.org_1   | 2022-08-24 20:56:50,635 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 20:56:53,002 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: c246fc61-bbb1-4dcb-9a40-3c09f539f100
scm1.org_1   | 2022-08-24 20:56:53,467 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:56:53,485 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2022-08-24 20:56:53,485 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm1.org_1   | 2022-08-24 20:56:53,848 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:50768
scm1.org_1   | 2022-08-24 20:56:53,865 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:56:53,865 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147
scm1.org_1   | 2022-08-24 20:56:55,971 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:57:03,833 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33494
scm1.org_1   | 2022-08-24 20:57:03,930 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 20:57:08,802 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:32939
scm1.org_1   | 2022-08-24 20:57:08,823 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 20:57:10,395 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:56960
scm1.org_1   | 2022-08-24 20:57:10,527 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 20:57:10,529 [IPC Server handler 24 on default port 9863] INFO ha.SCMRatisServerImpl: 4c4be219-e818-4409-b18c-c29dce22a660: Submitting SetConfiguration request to Ratis server with new SCM peers list: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-08-24 20:57:10,531 [IPC Server handler 24 on default port 9863] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: receive setConfiguration SetConfigurationRequest:client-B5F3694C66CB->4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE, cid=1, seq=0, RW, null, peers:[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-08-24 20:57:10,531 [IPC Server handler 24 on default port 9863] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-B5F3694C66CB->4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE, cid=1, seq=0, RW, null, peers:[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-08-24 20:57:10,543 [IPC Server handler 24 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-08-24 20:57:10,543 [IPC Server handler 24 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-24 20:57:10,555 [IPC Server handler 24 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-08-24 20:57:10,646 [IPC Server handler 24 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-08-24 20:57:10,663 [IPC Server handler 24 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-08-24 20:57:10,672 [IPC Server handler 24 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-08-24 20:57:10,693 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2022-08-24 20:57:10,712 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-GrpcLogAppender: send 4c4be219-e818-4409-b18c-c29dce22a660->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2022-08-24 20:57:11,478 [grpc-default-executor-0] INFO server.GrpcLogAppender: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-InstallSnapshotResponseHandler: received the first reply 4c4be219-e818-4409-b18c-c29dce22a660<-9c76dfff-1a89-47d1-a1fa-c42b1e1bf147#0:FAIL-t0,ALREADY_INSTALLED
scm1.org_1   | 2022-08-24 20:57:11,481 [grpc-default-executor-0] INFO server.GrpcLogAppender: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2022-08-24 20:57:11,483 [grpc-default-executor-0] INFO leader.FollowerInfo: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-24 20:57:11,484 [grpc-default-executor-0] INFO leader.FollowerInfo: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-24 20:57:11,484 [grpc-default-executor-0] INFO leader.FollowerInfo: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2022-08-24 20:57:11,484 [grpc-default-executor-0] INFO leader.FollowerInfo: Follower 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147 acknowledged installing snapshot
scm1.org_1   | 2022-08-24 20:57:11,484 [grpc-default-executor-0] INFO leader.FollowerInfo: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2022-08-24 20:57:11,568 [grpc-default-executor-0] INFO leader.FollowerInfo: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147: nextIndex: updateUnconditionally 7 -> 0
scm1.org_1   | 2022-08-24 20:57:11,577 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderStateImpl] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: set configuration 7: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|priority:0], old=[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-08-24 20:57:11,601 [grpc-default-executor-0] INFO leader.FollowerInfo: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->9c76dfff-1a89-47d1-a1fa-c42b1e1bf147: nextIndex: updateUnconditionally 8 -> 0
scm1.org_1   | 2022-08-24 20:57:12,143 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderStateImpl] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: set configuration 9: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|priority:0], old=null
scm1.org_1   | 2022-08-24 20:57:12,233 [IPC Server handler 24 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147.
scm1.org_1   | 2022-08-24 20:57:13,622 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:50770
scm1.org_1   | 2022-08-24 20:57:13,633 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:57:15,162 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:32826
scm1.org_1   | 2022-08-24 20:57:15,210 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 20:57:16,314 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33496
scm1.org_1   | 2022-08-24 20:57:16,352 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 20:57:17,424 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:59046
scm1.org_1   | 2022-08-24 20:57:17,427 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:57:17,427 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: 32d0e816-7836-4618-b71b-8792003f2e21
scm1.org_1   | 2022-08-24 20:57:17,517 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:57:26,477 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33498
scm1.org_1   | 2022-08-24 20:57:26,542 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 20:57:28,310 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:32828
scm1.org_1   | 2022-08-24 20:57:28,409 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #183 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-08-24 21:12:12,951 [qtp864326906-77] INFO scm.XceiverClientRatis: Could not commit index 134 on pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]] to all the nodes. Server 635159ec-b87e-4c18-a398-f9f404aae830 has failed. Committed by majority.
s3g_1        | 2022-08-24 21:12:12,951 [qtp864326906-77] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 109611004723200055 bcsId: 134 on Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]]. Failed nodes: [635159ec-b87e-4c18-a398-f9f404aae830{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
scm2.org_1   | 2022-08-24 21:00:56,262 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:00:56,263 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 20:59:35,830 [32d0e816-7836-4618-b71b-8792003f2e21@group-CC84B7B042FE-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm3.org_1   | 2022-08-24 20:59:36,655 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55516
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 123 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:59:00,152 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 124 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-24 20:59:00,158 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
scm2.org_1   | 2022-08-24 21:00:56,346 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:01:26,176 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35462
om3_1        | 2022-08-24 21:06:33,503 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3
scm3.org_1   | 2022-08-24 20:59:36,754 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 20:59:39,470 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39926
scm3.org_1   | 2022-08-24 20:59:39,540 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 20:59:56,157 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39928
scm2.org_1   | 2022-08-24 21:01:26,197 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37686
scm2.org_1   | 2022-08-24 21:01:26,227 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:01:26,234 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:01:26,245 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35008
scm2.org_1   | 2022-08-24 21:01:26,273 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2022-08-24 21:06:33,503 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-24 21:06:32,340 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
s3g_1        | 2022-08-24 21:13:13,687 [qtp864326906-76] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #187 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:104)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:409)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:569)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:583)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:145)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:493)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:467)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:520)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:262)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm3.org_1   | 2022-08-24 20:59:56,241 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37156
scm3.org_1   | 2022-08-24 20:59:56,273 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55518
scm3.org_1   | 2022-08-24 20:59:56,287 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 20:59:56,318 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 20:59:56,357 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:02,248 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,268 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 125 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-24 20:59:02,683 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=a574462d-c45e-4fde-830b-069052b7ac42 reported by 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1250283857425, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-24 20:59:02,686 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a574462d-c45e-4fde-830b-069052b7ac42, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, CreationTimestamp2022-08-24T20:58:23.363Z[UTC]] moved to OPEN state
recon_1      | 2022-08-24 20:59:03,342 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
om1_1        | 2022-08-24 21:05:02,272 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,701 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3-0579730d-1832-44a3-83a2-6b2a4197637a-108879884275417124-1
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 2022-08-24 21:00:26,260 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37160
scm3.org_1   | 2022-08-24 21:00:26,294 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39934
scm3.org_1   | 2022-08-24 21:00:26,380 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55520
scm3.org_1   | 2022-08-24 21:00:26,399 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:00:26,432 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:02,705 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
scm3.org_1   | 2022-08-24 21:00:26,446 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:00:56,209 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37162
scm2.org_1   | 2022-08-24 21:01:56,179 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37688
scm2.org_1   | 2022-08-24 21:01:56,184 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35464
om3_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3 because parts are in Invalid order.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
om1_1        | 2022-08-24 21:05:02,710 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,731 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,757 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,768 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
scm2.org_1   | 2022-08-24 21:01:56,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35010
scm2.org_1   | 2022-08-24 21:01:56,211 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
om1_1        | 2022-08-24 21:05:02,780 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,782 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
scm3.org_1   | 2022-08-24 21:00:56,213 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55522
scm3.org_1   | 2022-08-24 21:00:56,236 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39936
scm3.org_1   | 2022-08-24 21:00:56,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
scm1.org_1   | 2022-08-24 20:57:28,411 [IPC Server handler 16 on default port 9863] INFO ha.SCMRatisServerImpl: 4c4be219-e818-4409-b18c-c29dce22a660: Submitting SetConfiguration request to Ratis server with new SCM peers list: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|priority:0, 32d0e816-7836-4618-b71b-8792003f2e21|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-08-24 20:57:28,411 [IPC Server handler 16 on default port 9863] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: receive setConfiguration SetConfigurationRequest:client-B5F3694C66CB->4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE, cid=2, seq=0, RW, null, peers:[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|priority:0, 32d0e816-7836-4618-b71b-8792003f2e21|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-08-24 20:57:28,412 [IPC Server handler 16 on default port 9863] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-B5F3694C66CB->4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE, cid=2, seq=0, RW, null, peers:[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|priority:0, 32d0e816-7836-4618-b71b-8792003f2e21|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-08-24 20:57:28,412 [IPC Server handler 16 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-08-24 20:57:28,413 [IPC Server handler 16 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-24 20:57:28,413 [IPC Server handler 16 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-08-24 20:57:28,414 [IPC Server handler 16 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-08-24 20:57:28,414 [IPC Server handler 16 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-08-24 20:57:28,415 [IPC Server handler 16 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-08-24 20:57:28,420 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->32d0e816-7836-4618-b71b-8792003f2e21-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->32d0e816-7836-4618-b71b-8792003f2e21-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2022-08-24 20:57:28,424 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->32d0e816-7836-4618-b71b-8792003f2e21-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->32d0e816-7836-4618-b71b-8792003f2e21-GrpcLogAppender: send 4c4be219-e818-4409-b18c-c29dce22a660->32d0e816-7836-4618-b71b-8792003f2e21#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2022-08-24 20:57:30,718 [grpc-default-executor-2] INFO server.GrpcLogAppender: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->32d0e816-7836-4618-b71b-8792003f2e21-InstallSnapshotResponseHandler: received the first reply 4c4be219-e818-4409-b18c-c29dce22a660<-32d0e816-7836-4618-b71b-8792003f2e21#0:FAIL-t0,ALREADY_INSTALLED
scm1.org_1   | 2022-08-24 20:57:30,718 [grpc-default-executor-2] INFO server.GrpcLogAppender: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->32d0e816-7836-4618-b71b-8792003f2e21-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2022-08-24 20:57:30,718 [grpc-default-executor-2] INFO leader.FollowerInfo: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->32d0e816-7836-4618-b71b-8792003f2e21: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-24 20:57:30,729 [grpc-default-executor-2] INFO leader.FollowerInfo: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->32d0e816-7836-4618-b71b-8792003f2e21: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-24 20:57:30,729 [grpc-default-executor-2] INFO leader.FollowerInfo: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->32d0e816-7836-4618-b71b-8792003f2e21: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2022-08-24 20:57:30,729 [grpc-default-executor-2] INFO leader.FollowerInfo: Follower 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->32d0e816-7836-4618-b71b-8792003f2e21 acknowledged installing snapshot
scm1.org_1   | 2022-08-24 20:57:30,729 [grpc-default-executor-2] INFO leader.FollowerInfo: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->32d0e816-7836-4618-b71b-8792003f2e21: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2022-08-24 20:57:30,922 [grpc-default-executor-2] INFO leader.FollowerInfo: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->32d0e816-7836-4618-b71b-8792003f2e21: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2022-08-24 20:57:30,944 [grpc-default-executor-2] INFO leader.FollowerInfo: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE->32d0e816-7836-4618-b71b-8792003f2e21: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2022-08-24 20:57:31,925 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderStateImpl] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: set configuration 13: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 32d0e816-7836-4618-b71b-8792003f2e21|rpc:scm3.org:9894|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|priority:0], old=[4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-08-24 20:57:31,999 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-LeaderStateImpl] INFO server.RaftServer$Division: 4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE: set configuration 15: [4c4be219-e818-4409-b18c-c29dce22a660|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 32d0e816-7836-4618-b71b-8792003f2e21|rpc:scm3.org:9894|priority:0, 9c76dfff-1a89-47d1-a1fa-c42b1e1bf147|rpc:scm2.org:9894|priority:0], old=null
scm1.org_1   | 2022-08-24 20:57:32,021 [IPC Server handler 16 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 32d0e816-7836-4618-b71b-8792003f2e21.
scm1.org_1   | 2022-08-24 20:57:36,996 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:59048
scm1.org_1   | 2022-08-24 20:57:37,008 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:57:49,842 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59236
scm1.org_1   | 2022-08-24 20:57:49,927 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 20:57:50,594 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43544
scm1.org_1   | 2022-08-24 20:57:50,618 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:34756
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-24 21:06:32,906 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3-0579730d-1832-44a3-83a2-6b2a4197637a-108879884275417124-2
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm3.org_1   | 2022-08-24 21:00:56,283 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:00:56,346 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:01:26,157 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39942
scm3.org_1   | 2022-08-24 21:01:26,187 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55526
scm3.org_1   | 2022-08-24 21:01:26,193 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37164
scm3.org_1   | 2022-08-24 21:01:26,215 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:01:26,219 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:01:26,268 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:01:56,186 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55530
scm3.org_1   | 2022-08-24 21:01:56,200 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39944
scm3.org_1   | 2022-08-24 21:01:56,245 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:01:56,274 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:01:56,287 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37166
scm3.org_1   | 2022-08-24 21:01:56,297 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:02:24,597 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-24 21:02:26,179 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37168
scm3.org_1   | 2022-08-24 21:02:26,185 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39948
scm3.org_1   | 2022-08-24 21:02:26,203 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:02:26,227 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55532
scm3.org_1   | 2022-08-24 21:02:26,262 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm2.org_1   | 2022-08-24 21:01:56,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:01:56,242 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:02:06,742 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-24 21:02:26,126 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35466
scm2.org_1   | 2022-08-24 21:02:26,172 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:02:26,189 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35012
scm2.org_1   | 2022-08-24 21:02:26,192 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37690
scm2.org_1   | 2022-08-24 21:02:26,261 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:02:26,279 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:02:56,162 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35468
scm2.org_1   | 2022-08-24 21:02:56,170 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37692
scm2.org_1   | 2022-08-24 21:02:56,171 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35014
scm2.org_1   | 2022-08-24 21:02:56,178 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:02:56,187 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:02:56,193 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:03:26,143 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37694
scm2.org_1   | 2022-08-24 21:03:26,145 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35470
scm2.org_1   | 2022-08-24 21:03:26,198 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:03:26,214 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:03:26,234 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35016
scm2.org_1   | 2022-08-24 21:03:26,243 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:03:56,147 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37696
scm2.org_1   | 2022-08-24 21:03:56,147 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35472
scm2.org_1   | 2022-08-24 21:03:56,170 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:03:56,180 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:03:56,266 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35018
scm2.org_1   | 2022-08-24 21:03:56,297 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:04:26,185 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37698
scm2.org_1   | 2022-08-24 21:04:26,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35474
scm2.org_1   | 2022-08-24 21:04:26,205 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35020
scm2.org_1   | 2022-08-24 21:04:26,230 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:04:26,241 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:04:26,251 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:04:56,126 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35478
scm2.org_1   | 2022-08-24 21:04:56,171 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:04:56,200 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37700
scm2.org_1   | 2022-08-24 21:04:56,206 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35022
scm2.org_1   | 2022-08-24 21:04:56,222 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:04:56,248 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 2022-08-24 21:06:33,501 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3
om2_1        | 2022-08-24 21:06:33,502 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 2022-08-24 21:05:02,792 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,845 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,851 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,894 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:02,994 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:03,623 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41451
om2_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3 because parts are in Invalid order.
scm2.org_1   | 2022-08-24 21:05:26,147 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35482
scm2.org_1   | 2022-08-24 21:05:26,172 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35024
scm2.org_1   | 2022-08-24 21:05:26,183 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37702
scm2.org_1   | 2022-08-24 21:05:26,198 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:05:26,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-24 21:06:36,660 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-0816342003/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-6750200698
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-6750200698key: ozone-test-0816342003/multipartKey5
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm3.org_1   | 2022-08-24 21:02:26,290 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:02:56,157 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55534
scm3.org_1   | 2022-08-24 21:02:56,209 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37170
scm3.org_1   | 2022-08-24 21:02:56,216 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39954
scm3.org_1   | 2022-08-24 21:02:56,221 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:02:56,228 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:02:56,268 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:03:26,164 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39956
scm3.org_1   | 2022-08-24 21:03:26,168 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37172
scm3.org_1   | 2022-08-24 21:03:26,179 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:03:26,189 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55536
scm3.org_1   | 2022-08-24 21:03:26,199 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:03:26,199 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:03:56,173 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39960
scm3.org_1   | 2022-08-24 21:03:56,183 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55538
scm3.org_1   | 2022-08-24 21:03:56,192 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:03:56,214 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:03:56,234 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37174
scm3.org_1   | 2022-08-24 21:03:56,289 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:04:26,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55540
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm3.org_1   | 2022-08-24 21:04:26,186 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39966
scm3.org_1   | 2022-08-24 21:04:26,217 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37178
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-24 21:06:37,211 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-6750200698, Key:ozone-test-1780686796/multipartKey. 
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:759)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
om3_1        | 2022-08-24 21:06:36,636 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-0816342003/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-6750200698
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-6750200698key: ozone-test-0816342003/multipartKey5
scm3.org_1   | 2022-08-24 21:04:26,228 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:04:26,246 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:04:26,250 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:04:56,142 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55542
scm3.org_1   | 2022-08-24 21:04:56,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37180
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
scm2.org_1   | 2022-08-24 21:05:26,247 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:05:56,120 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35026
scm3.org_1   | 2022-08-24 21:04:56,188 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39970
scm3.org_1   | 2022-08-24 21:04:56,209 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:04:56,231 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:04:56,246 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:05:26,167 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39974
scm3.org_1   | 2022-08-24 21:05:26,168 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37184
scm3.org_1   | 2022-08-24 21:05:26,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55546
scm3.org_1   | 2022-08-24 21:05:26,195 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:57:50,709 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 20:57:50,710 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 20:57:52,599 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56036
om1_1        | 2022-08-24 21:05:03,645 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:05:04,257 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:04,317 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:04,330 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:04,350 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:04,526 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:05,503 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:05,550 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
scm1.org_1   | 2022-08-24 20:57:52,832 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
om1_1        | 2022-08-24 21:05:05,557 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:08,624 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40902
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
scm2.org_1   | 2022-08-24 21:05:56,130 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37704
scm2.org_1   | 2022-08-24 21:05:56,141 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
scm3.org_1   | 2022-08-24 21:05:26,218 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:05:26,226 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:05:56,191 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55548
scm3.org_1   | 2022-08-24 21:05:56,207 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37186
scm3.org_1   | 2022-08-24 21:05:56,215 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39978
scm3.org_1   | 2022-08-24 21:05:56,217 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:05:56,220 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:57:52,833 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 527bfc57601e, UUID: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
scm1.org_1   | 2022-08-24 20:57:53,090 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:57:54,617 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35272
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-24 21:06:37,213 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-6750200698, Key:ozone-test-1780686796/multipartKey. 
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:759)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:283)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:283)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-24 21:07:27,522 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5414616179 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:07:28,089 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-57355 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:07:44,718 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3239440474 of layout LEGACY in volume: s3v
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm1.org_1   | 2022-08-24 20:57:54,626 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43228
scm1.org_1   | 2022-08-24 20:57:54,720 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:57:54,721 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 7541e863c794, UUID: 55f25964-0507-4416-bd5f-134f8268daba
scm1.org_1   | 2022-08-24 20:57:54,842 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:57:54,843 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 84533d7fcdfb, UUID: 635159ec-b87e-4c18-a398-f9f404aae830
scm1.org_1   | 2022-08-24 20:57:54,952 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:57:55,236 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 2022-08-24 21:07:27,524 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5414616179 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:07:28,096 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-57355 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-24 20:57:58,448 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33500
om3_1        | 2022-08-24 21:07:49,017 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-3239440474, Key:thereisnosuchfile.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm3.org_1   | 2022-08-24 21:05:56,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:06:26,126 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39984
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-24 21:07:52,362 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-3239440474, Key:ozone-test-3017881062/deletetestapidir/key=value/.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
scm1.org_1   | 2022-08-24 20:57:58,664 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:49756
scm1.org_1   | 2022-08-24 20:57:58,705 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om2_1        | 2022-08-24 21:07:44,720 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3239440474 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:07:49,019 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-3239440474, Key:thereisnosuchfile.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
scm1.org_1   | 2022-08-24 20:57:58,728 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:57:58,763 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: c06d1b6f-0906-4d1e-8c1a-968c6fd87400
scm1.org_1   | 2022-08-24 20:57:59,063 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:05:08,641 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:05:11,576 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:11,579 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:11,586 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3304228662 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:12,145 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:12,149 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
scm3.org_1   | 2022-08-24 21:06:26,160 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:06:26,163 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55550
scm2.org_1   | 2022-08-24 21:05:56,190 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35484
scm2.org_1   | 2022-08-24 21:05:56,198 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:05:56,229 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:06:26,128 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35486
scm2.org_1   | 2022-08-24 21:06:26,173 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:06:26,203 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37706
scm2.org_1   | 2022-08-24 21:06:26,205 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35028
scm2.org_1   | 2022-08-24 21:06:26,228 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:06:26,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:12,157 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6346790541 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:12,720 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:12,723 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:12,733 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7884169516 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:13,321 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
scm1.org_1   | 2022-08-24 20:58:01,515 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:51776
scm1.org_1   | 2022-08-24 20:58:01,539 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om1_1        | 2022-08-24 21:05:13,324 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:13,332 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-7884169516 in volume:s3v
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
scm2.org_1   | 2022-08-24 21:06:56,156 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35030
scm2.org_1   | 2022-08-24 21:06:56,186 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:06:56,187 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37708
scm2.org_1   | 2022-08-24 21:06:56,200 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35488
scm2.org_1   | 2022-08-24 21:06:56,223 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:06:56,246 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:07:06,743 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-24 21:07:26,167 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35490
scm2.org_1   | 2022-08-24 21:07:26,175 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37710
scm2.org_1   | 2022-08-24 21:07:26,177 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35032
scm2.org_1   | 2022-08-24 21:07:26,217 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:07:26,237 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:07:26,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
scm3.org_1   | 2022-08-24 21:06:26,167 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37188
scm3.org_1   | 2022-08-24 21:06:26,184 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:06:26,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:07:56,124 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35492
scm2.org_1   | 2022-08-24 21:07:56,170 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35034
om3_1        | 2022-08-24 21:07:55,308 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-3239440474, Key:ozone-test-3017881062/deletetestapiprefix/key=value/file.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
scm3.org_1   | 2022-08-24 21:06:56,150 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37190
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
om1_1        | 2022-08-24 21:05:13,902 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:14,706 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:14,709 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #187 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
scm1.org_1   | 2022-08-24 20:58:01,543 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: 8352630b-46dd-4e5b-90e1-418ccd62272d
scm1.org_1   | 2022-08-24 20:58:01,667 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:38456
scm2.org_1   | 2022-08-24 21:07:56,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37712
scm3.org_1   | 2022-08-24 21:06:56,180 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55552
scm3.org_1   | 2022-08-24 21:06:56,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39988
scm3.org_1   | 2022-08-24 21:06:56,200 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om1_1        | 2022-08-24 21:05:14,715 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4696656892 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-24 20:58:01,687 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 2022-08-24 21:05:17,791 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40904
scm1.org_1   | 2022-08-24 20:58:01,715 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:58:01,716 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: 413c49e8-374c-4a35-b347-7bef47b099ef
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-24 21:08:02,591 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8302286888 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:08:11,309 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0355249610 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:17,806 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
om3_1        | 2022-08-24 21:13:23,011 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1978567693 of layout LEGACY in volume: s3v
om3_1        | 2022-08-24 21:13:49,748 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2545197524 of layout LEGACY in volume: s3v
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-24 21:07:52,359 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-3239440474, Key:ozone-test-3017881062/deletetestapidir/key=value/.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 2022-08-24 21:05:21,240 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40906
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
scm2.org_1   | 2022-08-24 21:07:56,203 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:06:56,224 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:06:56,249 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:07:24,597 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-24 21:07:26,170 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37192
scm3.org_1   | 2022-08-24 21:07:26,178 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55554
scm3.org_1   | 2022-08-24 21:07:26,193 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:07:56,222 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
scm2.org_1   | 2022-08-24 21:07:56,230 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:08:26,149 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35036
scm3.org_1   | 2022-08-24 21:07:26,210 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39992
scm3.org_1   | 2022-08-24 21:07:26,243 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:07:26,247 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:07:56,150 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39994
scm1.org_1   | 2022-08-24 20:58:01,776 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:58:02,263 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56038
scm1.org_1   | 2022-08-24 20:58:02,275 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:58:04,869 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35274
scm2.org_1   | 2022-08-24 21:08:26,159 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37714
scm2.org_1   | 2022-08-24 21:08:26,168 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35494
scm2.org_1   | 2022-08-24 21:08:26,204 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:08:26,204 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:08:26,232 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:08:56,124 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35496
scm2.org_1   | 2022-08-24 21:08:56,139 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35038
scm2.org_1   | 2022-08-24 21:08:56,159 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37716
scm2.org_1   | 2022-08-24 21:08:56,169 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
om1_1        | 2022-08-24 21:05:21,262 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:05:24,216 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm1.org_1   | 2022-08-24 20:58:04,888 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:58:05,734 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43230
om1_1        | 2022-08-24 21:05:24,223 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm1.org_1   | 2022-08-24 20:58:05,800 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:58:16,947 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56550
scm1.org_1   | 2022-08-24 20:58:17,010 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:58:19,115 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44636
scm1.org_1   | 2022-08-24 20:58:19,201 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:58:20,547 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56112
scm1.org_1   | 2022-08-24 20:58:20,611 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:58:21,094 [IPC Server handler 3 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/635159ec-b87e-4c18-a398-f9f404aae830
scm1.org_1   | 2022-08-24 20:58:21,165 [IPC Server handler 3 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252470207979, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-08-24 20:58:21,185 [IPC Server handler 84 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
scm1.org_1   | 2022-08-24 20:58:21,313 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm3.org_1   | 2022-08-24 21:07:56,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37194
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
om1_1        | 2022-08-24 21:05:24,231 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5953658177 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:24,792 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
recon_1      | 	... 35 more
recon_1      | 2022-08-24 20:59:06,661 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41166
scm3.org_1   | 2022-08-24 21:07:56,179 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55556
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
om1_1        | 2022-08-24 21:05:24,796 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:24,803 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0264810494 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:25,350 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
scm3.org_1   | 2022-08-24 21:07:56,212 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:07:56,219 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:07:56,232 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:08:26,173 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55558
scm3.org_1   | 2022-08-24 21:08:26,179 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37196
om1_1        | 2022-08-24 21:05:25,354 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:25,926 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
recon_1      | 2022-08-24 20:59:06,702 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
s3g_1        | 2022-08-24 21:13:13,694 [qtp864326906-76] INFO scm.XceiverClientRatis: Could not commit index 138 on pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]] to all the nodes. Server 635159ec-b87e-4c18-a398-f9f404aae830 has failed. Committed by majority.
s3g_1        | 2022-08-24 21:13:13,695 [qtp864326906-76] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 109611004723200056 bcsId: 138 on Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]]. Failed nodes: [635159ec-b87e-4c18-a398-f9f404aae830{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-08-24 21:13:22,997 [qtp864326906-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1978567693, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:13:49,736 [qtp864326906-76] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2545197524, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-24 21:14:16,459 [qtp864326906-79] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]]
scm3.org_1   | 2022-08-24 21:08:26,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40000
recon_1      | 2022-08-24 20:59:29,250 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56940
recon_1      | 2022-08-24 20:59:29,274 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 20:59:32,676 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36716
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #192 timeout 180s
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm2.org_1   | 2022-08-24 21:08:56,185 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:08:56,200 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:09:26,123 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35498
scm2.org_1   | 2022-08-24 21:09:26,141 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-08-24 20:59:32,730 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 20:59:36,651 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41170
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm1.org_1   | 2022-08-24 20:58:21,255 [IPC Server handler 84 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1250283857425, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-08-24 21:09:26,150 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35040
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
recon_1      | 2022-08-24 20:59:36,689 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-08-24 21:08:26,206 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:08:26,217 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:25,931 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:25,942 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-1287075521 in volume:s3v
om1_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2498)
recon_1      | 2022-08-24 20:59:39,039 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #1 got from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-08-24 20:59:39,161 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1      | 2022-08-24 20:59:39,478 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56942
scm1.org_1   | 2022-08-24 20:58:21,399 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-08-24 20:58:21,446 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2022-08-24 20:58:21,682 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f0d2bb84-a865-4722-a590-71cdb3c1bbab to datanode:8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
scm1.org_1   | 2022-08-24 20:58:21,787 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2022-08-24 20:58:22,110 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f0d2bb84-a865-4722-a590-71cdb3c1bbab, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:21.661Z[UTC]].
scm1.org_1   | 2022-08-24 20:58:22,117 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:58:22,136 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6149d847-7841-4389-9c66-a4f4eafa6589 to datanode:635159ec-b87e-4c18-a398-f9f404aae830
scm1.org_1   | 2022-08-24 20:58:22,222 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6149d847-7841-4389-9c66-a4f4eafa6589, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:22.136Z[UTC]].
om2_1        | 2022-08-24 21:07:55,307 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-3239440474, Key:ozone-test-3017881062/deletetestapiprefix/key=value/file.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2468)
om1_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
scm1.org_1   | 2022-08-24 20:58:22,230 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:58:22,653 [IPC Server handler 49 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/55f25964-0507-4416-bd5f-134f8268daba
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
scm2.org_1   | 2022-08-24 21:09:26,152 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37718
scm2.org_1   | 2022-08-24 21:09:26,158 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:09:26,197 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:09:56,125 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37720
scm2.org_1   | 2022-08-24 21:09:56,154 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35500
scm2.org_1   | 2022-08-24 21:09:56,156 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35042
scm3.org_1   | 2022-08-24 21:08:26,230 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:08:56,128 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40002
scm3.org_1   | 2022-08-24 21:08:56,157 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55560
scm3.org_1   | 2022-08-24 21:08:56,173 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:08:56,184 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37198
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
recon_1      | 2022-08-24 20:59:39,546 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 20:59:56,228 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41176
recon_1      | 2022-08-24 20:59:56,238 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56944
recon_1      | 2022-08-24 20:59:56,281 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36718
recon_1      | 2022-08-24 20:59:56,299 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-24 21:08:02,586 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8302286888 of layout LEGACY in volume: s3v
scm2.org_1   | 2022-08-24 21:09:56,174 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:09:56,206 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:08:56,193 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:08:56,204 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:09:26,159 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40010
scm3.org_1   | 2022-08-24 21:09:26,166 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:09:56,227 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-08-24 20:59:56,301 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-08-24 20:59:56,335 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:05:28,624 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40908
om1_1        | 2022-08-24 21:05:28,646 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:05:31,594 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:31,597 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:31,604 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8426919085 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:08:11,312 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0355249610 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:13:23,007 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1978567693 of layout LEGACY in volume: s3v
om2_1        | 2022-08-24 21:13:49,746 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2545197524 of layout LEGACY in volume: s3v
scm2.org_1   | 2022-08-24 21:10:26,128 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37722
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:104)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:409)
scm1.org_1   | 2022-08-24 20:58:22,672 [IPC Server handler 49 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1252176017931, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-08-24 20:58:22,680 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-08-24 20:58:22,680 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e5375211-a7a5-4dcb-a220-2337c26f5c0c to datanode:55f25964-0507-4416-bd5f-134f8268daba
scm1.org_1   | 2022-08-24 20:58:22,963 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2022-08-24 20:58:22,977 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm3.org_1   | 2022-08-24 21:09:26,170 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37200
scm3.org_1   | 2022-08-24 21:09:26,183 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55562
scm3.org_1   | 2022-08-24 21:09:26,188 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:09:26,201 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:09:56,129 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55564
scm3.org_1   | 2022-08-24 21:09:56,178 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40014
recon_1      | 2022-08-24 20:59:56,341 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 20:59:56,336 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-08-24 20:59:56,342 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net.
scm2.org_1   | 2022-08-24 21:10:26,146 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35502
scm2.org_1   | 2022-08-24 21:10:26,183 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35044
scm2.org_1   | 2022-08-24 21:10:26,191 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:10:26,209 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:10:26,231 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:10:56,140 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37724
scm2.org_1   | 2022-08-24 21:10:56,152 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35504
scm2.org_1   | 2022-08-24 21:10:56,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35046
recon_1      | 2022-08-24 20:59:56,381 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-08-24 20:59:56,390 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-08-24 20:59:56,391 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-08-24 21:00:03,345 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm1.org_1   | 2022-08-24 20:58:22,977 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2022-08-24 20:58:22,977 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-08-24 20:58:22,978 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2022-08-24 20:58:22,978 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-08-24 20:58:23,149 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e5375211-a7a5-4dcb-a220-2337c26f5c0c, Nodes: 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:22.680Z[UTC]].
scm1.org_1   | 2022-08-24 20:58:23,162 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:58:23,190 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=0fca26ca-dda5-4802-a36e-c4a4d57205b6 to datanode:8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:569)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:583)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:145)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:493)
om1_1        | 2022-08-24 21:05:32,153 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:32,155 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:32,694 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:32,697 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:35,165 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40910
om1_1        | 2022-08-24 21:05:35,184 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm3.org_1   | 2022-08-24 21:09:56,184 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37202
scm3.org_1   | 2022-08-24 21:09:56,186 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:09:56,227 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:09:56,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:10:26,163 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55566
scm3.org_1   | 2022-08-24 21:10:26,166 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40018
recon_1      | 2022-08-24 21:00:03,346 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 21:00:03,387 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
scm2.org_1   | 2022-08-24 21:10:56,177 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:10:56,194 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:10:56,240 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:467)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:520)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:262)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
scm1.org_1   | 2022-08-24 20:58:23,236 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=0fca26ca-dda5-4802-a36e-c4a4d57205b6 to datanode:635159ec-b87e-4c18-a398-f9f404aae830
om1_1        | 2022-08-24 21:05:38,202 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:38,205 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:38,214 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9156506742 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:38,800 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm1.org_1   | 2022-08-24 20:58:23,236 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=0fca26ca-dda5-4802-a36e-c4a4d57205b6 to datanode:55f25964-0507-4416-bd5f-134f8268daba
scm1.org_1   | 2022-08-24 20:58:23,347 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]].
scm3.org_1   | 2022-08-24 21:10:26,195 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:10:26,216 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37204
scm3.org_1   | 2022-08-24 21:10:26,224 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:10:26,245 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:10:56,150 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40022
scm3.org_1   | 2022-08-24 21:10:56,151 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55568
scm2.org_1   | 2022-08-24 21:11:26,132 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37726
scm2.org_1   | 2022-08-24 21:11:26,145 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35048
scm2.org_1   | 2022-08-24 21:11:26,174 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35506
om1_1        | 2022-08-24 21:05:38,802 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:38,807 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:05:41,995 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40912
om1_1        | 2022-08-24 21:05:42,013 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:05:46,260 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40914
om1_1        | 2022-08-24 21:05:46,271 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:05:52,802 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:37427
scm1.org_1   | 2022-08-24 20:58:23,350 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:58:23,363 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a574462d-c45e-4fde-830b-069052b7ac42 to datanode:635159ec-b87e-4c18-a398-f9f404aae830
scm1.org_1   | 2022-08-24 20:58:23,373 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a574462d-c45e-4fde-830b-069052b7ac42 to datanode:8a3aa5b1-7501-4e35-bc9c-199b5d065ff2
scm2.org_1   | 2022-08-24 21:11:26,180 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:11:26,205 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:10:56,177 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37206
scm3.org_1   | 2022-08-24 21:10:56,189 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:10:56,219 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:10:56,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:11:26,141 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40024
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
scm2.org_1   | 2022-08-24 21:11:26,226 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:11:56,162 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37728
scm2.org_1   | 2022-08-24 21:11:56,164 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35508
scm2.org_1   | 2022-08-24 21:11:56,177 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35050
scm2.org_1   | 2022-08-24 21:11:56,186 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:11:56,194 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:11:56,204 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:58:23,374 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a574462d-c45e-4fde-830b-069052b7ac42 to datanode:55f25964-0507-4416-bd5f-134f8268daba
scm1.org_1   | 2022-08-24 20:58:23,431 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: a574462d-c45e-4fde-830b-069052b7ac42, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-24T20:58:23.363Z[UTC]].
scm1.org_1   | 2022-08-24 20:58:23,433 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:58:23,434 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=a574462d-c45e-4fde-830b-069052b7ac42 contains same datanodes as previous pipelines: PipelineID=0fca26ca-dda5-4802-a36e-c4a4d57205b6 nodeIds: 635159ec-b87e-4c18-a398-f9f404aae830, 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, 55f25964-0507-4416-bd5f-134f8268daba
scm1.org_1   | 2022-08-24 20:58:25,198 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59238
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
om1_1        | 2022-08-24 21:05:52,814 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:05:52,815 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,817 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm3.org_1   | 2022-08-24 21:11:26,165 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37208
scm3.org_1   | 2022-08-24 21:11:26,183 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55570
scm3.org_1   | 2022-08-24 21:11:26,194 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:11:26,206 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:11:26,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:11:56,108 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55572
scm3.org_1   | 2022-08-24 21:11:56,121 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37210
scm3.org_1   | 2022-08-24 21:11:56,157 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40030
scm1.org_1   | 2022-08-24 20:58:25,263 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 20:58:25,871 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41449
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
scm2.org_1   | 2022-08-24 21:12:06,743 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-24 21:12:26,151 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35512
scm2.org_1   | 2022-08-24 21:12:26,153 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35052
scm1.org_1   | 2022-08-24 20:58:25,887 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 20:58:26,022 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: e5375211-a7a5-4dcb-a220-2337c26f5c0c, Nodes: 55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:22.680Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-08-24 20:58:26,104 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:58:26,185 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1        | 2022-08-24 21:05:52,818 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,818 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,823 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm2.org_1   | 2022-08-24 21:12:26,180 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:12:26,229 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:12:26,241 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37730
scm2.org_1   | 2022-08-24 21:12:26,259 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:12:56,126 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35514
scm2.org_1   | 2022-08-24 21:12:56,140 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35054
scm2.org_1   | 2022-08-24 21:12:56,155 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:52,824 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,824 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,823 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,826 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm1.org_1   | 2022-08-24 20:58:26,961 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-24 20:58:27,670 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:34758
scm1.org_1   | 2022-08-24 20:58:27,760 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 20:58:27,819 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43546
scm1.org_1   | 2022-08-24 20:58:27,884 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm3.org_1   | 2022-08-24 21:11:56,172 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:11:56,194 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:11:56,209 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
om1_1        | 2022-08-24 21:05:52,827 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,831 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,841 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg0 of layout LEGACY in volume: s3v
scm3.org_1   | 2022-08-24 21:12:24,597 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-24 21:12:26,152 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40034
scm1.org_1   | 2022-08-24 20:58:31,962 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-24 20:58:32,032 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33502
scm2.org_1   | 2022-08-24 21:12:56,196 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:12:56,247 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37732
scm2.org_1   | 2022-08-24 21:12:56,261 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:13:26,116 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35516
scm2.org_1   | 2022-08-24 21:13:26,135 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35056
scm2.org_1   | 2022-08-24 21:13:26,151 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:58:32,137 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 20:58:33,373 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-24 20:58:35,408 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:49758
scm1.org_1   | 2022-08-24 20:58:35,459 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:58:35,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44640
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
scm3.org_1   | 2022-08-24 21:12:26,154 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37212
scm3.org_1   | 2022-08-24 21:12:26,181 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:12:26,221 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:52,842 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,844 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
scm3.org_1   | 2022-08-24 21:12:26,252 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55574
om1_1        | 2022-08-24 21:05:52,846 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
scm2.org_1   | 2022-08-24 21:13:26,156 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:13:26,234 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37734
scm2.org_1   | 2022-08-24 21:13:26,260 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om1_1        | 2022-08-24 21:05:52,859 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,859 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,866 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,843 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg2 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:52,865 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,872 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg4 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:52,875 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg5 of layout LEGACY in volume: s3v
scm3.org_1   | 2022-08-24 21:12:26,259 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:58:35,840 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:58:35,841 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]] moved to OPEN state
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
scm3.org_1   | 2022-08-24 21:12:56,141 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37214
scm3.org_1   | 2022-08-24 21:12:56,144 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40038
scm3.org_1   | 2022-08-24 21:12:56,170 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:12:56,210 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:12:56,239 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55576
scm2.org_1   | 2022-08-24 21:13:56,163 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35058
scm2.org_1   | 2022-08-24 21:13:56,235 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35518
scm2.org_1   | 2022-08-24 21:13:56,283 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-24 21:13:56,309 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
scm1.org_1   | 2022-08-24 20:58:35,858 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-24 20:58:35,860 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-24 20:58:35,893 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 2022-08-24 20:58:35,894 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm1.org_1   | 2022-08-24 20:58:35,894 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm1.org_1   | 2022-08-24 20:58:35,894 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
scm2.org_1   | 2022-08-24 21:13:56,348 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37736
scm2.org_1   | 2022-08-24 21:13:56,373 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:52,846 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,846 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,889 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg3 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-24 20:58:35,896 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2022-08-24 21:12:56,253 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:13:26,157 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40042
scm3.org_1   | 2022-08-24 21:13:26,161 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37216
scm3.org_1   | 2022-08-24 21:13:26,171 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:13:26,176 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:13:26,232 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55578
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
scm1.org_1   | 2022-08-24 20:58:35,896 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
scm1.org_1   | 2022-08-24 20:58:35,896 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
scm1.org_1   | 2022-08-24 20:58:35,897 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO UnderReplicatedQueueThread: Service UnderReplicatedQueueThread transitions to RUNNING.
scm1.org_1   | 2022-08-24 20:58:35,898 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO OverReplicatedQueueThread: Service OverReplicatedQueueThread transitions to RUNNING.
scm1.org_1   | 2022-08-24 20:58:35,898 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
om1_1        | 2022-08-24 21:05:52,889 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg1 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:52,906 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg7 of layout LEGACY in volume: s3v
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
om1_1        | 2022-08-24 21:05:52,929 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg8 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:52,939 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm3.org_1   | 2022-08-24 21:13:26,260 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:13:56,161 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37218
scm3.org_1   | 2022-08-24 21:13:56,266 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55580
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om1_1        | 2022-08-24 21:05:52,953 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,954 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,972 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:52,978 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg6 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:52,979 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg9 of layout LEGACY in volume: s3v
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
scm1.org_1   | 2022-08-24 20:58:35,929 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
scm1.org_1   | 2022-08-24 20:58:36,966 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:38460
scm1.org_1   | 2022-08-24 20:58:37,035 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:58:37,866 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:51778
scm1.org_1   | 2022-08-24 20:58:37,908 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:58:51,696 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33504
scm1.org_1   | 2022-08-24 20:58:51,733 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 20:58:54,023 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42095
scm3.org_1   | 2022-08-24 21:13:56,268 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40048
scm3.org_1   | 2022-08-24 21:13:56,278 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:13:56,293 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-24 21:13:56,372 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
om1_1        | 2022-08-24 21:05:52,995 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg12 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,013 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,018 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,020 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,024 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,034 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #192 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
scm1.org_1   | 2022-08-24 20:58:54,040 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om1_1        | 2022-08-24 21:05:53,037 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-24 21:00:26,211 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56948
recon_1      | 2022-08-24 21:00:26,226 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36720
recon_1      | 2022-08-24 21:00:26,242 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41178
scm1.org_1   | 2022-08-24 20:58:54,065 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56552
scm1.org_1   | 2022-08-24 20:58:54,068 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44642
scm1.org_1   | 2022-08-24 20:58:54,109 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:58:54,113 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f0d2bb84-a865-4722-a590-71cdb3c1bbab, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, CreationTimestamp2022-08-24T20:58:21.661Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-08-24 20:58:54,195 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:58:54,209 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6149d847-7841-4389-9c66-a4f4eafa6589, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:635159ec-b87e-4c18-a398-f9f404aae830, CreationTimestamp2022-08-24T20:58:22.136Z[UTC]] moved to OPEN state
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
om1_1        | 2022-08-24 21:05:53,037 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,037 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,036 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,036 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,037 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,048 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 2022-08-24 21:00:26,302 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:00:26,317 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:00:26,385 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:00:56,214 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36722
recon_1      | 2022-08-24 21:00:56,221 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41184
recon_1      | 2022-08-24 21:00:56,228 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56950
recon_1      | 2022-08-24 21:00:56,289 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 2022-08-24 21:05:53,056 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg10 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,057 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg11 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,059 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,059 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,058 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,080 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg16 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,081 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg17 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-24 20:59:02,679 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: a574462d-c45e-4fde-830b-069052b7ac42, Nodes: 635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:8a3aa5b1-7501-4e35-bc9c-199b5d065ff2, CreationTimestamp2022-08-24T20:58:23.363Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-08-24 20:59:06,656 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56114
scm1.org_1   | 2022-08-24 20:59:06,699 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:59:29,248 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44644
scm1.org_1   | 2022-08-24 20:59:29,280 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:59:32,689 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56554
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
recon_1      | 2022-08-24 21:00:56,289 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm1.org_1   | 2022-08-24 20:59:32,735 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-08-24 21:00:56,349 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:01:03,388 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 21:01:03,388 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 21:01:03,432 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
scm1.org_1   | 2022-08-24 20:59:35,698 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59240
scm1.org_1   | 2022-08-24 20:59:35,712 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 20:59:35,747 [IPC Server handler 7 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm1.org_1   | 2022-08-24 20:59:35,803 [4c4be219-e818-4409-b18c-c29dce22a660@group-CC84B7B042FE-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm1.org_1   | 2022-08-24 20:59:35,835 [IPC Server handler 7 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
scm1.org_1   | 2022-08-24 20:59:36,667 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56116
om1_1        | 2022-08-24 21:05:53,113 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg13 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,137 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg14 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,150 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg15 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,180 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,183 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,183 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,184 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,198 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
s3g_1        | 2022-08-24 21:14:16,464 [qtp864326906-79] INFO scm.XceiverClientRatis: Could not commit index 142 on pipeline Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]] to all the nodes. Server 635159ec-b87e-4c18-a398-f9f404aae830 has failed. Committed by majority.
s3g_1        | 2022-08-24 21:14:16,464 [qtp864326906-79] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 2 locID: 109611004723200057 bcsId: 142 on Pipeline[ Id: 0fca26ca-dda5-4802-a36e-c4a4d57205b6, Nodes: 8a3aa5b1-7501-4e35-bc9c-199b5d065ff2{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}635159ec-b87e-4c18-a398-f9f404aae830{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}55f25964-0507-4416-bd5f-134f8268daba{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:55f25964-0507-4416-bd5f-134f8268daba, CreationTimestamp2022-08-24T20:58:23.190Z[UTC]]. Failed nodes: [635159ec-b87e-4c18-a398-f9f404aae830{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
scm1.org_1   | 2022-08-24 20:59:36,760 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:59:38,676 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56040
scm1.org_1   | 2022-08-24 20:59:38,689 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:59:38,901 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35276
scm1.org_1   | 2022-08-24 20:59:38,915 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:59:39,083 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40389
scm1.org_1   | 2022-08-24 20:59:39,097 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 20:59:39,107 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:43232
om1_1        | 2022-08-24 21:05:53,200 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg26 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,210 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,211 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,211 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,218 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,219 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,219 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm1.org_1   | 2022-08-24 20:59:39,158 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-24 20:59:39,478 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44646
scm1.org_1   | 2022-08-24 20:59:39,540 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:59:56,196 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44648
scm1.org_1   | 2022-08-24 20:59:56,332 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44501
om1_1        | 2022-08-24 21:05:53,221 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,220 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,219 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,232 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,233 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,233 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,234 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,237 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm1.org_1   | 2022-08-24 20:59:56,334 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56118
scm1.org_1   | 2022-08-24 20:59:56,335 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:59:56,353 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 20:59:56,412 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56556
om1_1        | 2022-08-24 21:05:53,255 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg18 of layout LEGACY in volume: s3v
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
om1_1        | 2022-08-24 21:05:53,275 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,278 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg20 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-24 20:59:56,417 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 20:59:56,425 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:00:16,720 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40902
om1_1        | 2022-08-24 21:05:53,278 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg19 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,287 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,309 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg21 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,311 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg23 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,321 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm1.org_1   | 2022-08-24 21:00:16,735 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 21:00:26,283 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44650
scm1.org_1   | 2022-08-24 21:00:26,328 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56558
scm1.org_1   | 2022-08-24 21:00:26,334 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56120
scm1.org_1   | 2022-08-24 21:00:26,386 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
om1_1        | 2022-08-24 21:05:53,321 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,329 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,356 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg27 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,359 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,360 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,362 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg24 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-24 21:00:26,400 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:00:26,426 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:00:43,853 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59242
scm1.org_1   | 2022-08-24 21:00:43,858 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:00:47,879 [IPC Server handler 7 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm1.org_1   | 2022-08-24 21:00:56,247 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56562
scm1.org_1   | 2022-08-24 21:00:56,247 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56122
om1_1        | 2022-08-24 21:05:53,364 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg25 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,369 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg22 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,374 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,375 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg28 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,378 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg29 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,408 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg30 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,412 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg32 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-24 21:00:56,265 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44652
scm1.org_1   | 2022-08-24 21:00:56,291 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:00:56,299 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:00:56,367 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:01:26,170 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56564
scm1.org_1   | 2022-08-24 21:01:26,172 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44654
scm1.org_1   | 2022-08-24 21:01:26,224 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
om1_1        | 2022-08-24 21:05:53,420 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg31 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,435 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,457 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,463 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,470 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,477 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,477 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,494 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg34 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,494 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,499 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,502 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg33 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,516 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,517 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm1.org_1   | 2022-08-24 21:01:26,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:01:26,245 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56124
scm1.org_1   | 2022-08-24 21:01:26,277 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:01:41,698 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59244
scm1.org_1   | 2022-08-24 21:01:41,705 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:01:44,031 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-08-24 21:01:49,578 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40904
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
scm1.org_1   | 2022-08-24 21:01:49,583 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 21:01:55,357 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59246
scm1.org_1   | 2022-08-24 21:01:55,363 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
scm1.org_1   | 2022-08-24 21:01:56,150 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56128
scm1.org_1   | 2022-08-24 21:01:56,168 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56566
scm1.org_1   | 2022-08-24 21:01:56,173 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44658
scm1.org_1   | 2022-08-24 21:01:56,177 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:01:56,185 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:01:56,274 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	... 27 more
om1_1        | 2022-08-24 21:05:53,517 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,518 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,527 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-24 21:01:26,137 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56952
om1_1        | 2022-08-24 21:05:53,527 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,527 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,527 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,537 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg35 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,554 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg39 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,565 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,566 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm1.org_1   | 2022-08-24 21:02:01,760 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40906
scm1.org_1   | 2022-08-24 21:02:01,770 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 21:02:09,770 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46237
scm1.org_1   | 2022-08-24 21:02:09,776 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 21:02:26,146 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44660
scm1.org_1   | 2022-08-24 21:02:26,173 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-08-24 21:01:26,169 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41186
recon_1      | 2022-08-24 21:01:26,172 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36724
recon_1      | 2022-08-24 21:01:26,172 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 2022-08-24 21:05:53,582 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,584 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
recon_1      | 2022-08-24 21:01:26,221 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm1.org_1   | 2022-08-24 21:02:26,289 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56568
scm1.org_1   | 2022-08-24 21:02:26,297 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56132
scm1.org_1   | 2022-08-24 21:02:26,319 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:02:26,320 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:02:47,813 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59248
scm1.org_1   | 2022-08-24 21:02:47,815 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:02:56,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44662
scm1.org_1   | 2022-08-24 21:02:56,220 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56134
scm1.org_1   | 2022-08-24 21:02:56,234 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:02:56,253 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56570
scm1.org_1   | 2022-08-24 21:02:56,269 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:02:56,289 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:03:26,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56572
scm1.org_1   | 2022-08-24 21:03:26,213 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56136
scm1.org_1   | 2022-08-24 21:03:26,220 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44664
scm1.org_1   | 2022-08-24 21:03:26,232 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:03:26,235 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:03:26,240 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:03:44,062 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:03:44,067 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:03:47,232 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59250
scm1.org_1   | 2022-08-24 21:03:47,234 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:03:53,471 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40908
scm1.org_1   | 2022-08-24 21:03:53,473 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 21:03:56,197 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44666
scm1.org_1   | 2022-08-24 21:03:56,214 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:03:56,228 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56140
scm1.org_1   | 2022-08-24 21:03:56,235 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:03:56,296 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56574
scm1.org_1   | 2022-08-24 21:03:56,308 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:04:14,062 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:04:14,067 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:04:26,168 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56576
scm1.org_1   | 2022-08-24 21:04:26,188 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56142
scm1.org_1   | 2022-08-24 21:04:26,190 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44668
scm1.org_1   | 2022-08-24 21:04:26,232 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:04:26,247 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:04:26,255 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:04:40,168 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59252
scm1.org_1   | 2022-08-24 21:04:40,176 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:04:44,063 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:04:44,067 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:04:56,128 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44670
scm1.org_1   | 2022-08-24 21:04:56,158 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:04:56,169 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56144
scm1.org_1   | 2022-08-24 21:04:56,196 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56578
scm1.org_1   | 2022-08-24 21:04:56,216 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:04:56,238 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:05:02,311 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40910
scm1.org_1   | 2022-08-24 21:05:02,314 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 21:05:14,063 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:05:14,067 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:05:26,188 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56146
scm1.org_1   | 2022-08-24 21:05:26,200 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56580
scm1.org_1   | 2022-08-24 21:05:26,216 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44672
scm1.org_1   | 2022-08-24 21:05:26,220 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:05:26,251 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:05:26,257 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:05:44,063 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:05:44,068 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:05:47,800 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59254
scm1.org_1   | 2022-08-24 21:05:47,807 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:05:56,145 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56584
scm1.org_1   | 2022-08-24 21:05:56,179 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:53,586 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
recon_1      | 2022-08-24 21:01:26,273 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:01:56,121 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41192
recon_1      | 2022-08-24 21:01:56,139 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56956
recon_1      | 2022-08-24 21:01:56,140 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36726
recon_1      | 2022-08-24 21:01:56,159 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:01:56,190 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:01:56,208 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:02:03,451 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 21:02:03,452 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 21:02:03,520 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
om1_1        | 2022-08-24 21:05:53,587 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg36 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,604 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg38 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,606 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,613 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,613 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,615 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg40 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,615 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,614 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,614 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,613 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,628 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg43 of layout LEGACY in volume: s3v
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
scm1.org_1   | 2022-08-24 21:05:56,233 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56148
scm1.org_1   | 2022-08-24 21:05:56,237 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44674
scm1.org_1   | 2022-08-24 21:05:56,242 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:05:56,260 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:06:02,606 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59256
scm1.org_1   | 2022-08-24 21:06:02,608 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:06:09,621 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40912
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm1.org_1   | 2022-08-24 21:06:09,626 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 21:06:14,063 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:06:14,068 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 2022-08-24 21:05:53,646 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,646 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,647 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,654 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg46 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,654 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,667 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm1.org_1   | 2022-08-24 21:06:26,180 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56586
scm1.org_1   | 2022-08-24 21:06:26,186 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44676
scm1.org_1   | 2022-08-24 21:06:26,191 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56150
scm1.org_1   | 2022-08-24 21:06:26,203 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:53,671 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg37 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,677 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,691 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,688 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg42 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-24 21:06:26,228 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:06:26,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:06:34,653 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40914
scm1.org_1   | 2022-08-24 21:06:34,656 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 21:06:44,032 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm1.org_1   | 2022-08-24 21:06:44,068 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-24 21:02:09,608 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 34 milliseconds to process 0 existing database records.
recon_1      | 2022-08-24 21:02:09,629 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 21 milliseconds for processing 2 containers.
recon_1      | 2022-08-24 21:02:09,783 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-08-24 21:02:09,787 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 41 milliseconds.
recon_1      | 2022-08-24 21:02:26,170 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56958
recon_1      | 2022-08-24 21:02:26,180 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36728
recon_1      | 2022-08-24 21:02:26,184 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:02:26,189 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41196
recon_1      | 2022-08-24 21:02:26,221 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:02:26,261 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:02:56,143 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56960
recon_1      | 2022-08-24 21:02:56,172 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41198
recon_1      | 2022-08-24 21:02:56,184 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36730
recon_1      | 2022-08-24 21:02:56,185 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:02:56,200 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 2022-08-24 21:05:53,687 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,687 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,696 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg41 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,699 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg45 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,701 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,706 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg47 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,715 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg49 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,716 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg44 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,735 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,743 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm1.org_1   | 2022-08-24 21:06:44,070 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:06:49,139 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40916
scm1.org_1   | 2022-08-24 21:06:49,144 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 21:06:56,153 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56590
scm1.org_1   | 2022-08-24 21:06:56,171 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56152
scm1.org_1   | 2022-08-24 21:06:56,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44678
scm1.org_1   | 2022-08-24 21:06:56,193 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:06:56,215 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:06:56,228 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:07:09,820 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45925
scm1.org_1   | 2022-08-24 21:07:09,825 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 21:07:14,068 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:07:14,070 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:07:26,198 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56154
scm1.org_1   | 2022-08-24 21:07:26,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56592
scm1.org_1   | 2022-08-24 21:07:26,215 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44680
scm1.org_1   | 2022-08-24 21:07:26,223 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:07:26,244 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:07:26,257 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:07:28,703 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59258
scm1.org_1   | 2022-08-24 21:07:28,706 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:07:32,465 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40918
scm1.org_1   | 2022-08-24 21:07:32,467 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 21:07:44,068 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:07:44,071 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:07:45,317 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59260
scm1.org_1   | 2022-08-24 21:07:45,319 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:07:56,198 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56156
scm1.org_1   | 2022-08-24 21:07:56,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44682
scm1.org_1   | 2022-08-24 21:07:56,210 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56594
scm1.org_1   | 2022-08-24 21:07:56,233 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:07:56,243 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:53,747 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg50 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,751 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,754 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm1.org_1   | 2022-08-24 21:07:56,264 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:08:14,068 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:08:14,071 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:08:26,147 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56596
scm1.org_1   | 2022-08-24 21:08:26,152 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56158
scm1.org_1   | 2022-08-24 21:08:26,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44684
scm1.org_1   | 2022-08-24 21:08:26,197 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:08:26,206 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:08:26,230 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:53,768 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
recon_1      | 2022-08-24 21:02:56,265 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 2022-08-24 21:05:53,771 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,777 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,779 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,783 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm1.org_1   | 2022-08-24 21:08:44,069 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:08:44,071 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:08:47,812 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59262
scm1.org_1   | 2022-08-24 21:08:47,817 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:08:56,120 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44686
scm1.org_1   | 2022-08-24 21:08:56,159 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56160
scm1.org_1   | 2022-08-24 21:08:56,169 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:53,784 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,790 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,791 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,795 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,794 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,799 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg51 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,818 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg56 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,828 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm1.org_1   | 2022-08-24 21:08:56,193 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56598
scm1.org_1   | 2022-08-24 21:08:56,200 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:08:56,213 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:09:12,838 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59264
recon_1      | 2022-08-24 21:03:03,525 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 21:03:03,525 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
scm1.org_1   | 2022-08-24 21:09:12,840 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om1_1        | 2022-08-24 21:05:53,829 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,829 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,830 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg53 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,836 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg48 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,840 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg52 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,845 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg54 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,846 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg55 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,852 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg57 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,856 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm1.org_1   | 2022-08-24 21:09:14,069 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:09:14,071 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:09:26,106 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44688
recon_1      | 2022-08-24 21:03:03,561 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
scm1.org_1   | 2022-08-24 21:09:26,147 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:09:26,169 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56600
scm1.org_1   | 2022-08-24 21:09:26,184 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56162
scm1.org_1   | 2022-08-24 21:09:26,188 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:09:26,202 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:09:44,069 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om1_1        | 2022-08-24 21:05:53,892 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,898 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,894 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,894 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,894 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,893 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,909 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg58 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,893 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,915 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2022-08-24 21:09:44,071 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:09:56,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56164
scm1.org_1   | 2022-08-24 21:09:56,162 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56602
scm1.org_1   | 2022-08-24 21:09:56,172 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44690
scm1.org_1   | 2022-08-24 21:09:56,178 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:09:56,206 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om1_1        | 2022-08-24 21:05:53,920 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm1.org_1   | 2022-08-24 21:09:56,221 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:53,920 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,926 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm1.org_1   | 2022-08-24 21:10:13,573 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59266
scm1.org_1   | 2022-08-24 21:10:13,584 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:10:14,069 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om1_1        | 2022-08-24 21:05:53,926 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,935 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg59 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,957 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg60 of layout LEGACY in volume: s3v
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
scm1.org_1   | 2022-08-24 21:10:14,071 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:10:26,145 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44692
scm1.org_1   | 2022-08-24 21:10:26,164 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56166
scm1.org_1   | 2022-08-24 21:10:26,176 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56604
scm1.org_1   | 2022-08-24 21:10:26,194 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:10:26,219 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:10:26,227 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:10:44,069 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
om1_1        | 2022-08-24 21:05:53,962 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg66 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,975 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,962 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1        | 2022-08-24 21:05:53,996 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,000 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg64 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,006 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg65 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:53,996 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:53,999 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,012 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg62 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,018 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg61 of layout LEGACY in volume: s3v
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
scm1.org_1   | 2022-08-24 21:10:44,072 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:10:56,138 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56606
scm1.org_1   | 2022-08-24 21:10:56,142 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56170
scm1.org_1   | 2022-08-24 21:10:56,169 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44694
scm1.org_1   | 2022-08-24 21:10:56,177 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:10:56,188 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
om1_1        | 2022-08-24 21:05:54,021 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg63 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-24 21:10:56,236 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:11:14,070 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:11:14,072 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:11:16,333 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59268
scm1.org_1   | 2022-08-24 21:11:16,342 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:11:26,129 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44696
scm1.org_1   | 2022-08-24 21:11:26,147 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56608
scm1.org_1   | 2022-08-24 21:11:26,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56172
scm1.org_1   | 2022-08-24 21:11:26,197 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:11:26,205 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:11:26,226 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:11:44,033 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm1.org_1   | 2022-08-24 21:11:44,070 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:11:44,072 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:11:56,143 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56610
scm1.org_1   | 2022-08-24 21:11:56,144 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44698
scm1.org_1   | 2022-08-24 21:11:56,181 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56174
scm1.org_1   | 2022-08-24 21:11:56,192 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:11:56,198 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:11:56,202 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:54,058 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg67 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,092 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,094 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,094 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,095 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,096 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,097 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,093 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,093 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,093 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,106 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg69 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,103 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,103 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,137 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg70 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,153 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,159 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,141 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,167 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,167 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,167 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,180 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg75 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,184 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg68 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,203 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,204 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,184 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,220 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg72 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,221 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,221 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,226 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,226 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg71 of layout LEGACY in volume: s3v
scm1.org_1   | 2022-08-24 21:12:09,861 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40969
scm1.org_1   | 2022-08-24 21:12:09,865 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-24 21:12:14,070 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:12:14,072 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:12:20,193 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59270
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
scm1.org_1   | 2022-08-24 21:12:20,203 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:12:26,113 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56612
scm1.org_1   | 2022-08-24 21:12:26,136 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44700
scm1.org_1   | 2022-08-24 21:12:26,149 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:12:26,218 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:12:26,229 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56176
scm1.org_1   | 2022-08-24 21:12:26,258 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om1_1        | 2022-08-24 21:05:54,240 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg73 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,250 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg76 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,247 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,268 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg77 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,276 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm1.org_1   | 2022-08-24 21:12:44,070 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:12:44,072 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:12:47,825 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59272
scm1.org_1   | 2022-08-24 21:12:47,837 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:12:56,113 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56614
scm1.org_1   | 2022-08-24 21:12:56,143 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:12:56,161 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44702
scm1.org_1   | 2022-08-24 21:12:56,215 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:12:56,225 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56178
scm1.org_1   | 2022-08-24 21:12:56,257 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:13:14,072 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:13:14,073 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:13:21,420 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59274
scm1.org_1   | 2022-08-24 21:13:21,429 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:13:26,163 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56616
scm1.org_1   | 2022-08-24 21:13:26,174 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:13:26,182 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44704
scm1.org_1   | 2022-08-24 21:13:26,186 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:13:26,224 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56180
scm1.org_1   | 2022-08-24 21:13:26,252 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:13:27,194 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:40920
scm1.org_1   | 2022-08-24 21:13:27,196 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om1_1        | 2022-08-24 21:05:54,282 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg74 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,288 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,289 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg80 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,297 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg79 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,310 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg78 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,327 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg81 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,361 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,362 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,362 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,368 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,370 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,370 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,371 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,373 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,373 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,372 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,379 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,381 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,382 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,386 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,386 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,387 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,388 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,408 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg85 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,421 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg90 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,424 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg88 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,435 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg84 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,427 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,454 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg87 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,457 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg83 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,460 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg82 of layout LEGACY in volume: s3v
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-24 21:03:26,147 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36732
recon_1      | 2022-08-24 21:03:26,153 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56964
recon_1      | 2022-08-24 21:03:26,158 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41204
recon_1      | 2022-08-24 21:03:26,160 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:03:26,181 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:03:26,194 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:03:56,142 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56966
recon_1      | 2022-08-24 21:03:56,181 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:03:56,197 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41208
recon_1      | 2022-08-24 21:03:56,219 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm1.org_1   | 2022-08-24 21:13:44,073 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:13:44,073 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-24 21:13:47,804 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:59276
scm1.org_1   | 2022-08-24 21:13:47,809 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-24 21:13:56,152 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:56618
scm1.org_1   | 2022-08-24 21:13:56,249 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:13:56,331 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44706
recon_1      | 2022-08-24 21:03:56,227 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36734
recon_1      | 2022-08-24 21:03:56,287 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:04:03,562 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 21:04:03,562 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 21:04:03,601 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
scm1.org_1   | 2022-08-24 21:13:56,340 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:13:56,351 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56182
scm1.org_1   | 2022-08-24 21:13:56,371 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-24 21:14:14,073 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
om1_1        | 2022-08-24 21:05:54,469 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg89 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,471 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg86 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,507 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,507 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,515 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,516 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,517 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,520 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg91 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,544 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 2022-08-24 21:05:54,517 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,557 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg97 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,539 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,538 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
scm1.org_1   | 2022-08-24 21:14:14,074 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
om1_1        | 2022-08-24 21:05:54,538 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,575 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,561 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,561 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,560 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
om1_1        | 2022-08-24 21:05:54,559 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,579 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,581 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: a0202da6d16eb71873fc1673d8f90e46c8faefc59e0a2e8b7985d0b876035f3d
om1_1        | 2022-08-24 21:05:54,604 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg93 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,609 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg98 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,617 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg92 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,634 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg94 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,640 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg96 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,644 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg95 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:54,648 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg99 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:05:58,271 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40916
om1_1        | 2022-08-24 21:05:58,293 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:06:01,252 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:01,259 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:01,268 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6750200698 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:06:01,892 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:01,895 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:01,898 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:02,560 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:02,566 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:02,585 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:03,686 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36011
om1_1        | 2022-08-24 21:06:03,695 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:06:05,509 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:06,120 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:06,123 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:06,144 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-24 21:04:26,133 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56968
recon_1      | 2022-08-24 21:04:26,158 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36736
recon_1      | 2022-08-24 21:04:26,164 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41210
recon_1      | 2022-08-24 21:04:26,177 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:04:26,222 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:04:26,233 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:04:56,106 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41214
recon_1      | 2022-08-24 21:04:56,115 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:04:56,127 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56970
recon_1      | 2022-08-24 21:04:56,158 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36738
recon_1      | 2022-08-24 21:04:56,189 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:04:56,207 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:05:03,606 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 21:05:03,606 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 21:05:03,661 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:06:08,377 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:08,990 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:08,992 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:09,589 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:09,592 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:10,601 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:10,607 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:10,612 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:11,242 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:11,245 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:11,247 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:11,922 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:11,927 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:11,946 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:12,263 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:12,965 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:12,971 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:12,987 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:13,373 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:14,013 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:14,018 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:14,020 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:14,684 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:14,687 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:14,713 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:15,029 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:15,735 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:15,748 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:15,767 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:18,353 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:18,998 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:19,000 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:19,595 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:19,600 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:20,552 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:20,555 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:20,557 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:21,174 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:21,176 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:21,194 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:23,432 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:24,052 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:24,055 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:24,066 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:25,931 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:26,709 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:26,711 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:26,717 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-6750200698/ozone-test-2364806815/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
om1_1        | 2022-08-24 21:06:26,720 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2364806815/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om1_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2364806815/multipartKey2. Entity too small.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:06:27,300 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:27,304 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:27,307 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
om1_1        | 2022-08-24 21:06:27,903 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:27,906 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:27,913 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1        | partName: "etag1"
om1_1        | , partNumber: 2
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-08-24 21:06:27,938 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:06:28,493 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:28,499 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:28,508 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1        | partName: "etag1"
om1_1        | , partNumber: 1
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-08-24 21:06:28,513 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-24 21:05:26,136 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36740
recon_1      | 2022-08-24 21:05:26,140 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56974
recon_1      | 2022-08-24 21:05:26,173 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:05:26,189 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41218
recon_1      | 2022-08-24 21:05:26,208 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:05:26,257 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:05:56,154 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41226
recon_1      | 2022-08-24 21:05:56,183 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36742
recon_1      | 2022-08-24 21:05:56,194 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:05:56,199 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:05:56,209 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56976
recon_1      | 2022-08-24 21:05:56,230 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:06:03,665 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 21:06:03,665 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 21:06:03,705 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:06:29,123 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:29,127 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:29,145 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:29,494 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:30,378 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:30,382 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:30,423 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:30,936 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:31,585 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:31,588 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:31,608 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:31,706 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:32,326 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:32,329 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:32,335 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3-0579730d-1832-44a3-83a2-6b2a4197637a-108879884275417124-1
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:06:32,895 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:32,897 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:32,908 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3-0579730d-1832-44a3-83a2-6b2a4197637a-108879884275417124-2
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:06:33,486 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:33,489 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:33,495 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-6750200698/ozone-test-2060317012/multipartKey3
om1_1        | 2022-08-24 21:06:33,496 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-2060317012/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-6750200698
om1_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-6750200698 key: ozone-test-2060317012/multipartKey3 because parts are in Invalid order.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:06:34,054 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:34,057 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:34,626 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:34,629 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:35,446 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:35,450 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:35,452 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:36,056 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:36,060 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:36,618 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:36,623 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:36,633 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-0816342003/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-6750200698
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-6750200698key: ozone-test-0816342003/multipartKey5
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:06:37,199 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:37,201 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:37,208 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-6750200698, Key:ozone-test-1780686796/multipartKey. 
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:759)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:283)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:06:37,780 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:37,782 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:37,786 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:38,460 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:38,464 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:38,484 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:40,949 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:41,558 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:41,561 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:41,580 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:43,454 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:44,056 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:44,058 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:44,062 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:44,777 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:44,780 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:44,781 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:45,410 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:45,413 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:45,415 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:45,999 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:46,007 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:46,740 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:46,742 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:46,744 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:46,833 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:46,839 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-24 21:06:26,118 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56978
recon_1      | 2022-08-24 21:06:26,164 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:06:26,174 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41228
recon_1      | 2022-08-24 21:06:26,176 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36744
recon_1      | 2022-08-24 21:06:26,225 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:06:26,238 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:06:56,106 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36746
recon_1      | 2022-08-24 21:06:56,150 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:06:56,164 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41232
recon_1      | 2022-08-24 21:06:56,173 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56980
recon_1      | 2022-08-24 21:06:56,184 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:06:56,213 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:07:03,706 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 21:07:03,706 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 21:07:03,775 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-24 21:07:09,631 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1      | 2022-08-24 21:07:09,634 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 4 milliseconds for processing 2 containers.
recon_1      | 2022-08-24 21:07:09,829 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-08-24 21:07:09,831 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 38 milliseconds.
recon_1      | 2022-08-24 21:07:26,159 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56984
recon_1      | 2022-08-24 21:07:26,171 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36748
recon_1      | 2022-08-24 21:07:26,174 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41236
recon_1      | 2022-08-24 21:07:26,220 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:07:26,237 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:07:26,247 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:07:56,122 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56988
recon_1      | 2022-08-24 21:07:56,157 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36750
recon_1      | 2022-08-24 21:07:56,181 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41242
recon_1      | 2022-08-24 21:07:56,192 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:07:56,212 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:07:56,239 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:08:03,776 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 21:08:03,776 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 21:08:03,826 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
om1_1        | 2022-08-24 21:06:46,852 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:46,901 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:46,903 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:46,905 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:46,916 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:46,920 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:46,938 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:48,013 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:48,065 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:48,458 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:48,482 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:48,484 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:49,057 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:49,061 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:49,077 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:49,082 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:49,090 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:49,091 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:49,092 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:49,100 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:50,309 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:50,311 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:51,065 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:51,068 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:51,070 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:53,466 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:54,012 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:54,014 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:54,016 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:54,634 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:54,642 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:54,659 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:54,724 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:55,967 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:56,723 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:56,726 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:57,284 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:57,286 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:58,146 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:58,148 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:06:58,150 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:01,083 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:01,677 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:01,680 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:01,684 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:02,306 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-24 21:08:26,119 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41244
recon_1      | 2022-08-24 21:08:26,165 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:08:26,177 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56990
recon_1      | 2022-08-24 21:08:26,198 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36752
recon_1      | 2022-08-24 21:08:26,212 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:08:26,226 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:08:56,111 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56992
recon_1      | 2022-08-24 21:08:56,129 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36754
recon_1      | 2022-08-24 21:08:56,145 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41252
recon_1      | 2022-08-24 21:08:56,168 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:08:56,181 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om1_1        | 2022-08-24 21:07:02,308 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:02,326 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:02,390 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:03,028 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:03,711 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:03,714 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:03,743 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46037
om1_1        | 2022-08-24 21:07:03,745 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:03,754 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:07:03,788 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:06,088 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:06,714 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:06,716 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:07,274 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:07,277 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:08,305 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:08,307 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:08,310 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:11,119 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:11,677 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:11,679 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:11,681 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:12,277 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:12,278 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:14,499 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:14,501 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:14,511 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:14,537 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:15,121 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:15,123 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:15,140 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:15,153 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:15,731 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:15,733 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:15,745 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:15,783 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:16,312 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:16,936 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:16,938 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:16,962 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:16,994 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:17,075 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:17,692 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:17,695 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:17,720 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:17,797 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:18,324 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:19,014 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:19,017 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:19,605 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:19,606 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:20,514 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:20,516 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:20,518 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:21,112 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:21,114 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:21,116 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:21,719 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:21,721 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:21,725 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:24,449 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40918
om1_1        | 2022-08-24 21:07:24,463 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:07:27,510 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:27,512 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:27,518 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5414616179 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:07:28,069 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:28,072 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:28,082 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-57355 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:07:28,681 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:28,683 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:28,686 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:31,223 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:31,848 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:31,854 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:31,856 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:31,859 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:32,445 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:32,450 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:32,453 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:32,473 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:32,489 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:32,637 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:32,658 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:33,191 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:33,193 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:33,194 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
recon_1      | 2022-08-24 21:08:56,197 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:09:03,831 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 21:09:03,831 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 21:09:03,870 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-24 21:09:26,142 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41254
recon_1      | 2022-08-24 21:09:26,147 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56994
recon_1      | 2022-08-24 21:09:26,151 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36756
recon_1      | 2022-08-24 21:09:26,157 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:09:26,184 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:09:26,186 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:09:56,157 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36758
recon_1      | 2022-08-24 21:09:56,159 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41258
recon_1      | 2022-08-24 21:09:56,172 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56996
recon_1      | 2022-08-24 21:09:56,185 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:09:56,207 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:09:56,214 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:10:03,874 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 21:10:03,874 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 21:10:03,926 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
om1_1        | 2022-08-24 21:07:33,199 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:33,742 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:33,744 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:33,746 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:33,752 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:33,759 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:36,223 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:36,233 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:36,804 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:36,805 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:36,807 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:36,809 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:37,361 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:37,365 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:37,917 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:37,919 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:37,925 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:38,511 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:38,513 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:39,076 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:39,079 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:39,081 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:41,752 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40920
om1_1        | 2022-08-24 21:07:41,770 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:07:44,707 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:44,709 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:44,715 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-3239440474 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:07:45,282 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:45,292 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:45,295 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:46,234 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:46,798 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:46,799 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:46,801 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:46,803 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:47,349 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:47,353 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:47,941 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:47,943 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:47,945 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:48,470 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:48,472 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:48,473 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:49,005 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:49,007 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:49,012 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-3239440474, Key:thereisnosuchfile.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:07:49,543 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:49,545 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:49,550 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:50,094 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:50,099 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:50,102 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:51,239 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:51,784 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:51,786 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:51,787 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:51,789 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:52,345 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-24 21:10:26,163 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:56998
recon_1      | 2022-08-24 21:10:26,180 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:10:26,188 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41262
recon_1      | 2022-08-24 21:10:26,204 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36760
recon_1      | 2022-08-24 21:10:26,225 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:10:26,238 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:10:56,108 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41266
recon_1      | 2022-08-24 21:10:56,114 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:10:56,127 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36762
recon_1      | 2022-08-24 21:10:56,154 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:10:56,161 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57000
recon_1      | 2022-08-24 21:10:56,239 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:11:03,927 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 21:11:03,927 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 21:11:03,967 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-24 21:11:26,140 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57002
recon_1      | 2022-08-24 21:11:26,158 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41272
recon_1      | 2022-08-24 21:11:26,163 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36766
recon_1      | 2022-08-24 21:11:26,191 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:11:26,210 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:11:26,233 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:11:56,121 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36768
recon_1      | 2022-08-24 21:11:56,159 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57004
recon_1      | 2022-08-24 21:11:56,161 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41274
recon_1      | 2022-08-24 21:11:56,176 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:11:56,191 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:11:56,208 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:12:04,000 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 21:12:04,000 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 21:12:04,040 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
om1_1        | 2022-08-24 21:07:52,349 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:52,355 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-3239440474, Key:ozone-test-3017881062/deletetestapidir/key=value/.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:07:52,914 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:52,917 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:52,922 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:52,925 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:53,491 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:53,493 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:54,047 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:54,048 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:54,050 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:54,146 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:54,737 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:54,741 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:54,743 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:54,747 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:55,290 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:55,294 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:55,299 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-3239440474, Key:ozone-test-3017881062/deletetestapiprefix/key=value/file.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-24 21:07:55,849 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:55,851 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:55,862 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:55,864 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:56,570 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:56,573 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:57,121 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:57,122 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:07:59,694 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40922
om1_1        | 2022-08-24 21:07:59,710 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:08:02,572 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:02,574 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:02,581 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8302286888 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:08:03,153 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:03,155 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:03,170 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:03,265 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:03,798 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46821
om1_1        | 2022-08-24 21:08:03,812 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:08:03,827 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:03,829 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:04,390 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:04,394 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:04,967 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:04,969 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:05,527 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:05,529 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:08,160 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40924
om1_1        | 2022-08-24 21:08:08,180 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:08:11,298 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:11,301 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:11,309 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0355249610 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:08:11,889 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:11,891 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:11,893 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:11,991 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:12,580 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:12,583 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:08:12,586 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:09:03,854 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42757
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-24 21:12:09,636 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1      | 2022-08-24 21:12:09,642 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 7 milliseconds for processing 2 containers.
recon_1      | 2022-08-24 21:12:09,868 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-08-24 21:12:09,871 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 34 milliseconds.
recon_1      | 2022-08-24 21:12:26,147 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57006
recon_1      | 2022-08-24 21:12:26,148 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36770
recon_1      | 2022-08-24 21:12:26,180 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:12:26,219 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:12:26,226 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41282
recon_1      | 2022-08-24 21:12:26,257 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:12:56,093 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57008
recon_1      | 2022-08-24 21:12:56,151 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36772
recon_1      | 2022-08-24 21:12:56,172 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:12:56,196 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:12:56,223 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41286
recon_1      | 2022-08-24 21:12:56,261 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:13:04,041 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 21:13:04,041 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 21:13:04,080 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-24 21:13:26,115 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57010
recon_1      | 2022-08-24 21:13:26,144 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36776
recon_1      | 2022-08-24 21:13:26,148 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:13:26,158 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:13:26,221 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41290
recon_1      | 2022-08-24 21:13:26,242 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:13:56,112 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36778
recon_1      | 2022-08-24 21:13:56,154 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:13:56,255 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41296
recon_1      | 2022-08-24 21:13:56,257 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:57012
recon_1      | 2022-08-24 21:13:56,294 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:13:56,367 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-24 21:14:04,081 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-24 21:14:04,081 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-24 21:14:04,154 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om1:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
om1_1        | 2022-08-24 21:09:03,860 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:09:12,809 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:38505
om1_1        | 2022-08-24 21:09:12,812 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:09:12,812 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:09:12,815 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:09:12,817 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:10:03,907 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36105
om1_1        | 2022-08-24 21:10:03,915 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:10:13,495 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:34503
om1_1        | 2022-08-24 21:10:13,497 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:10:13,497 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:10:13,501 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:10:13,551 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:11:03,946 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46289
om1_1        | 2022-08-24 21:11:03,953 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:11:13,627 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:42175
om1_1        | 2022-08-24 21:11:13,633 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:11:13,634 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:11:16,296 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:11:16,298 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:11:16,302 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:12:04,026 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33991
om1_1        | 2022-08-24 21:12:04,032 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:12:13,611 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:40727
om1_1        | 2022-08-24 21:12:13,623 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:12:13,623 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:12:20,165 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:12:20,167 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:12:20,168 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:12:20,301 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:12:20,897 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:12:20,902 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:12:20,904 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:04,064 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:45397
om1_1        | 2022-08-24 21:13:04,070 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:13:14,624 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:35071
om1_1        | 2022-08-24 21:13:14,626 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:13:14,627 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:17,757 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40926
om1_1        | 2022-08-24 21:13:17,796 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:13:21,392 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:21,394 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:21,397 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:22,995 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:22,998 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:23,003 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1978567693 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:13:23,823 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:23,827 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:23,830 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:23,954 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:24,714 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:24,717 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:24,718 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:24,720 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:25,483 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:25,485 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:25,487 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:25,508 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:26,428 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:26,430 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:26,433 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:26,438 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:27,170 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:27,174 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:27,414 [IPC Server handler 43 on default port 9862] ERROR security.OzoneDelegationTokenSecretManager: Error while validating S3 identifier:OzoneToken owner=scm/scm@EXAMPLE.COM, renewer=, realUser=, issueDate=1970-01-01T00:00:00Z, maxDate=1970-01-01T00:00:00Z, sequenceNumber=0, masterKeyId=0, strToSign=, signature=asdfqwerty, awsAccessKeyId=scm/scm@EXAMPLE.COM, omServiceId=null
om1_1        | org.apache.hadoop.hdds.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId scm/scm@EXAMPLE.COM
om1_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om1_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3AuthInfo(OzoneDelegationTokenSecretManager.java:515)
om1_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:431)
om1_1        | 	at org.apache.hadoop.ozone.security.S3SecurityUtil.validateS3Credential(S3SecurityUtil.java:61)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:166)
om1_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
om1_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om1_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om1_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
om1_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om1_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om1_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
om1_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om1_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
om1_1        | 2022-08-24 21:13:27,415 [IPC Server handler 43 on default port 9862] ERROR protocolPB.OzoneManagerProtocolServerSideTranslatorPB: signatures do NOT match for S3 identifier:OzoneToken owner=scm/scm@EXAMPLE.COM, renewer=, realUser=, issueDate=1970-01-01T00:00:00Z, maxDate=1970-01-01T00:00:00Z, sequenceNumber=0, masterKeyId=0, strToSign=, signature=asdfqwerty, awsAccessKeyId=scm/scm@EXAMPLE.COM, omServiceId=null
om1_1        | org.apache.hadoop.security.token.SecretManager$InvalidToken: No S3 secret found for S3 identifier:OzoneToken owner=scm/scm@EXAMPLE.COM, renewer=, realUser=, issueDate=1970-01-01T00:00:00Z, maxDate=1970-01-01T00:00:00Z, sequenceNumber=0, masterKeyId=0, strToSign=, signature=asdfqwerty, awsAccessKeyId=scm/scm@EXAMPLE.COM, omServiceId=null
om1_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3AuthInfo(OzoneDelegationTokenSecretManager.java:520)
om1_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:431)
om1_1        | 	at org.apache.hadoop.ozone.security.S3SecurityUtil.validateS3Credential(S3SecurityUtil.java:61)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:166)
om1_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
om1_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om1_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om1_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
om1_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om1_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om1_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
om1_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om1_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
om1_1        | 2022-08-24 21:13:28,054 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:28,056 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:28,844 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:28,846 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:29,569 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:29,571 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:30,337 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:30,341 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:31,099 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:31,101 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:31,994 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:31,996 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:32,840 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:32,842 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:33,542 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:33,544 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:34,326 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:34,328 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:35,183 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:35,185 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:35,985 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:35,987 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:36,773 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:36,775 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:37,637 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:37,639 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:38,348 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:38,351 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:39,130 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:39,133 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:45,027 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40928
om1_1        | 2022-08-24 21:13:45,053 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:13:49,730 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:37985
om1_1        | 2022-08-24 21:13:49,733 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:13:49,734 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:49,737 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
om1_1        | 2022-08-24 21:13:49,743 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2545197524 of layout LEGACY in volume: s3v
om1_1        | 2022-08-24 21:14:04,116 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42177
om1_1        | 2022-08-24 21:14:04,133 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:14:16,646 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:41109
om1_1        | 2022-08-24 21:14:16,656 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-24 21:14:16,658 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: b43bf4b9ed5e1bfc3cc65c164653fe1725f446f60511b0f445a55a79ceb62e88
