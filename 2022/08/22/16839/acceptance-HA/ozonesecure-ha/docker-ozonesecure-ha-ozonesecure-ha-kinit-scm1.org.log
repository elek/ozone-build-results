Attaching to ozonesecure-ha_scm2.org_1, ozonesecure-ha_om2_1, ozonesecure-ha_recon_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_scm3.org_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_om3_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_kdc_1, ozonesecure-ha_s3g_1, ozonesecure-ha_om1_1, ozonesecure-ha_datanode2_1, ozonesecure-ha_kms_1
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2022-08-22 01:17:57,458 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = 07ab41f3ff0f/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
datanode2_1  | STARTUP_MSG:   java = 11.0.14.1
datanode2_1  | ************************************************************/
datanode2_1  | 2022-08-22 01:17:57,563 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2022-08-22 01:17:58,017 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2022-08-22 01:17:58,605 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2022-08-22 01:17:59,415 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2022-08-22 01:17:59,415 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2022-08-22 01:17:59,970 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:07ab41f3ff0f ip:172.25.0.103
datanode2_1  | 2022-08-22 01:18:03,293 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2022-08-22 01:18:04,140 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2022-08-22 01:18:04,149 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2022-08-22 01:18:06,606 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2022-08-22 01:18:06,606 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2022-08-22 01:18:06,606 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2022-08-22 01:18:06,607 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2022-08-22 01:18:13,761 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2022-08-22 01:18:13,831 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:07ab41f3ff0f
datanode2_1  | 2022-08-22 01:18:13,852 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2022-08-22 01:18:13,869 [main] ERROR client.DNCertificateClient: Invalid domain 07ab41f3ff0f
datanode2_1  | 2022-08-22 01:18:13,880 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@07ab41f3ff0f
datanode2_1  | 2022-08-22 01:18:18,247 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2022-08-22 01:18:18,331 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2022-08-22 01:18:18,371 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/1174539974108.crt.
datanode2_1  | 2022-08-22 01:18:18,400 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-1085506235870.crt.
datanode2_1  | 2022-08-22 01:18:18,400 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2022-08-22 01:18:18,522 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode2_1  | 2022-08-22 01:18:19,449 [main] INFO reflections.Reflections: Reflections took 662 ms to scan 2 urls, producing 90 keys and 199 values 
datanode2_1  | 2022-08-22 01:18:19,851 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode2_1  | 2022-08-22 01:18:20,841 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2022-08-22 01:18:20,926 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode2_1  | 2022-08-22 01:18:20,960 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2022-08-22 01:18:20,961 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2022-08-22 01:18:21,208 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2022-08-22 01:18:21,344 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-08-22 01:18:21,356 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2022-08-22 01:18:21,358 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2022-08-22 01:18:21,363 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2022-08-22 01:18:21,364 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode2_1  | 2022-08-22 01:18:21,563 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2022-08-22 01:18:21,597 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2022-08-22 01:18:26,404 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode2_1  | 2022-08-22 01:18:28,085 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2022-08-22 01:18:28,348 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2022-08-22 01:18:28,884 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2022-08-22 01:18:28,886 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2022-08-22 01:18:28,886 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2022-08-22 01:18:28,887 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2022-08-22 01:18:28,899 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-22 01:18:28,908 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2022-08-22 01:18:28,912 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-08-22 01:18:29,045 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode2_1  | 2022-08-22 01:18:29,053 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode2_1  | 2022-08-22 01:18:34,741 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2022-08-22 01:18:34,749 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2022-08-22 01:17:58,284 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = 2cdeb7efff84/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2022-08-22 01:17:57,981 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = d60fa041091d/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
datanode1_1  | STARTUP_MSG:   java = 11.0.14.1
datanode1_1  | ************************************************************/
datanode1_1  | 2022-08-22 01:17:58,365 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2022-08-22 01:17:58,675 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2022-08-22 01:17:59,371 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2022-08-22 01:18:00,453 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2022-08-22 01:18:00,453 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2022-08-22 01:18:01,589 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:2cdeb7efff84 ip:172.25.0.102
datanode1_1  | 2022-08-22 01:18:04,130 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2022-08-22 01:18:04,902 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2022-08-22 01:18:04,902 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2022-08-22 01:18:06,999 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2022-08-22 01:18:07,008 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2022-08-22 01:18:07,008 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2022-08-22 01:18:07,009 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2022-08-22 01:18:10,275 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2022-08-22 01:18:10,364 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:2cdeb7efff84
datanode1_1  | 2022-08-22 01:18:10,364 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2022-08-22 01:18:10,367 [main] ERROR client.DNCertificateClient: Invalid domain 2cdeb7efff84
datanode1_1  | 2022-08-22 01:18:10,385 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@2cdeb7efff84
datanode1_1  | 2022-08-22 01:18:15,075 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2022-08-22 01:18:15,167 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2022-08-22 01:18:15,185 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/1171297874022.crt.
datanode1_1  | 2022-08-22 01:18:15,203 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-1085506235870.crt.
datanode1_1  | 2022-08-22 01:18:15,204 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2022-08-22 01:18:15,272 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode1_1  | 2022-08-22 01:18:16,091 [main] INFO reflections.Reflections: Reflections took 625 ms to scan 2 urls, producing 90 keys and 199 values 
datanode1_1  | 2022-08-22 01:18:16,478 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode1_1  | 2022-08-22 01:18:17,570 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2022-08-22 01:18:17,690 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode1_1  | 2022-08-22 01:18:17,732 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2022-08-22 01:18:17,763 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2022-08-22 01:18:18,004 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2022-08-22 01:18:18,111 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-08-22 01:18:18,129 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2022-08-22 01:18:18,130 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2022-08-22 01:18:18,131 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2022-08-22 01:18:18,136 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2022-08-22 01:18:18,349 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2022-08-22 01:18:18,371 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2022-08-22 01:18:23,174 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode1_1  | 2022-08-22 01:18:24,657 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2022-08-22 01:18:25,036 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2022-08-22 01:18:25,590 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2022-08-22 01:18:25,591 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2022-08-22 01:18:25,592 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2022-08-22 01:18:25,595 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2022-08-22 01:18:25,595 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-08-22 01:18:25,597 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2022-08-22 01:18:25,598 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-08-22 01:18:25,689 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode1_1  | 2022-08-22 01:18:25,689 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.3.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
datanode3_1  | STARTUP_MSG:   java = 11.0.14.1
datanode3_1  | ************************************************************/
datanode3_1  | 2022-08-22 01:17:58,040 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2022-08-22 01:17:58,284 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2022-08-22 01:17:58,860 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2022-08-22 01:17:59,540 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2022-08-22 01:17:59,540 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2022-08-22 01:18:00,417 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:d60fa041091d ip:172.25.0.104
datanode3_1  | 2022-08-22 01:18:03,556 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2022-08-22 01:18:04,445 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2022-08-22 01:18:04,445 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2022-08-22 01:18:06,419 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2022-08-22 01:18:06,445 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2022-08-22 01:18:06,449 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2022-08-22 01:18:06,450 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2022-08-22 01:18:10,101 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2022-08-22 01:18:10,164 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:d60fa041091d
datanode3_1  | 2022-08-22 01:18:10,180 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2022-08-22 01:18:10,183 [main] ERROR client.DNCertificateClient: Invalid domain d60fa041091d
datanode3_1  | 2022-08-22 01:18:10,183 [main] INFO ozone.HddsDatanodeService: Creating csr for DN-> subject:dn@d60fa041091d
datanode3_1  | 2022-08-22 01:18:14,844 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2022-08-22 01:18:14,910 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2022-08-22 01:18:14,923 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/1171021466938.crt.
datanode3_1  | 2022-08-22 01:18:14,944 [main] INFO client.DNCertificateClient: Added certificate from file:/data/metadata/dn/certs/CA-1085506235870.crt.
datanode3_1  | 2022-08-22 01:18:14,944 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2022-08-22 01:18:15,080 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode3_1  | 2022-08-22 01:18:15,942 [main] INFO reflections.Reflections: Reflections took 611 ms to scan 2 urls, producing 90 keys and 199 values 
datanode3_1  | 2022-08-22 01:18:16,392 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode3_1  | 2022-08-22 01:18:17,626 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2022-08-22 01:18:17,719 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode3_1  | 2022-08-22 01:18:17,799 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2022-08-22 01:18:17,803 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2022-08-22 01:18:18,006 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2022-08-22 01:18:18,145 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-08-22 01:18:18,162 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2022-08-22 01:18:18,173 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2022-08-22 01:18:18,174 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2022-08-22 01:18:18,177 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2022-08-22 01:18:18,261 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2022-08-22 01:18:18,304 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2022-08-22 01:18:23,248 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode3_1  | 2022-08-22 01:18:24,895 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2022-08-22 01:18:25,270 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2022-08-22 01:18:26,115 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2022-08-22 01:18:26,121 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2022-08-22 01:18:26,135 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2022-08-22 01:18:26,136 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2022-08-22 01:18:26,136 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-22 01:18:26,137 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2022-08-22 01:18:26,139 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2022-08-22 01:18:26,221 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode3_1  | 2022-08-22 01:18:26,227 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode3_1  | 2022-08-22 01:18:31,363 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
kdc_1        | Aug 22 01:16:26 kdc krb5kdc[7](info): Loaded
kdc_1        | Aug 22 01:16:26 kdc krb5kdc[7](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Aug 22 01:16:26 kdc krb5kdc[7](info): setting up network...
kdc_1        | Aug 22 01:16:26 kdc krb5kdc[7](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Aug 22 01:16:26 kdc krb5kdc[7](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Aug 22 01:16:26 kdc krb5kdc[7](info): set up 4 sockets
kdc_1        | Aug 22 01:16:26 kdc krb5kdc[7](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Aug 22 01:16:32 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661130992, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:16:37 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.114: ISSUE: authtime 1661130997, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:16:42 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.115: ISSUE: authtime 1661131002, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:16:49 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131009, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:16:53 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1661131013, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:16:58 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1661131018, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:17:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1661131013, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:17:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1661131002, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:17:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131009, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:17:17 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131037, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:17:22 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1661131042, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:17:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131037, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:17:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1661131042, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:17:30 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131050, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:17:34 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1661131054, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:17:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1661131054, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:17:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131050, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:17:40 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1661131060, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode2_1  | 2022-08-22 01:18:34,749 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode2_1  | 2022-08-22 01:18:34,750 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-08-22 01:18:34,753 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-08-22 01:18:34,761 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-08-22 01:18:35,163 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode2_1  | 2022-08-22 01:18:36,110 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-08-22 01:18:36,124 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode2_1  | 2022-08-22 01:18:36,513 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2022-08-22 01:18:36,520 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2022-08-22 01:18:36,520 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2022-08-22 01:18:36,726 [main] INFO util.log: Logging initialized @48804ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2022-08-22 01:18:37,793 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2022-08-22 01:18:37,838 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2022-08-22 01:18:37,842 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2022-08-22 01:18:37,842 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2022-08-22 01:18:37,842 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2022-08-22 01:18:37,844 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2022-08-22 01:18:38,269 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2022-08-22 01:18:38,275 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode2_1  | 2022-08-22 01:18:38,552 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2022-08-22 01:18:38,566 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2022-08-22 01:18:38,577 [main] INFO server.session: node0 Scavenging every 600000ms
datanode2_1  | 2022-08-22 01:18:38,767 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-08-22 01:18:38,783 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1b5a3bba{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2022-08-22 01:18:38,808 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1912ba29{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2022-08-22 01:18:39,660 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2022-08-22 01:18:39,754 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@63f093a{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-178248051864380968/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2022-08-22 01:18:39,833 [main] INFO server.AbstractConnector: Started ServerConnector@4af8ff3{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2022-08-22 01:18:39,834 [main] INFO server.Server: Started @51912ms
datanode2_1  | 2022-08-22 01:18:39,867 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2022-08-22 01:18:39,884 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2022-08-22 01:18:39,888 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2022-08-22 01:18:39,922 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode2_1  | 2022-08-22 01:18:40,118 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d479e67] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2022-08-22 01:18:40,787 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2022-08-22 01:18:40,857 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode2_1  | 2022-08-22 01:18:43,524 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5/DS-1455fc58-c4fb-4350-b6fc-02acb138cf6c/container.db for volume DS-1455fc58-c4fb-4350-b6fc-02acb138cf6c
datanode2_1  | 2022-08-22 01:18:43,618 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5/DS-1455fc58-c4fb-4350-b6fc-02acb138cf6c/container.db for volume DS-1455fc58-c4fb-4350-b6fc-02acb138cf6c
datanode2_1  | 2022-08-22 01:18:43,618 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2022-08-22 01:18:43,634 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode2_1  | 2022-08-22 01:18:44,198 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 3100efb7-0525-45d4-a0fd-e73779181107
datanode2_1  | 2022-08-22 01:18:44,281 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode2_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:660)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:298)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:493)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode2_1  | Caused by: java.util.concurrent.TimeoutException
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode2_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode2_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	... 1 more
datanode2_1  | 2022-08-22 01:18:44,548 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.RaftServer: 3100efb7-0525-45d4-a0fd-e73779181107: start RPC server
datanode2_1  | 2022-08-22 01:18:44,579 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 3100efb7-0525-45d4-a0fd-e73779181107: GrpcService started, listening on 9856
datanode2_1  | 2022-08-22 01:18:44,594 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 3100efb7-0525-45d4-a0fd-e73779181107: GrpcService started, listening on 9857
datanode2_1  | 2022-08-22 01:18:44,596 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 3100efb7-0525-45d4-a0fd-e73779181107: GrpcService started, listening on 9858
datanode2_1  | 2022-08-22 01:18:44,626 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3100efb7-0525-45d4-a0fd-e73779181107 is started using port 9858 for RATIS
datanode2_1  | 2022-08-22 01:18:44,634 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3100efb7-0525-45d4-a0fd-e73779181107 is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2022-08-22 01:18:44,635 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3100efb7-0525-45d4-a0fd-e73779181107 is started using port 9856 for RATIS_SERVER
datanode2_1  | 2022-08-22 01:18:44,628 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$391/0x00000008405e6c40@4e457543] INFO util.JvmPauseMonitor: JvmPauseMonitor-3100efb7-0525-45d4-a0fd-e73779181107: Started
datanode2_1  | 2022-08-22 01:18:44,754 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-08-22 01:18:44,754 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2022-08-22 01:18:49,506 [Command processor thread] INFO server.RaftServer: 3100efb7-0525-45d4-a0fd-e73779181107: addNew group-7719FBA37020:[3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-7719FBA37020:java.util.concurrent.CompletableFuture@5d76a61b[Not completed]
datanode2_1  | 2022-08-22 01:18:49,656 [pool-23-thread-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107: new RaftServerImpl for group-7719FBA37020:[3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-08-22 01:18:49,661 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-08-22 01:18:49,664 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-08-22 01:18:32,016 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
kdc_1        | Aug 22 01:17:42 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131062, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:17:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1661131060, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:17:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131062, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:18:01 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131081, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:18:03 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1661131083, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:18:04 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1661131084, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:18:04 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1661131084, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:18:07 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1661131087, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:18:08 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1661131088, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:18:08 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1661131088, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:18:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1661131087, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:18:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1661131088, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:18:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1661131088, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:18:13 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1661131084, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:18:13 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1661131084, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:18:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1661131083, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:18:32 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131081, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:18:37 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131117, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:18:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1661131084, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Aug 22 01:18:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1661131084, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Aug 22 01:18:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1661131083, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Aug 22 01:18:45 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1661131125, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:18:46 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1661131126, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:18:48 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1661131128, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:18:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1661131125, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:18:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1661131126, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:18:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1661131128, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:19:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131117, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Aug 22 01:19:07 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131147, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:19:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1661131002, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:19:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131147, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:19:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:19:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:19:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:19:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:19:27 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:19:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:19:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2022-08-22 01:18:49,669 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-08-22 01:18:49,670 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-08-22 01:18:49,672 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-08-22 01:18:49,672 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-08-22 01:18:49,691 [pool-23-thread-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020: ConfigurationManager, init=-1: [3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-08-22 01:18:49,693 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-08-22 01:18:49,708 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-08-22 01:18:49,709 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-08-22 01:18:49,712 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6bb8ab60-60a4-4383-9c3b-7719fba37020 does not exist. Creating ...
datanode2_1  | 2022-08-22 01:18:49,755 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6bb8ab60-60a4-4383-9c3b-7719fba37020/in_use.lock acquired by nodename 6@07ab41f3ff0f
datanode2_1  | 2022-08-22 01:18:49,810 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6bb8ab60-60a4-4383-9c3b-7719fba37020 has been successfully formatted.
datanode2_1  | 2022-08-22 01:18:49,833 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-7719FBA37020: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-08-22 01:18:49,841 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-08-22 01:18:49,861 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-08-22 01:18:49,918 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-08-22 01:18:49,928 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-22 01:18:49,933 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-08-22 01:18:50,039 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-22 01:18:50,129 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-08-22 01:18:50,131 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-08-22 01:18:50,167 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/6bb8ab60-60a4-4383-9c3b-7719fba37020
datanode2_1  | 2022-08-22 01:18:50,169 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-08-22 01:18:50,170 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-08-22 01:18:50,174 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-22 01:18:50,180 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-08-22 01:18:50,184 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-08-22 01:18:50,188 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-08-22 01:18:50,189 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-08-22 01:18:32,034 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode1_1  | 2022-08-22 01:18:32,045 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode1_1  | 2022-08-22 01:18:32,045 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-08-22 01:18:32,063 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-08-22 01:18:32,091 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-08-22 01:18:32,579 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode1_1  | 2022-08-22 01:18:33,750 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode1_1  | 2022-08-22 01:18:33,781 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode1_1  | 2022-08-22 01:18:34,217 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2022-08-22 01:18:34,219 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2022-08-22 01:18:34,220 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2022-08-22 01:18:34,363 [main] INFO util.log: Logging initialized @46389ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2022-08-22 01:18:34,830 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2022-08-22 01:18:34,896 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2022-08-22 01:18:34,898 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2022-08-22 01:18:34,905 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2022-08-22 01:18:34,905 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2022-08-22 01:18:34,927 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2022-08-22 01:18:35,208 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2022-08-22 01:18:35,238 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode1_1  | 2022-08-22 01:18:35,428 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2022-08-22 01:18:35,449 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2022-08-22 01:18:35,458 [main] INFO server.session: node0 Scavenging every 600000ms
datanode1_1  | 2022-08-22 01:18:35,645 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-08-22 01:18:35,655 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@440d45c5{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2022-08-22 01:18:35,658 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7442be61{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2022-08-22 01:18:36,234 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2022-08-22 01:18:36,289 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1d7914a5{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-17105602927858116837/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2022-08-22 01:18:36,346 [main] INFO server.AbstractConnector: Started ServerConnector@261d7ee2{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2022-08-22 01:18:36,368 [main] INFO server.Server: Started @48395ms
datanode1_1  | 2022-08-22 01:18:36,374 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2022-08-22 01:18:36,376 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2022-08-22 01:18:36,389 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2022-08-22 01:18:36,412 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode1_1  | 2022-08-22 01:18:36,606 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5c562c48] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2022-08-22 01:18:37,221 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2022-08-22 01:18:37,301 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode1_1  | 2022-08-22 01:18:41,085 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5/DS-37524697-3837-4bb1-a1b8-c11da23e060e/container.db for volume DS-37524697-3837-4bb1-a1b8-c11da23e060e
datanode1_1  | 2022-08-22 01:18:41,143 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5/DS-37524697-3837-4bb1-a1b8-c11da23e060e/container.db for volume DS-37524697-3837-4bb1-a1b8-c11da23e060e
datanode1_1  | 2022-08-22 01:18:41,146 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2022-08-22 01:18:41,166 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode1_1  | 2022-08-22 01:18:41,881 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 61e48a95-a5d7-43eb-addf-1603d4744f3f
datanode1_1  | 2022-08-22 01:18:42,007 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: 61e48a95-a5d7-43eb-addf-1603d4744f3f: start RPC server
datanode1_1  | 2022-08-22 01:18:42,036 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 61e48a95-a5d7-43eb-addf-1603d4744f3f: GrpcService started, listening on 9856
datanode1_1  | 2022-08-22 01:18:42,037 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 61e48a95-a5d7-43eb-addf-1603d4744f3f: GrpcService started, listening on 9857
datanode1_1  | 2022-08-22 01:18:42,041 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: 61e48a95-a5d7-43eb-addf-1603d4744f3f: GrpcService started, listening on 9858
datanode1_1  | 2022-08-22 01:18:42,047 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 61e48a95-a5d7-43eb-addf-1603d4744f3f is started using port 9858 for RATIS
datanode1_1  | 2022-08-22 01:18:42,047 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$393/0x00000008405e2440@6c277721] INFO util.JvmPauseMonitor: JvmPauseMonitor-61e48a95-a5d7-43eb-addf-1603d4744f3f: Started
datanode1_1  | 2022-08-22 01:18:42,058 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 61e48a95-a5d7-43eb-addf-1603d4744f3f is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2022-08-22 01:18:42,058 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 61e48a95-a5d7-43eb-addf-1603d4744f3f is started using port 9856 for RATIS_SERVER
datanode1_1  | 2022-08-22 01:18:42,129 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-08-22 01:18:42,133 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2022-08-22 01:18:45,910 [Command processor thread] INFO server.RaftServer: 61e48a95-a5d7-43eb-addf-1603d4744f3f: addNew group-33E77642BFFD:[61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] returns group-33E77642BFFD:java.util.concurrent.CompletableFuture@46149d21[Not completed]
datanode1_1  | 2022-08-22 01:18:46,016 [pool-23-thread-1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f: new RaftServerImpl for group-33E77642BFFD:[61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-08-22 01:18:46,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-08-22 01:18:46,033 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-08-22 01:18:46,041 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-08-22 01:18:46,045 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-08-22 01:18:46,046 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
kdc_1        | Aug 22 01:19:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:19:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:19:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:20:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:20:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:20:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:20:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:20:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:20:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:20:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:20:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:20:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:21:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:21:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:21:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:21:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:21:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:21:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:21:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2022-08-22 01:17:58,135 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-08-22 01:17:58,217 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-08-22 01:18:04,839 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-08-22 01:18:07,227 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-08-22 01:18:07,945 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-08-22 01:18:07,949 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-08-22 01:18:07,949 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-08-22 01:18:09,478 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-08-22 01:18:09,508 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-08-22 01:18:09,696 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-08-22 01:18:10,417 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-08-22 01:18:13,117 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2022-08-22 01:18:16,242 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2022-08-22 01:18:16,248 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om1_1        | 2022-08-22 01:18:16,250 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2022-08-22 01:18:22,024 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2022-08-22 01:18:22,284 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2022-08-22 01:18:22,284 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2022-08-22 01:18:22,313 [main] ERROR client.OMCertificateClient: Invalid domain om1
om1_1        | 2022-08-22 01:18:22,313 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-08-22 01:18:22,314 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-08-22 01:18:22,314 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-08-22 01:18:22,314 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-08-22 01:18:22,349 [main] INFO om.OzoneManager: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:e5262d73-6b1c-4541-a42b-1a92d56a8751,clusterId:CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5,subject:om1
om1_1        | 2022-08-22 01:18:23,233 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2022-08-22 01:18:24,957 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5;layoutVersion=3
om1_1        | 2022-08-22 01:18:25,106 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2022-08-22 01:18:31,376 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode3_1  | 2022-08-22 01:18:31,377 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode3_1  | 2022-08-22 01:18:31,377 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-08-22 01:18:31,379 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-08-22 01:18:31,419 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-08-22 01:18:31,897 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode3_1  | 2022-08-22 01:18:33,023 [main] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-08-22 01:18:33,030 [main] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
datanode3_1  | 2022-08-22 01:18:33,385 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2022-08-22 01:18:33,389 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2022-08-22 01:18:33,390 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2022-08-22 01:18:33,548 [main] INFO util.log: Logging initialized @45293ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2022-08-22 01:18:34,163 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2022-08-22 01:18:34,203 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2022-08-22 01:18:34,233 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2022-08-22 01:18:34,233 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2022-08-22 01:18:34,234 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2022-08-22 01:18:34,245 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2022-08-22 01:18:34,483 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2022-08-22 01:18:34,503 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
datanode3_1  | 2022-08-22 01:18:34,871 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2022-08-22 01:18:34,871 [main] INFO server.session: No SessionScavenger set, using defaults
kdc_1        | Aug 22 01:21:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:21:32 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:21:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:21:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:21:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:21:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:21:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:21:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131167, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:21:59 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:22:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:22:07 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131319, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:22:08 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131328, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:22:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131328, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:22:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131328, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:22:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131328, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:22:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:22:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:22:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131328, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode2_1  | 2022-08-22 01:18:50,189 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-08-22 01:18:50,236 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-08-22 01:18:50,237 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-08-22 01:18:50,238 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-08-22 01:18:50,270 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-22 01:18:50,272 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-22 01:18:50,296 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-08-22 01:18:50,308 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-08-22 01:18:50,310 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-08-22 01:18:50,314 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-08-22 01:18:50,323 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-08-22 01:18:50,326 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-08-22 01:18:50,604 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-22 01:18:50,624 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-08-22 01:18:50,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-08-22 01:18:50,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-08-22 01:18:50,629 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-08-22 01:18:50,630 [pool-23-thread-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020: start as a follower, conf=-1: [3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-08-22 01:18:50,633 [pool-23-thread-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-08-22 01:18:50,635 [pool-23-thread-1] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-FollowerState
datanode2_1  | 2022-08-22 01:18:50,664 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7719FBA37020,id=3100efb7-0525-45d4-a0fd-e73779181107
datanode2_1  | 2022-08-22 01:18:50,731 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=6bb8ab60-60a4-4383-9c3b-7719fba37020
datanode2_1  | 2022-08-22 01:18:50,735 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=6bb8ab60-60a4-4383-9c3b-7719fba37020.
datanode2_1  | 2022-08-22 01:18:50,737 [Command processor thread] INFO server.RaftServer: 3100efb7-0525-45d4-a0fd-e73779181107: addNew group-BE98E62D2A2A:[61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] returns group-BE98E62D2A2A:java.util.concurrent.CompletableFuture@615c1bd2[Not completed]
datanode2_1  | 2022-08-22 01:18:50,765 [pool-23-thread-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107: new RaftServerImpl for group-BE98E62D2A2A:[61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-08-22 01:18:50,766 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-08-22 01:18:50,769 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-08-22 01:18:50,769 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-08-22 01:18:50,769 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-08-22 01:18:50,793 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-08-22 01:18:50,796 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-08-22 01:18:50,797 [pool-23-thread-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A: ConfigurationManager, init=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-08-22 01:18:50,798 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-08-22 01:18:50,800 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-08-22 01:18:50,804 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-08-22 01:18:50,804 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a does not exist. Creating ...
datanode2_1  | 2022-08-22 01:18:50,811 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a/in_use.lock acquired by nodename 6@07ab41f3ff0f
datanode2_1  | 2022-08-22 01:18:50,813 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a has been successfully formatted.
datanode2_1  | 2022-08-22 01:18:50,830 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BE98E62D2A2A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-08-22 01:18:50,868 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-08-22 01:18:50,870 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-08-22 01:18:50,871 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-08-22 01:18:46,046 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-08-22 01:18:46,070 [pool-23-thread-1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD: ConfigurationManager, init=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-08-22 01:18:46,076 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-08-22 01:18:46,092 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-08-22 01:18:46,109 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-08-22 01:18:46,111 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/23fafdf1-808a-47f3-a6c2-33e77642bffd does not exist. Creating ...
datanode1_1  | 2022-08-22 01:18:46,147 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/23fafdf1-808a-47f3-a6c2-33e77642bffd/in_use.lock acquired by nodename 6@2cdeb7efff84
datanode1_1  | 2022-08-22 01:18:46,175 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/23fafdf1-808a-47f3-a6c2-33e77642bffd has been successfully formatted.
datanode1_1  | 2022-08-22 01:18:46,211 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-33E77642BFFD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-08-22 01:18:46,225 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-08-22 01:18:46,235 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-08-22 01:18:46,279 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-08-22 01:18:46,283 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-08-22 01:18:46,284 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-08-22 01:18:46,569 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-22 01:18:46,738 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-08-22 01:18:46,770 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-08-22 01:18:46,830 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/23fafdf1-808a-47f3-a6c2-33e77642bffd
datanode1_1  | 2022-08-22 01:18:46,842 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-08-22 01:18:46,851 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-08-22 01:18:46,855 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-22 01:18:46,861 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-08-22 01:18:46,868 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-08-22 01:18:46,882 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-08-22 01:18:46,886 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-08-22 01:18:46,886 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-08-22 01:18:46,956 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-08-22 01:18:46,997 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-08-22 01:18:46,999 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-08-22 01:18:47,019 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-22 01:18:47,019 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-22 01:18:47,023 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-08-22 01:18:47,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-08-22 01:18:47,032 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-08-22 01:18:47,037 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-08-22 01:18:47,038 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-08-22 01:18:47,039 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-08-22 01:18:47,190 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-08-22 01:18:47,212 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-08-22 01:18:47,212 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-08-22 01:18:47,213 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-08-22 01:18:47,213 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-08-22 01:18:47,220 [pool-23-thread-1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD: start as a follower, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-08-22 01:18:47,221 [pool-23-thread-1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-08-22 01:18:47,232 [pool-23-thread-1] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: start 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-FollowerState
datanode1_1  | 2022-08-22 01:18:47,275 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-33E77642BFFD,id=61e48a95-a5d7-43eb-addf-1603d4744f3f
datanode1_1  | 2022-08-22 01:18:47,311 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=23fafdf1-808a-47f3-a6c2-33e77642bffd
datanode1_1  | 2022-08-22 01:18:47,316 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=23fafdf1-808a-47f3-a6c2-33e77642bffd.
datanode1_1  | 2022-08-22 01:18:52,280 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-FollowerState] INFO impl.FollowerState: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5047955672ns, electionTimeout:5013ms
datanode1_1  | 2022-08-22 01:18:52,281 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-FollowerState] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: shutdown 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-FollowerState
datanode1_1  | 2022-08-22 01:18:52,282 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-FollowerState] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2022-08-22 01:18:52,287 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-08-22 01:18:52,287 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-FollowerState] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: start 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1
datanode1_1  | 2022-08-22 01:18:52,317 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO impl.LeaderElection: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1], old=null
datanode1_1  | 2022-08-22 01:18:52,318 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO impl.LeaderElection: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2022-08-22 01:18:52,319 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: shutdown 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1
datanode1_1  | 2022-08-22 01:18:52,319 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2022-08-22 01:18:52,320 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-33E77642BFFD with new leaderId: 61e48a95-a5d7-43eb-addf-1603d4744f3f
datanode1_1  | 2022-08-22 01:18:52,356 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD: change Leader from null to 61e48a95-a5d7-43eb-addf-1603d4744f3f at term 1 for becomeLeader, leader elected after 6095ms
datanode1_1  | 2022-08-22 01:18:52,425 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-08-22 01:18:52,449 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-08-22 01:18:34,877 [main] INFO server.session: node0 Scavenging every 600000ms
datanode3_1  | 2022-08-22 01:18:35,124 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-08-22 01:18:35,138 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@69815126{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2022-08-22 01:18:35,140 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@22a89db{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2022-08-22 01:18:35,434 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2022-08-22 01:18:35,444 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1b6441c9{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_3_0-SNAPSHOT_jar-_-any-12027760087170150478/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2022-08-22 01:18:35,479 [main] INFO server.AbstractConnector: Started ServerConnector@7789719e{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2022-08-22 01:18:35,479 [main] INFO server.Server: Started @47231ms
datanode3_1  | 2022-08-22 01:18:35,504 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2022-08-22 01:18:35,504 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2022-08-22 01:18:35,508 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2022-08-22 01:18:35,546 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode3_1  | 2022-08-22 01:18:35,729 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@299c51a6] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2022-08-22 01:18:36,054 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2022-08-22 01:18:36,100 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode3_1  | 2022-08-22 01:18:40,979 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5/DS-fc48dc4f-bb82-4a45-9a27-fb7b9c76b11b/container.db for volume DS-fc48dc4f-bb82-4a45-9a27-fb7b9c76b11b
datanode3_1  | 2022-08-22 01:18:41,065 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is stopped at /data/hdds/hdds/CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5/DS-fc48dc4f-bb82-4a45-9a27-fb7b9c76b11b/container.db for volume DS-fc48dc4f-bb82-4a45-9a27-fb7b9c76b11b
datanode3_1  | 2022-08-22 01:18:41,073 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2022-08-22 01:18:41,075 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode3_1  | 2022-08-22 01:18:41,503 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 3c60044e-b181-445f-8fa2-782a9e9eb45c
datanode3_1  | 2022-08-22 01:18:41,665 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.RaftServer: 3c60044e-b181-445f-8fa2-782a9e9eb45c: start RPC server
datanode3_1  | 2022-08-22 01:18:41,682 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 3c60044e-b181-445f-8fa2-782a9e9eb45c: GrpcService started, listening on 9856
datanode3_1  | 2022-08-22 01:18:41,721 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 3c60044e-b181-445f-8fa2-782a9e9eb45c: GrpcService started, listening on 9857
datanode3_1  | 2022-08-22 01:18:41,727 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO server.GrpcService: 3c60044e-b181-445f-8fa2-782a9e9eb45c: GrpcService started, listening on 9858
datanode3_1  | 2022-08-22 01:18:41,733 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3c60044e-b181-445f-8fa2-782a9e9eb45c is started using port 9858 for RATIS
datanode3_1  | 2022-08-22 01:18:41,735 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3c60044e-b181-445f-8fa2-782a9e9eb45c is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2022-08-22 01:18:41,735 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 3c60044e-b181-445f-8fa2-782a9e9eb45c is started using port 9856 for RATIS_SERVER
datanode3_1  | 2022-08-22 01:18:41,735 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$392/0x00000008405e6840@191f4d79] INFO util.JvmPauseMonitor: JvmPauseMonitor-3c60044e-b181-445f-8fa2-782a9e9eb45c: Started
datanode3_1  | 2022-08-22 01:18:41,793 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-08-22 01:18:41,793 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2022-08-22 01:18:54,848 [grpc-default-executor-0] INFO server.RaftServer: 3c60044e-b181-445f-8fa2-782a9e9eb45c: addNew group-BE98E62D2A2A:[61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1] returns group-BE98E62D2A2A:java.util.concurrent.CompletableFuture@7df19507[Not completed]
datanode3_1  | 2022-08-22 01:18:54,918 [pool-23-thread-1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c: new RaftServerImpl for group-BE98E62D2A2A:[61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-08-22 01:18:54,930 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-08-22 01:18:54,934 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-08-22 01:18:54,936 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-08-22 01:18:54,936 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-08-22 01:18:54,937 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-08-22 01:18:54,937 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-08-22 01:18:54,965 [pool-23-thread-1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A: ConfigurationManager, init=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-08-22 01:18:54,972 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-08-22 01:18:55,011 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-08-22 01:18:55,012 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-08-22 01:18:55,027 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a does not exist. Creating ...
datanode3_1  | 2022-08-22 01:18:55,056 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a/in_use.lock acquired by nodename 7@d60fa041091d
datanode3_1  | 2022-08-22 01:18:55,091 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a has been successfully formatted.
datanode3_1  | 2022-08-22 01:18:55,156 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BE98E62D2A2A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-08-22 01:18:55,170 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-08-22 01:18:55,193 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-08-22 01:18:55,292 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2022-08-22 01:18:34,953 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2022-08-22 01:18:34,986 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2022-08-22 01:18:41,857 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2022-08-22 01:18:44,900 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2022-08-22 01:18:45,608 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2022-08-22 01:18:45,609 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2022-08-22 01:18:45,609 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2022-08-22 01:18:45,695 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-08-22 01:18:45,942 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om1_1        | 2022-08-22 01:18:47,599 [main] INFO reflections.Reflections: Reflections took 1349 ms to scan 1 urls, producing 113 keys and 334 values [using 2 cores]
om1_1        | 2022-08-22 01:18:48,492 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2022-08-22 01:18:48,492 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2022-08-22 01:18:48,495 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-08-22 01:18:50,485 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-08-22 01:18:50,743 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2022-08-22 01:18:54,493 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2022-08-22 01:18:55,065 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2022-08-22 01:18:55,088 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/1181595495935.crt.
om1_1        | 2022-08-22 01:18:55,117 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1085506235870.crt.
om1_1        | 2022-08-22 01:18:55,491 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2022-08-22 01:18:56,581 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-08-22 01:18:56,589 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1        | 2022-08-22 01:18:58,454 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om1_1        | 2022-08-22 01:18:58,548 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om1_1        | 2022-08-22 01:18:58,549 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om1_1        | 2022-08-22 01:18:59,516 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om1_1        | 2022-08-22 01:19:00,023 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-08-22 01:19:00,029 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om1_1        | 2022-08-22 01:19:00,190 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1        | 2022-08-22 01:19:00,802 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1        | 2022-08-22 01:19:00,860 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1        | 2022-08-22 01:19:01,005 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om1:9872, om3:9872, om2:9872
om1_1        | 2022-08-22 01:19:01,045 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
datanode3_1  | 2022-08-22 01:18:55,298 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-22 01:18:55,328 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-08-22 01:18:55,359 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-22 01:18:55,415 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-08-22 01:18:55,429 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-08-22 01:18:55,508 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a
datanode3_1  | 2022-08-22 01:18:55,512 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-08-22 01:18:55,512 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-08-22 01:18:55,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-22 01:18:55,529 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-08-22 01:18:55,530 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-08-22 01:18:55,545 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-08-22 01:18:55,547 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-08-22 01:18:55,550 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-08-22 01:18:55,603 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-08-22 01:18:55,612 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-08-22 01:18:55,616 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-08-22 01:18:55,723 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-22 01:18:55,729 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
kdc_1        | Aug 22 01:22:34 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131354, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:22:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131354, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:22:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131354, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:22:49 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131369, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:22:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131369, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:22:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131369, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:22:59 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131379, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:23:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131379, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:23:07 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131379, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:23:08 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131388, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:23:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131388, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:23:13 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131393, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:23:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131393, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:23:17 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131397, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:23:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131397, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:23:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131397, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:23:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
om1_1        | 2022-08-22 01:19:02,275 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om1_1        | 2022-08-22 01:19:02,840 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om1_1        | 2022-08-22 01:19:02,840 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-08-22 01:19:02,843 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om1_1        | 2022-08-22 01:19:02,843 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-08-22 01:19:02,844 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1        | 2022-08-22 01:19:02,845 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1        | 2022-08-22 01:19:02,879 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-08-22 01:19:02,892 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1        | 2022-08-22 01:19:02,893 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1        | 2022-08-22 01:19:02,987 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om1_1        | 2022-08-22 01:19:02,989 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om1_1        | 2022-08-22 01:19:05,046 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1        | 2022-08-22 01:19:05,052 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om1_1        | 2022-08-22 01:19:05,064 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om1_1        | 2022-08-22 01:19:05,065 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-08-22 01:19:05,067 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-08-22 01:19:05,089 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-08-22 01:19:05,133 [main] INFO server.RaftServer: om1: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@38f12596[Not completed]
om1_1        | 2022-08-22 01:19:05,137 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1        | 2022-08-22 01:19:05,204 [pool-27-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om1_1        | 2022-08-22 01:19:05,222 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om1_1        | 2022-08-22 01:19:05,222 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om1_1        | 2022-08-22 01:19:05,223 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1        | 2022-08-22 01:19:05,224 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1        | 2022-08-22 01:19:05,225 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1        | 2022-08-22 01:19:05,225 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om1_1        | 2022-08-22 01:19:05,246 [main] INFO om.OzoneManager: Creating RPC Server
om1_1        | 2022-08-22 01:19:05,266 [pool-27-thread-1] INFO server.RaftServer$Division: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om1_1        | 2022-08-22 01:19:05,271 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1        | 2022-08-22 01:19:05,281 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1        | 2022-08-22 01:19:05,296 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om1_1        | 2022-08-22 01:19:05,297 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1        | 2022-08-22 01:19:05,437 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@om1
om1_1        | 2022-08-22 01:19:05,553 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1        | 2022-08-22 01:19:05,565 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1        | 2022-08-22 01:19:05,571 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1        | 2022-08-22 01:19:05,659 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1        | 2022-08-22 01:19:05,665 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1        | 2022-08-22 01:19:05,682 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om1_1        | 2022-08-22 01:19:05,811 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-08-22 01:19:05,986 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1        | 2022-08-22 01:19:05,989 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om1_1        | 2022-08-22 01:19:06,042 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1        | 2022-08-22 01:19:06,048 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1        | 2022-08-22 01:19:06,058 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1        | 2022-08-22 01:19:06,064 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1        | 2022-08-22 01:19:06,085 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1        | 2022-08-22 01:19:06,097 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | 2022-08-22 01:19:06,106 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1        | 2022-08-22 01:19:06,120 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1        | 2022-08-22 01:19:06,128 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1        | 2022-08-22 01:19:06,270 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1        | 2022-08-22 01:19:06,304 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om1_1        | 2022-08-22 01:19:06,305 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
kdc_1        | Aug 22 01:23:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:23:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131397, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:23:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131397, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:23:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131397, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:23:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131397, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:23:45 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131425, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:23:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131425, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:23:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131425, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:23:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131425, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:24:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131425, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:24:04 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131444, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:24:04 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131444, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:24:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131444, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:24:09 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131449, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:24:09 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131449, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:24:13 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131449, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:24:13 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131453, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:24:13 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131453, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:24:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131453, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:24:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131453, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:24:23 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131463, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:24:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:24:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:24:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131463, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:24:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131463, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:24:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131463, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:24:39 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131463, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:24:40 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131480, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:24:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131480, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:24:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131480, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:24:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131480, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:24:59 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131499, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:25:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131499, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:25:07 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131499, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:25:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131499, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-08-22 01:17:57,392 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-08-22 01:17:57,463 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-08-22 01:18:04,015 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-08-22 01:18:06,185 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-08-22 01:18:06,660 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-08-22 01:18:06,660 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-08-22 01:18:06,661 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-08-22 01:18:08,345 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-08-22 01:18:08,351 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-08-22 01:18:08,430 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-08-22 01:18:09,012 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-08-22 01:18:11,185 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2022-08-22 01:18:14,249 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2022-08-22 01:18:14,249 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om2_1        | 2022-08-22 01:18:14,250 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2022-08-22 01:18:18,948 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2022-08-22 01:18:19,247 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2022-08-22 01:18:19,260 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2022-08-22 01:18:19,271 [main] ERROR client.OMCertificateClient: Invalid domain om2
om2_1        | 2022-08-22 01:18:19,282 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-08-22 01:18:19,292 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-08-22 01:18:19,293 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-08-22 01:18:19,293 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-08-22 01:18:19,306 [main] INFO om.OzoneManager: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:e5262d73-6b1c-4541-a42b-1a92d56a8751,clusterId:CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5,subject:om2
om2_1        | 2022-08-22 01:18:20,280 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2022-08-22 01:18:22,501 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5;layoutVersion=3
om2_1        | 2022-08-22 01:18:22,651 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2022-08-22 01:18:32,242 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
datanode1_1  | 2022-08-22 01:18:52,475 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-08-22 01:18:52,511 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-08-22 01:18:52,512 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-08-22 01:18:52,517 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-08-22 01:18:52,534 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-08-22 01:18:52,557 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-08-22 01:18:52,574 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: start 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderStateImpl
datanode1_1  | 2022-08-22 01:18:52,680 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-08-22 01:18:52,964 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-LeaderElection1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD: set configuration 0: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-08-22 01:18:53,109 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-33E77642BFFD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/23fafdf1-808a-47f3-a6c2-33e77642bffd/current/log_inprogress_0
datanode1_1  | 2022-08-22 01:18:58,281 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: 61e48a95-a5d7-43eb-addf-1603d4744f3f: Failed requestVote 3100efb7-0525-45d4-a0fd-e73779181107->61e48a95-a5d7-43eb-addf-1603d4744f3f#0
datanode2_1  | 2022-08-22 01:18:50,871 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-22 01:18:50,871 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-08-22 01:18:50,871 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-22 01:18:50,872 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-08-22 01:18:50,873 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-08-22 01:18:50,876 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a
datanode2_1  | 2022-08-22 01:18:50,876 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-08-22 01:18:50,877 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-08-22 01:18:50,877 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-22 01:18:50,877 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-08-22 01:18:50,877 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-08-22 01:18:50,877 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-08-22 01:18:50,877 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-08-22 01:18:50,878 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-08-22 01:18:50,882 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-08-22 01:18:50,884 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-08-22 01:18:50,885 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-08-22 01:18:50,891 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-22 01:18:50,892 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-22 01:18:50,901 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-08-22 01:18:50,901 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-08-22 01:18:50,901 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-08-22 01:18:50,901 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-08-22 01:18:50,902 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-08-22 01:18:50,902 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-08-22 01:18:50,907 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-22 01:18:50,911 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-08-22 01:18:50,911 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-08-22 01:18:50,911 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-08-22 01:18:50,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-08-22 01:18:50,912 [pool-23-thread-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A: start as a follower, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-08-22 01:18:50,917 [pool-23-thread-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-08-22 01:18:50,917 [pool-23-thread-1] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-FollowerState
datanode2_1  | 2022-08-22 01:18:50,919 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BE98E62D2A2A,id=3100efb7-0525-45d4-a0fd-e73779181107
datanode2_1  | 2022-08-22 01:18:50,939 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=fcac9307-f9c6-4fe2-a014-be98e62d2a2a
datanode2_1  | 2022-08-22 01:18:55,718 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-FollowerState] INFO impl.FollowerState: 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5083095764ns, electionTimeout:5052ms
datanode2_1  | 2022-08-22 01:18:55,718 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-FollowerState] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-FollowerState
datanode2_1  | 2022-08-22 01:18:55,719 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-FollowerState] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-08-22 01:18:55,722 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-22 01:18:55,722 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-FollowerState] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1
datanode2_1  | 2022-08-22 01:18:55,740 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-08-22 01:18:55,744 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode2_1  | 2022-08-22 01:18:55,745 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1
om1_1        | 2022-08-22 01:19:06,381 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1        | 2022-08-22 01:19:06,388 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1        | 2022-08-22 01:19:06,447 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1        | 2022-08-22 01:19:06,475 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1        | 2022-08-22 01:19:06,515 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1        | 2022-08-22 01:19:06,523 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1        | 2022-08-22 01:19:06,546 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1        | 2022-08-22 01:19:06,546 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om1_1        | 2022-08-22 01:19:07,041 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1        | 2022-08-22 01:19:07,042 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om1_1        | 2022-08-22 01:19:07,042 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om1_1        | 2022-08-22 01:19:07,042 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om1_1        | 2022-08-22 01:19:07,049 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om1_1        | 2022-08-22 01:19:07,666 [main] INFO reflections.Reflections: Reflections took 2079 ms to scan 8 urls, producing 23 keys and 517 values [using 2 cores]
om1_1        | 2022-08-22 01:19:08,408 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1        | 2022-08-22 01:19:08,441 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1        | 2022-08-22 01:19:11,645 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1        | 2022-08-22 01:19:11,745 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1        | 2022-08-22 01:19:11,747 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1        | 2022-08-22 01:19:11,963 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.25.0.111:9862
om1_1        | 2022-08-22 01:19:11,965 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1        | 2022-08-22 01:19:11,972 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-22 01:19:11,975 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1        | 2022-08-22 01:19:11,976 [om1-impl-thread1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-08-22 01:19:11,982 [om1-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1        | 2022-08-22 01:19:12,007 [Listener at om1/9862] INFO server.RaftServer: om1: start RPC server
om1_1        | 2022-08-22 01:19:12,204 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
om1_1        | 2022-08-22 01:19:12,220 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$452/0x00000008405b2040@77dfc923] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om1_1        | 2022-08-22 01:19:12,221 [Listener at om1/9862] INFO om.OzoneManager: Starting OM block token secret manager
om1_1        | 2022-08-22 01:19:12,221 [Listener at om1/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-08-22 01:19:12,222 [Listener at om1/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om1_1        | 2022-08-22 01:19:12,225 [Listener at om1/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om1_1        | 2022-08-22 01:19:12,230 [Listener at om1/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om1_1        | 2022-08-22 01:19:12,241 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om1_1        | 2022-08-22 01:19:12,354 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1        | 2022-08-22 01:19:12,354 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om1_1        | 2022-08-22 01:19:12,354 [Listener at om1/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om1_1        | 2022-08-22 01:19:12,461 [Listener at om1/9862] INFO util.log: Logging initialized @46298ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1        | 2022-08-22 01:19:12,798 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1        | 2022-08-22 01:19:12,836 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1        | 2022-08-22 01:19:12,863 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om1_1        | 2022-08-22 01:19:12,863 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om1_1        | 2022-08-22 01:19:12,863 [Listener at om1/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om1_1        | 2022-08-22 01:19:12,867 [Listener at om1/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om1_1        | 2022-08-22 01:19:13,063 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1        | 2022-08-22 01:19:13,069 [Listener at om1/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om1_1        | 2022-08-22 01:19:13,206 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1        | 2022-08-22 01:19:13,207 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1        | 2022-08-22 01:19:13,215 [Listener at om1/9862] INFO server.session: node0 Scavenging every 600000ms
om1_1        | 2022-08-22 01:19:13,281 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-08-22 01:19:13,287 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4aab6203{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
kdc_1        | Aug 22 01:25:13 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131513, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:25:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131513, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:25:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131513, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:25:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:25:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:25:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131513, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:26:03 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131563, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:26:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131563, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:26:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.114: ISSUE: authtime 1661130997, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:26:13 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131573, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:26:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131573, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:26:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:26:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:26:27 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131587, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:26:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131587, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:26:43 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131603, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:26:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131603, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:26:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131603, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:26:59 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131619, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:27:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131619, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:27:08 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131628, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:27:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131628, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:27:16 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131636, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:27:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131636, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:27:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:27:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:27:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131636, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:27:29 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131649, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:27:32 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131649, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:27:43 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:27:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:28:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:28:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:29:11 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131751, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:29:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131751, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:29:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
om1_1        | 2022-08-22 01:19:13,294 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@18acf886{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1        | 2022-08-22 01:19:13,557 [Listener at om1/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om1_1        | 2022-08-22 01:19:13,585 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@93235f1{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-11963241631356431077/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1        | 2022-08-22 01:19:13,612 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@79091c84{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1        | 2022-08-22 01:19:13,612 [Listener at om1/9862] INFO server.Server: Started @47450ms
om1_1        | 2022-08-22 01:19:13,614 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2022-08-22 01:19:13,614 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1        | 2022-08-22 01:19:13,620 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1        | 2022-08-22 01:19:13,620 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1        | 2022-08-22 01:19:13,635 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1        | 2022-08-22 01:19:13,756 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om1_1        | 2022-08-22 01:19:13,920 [Listener at om1/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om1_1        | 2022-08-22 01:19:13,950 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3cb034af] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1        | 2022-08-22 01:19:16,230 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35131
om1_1        | 2022-08-22 01:19:16,241 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:19:17,061 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5084960755ns, electionTimeout:5081ms
om1_1        | 2022-08-22 01:19:17,067 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-08-22 01:19:17,074 [om1@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1        | 2022-08-22 01:19:17,076 [om1@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om1_1        | 2022-08-22 01:19:17,077 [om1@group-562213E44849-FollowerState] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1        | 2022-08-22 01:19:17,161 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-22 01:19:17,502 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35238
om1_1        | 2022-08-22 01:19:17,541 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:19:17,707 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-08-22 01:19:17,718 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om1_1        | 2022-08-22 01:19:17,781 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om1 at current term 1
om1_1        | 2022-08-22 01:19:17,787 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-22 01:19:17,788 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om1 at current term 1
om1_1        | 2022-08-22 01:19:17,789 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:FAIL-t1. Peer's state: om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-22 01:19:18,113 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om1_1        | 2022-08-22 01:19:18,113 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om1<-om3#0:FAIL-t1
om1_1        | 2022-08-22 01:19:18,113 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om1<-om2#0:FAIL-t1
om1_1        | 2022-08-22 01:19:18,113 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om1_1        | 2022-08-22 01:19:18,114 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om1_1        | 2022-08-22 01:19:18,114 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1        | 2022-08-22 01:19:18,114 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-08-22 01:19:22,945 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 2, (t:0, i:~))
datanode3_1  | 2022-08-22 01:18:55,772 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-08-22 01:18:55,778 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-08-22 01:18:55,785 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-08-22 01:18:55,786 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-08-22 01:18:55,800 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-08-22 01:18:55,801 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-08-22 01:18:56,062 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-08-22 01:18:56,079 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-08-22 01:18:56,083 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-08-22 01:18:56,083 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-08-22 01:18:56,084 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-08-22 01:18:56,086 [pool-23-thread-1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A: start as a follower, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-08-22 01:18:56,103 [pool-23-thread-1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-08-22 01:18:56,105 [pool-23-thread-1] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: start 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A-FollowerState
datanode3_1  | 2022-08-22 01:18:56,157 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BE98E62D2A2A,id=3c60044e-b181-445f-8fa2-782a9e9eb45c
datanode3_1  | 2022-08-22 01:18:57,148 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A: receive requestVote(ELECTION, 3100efb7-0525-45d4-a0fd-e73779181107, group-BE98E62D2A2A, 1, (t:0, i:0))
datanode3_1  | 2022-08-22 01:18:57,177 [grpc-default-executor-0] INFO impl.VoteContext: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A-FOLLOWER: accept ELECTION from 3100efb7-0525-45d4-a0fd-e73779181107: our priority 0 <= candidate's priority 1
datanode3_1  | 2022-08-22 01:18:57,178 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:3100efb7-0525-45d4-a0fd-e73779181107
datanode3_1  | 2022-08-22 01:18:57,178 [grpc-default-executor-0] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: shutdown 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A-FollowerState
datanode3_1  | 2022-08-22 01:18:57,179 [grpc-default-executor-0] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: start 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A-FollowerState
datanode3_1  | 2022-08-22 01:18:57,179 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A-FollowerState] INFO impl.FollowerState: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A-FollowerState was interrupted
datanode3_1  | 2022-08-22 01:18:57,235 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A replies to ELECTION vote request: 3100efb7-0525-45d4-a0fd-e73779181107<-3c60044e-b181-445f-8fa2-782a9e9eb45c#0:OK-t1. Peer's state: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A:t1, leader=null, voted=3100efb7-0525-45d4-a0fd-e73779181107, raftlog=3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-08-22 01:18:58,114 [3c60044e-b181-445f-8fa2-782a9e9eb45c-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BE98E62D2A2A with new leaderId: 3100efb7-0525-45d4-a0fd-e73779181107
datanode3_1  | 2022-08-22 01:18:58,115 [3c60044e-b181-445f-8fa2-782a9e9eb45c-server-thread1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A: change Leader from null to 3100efb7-0525-45d4-a0fd-e73779181107 at term 1 for appendEntries, leader elected after 2944ms
datanode3_1  | 2022-08-22 01:18:58,246 [3c60044e-b181-445f-8fa2-782a9e9eb45c-server-thread1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A: set configuration 0: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-08-22 01:18:58,286 [3c60044e-b181-445f-8fa2-782a9e9eb45c-server-thread1] INFO segmented.SegmentedRaftLogWorker: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-08-22 01:18:58,648 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-BE98E62D2A2A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a/current/log_inprogress_0
datanode3_1  | 2022-08-22 01:19:00,051 [grpc-default-executor-0] INFO server.RaftServer: 3c60044e-b181-445f-8fa2-782a9e9eb45c: addNew group-C7FFD18C9838:[61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] returns group-C7FFD18C9838:java.util.concurrent.CompletableFuture@6bc46309[Not completed]
datanode3_1  | 2022-08-22 01:19:00,063 [pool-23-thread-1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c: new RaftServerImpl for group-C7FFD18C9838:[61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-08-22 01:19:00,064 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2022-08-22 01:18:32,329 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2022-08-22 01:18:38,758 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2022-08-22 01:18:41,455 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2022-08-22 01:18:41,864 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2022-08-22 01:18:41,866 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2022-08-22 01:18:41,868 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2022-08-22 01:18:41,937 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-08-22 01:18:42,260 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om2_1        | 2022-08-22 01:18:44,205 [main] INFO reflections.Reflections: Reflections took 1246 ms to scan 1 urls, producing 113 keys and 334 values [using 2 cores]
om2_1        | 2022-08-22 01:18:45,869 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2022-08-22 01:18:45,869 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2022-08-22 01:18:45,872 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-08-22 01:18:47,957 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-08-22 01:18:48,186 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2022-08-22 01:18:51,434 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2022-08-22 01:18:52,171 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/1178992405738.crt.
om2_1        | 2022-08-22 01:18:52,191 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2022-08-22 01:18:52,215 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1085506235870.crt.
om2_1        | 2022-08-22 01:18:52,442 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2022-08-22 01:18:53,416 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-08-22 01:18:53,419 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1        | 2022-08-22 01:18:54,952 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om2_1        | 2022-08-22 01:18:55,025 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om2_1        | 2022-08-22 01:18:55,028 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om2_1        | 2022-08-22 01:18:55,736 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om2_1        | 2022-08-22 01:18:56,412 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-08-22 01:18:56,415 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om2_1        | 2022-08-22 01:18:56,495 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1        | 2022-08-22 01:18:56,934 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1        | 2022-08-22 01:18:56,981 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1        | 2022-08-22 01:18:57,321 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om2:9872, om1:9872, om3:9872
om2_1        | 2022-08-22 01:18:57,396 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1        | 2022-08-22 01:18:59,140 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om2_1        | 2022-08-22 01:18:59,611 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om2_1        | 2022-08-22 01:18:59,617 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-08-22 01:18:59,618 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om2_1        | 2022-08-22 01:18:59,618 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-08-22 01:18:59,639 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1        | 2022-08-22 01:18:59,640 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1        | 2022-08-22 01:18:59,646 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-08-22 01:18:59,647 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1        | 2022-08-22 01:18:59,647 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1        | 2022-08-22 01:18:59,730 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om2_1        | 2022-08-22 01:18:59,730 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode1_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: 61e48a95-a5d7-43eb-addf-1603d4744f3f: group-BE98E62D2A2A not found.
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:148)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:347)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:356)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:351)
datanode1_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:603)
datanode1_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:172)
datanode1_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:382)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:340)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:866)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode1_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode1_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode1_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode1_1  | 2022-08-22 01:18:58,471 [pool-23-thread-1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f: new RaftServerImpl for group-BE98E62D2A2A:[61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-08-22 01:18:58,480 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-08-22 01:18:58,483 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-08-22 01:18:58,484 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-08-22 01:18:58,484 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-08-22 01:18:58,484 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-08-22 01:18:58,487 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-08-22 01:18:58,490 [pool-23-thread-1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-BE98E62D2A2A: ConfigurationManager, init=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-08-22 01:18:58,490 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-08-22 01:18:58,491 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-08-22 01:18:58,492 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-08-22 01:18:58,492 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a does not exist. Creating ...
datanode1_1  | 2022-08-22 01:18:58,507 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a/in_use.lock acquired by nodename 6@2cdeb7efff84
datanode1_1  | 2022-08-22 01:18:58,515 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a has been successfully formatted.
datanode1_1  | 2022-08-22 01:18:58,516 [grpc-default-executor-1] INFO server.RaftServer: 61e48a95-a5d7-43eb-addf-1603d4744f3f: addNew group-BE98E62D2A2A:[61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1] returns group-BE98E62D2A2A:java.util.concurrent.CompletableFuture@3cb91abf[Not completed]
datanode1_1  | 2022-08-22 01:18:58,533 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-BE98E62D2A2A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-08-22 01:18:58,533 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-08-22 01:18:58,533 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-08-22 01:18:58,534 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-08-22 01:18:58,534 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-08-22 01:18:58,535 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-08-22 01:18:58,535 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-22 01:18:58,536 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-08-22 01:18:58,578 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-08-22 01:18:58,580 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-BE98E62D2A2A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a
datanode1_1  | 2022-08-22 01:18:58,580 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-08-22 01:18:58,580 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-08-22 01:18:58,580 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-22 01:18:58,581 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-08-22 01:18:58,587 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-08-22 01:18:58,588 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-08-22 01:18:58,606 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-08-22 01:18:58,607 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-08-22 01:18:58,617 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-08-22 01:18:58,621 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-08-22 01:18:58,628 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-08-22 01:18:58,629 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-BE98E62D2A2A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-22 01:18:58,629 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-BE98E62D2A2A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-22 01:18:58,646 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-08-22 01:18:58,647 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-08-22 01:18:58,648 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
kdc_1        | Aug 22 01:29:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:29:27 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131767, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:29:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131767, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:30:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:30:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:31:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:31:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:31:49 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131909, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:31:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131909, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:32:04 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661131924, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:32:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661131924, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:32:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:32:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:33:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:33:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:34:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:34:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:35:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:35:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:36:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:36:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:37:16 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661132236, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:37:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661132236, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:37:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:37:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: LOOKING_UP_SERVER: authtime 0, etypes {rep=UNSUPPORTED:(0)} recon/recon@EXAMPLE.COM for HTTP/om3@EXAMPLE.COM, Server not found in Kerberos database
kdc_1        | Aug 22 01:37:43 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661132263, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:37:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1661132263, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1        | Aug 22 01:37:54 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661132274, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Aug 22 01:37:54 kdc krb5kdc[7](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1661132274, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/s3g@EXAMPLE.COM
om1_1        | 2022-08-22 01:19:23,021 [grpc-default-executor-1] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: accept ELECTION from om3: our priority 0 <= candidate's priority 0
om1_1        | 2022-08-22 01:19:23,021 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:om3
om1_1        | 2022-08-22 01:19:23,023 [grpc-default-executor-1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1        | 2022-08-22 01:19:23,023 [grpc-default-executor-1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1        | 2022-08-22 01:19:23,029 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 2, (t:0, i:~))
om1_1        | 2022-08-22 01:19:23,023 [om1@group-562213E44849-FollowerState] INFO impl.FollowerState: om1@group-562213E44849-FollowerState was interrupted
datanode2_1  | 2022-08-22 01:18:55,759 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-08-22 01:18:55,759 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-7719FBA37020 with new leaderId: 3100efb7-0525-45d4-a0fd-e73779181107
datanode2_1  | 2022-08-22 01:18:55,784 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020: change Leader from null to 3100efb7-0525-45d4-a0fd-e73779181107 at term 1 for becomeLeader, leader elected after 5918ms
datanode2_1  | 2022-08-22 01:18:55,808 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-08-22 01:18:55,825 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-08-22 01:18:55,826 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-08-22 01:18:55,853 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-08-22 01:18:55,853 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode2_1  | 2022-08-22 01:18:55,854 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-08-22 01:18:55,867 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-08-22 01:18:55,891 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-08-22 01:18:55,909 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderStateImpl
datanode2_1  | 2022-08-22 01:18:55,931 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-FollowerState] INFO impl.FollowerState: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5013499437ns, electionTimeout:5010ms
datanode2_1  | 2022-08-22 01:18:55,939 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-FollowerState] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-FollowerState
datanode2_1  | 2022-08-22 01:18:55,939 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-FollowerState] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-08-22 01:18:55,939 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-22 01:18:55,940 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-FollowerState] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2
datanode2_1  | 2022-08-22 01:18:56,008 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:1], old=null
datanode2_1  | 2022-08-22 01:18:56,060 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-08-22 01:18:56,512 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-LeaderElection1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020: set configuration 0: [3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-08-22 01:18:57,330 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-08-22 01:18:57,342 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO impl.LeaderElection:   Response 0: 3100efb7-0525-45d4-a0fd-e73779181107<-3c60044e-b181-445f-8fa2-782a9e9eb45c#0:OK-t1
datanode2_1  | 2022-08-22 01:18:57,344 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2 ELECTION round 0: result PASSED
datanode2_1  | 2022-08-22 01:18:57,344 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2
datanode2_1  | 2022-08-22 01:18:57,344 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode2_1  | 2022-08-22 01:18:57,345 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BE98E62D2A2A with new leaderId: 3100efb7-0525-45d4-a0fd-e73779181107
datanode2_1  | 2022-08-22 01:18:57,360 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A: change Leader from null to 3100efb7-0525-45d4-a0fd-e73779181107 at term 1 for becomeLeader, leader elected after 6476ms
datanode2_1  | 2022-08-22 01:18:57,360 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode2_1  | 2022-08-22 01:18:57,381 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-08-22 01:18:57,390 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode2_1  | 2022-08-22 01:18:57,392 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode2_1  | 2022-08-22 01:18:57,393 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-08-22 01:19:00,065 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-08-22 01:19:00,067 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-08-22 01:19:00,068 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-08-22 01:19:00,068 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-08-22 01:19:00,068 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-08-22 01:19:00,069 [pool-23-thread-1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: ConfigurationManager, init=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-08-22 01:19:00,069 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-08-22 01:19:00,069 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-08-22 01:19:00,070 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-08-22 01:19:00,070 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 does not exist. Creating ...
datanode3_1  | 2022-08-22 01:19:00,074 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838/in_use.lock acquired by nodename 7@d60fa041091d
datanode1_1  | 2022-08-22 01:18:58,648 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-08-22 01:18:58,650 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-08-22 01:18:58,657 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-08-22 01:18:58,662 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-08-22 01:18:58,666 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2022-08-22 01:18:58,670 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-08-22 01:18:58,675 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-08-22 01:18:58,679 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-08-22 01:18:58,679 [pool-23-thread-1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-BE98E62D2A2A: start as a follower, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-08-22 01:18:58,682 [pool-23-thread-1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-BE98E62D2A2A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2022-08-22 01:18:58,682 [pool-23-thread-1] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: start 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-BE98E62D2A2A-FollowerState
datanode1_1  | 2022-08-22 01:18:58,706 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BE98E62D2A2A,id=61e48a95-a5d7-43eb-addf-1603d4744f3f
datanode1_1  | 2022-08-22 01:18:58,801 [61e48a95-a5d7-43eb-addf-1603d4744f3f-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-BE98E62D2A2A with new leaderId: 3100efb7-0525-45d4-a0fd-e73779181107
datanode1_1  | 2022-08-22 01:18:58,812 [61e48a95-a5d7-43eb-addf-1603d4744f3f-server-thread1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-BE98E62D2A2A: change Leader from null to 3100efb7-0525-45d4-a0fd-e73779181107 at term 1 for appendEntries, leader elected after 268ms
datanode1_1  | 2022-08-22 01:18:58,828 [61e48a95-a5d7-43eb-addf-1603d4744f3f-server-thread1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-BE98E62D2A2A: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode1_1  | 2022-08-22 01:18:58,875 [61e48a95-a5d7-43eb-addf-1603d4744f3f-server-thread1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-BE98E62D2A2A: inconsistency entries. Reply:3100efb7-0525-45d4-a0fd-e73779181107<-61e48a95-a5d7-43eb-addf-1603d4744f3f#2:FAIL-t0,INCONSISTENCY,nextIndex=0,followerCommit=-1
datanode1_1  | 2022-08-22 01:18:58,975 [61e48a95-a5d7-43eb-addf-1603d4744f3f-server-thread1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-BE98E62D2A2A: set configuration 0: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode1_1  | 2022-08-22 01:18:58,983 [61e48a95-a5d7-43eb-addf-1603d4744f3f-server-thread1] INFO segmented.SegmentedRaftLogWorker: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-BE98E62D2A2A-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-08-22 01:18:58,987 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-BE98E62D2A2A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-BE98E62D2A2A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a/current/log_inprogress_0
datanode1_1  | 2022-08-22 01:18:59,566 [grpc-default-executor-0] INFO server.RaftServer: 61e48a95-a5d7-43eb-addf-1603d4744f3f: addNew group-C7FFD18C9838:[61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] returns group-C7FFD18C9838:java.util.concurrent.CompletableFuture@49d54018[Not completed]
datanode1_1  | 2022-08-22 01:18:59,569 [pool-23-thread-1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f: new RaftServerImpl for group-C7FFD18C9838:[61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0] with ContainerStateMachine:uninitialized
datanode1_1  | 2022-08-22 01:18:59,570 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2022-08-22 01:18:59,570 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2022-08-22 01:18:59,570 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2022-08-22 01:18:59,570 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2022-08-22 01:18:59,570 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2022-08-22 01:18:59,570 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2022-08-22 01:18:59,570 [pool-23-thread-1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: ConfigurationManager, init=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2022-08-22 01:18:59,570 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2022-08-22 01:18:59,570 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2022-08-22 01:18:59,570 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2022-08-22 01:18:59,570 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 does not exist. Creating ...
datanode1_1  | 2022-08-22 01:18:59,572 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838/in_use.lock acquired by nodename 6@2cdeb7efff84
datanode1_1  | 2022-08-22 01:18:59,573 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 has been successfully formatted.
datanode1_1  | 2022-08-22 01:18:59,574 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-C7FFD18C9838: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2022-08-22 01:18:59,574 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2022-08-22 01:18:59,602 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2022-08-22 01:18:59,603 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2022-08-22 01:18:59,605 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-08-22 01:18:59,605 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2022-08-22 01:18:59,605 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-22 01:18:59,606 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2022-08-22 01:18:59,606 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2022-08-22 01:18:59,606 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838
datanode1_1  | 2022-08-22 01:18:59,607 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2022-08-22 01:18:59,608 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2022-08-22 01:18:59,608 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2022-08-22 01:18:59,610 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2022-08-22 01:18:59,612 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2022-08-22 01:18:59,612 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2022-08-22 01:18:59,612 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2022-08-22 01:18:59,616 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2022-08-22 01:18:59,620 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2022-08-22 01:18:59,624 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2022-08-22 01:18:59,627 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2022-08-22 01:18:59,627 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-22 01:18:59,628 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2022-08-22 01:18:59,642 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2022-08-22 01:18:59,642 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2022-08-22 01:18:59,643 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2022-08-22 01:18:59,643 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2022-08-22 01:18:59,643 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2022-08-22 01:18:59,643 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2022-08-22 01:18:59,652 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-08-22 01:18:59,652 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-08-22 01:18:57,397 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode2_1  | 2022-08-22 01:18:57,399 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode2_1  | 2022-08-22 01:18:57,399 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode2_1  | 2022-08-22 01:18:57,555 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-08-22 01:18:57,561 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-22 01:18:57,580 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-08-22 01:18:57,623 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-08-22 01:18:57,674 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-08-22 01:18:57,675 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-22 01:18:57,673 [3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3100efb7-0525-45d4-a0fd-e73779181107@group-7719FBA37020-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6bb8ab60-60a4-4383-9c3b-7719fba37020/current/log_inprogress_0
datanode2_1  | 2022-08-22 01:18:57,726 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode2_1  | 2022-08-22 01:18:57,729 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-22 01:18:57,732 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode2_1  | 2022-08-22 01:18:57,737 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode2_1  | 2022-08-22 01:18:57,783 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2022-08-22 01:18:57,829 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-22 01:18:57,831 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderStateImpl
datanode2_1  | 2022-08-22 01:18:57,876 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-08-22 01:18:57,888 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fcac9307-f9c6-4fe2-a014-be98e62d2a2a/current/log_inprogress_0
datanode2_1  | 2022-08-22 01:18:57,928 [3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A-LeaderElection2] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A: set configuration 0: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:0, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:1], old=null
datanode2_1  | 2022-08-22 01:18:58,928 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=fcac9307-f9c6-4fe2-a014-be98e62d2a2a.
datanode2_1  | 2022-08-22 01:18:58,929 [Command processor thread] INFO server.RaftServer: 3100efb7-0525-45d4-a0fd-e73779181107: addNew group-C7FFD18C9838:[61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0] returns group-C7FFD18C9838:java.util.concurrent.CompletableFuture@51b47c33[Not completed]
datanode2_1  | 2022-08-22 01:18:58,938 [grpc-default-executor-1] INFO leader.FollowerInfo: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f: nextIndex: updateUnconditionally 1 -> 0
datanode2_1  | 2022-08-22 01:18:58,946 [pool-23-thread-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107: new RaftServerImpl for group-C7FFD18C9838:[61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0] with ContainerStateMachine:uninitialized
datanode2_1  | 2022-08-22 01:18:58,952 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2022-08-22 01:18:58,952 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2022-08-22 01:18:58,952 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode2_1  | 2022-08-22 01:18:58,953 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2022-08-22 01:18:58,953 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2022-08-22 01:18:58,953 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2022-08-22 01:18:58,953 [pool-23-thread-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: ConfigurationManager, init=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2022-08-22 01:18:58,954 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2022-08-22 01:18:58,955 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2022-08-22 01:18:58,955 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2022-08-22 01:18:58,956 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 does not exist. Creating ...
datanode2_1  | 2022-08-22 01:18:58,969 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838/in_use.lock acquired by nodename 6@07ab41f3ff0f
datanode2_1  | 2022-08-22 01:18:58,975 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 has been successfully formatted.
datanode2_1  | 2022-08-22 01:18:58,983 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-C7FFD18C9838: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode2_1  | 2022-08-22 01:18:58,984 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2022-08-22 01:18:59,026 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode2_1  | 2022-08-22 01:18:59,026 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode2_1  | 2022-08-22 01:18:59,026 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2022-08-22 01:18:59,026 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode2_1  | 2022-08-22 01:18:59,027 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-22 01:18:59,028 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode2_1  | 2022-08-22 01:18:59,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode2_1  | 2022-08-22 01:18:59,030 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838
datanode2_1  | 2022-08-22 01:18:59,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode2_1  | 2022-08-22 01:18:59,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode2_1  | 2022-08-22 01:18:59,030 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode2_1  | 2022-08-22 01:18:59,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode2_1  | 2022-08-22 01:18:59,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode2_1  | 2022-08-22 01:18:59,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2022-08-22 01:18:59,031 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode2_1  | 2022-08-22 01:18:59,032 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode2_1  | 2022-08-22 01:18:59,047 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode2_1  | 2022-08-22 01:18:59,056 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode2_1  | 2022-08-22 01:18:59,062 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode2_1  | 2022-08-22 01:18:59,113 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-22 01:18:59,114 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode2_1  | 2022-08-22 01:18:59,116 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode2_1  | 2022-08-22 01:18:59,116 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode2_1  | 2022-08-22 01:18:59,117 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode2_1  | 2022-08-22 01:18:59,119 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode2_1  | 2022-08-22 01:18:59,119 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2022-08-22 01:18:59,119 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode2_1  | 2022-08-22 01:18:59,125 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode2_1  | 2022-08-22 01:18:59,125 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode2_1  | 2022-08-22 01:18:59,125 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode2_1  | 2022-08-22 01:18:59,126 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode2_1  | 2022-08-22 01:18:59,126 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode2_1  | 2022-08-22 01:18:59,126 [pool-23-thread-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: start as a follower, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-22 01:18:59,128 [pool-23-thread-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode2_1  | 2022-08-22 01:18:59,129 [pool-23-thread-1] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState
datanode2_1  | 2022-08-22 01:18:59,146 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C7FFD18C9838,id=3100efb7-0525-45d4-a0fd-e73779181107
datanode2_1  | 2022-08-22 01:18:59,147 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=85ae3250-a1a7-4fa0-96fb-c7ffd18c9838
datanode2_1  | 2022-08-22 01:19:00,172 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=85ae3250-a1a7-4fa0-96fb-c7ffd18c9838.
datanode2_1  | 2022-08-22 01:19:04,325 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5196760743ns, electionTimeout:5179ms
datanode2_1  | 2022-08-22 01:19:04,326 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState
datanode3_1  | 2022-08-22 01:19:00,076 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 has been successfully formatted.
datanode3_1  | 2022-08-22 01:19:00,077 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-C7FFD18C9838: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-08-22 01:19:00,078 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-08-22 01:19:00,086 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-08-22 01:19:00,099 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-08-22 01:19:00,099 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-22 01:19:00,099 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-08-22 01:19:00,099 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-22 01:19:00,105 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-08-22 01:19:00,115 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-08-22 01:19:00,123 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838
datanode3_1  | 2022-08-22 01:19:00,123 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-08-22 01:19:00,123 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-08-22 01:19:00,123 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-22 01:19:00,123 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-08-22 01:19:00,124 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-08-22 01:19:00,125 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-08-22 01:19:00,128 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-08-22 01:19:00,129 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-08-22 01:19:00,129 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-08-22 01:19:00,133 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-08-22 01:19:00,140 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-08-22 01:19:00,140 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-22 01:19:00,141 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-22 01:19:00,141 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-08-22 01:19:00,141 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-08-22 01:19:00,141 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-08-22 01:19:00,141 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-08-22 01:19:00,142 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-08-22 01:19:00,142 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-08-22 01:19:00,144 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-08-22 01:19:00,145 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-08-22 01:19:00,145 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-08-22 01:19:00,146 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-08-22 01:19:00,146 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om2_1        | 2022-08-22 01:19:02,351 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1        | 2022-08-22 01:19:02,380 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om2_1        | 2022-08-22 01:19:02,389 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om2_1        | 2022-08-22 01:19:02,390 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-08-22 01:19:02,390 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-08-22 01:19:02,410 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-08-22 01:19:02,473 [main] INFO server.RaftServer: om2: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@18cb7c6[Not completed]
om2_1        | 2022-08-22 01:19:02,476 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1        | 2022-08-22 01:19:02,665 [pool-27-thread-1] INFO server.RaftServer$Division: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
om2_1        | 2022-08-22 01:19:02,698 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om2_1        | 2022-08-22 01:19:02,700 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om2_1        | 2022-08-22 01:19:02,700 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1        | 2022-08-22 01:19:02,700 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1        | 2022-08-22 01:19:02,700 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1        | 2022-08-22 01:19:02,700 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om2_1        | 2022-08-22 01:19:02,725 [main] INFO om.OzoneManager: Creating RPC Server
om2_1        | 2022-08-22 01:19:02,732 [pool-27-thread-1] INFO server.RaftServer$Division: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om2_1        | 2022-08-22 01:19:02,751 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1        | 2022-08-22 01:19:02,760 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1        | 2022-08-22 01:19:02,785 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om2_1        | 2022-08-22 01:19:02,804 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1        | 2022-08-22 01:19:02,924 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 8@om2
om2_1        | 2022-08-22 01:19:03,121 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1        | 2022-08-22 01:19:03,144 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1        | 2022-08-22 01:19:03,167 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1        | 2022-08-22 01:19:03,382 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1        | 2022-08-22 01:19:03,382 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1        | 2022-08-22 01:19:03,388 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om2_1        | 2022-08-22 01:19:03,534 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-08-22 01:19:03,617 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1        | 2022-08-22 01:19:03,626 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om2_1        | 2022-08-22 01:19:03,692 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1        | 2022-08-22 01:19:03,693 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1        | 2022-08-22 01:19:03,696 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1        | 2022-08-22 01:19:03,704 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1        | 2022-08-22 01:19:03,714 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1        | 2022-08-22 01:19:03,714 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1        | 2022-08-22 01:19:03,734 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1        | 2022-08-22 01:19:03,734 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1        | 2022-08-22 01:19:03,782 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1        | 2022-08-22 01:19:03,910 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1        | 2022-08-22 01:19:03,931 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om2_1        | 2022-08-22 01:19:03,932 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-08-22 01:17:57,776 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-08-22 01:17:57,837 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-08-22 01:18:04,600 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-08-22 01:18:06,886 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-08-22 01:18:07,401 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-08-22 01:18:07,416 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-08-22 01:18:07,417 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-08-22 01:18:08,583 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-08-22 01:18:08,583 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-08-22 01:18:08,634 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-08-22 01:18:09,378 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-08-22 01:18:11,525 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2022-08-22 01:18:14,594 [main] ERROR client.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2022-08-22 01:18:14,595 [main] INFO client.OMCertificateClient: Certificate client init case: 0
om3_1        | 2022-08-22 01:18:14,629 [main] INFO client.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2022-08-22 01:18:19,609 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2022-08-22 01:18:19,768 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2022-08-22 01:18:19,769 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2022-08-22 01:18:19,779 [main] ERROR client.OMCertificateClient: Invalid domain om3
om3_1        | 2022-08-22 01:18:19,790 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-08-22 01:18:19,799 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-08-22 01:18:19,800 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-08-22 01:18:19,800 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-08-22 01:18:19,802 [main] INFO om.OzoneManager: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:e5262d73-6b1c-4541-a42b-1a92d56a8751,clusterId:CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5,subject:om3
om3_1        | 2022-08-22 01:18:20,669 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2022-08-22 01:18:22,695 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5;layoutVersion=3
om3_1        | 2022-08-22 01:18:22,897 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2022-08-22 01:18:32,386 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2022-08-22 01:16:37,812 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.33.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.33.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.33.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
recon_1      | STARTUP_MSG:   java = 11.0.14.1
recon_1      | ************************************************************/
recon_1      | 2022-08-22 01:16:37,825 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2022-08-22 01:16:39,650 [main] INFO reflections.Reflections: Reflections took 240 ms to scan 1 urls, producing 16 keys and 48 values 
recon_1      | 2022-08-22 01:16:41,747 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2022-08-22 01:16:41,862 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2022-08-22 01:16:42,385 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
recon_1      | 2022-08-22 01:16:42,386 [main] INFO recon.ReconServer: Recon login successful.
recon_1      | 2022-08-22 01:16:42,386 [main] INFO recon.ReconServer: Initializing secure Recon.
recon_1      | 2022-08-22 01:16:43,626 [main] ERROR client.ReconCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
recon_1      | 2022-08-22 01:16:43,626 [main] INFO client.ReconCertificateClient: Certificate client init case: 0
recon_1      | 2022-08-22 01:16:43,633 [main] INFO client.ReconCertificateClient: Creating keypair for client as keypair and certificate not found.
recon_1      | 2022-08-22 01:16:44,872 [main] INFO recon.ReconServer: Init response: GETCERT
recon_1      | 2022-08-22 01:16:44,922 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.115,host:recon
recon_1      | 2022-08-22 01:16:44,923 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
recon_1      | 2022-08-22 01:16:44,939 [main] ERROR client.ReconCertificateClient: Invalid domain recon
recon_1      | 2022-08-22 01:16:45,197 [main] INFO recon.ReconServer: Creating CSR for Recon.
recon_1      | 2022-08-22 01:16:47,941 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:16:49,943 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:16:51,945 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:16:53,946 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:16:55,948 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:16:57,949 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:16:59,951 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:17:01,952 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:17:04,189 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:e5262d73-6b1c-4541-a42b-1a92d56a8751 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1      | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1      | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
recon_1      | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:17:06,190 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:17:08,192 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:17:10,480 [main] INFO recon.ReconServer: Successfully stored SCM signed certificate, case:GETCERT.
recon_1      | 2022-08-22 01:17:10,707 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2022-08-22 01:17:11,690 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
recon_1      | 2022-08-22 01:17:12,337 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
om2_1        | 2022-08-22 01:19:04,013 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1        | 2022-08-22 01:19:04,013 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1        | 2022-08-22 01:19:04,056 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1        | 2022-08-22 01:19:04,068 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1        | 2022-08-22 01:19:04,069 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1        | 2022-08-22 01:19:04,070 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1        | 2022-08-22 01:19:04,104 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1        | 2022-08-22 01:19:04,105 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om2_1        | 2022-08-22 01:19:04,570 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1        | 2022-08-22 01:19:04,571 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om2_1        | 2022-08-22 01:19:04,573 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om2_1        | 2022-08-22 01:19:04,573 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om2_1        | 2022-08-22 01:19:04,574 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om2_1        | 2022-08-22 01:19:05,251 [main] INFO reflections.Reflections: Reflections took 2101 ms to scan 8 urls, producing 23 keys and 517 values [using 2 cores]
om2_1        | 2022-08-22 01:19:06,080 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1        | 2022-08-22 01:19:06,211 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1        | 2022-08-22 01:19:09,781 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1        | 2022-08-22 01:19:09,860 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1        | 2022-08-22 01:19:09,861 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1        | 2022-08-22 01:19:10,004 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.25.0.112:9862
om2_1        | 2022-08-22 01:19:10,015 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1        | 2022-08-22 01:19:10,017 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-08-22 01:19:10,023 [om2-impl-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2022-08-22 01:19:10,024 [om2-impl-thread1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-08-22 01:19:10,051 [om2-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1        | 2022-08-22 01:19:10,073 [Listener at om2/9862] INFO server.RaftServer: om2: start RPC server
om2_1        | 2022-08-22 01:19:10,210 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 9872
om2_1        | 2022-08-22 01:19:10,224 [Listener at om2/9862] INFO om.OzoneManager: Starting OM block token secret manager
om2_1        | 2022-08-22 01:19:10,224 [Listener at om2/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-08-22 01:19:10,226 [Listener at om2/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om2_1        | 2022-08-22 01:19:10,228 [Listener at om2/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om2_1        | 2022-08-22 01:19:10,236 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$452/0x00000008405b2040@59a330cd] INFO util.JvmPauseMonitor: JvmPauseMonitor-om2: Started
om2_1        | 2022-08-22 01:19:10,244 [Listener at om2/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om2_1        | 2022-08-22 01:19:10,251 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om2_1        | 2022-08-22 01:19:10,449 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1        | 2022-08-22 01:19:10,450 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om2_1        | 2022-08-22 01:19:10,450 [Listener at om2/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om2_1        | 2022-08-22 01:19:10,577 [Listener at om2/9862] INFO util.log: Logging initialized @47022ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1        | 2022-08-22 01:19:10,980 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1        | 2022-08-22 01:19:11,012 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1        | 2022-08-22 01:19:11,021 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om2_1        | 2022-08-22 01:19:11,022 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om2_1        | 2022-08-22 01:19:11,022 [Listener at om2/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om2_1        | 2022-08-22 01:19:11,031 [Listener at om2/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om2_1        | 2022-08-22 01:19:11,249 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1        | 2022-08-22 01:19:11,279 [Listener at om2/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om2_1        | 2022-08-22 01:19:11,394 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1        | 2022-08-22 01:19:11,394 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1        | 2022-08-22 01:19:11,400 [Listener at om2/9862] INFO server.session: node0 Scavenging every 600000ms
om2_1        | 2022-08-22 01:19:11,510 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-08-22 01:19:11,517 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2de8f1dd{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1        | 2022-08-22 01:19:11,527 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2d1b923f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1        | 2022-08-22 01:19:11,942 [Listener at om2/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om2_1        | 2022-08-22 01:19:11,979 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6185cb4d{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-12227098395314641779/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1        | 2022-08-22 01:19:12,014 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@77cc9049{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1        | 2022-08-22 01:19:12,015 [Listener at om2/9862] INFO server.Server: Started @48462ms
om2_1        | 2022-08-22 01:19:12,032 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1        | 2022-08-22 01:19:12,032 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1        | 2022-08-22 01:19:12,034 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1        | 2022-08-22 01:19:12,046 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1        | 2022-08-22 01:19:12,084 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1        | 2022-08-22 01:19:12,169 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om2_1        | 2022-08-22 01:19:12,512 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37673
om2_1        | 2022-08-22 01:19:12,529 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:19:12,622 [Listener at om2/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om2_1        | 2022-08-22 01:19:12,659 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2356947a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1        | 2022-08-22 01:19:15,177 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5153357973ns, electionTimeout:5139ms
om2_1        | 2022-08-22 01:19:15,179 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-08-22 01:19:15,179 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1        | 2022-08-22 01:19:15,183 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2022-08-22 01:19:15,183 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1        | 2022-08-22 01:19:15,190 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-22 01:19:23,034 [grpc-default-executor-1] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om3<-om1#0:OK-t2. Peer's state: om1@group-562213E44849:t2, leader=null, voted=om3, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-22 01:19:23,034 [grpc-default-executor-0] INFO impl.VoteContext: om1@group-562213E44849-FOLLOWER: reject ELECTION from om2: already has voted for om3 at current term 2
om1_1        | 2022-08-22 01:19:23,035 [grpc-default-executor-0] INFO server.RaftServer$Division: om1@group-562213E44849 replies to ELECTION vote request: om2<-om1#0:FAIL-t2. Peer's state: om1@group-562213E44849:t2, leader=null, voted=om3, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om1_1        | 2022-08-22 01:19:23,216 [om1-server-thread1] INFO server.RaftServer$Division: om1@group-562213E44849: change Leader from null to om3 at term 2 for appendEntries, leader elected after 17651ms
om1_1        | 2022-08-22 01:19:23,292 [om1-server-thread2] INFO server.RaftServer$Division: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om1_1        | 2022-08-22 01:19:23,296 [om1-server-thread2] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1        | 2022-08-22 01:19:23,450 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1        | 2022-08-22 01:19:26,283 [om1@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om1_1        | [id: "om1"
om1_1        | address: "om1:9872"
om1_1        | , id: "om3"
om1_1        | address: "om3:9872"
om1_1        | , id: "om2"
om1_1        | address: "om2:9872"
om1_1        | ]
om1_1        | 2022-08-22 01:19:39,075 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35312
om1_1        | 2022-08-22 01:19:39,132 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:19:44,023 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35328
om1_1        | 2022-08-22 01:19:44,045 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:19:48,918 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35344
om1_1        | 2022-08-22 01:19:48,952 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:19:53,405 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35360
om1_1        | 2022-08-22 01:19:53,424 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:19:57,929 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35376
om1_1        | 2022-08-22 01:19:57,945 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:19:58,832 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om1_1        | 2022-08-22 01:19:59,166 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om1_1        | 2022-08-22 01:20:09,510 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35446
om1_1        | 2022-08-22 01:20:09,525 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:20:10,192 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35452
om1_1        | 2022-08-22 01:20:10,193 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:20:15,279 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35470
om1_1        | 2022-08-22 01:20:15,301 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:20:15,872 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35476
om1_1        | 2022-08-22 01:20:15,889 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:20:15,955 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om1_1        | 2022-08-22 01:20:21,078 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35492
om1_1        | 2022-08-22 01:20:21,098 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:20:29,399 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35514
om1_1        | 2022-08-22 01:20:29,421 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:20:35,093 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35554
om1_1        | 2022-08-22 01:20:35,109 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:20:35,689 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35560
datanode3_1  | 2022-08-22 01:19:00,146 [pool-23-thread-1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: start as a follower, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-22 01:19:00,150 [pool-23-thread-1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-08-22 01:19:00,150 [pool-23-thread-1] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: start 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState
datanode3_1  | 2022-08-22 01:19:00,151 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C7FFD18C9838,id=3c60044e-b181-445f-8fa2-782a9e9eb45c
datanode3_1  | 2022-08-22 01:19:04,356 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: receive requestVote(ELECTION, 3100efb7-0525-45d4-a0fd-e73779181107, group-C7FFD18C9838, 1, (t:0, i:0))
datanode3_1  | 2022-08-22 01:19:04,357 [grpc-default-executor-0] INFO impl.VoteContext: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FOLLOWER: accept ELECTION from 3100efb7-0525-45d4-a0fd-e73779181107: our priority 0 <= candidate's priority 0
datanode3_1  | 2022-08-22 01:19:04,357 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:3100efb7-0525-45d4-a0fd-e73779181107
datanode3_1  | 2022-08-22 01:19:04,359 [grpc-default-executor-0] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: shutdown 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState
datanode3_1  | 2022-08-22 01:19:04,359 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState was interrupted
datanode3_1  | 2022-08-22 01:19:04,362 [grpc-default-executor-0] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: start 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState
datanode3_1  | 2022-08-22 01:19:04,372 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838 replies to ELECTION vote request: 3100efb7-0525-45d4-a0fd-e73779181107<-3c60044e-b181-445f-8fa2-782a9e9eb45c#0:OK-t1. Peer's state: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838:t1, leader=null, voted=3100efb7-0525-45d4-a0fd-e73779181107, raftlog=3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-22 01:19:09,488 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: receive requestVote(ELECTION, 3100efb7-0525-45d4-a0fd-e73779181107, group-C7FFD18C9838, 2, (t:0, i:0))
datanode3_1  | 2022-08-22 01:19:09,488 [grpc-default-executor-0] INFO impl.VoteContext: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FOLLOWER: accept ELECTION from 3100efb7-0525-45d4-a0fd-e73779181107: our priority 0 <= candidate's priority 0
datanode3_1  | 2022-08-22 01:19:09,488 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:3100efb7-0525-45d4-a0fd-e73779181107
datanode3_1  | 2022-08-22 01:19:09,488 [grpc-default-executor-0] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: shutdown 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState
datanode3_1  | 2022-08-22 01:19:09,488 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState was interrupted
datanode3_1  | 2022-08-22 01:19:09,494 [grpc-default-executor-0] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: start 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState
datanode3_1  | 2022-08-22 01:19:09,510 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838 replies to ELECTION vote request: 3100efb7-0525-45d4-a0fd-e73779181107<-3c60044e-b181-445f-8fa2-782a9e9eb45c#0:OK-t2. Peer's state: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838:t2, leader=null, voted=3100efb7-0525-45d4-a0fd-e73779181107, raftlog=3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-22 01:19:14,546 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: receive requestVote(ELECTION, 3100efb7-0525-45d4-a0fd-e73779181107, group-C7FFD18C9838, 3, (t:0, i:0))
datanode3_1  | 2022-08-22 01:19:14,548 [grpc-default-executor-0] INFO impl.VoteContext: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FOLLOWER: accept ELECTION from 3100efb7-0525-45d4-a0fd-e73779181107: our priority 0 <= candidate's priority 0
datanode3_1  | 2022-08-22 01:19:14,548 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:3100efb7-0525-45d4-a0fd-e73779181107
datanode3_1  | 2022-08-22 01:19:14,548 [grpc-default-executor-0] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: shutdown 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState
datanode3_1  | 2022-08-22 01:19:14,548 [grpc-default-executor-0] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: start 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState
datanode3_1  | 2022-08-22 01:19:14,548 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState was interrupted
datanode3_1  | 2022-08-22 01:19:14,561 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838 replies to ELECTION vote request: 3100efb7-0525-45d4-a0fd-e73779181107<-3c60044e-b181-445f-8fa2-782a9e9eb45c#0:OK-t3. Peer's state: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838:t3, leader=null, voted=3100efb7-0525-45d4-a0fd-e73779181107, raftlog=3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-22 01:19:14,853 [Command processor thread] INFO server.RaftServer: 3c60044e-b181-445f-8fa2-782a9e9eb45c: addNew group-EE9A9D2C444E:[3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] returns group-EE9A9D2C444E:java.util.concurrent.CompletableFuture@675ba7e8[Not completed]
recon_1      | 2022-08-22 01:17:12,370 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2022-08-22 01:17:12,373 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2022-08-22 01:17:14,544 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2022-08-22 01:17:14,545 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2022-08-22 01:17:14,545 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2022-08-22 01:17:14,585 [main] INFO util.log: Logging initialized @40715ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2022-08-22 01:17:14,716 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2022-08-22 01:17:14,727 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2022-08-22 01:17:14,729 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2022-08-22 01:17:14,729 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2022-08-22 01:17:14,729 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2022-08-22 01:17:14,731 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2022-08-22 01:17:14,881 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2022-08-22 01:17:15,353 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2022-08-22 01:17:15,373 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2022-08-22 01:17:15,376 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTaskWithFSO with controller.
recon_1      | 2022-08-22 01:17:15,439 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2022-08-22 01:17:16,361 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-08-22 01:17:16,609 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-08-22 01:17:16,852 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2022-08-22 01:17:16,856 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2022-08-22 01:17:17,138 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-08-22 01:17:17,473 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
recon_1      | 2022-08-22 01:17:17,669 [main] INFO reflections.Reflections: Reflections took 188 ms to scan 3 urls, producing 110 keys and 247 values 
recon_1      | 2022-08-22 01:17:17,879 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2022-08-22 01:17:17,972 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2022-08-22 01:17:17,989 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2022-08-22 01:17:18,019 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2022-08-22 01:17:18,116 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1      | 2022-08-22 01:17:18,185 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2022-08-22 01:17:18,200 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2022-08-22 01:17:18,338 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 2022-08-22 01:17:18,673 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2022-08-22 01:17:18,677 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2022-08-22 01:17:18,865 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2022-08-22 01:17:18,890 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2022-08-22 01:17:18,890 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2022-08-22 01:17:19,437 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2022-08-22 01:17:19,438 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
recon_1      | 2022-08-22 01:17:19,555 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2022-08-22 01:17:19,555 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2022-08-22 01:17:19,557 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
recon_1      | 2022-08-22 01:17:19,619 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-08-22 01:17:19,627 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6cd1ee{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 2022-08-22 01:17:19,627 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4c682826{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2022-08-22 01:17:20,381 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-08-22 01:17:20,393 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2022-08-22 01:17:24,558 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@422f7c73{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0-SNAPSHOT_jar-_-any-3996197509975808164/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0-SNAPSHOT.jar!/webapps/recon}
recon_1      | 2022-08-22 01:17:24,584 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@1d7f2719{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1      | 2022-08-22 01:17:24,584 [Listener at 0.0.0.0/9891] INFO server.Server: Started @50713ms
recon_1      | 2022-08-22 01:17:24,596 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1        | 2022-08-22 01:20:35,696 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:20:35,779 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om1_1        | 2022-08-22 01:20:40,251 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35576
om1_1        | 2022-08-22 01:20:40,266 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:20:45,350 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35592
om1_1        | 2022-08-22 01:20:45,381 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:21:01,294 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35638
om1_1        | 2022-08-22 01:21:01,315 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:21:02,150 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:39072-source for user:testuser
om1_1        | 2022-08-22 01:21:06,474 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35670
om1_1        | 2022-08-22 01:21:06,490 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:21:07,082 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:39072-target for user:testuser
om1_1        | 2022-08-22 01:21:10,928 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35688
om1_1        | 2022-08-22 01:21:10,949 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:21:11,997 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 39072-source
om1_1        | 2022-08-22 01:21:15,804 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35706
om1_1        | 2022-08-22 01:21:15,841 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:21:23,082 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35748
om1_1        | 2022-08-22 01:21:23,098 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:21:23,809 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 39072-source
om1_1        | 2022-08-22 01:21:27,491 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35766
om1_1        | 2022-08-22 01:21:27,515 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:21:28,148 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 39072-target
om1_1        | 2022-08-22 01:21:32,275 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35782
om1_1        | 2022-08-22 01:21:32,287 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:21:32,893 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 39072-target
om1_1        | 2022-08-22 01:21:36,662 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35790
om1_1        | 2022-08-22 01:21:36,681 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:21:37,287 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 39072-target
om1_1        | 2022-08-22 01:21:41,088 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35806
om1_1        | 2022-08-22 01:21:41,106 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:21:45,392 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35822
om1_1        | 2022-08-22 01:21:45,414 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:21:49,944 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35862
om1_1        | 2022-08-22 01:21:49,958 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:21:53,871 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35870
om1_1        | 2022-08-22 01:21:53,890 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:21:58,203 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35886
om1_1        | 2022-08-22 01:21:58,238 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:22:02,924 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35912
om1_1        | 2022-08-22 01:22:02,940 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:22:03,633 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 39072-target
om1_1        | 2022-08-22 01:22:07,222 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35930
om1_1        | 2022-08-22 01:22:07,248 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:22:11,938 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35942
om1_1        | 2022-08-22 01:22:11,953 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:22:12,715 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 39072-target
om1_1        | 2022-08-22 01:22:16,560 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35958
om1_1        | 2022-08-22 01:22:16,583 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:22:17,252 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 39072-source
om1_1        | 2022-08-22 01:22:21,645 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35998
om1_1        | 2022-08-22 01:22:21,661 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:22:31,598 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36028
om1_1        | 2022-08-22 01:22:31,619 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:22:38,506 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36048
om1_1        | 2022-08-22 01:22:38,531 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:22:45,760 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36068
datanode1_1  | 2022-08-22 01:18:59,652 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2022-08-22 01:18:59,653 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2022-08-22 01:18:59,655 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2022-08-22 01:18:59,655 [pool-23-thread-1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: start as a follower, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-22 01:18:59,656 [pool-23-thread-1] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1        | 2022-08-22 01:19:17,626 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52306
om2_1        | 2022-08-22 01:19:17,638 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:19:17,743 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-08-22 01:19:17,744 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om2 at current term 1
om2_1        | 2022-08-22 01:19:17,749 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-08-22 01:19:17,875 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om2_1        | 2022-08-22 01:19:17,875 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t1
om2_1        | 2022-08-22 01:19:17,876 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t1
om2_1        | 2022-08-22 01:19:17,876 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om2_1        | 2022-08-22 01:19:17,880 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om2_1        | 2022-08-22 01:19:17,880 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1        | 2022-08-22 01:19:17,881 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-08-22 01:19:18,094 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om2_1        | 2022-08-22 01:19:18,095 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-FOLLOWER: reject ELECTION from om1: already has voted for om2 at current term 1
om2_1        | 2022-08-22 01:19:18,095 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om1<-om2#0:FAIL-t1. Peer's state: om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-08-22 01:19:22,924 [om2@group-562213E44849-FollowerState] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5043081509ns, electionTimeout:5031ms
om2_1        | 2022-08-22 01:19:22,925 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1        | 2022-08-22 01:19:22,926 [om2@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om2_1        | 2022-08-22 01:19:22,926 [om2@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om2_1        | 2022-08-22 01:19:22,926 [om2@group-562213E44849-FollowerState] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection2
om2_1        | 2022-08-22 01:19:22,947 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
datanode2_1  | 2022-08-22 01:19:04,326 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode2_1  | 2022-08-22 01:19:04,326 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-22 01:19:04,327 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection3
datanode2_1  | 2022-08-22 01:19:04,334 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection3] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-22 01:19:04,386 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection3] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection3: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode2_1  | 2022-08-22 01:19:04,391 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection3] INFO impl.LeaderElection:   Response 0: 3100efb7-0525-45d4-a0fd-e73779181107<-61e48a95-a5d7-43eb-addf-1603d4744f3f#0:FAIL-t1
datanode2_1  | 2022-08-22 01:19:04,391 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection3] INFO impl.LeaderElection:   Response 1: 3100efb7-0525-45d4-a0fd-e73779181107<-3c60044e-b181-445f-8fa2-782a9e9eb45c#0:OK-t1
datanode2_1  | 2022-08-22 01:19:04,392 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection3] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection3 ELECTION round 0: result REJECTED
datanode2_1  | 2022-08-22 01:19:04,396 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode2_1  | 2022-08-22 01:19:04,406 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection3] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection3
datanode2_1  | 2022-08-22 01:19:04,407 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection3] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState
datanode2_1  | 2022-08-22 01:19:09,464 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5057054748ns, electionTimeout:5032ms
datanode2_1  | 2022-08-22 01:19:09,465 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState
datanode2_1  | 2022-08-22 01:19:09,465 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode2_1  | 2022-08-22 01:19:09,465 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-22 01:19:09,465 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection4
datanode2_1  | 2022-08-22 01:19:09,471 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection4] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection4 ELECTION round 0: submit vote requests at term 2 for -1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-22 01:19:09,497 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection4] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection4: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-08-22 01:19:09,497 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection4] INFO impl.LeaderElection:   Response 0: 3100efb7-0525-45d4-a0fd-e73779181107<-61e48a95-a5d7-43eb-addf-1603d4744f3f#0:FAIL-t2
datanode2_1  | 2022-08-22 01:19:09,497 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection4] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection4 ELECTION round 0: result REJECTED
datanode2_1  | 2022-08-22 01:19:09,498 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection4] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode2_1  | 2022-08-22 01:19:09,498 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection4] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection4
datanode2_1  | 2022-08-22 01:19:09,498 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection4] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState
datanode2_1  | 2022-08-22 01:19:14,528 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5029860298ns, electionTimeout:5005ms
datanode2_1  | 2022-08-22 01:19:14,528 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState
datanode2_1  | 2022-08-22 01:19:14,529 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode2_1  | 2022-08-22 01:19:14,529 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-22 01:19:14,529 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection5
recon_1      | 2022-08-22 01:17:24,596 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1      | 2022-08-22 01:17:24,598 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1      | 2022-08-22 01:17:24,599 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1      | 2022-08-22 01:17:24,623 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1      | 2022-08-22 01:17:24,630 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1      | 2022-08-22 01:17:24,631 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1      | 2022-08-22 01:17:24,631 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2022-08-22 01:17:24,632 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1      | 2022-08-22 01:17:24,640 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1      | 2022-08-22 01:17:25,341 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1      | 2022-08-22 01:17:25,342 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-08-22 01:17:25,342 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1      | 2022-08-22 01:17:25,355 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1      | 2022-08-22 01:17:25,360 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1      | 2022-08-22 01:17:25,724 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1      | 2022-08-22 01:17:25,724 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1      | 2022-08-22 01:17:25,734 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1      | 2022-08-22 01:17:25,734 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1      | 2022-08-22 01:17:25,783 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2022-08-22 01:17:25,798 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 61 milliseconds.
recon_1      | 2022-08-22 01:17:44,637 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:17:44,638 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:17:44,706 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:17:44,711 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:17:46,713 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 3 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:17:46,715 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 4 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:17:46,716 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:17:48,719 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 6 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:17:48,720 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 7 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:17:48,729 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:17:50,731 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 9 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:17:50,732 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 10 failover attempts. Trying to failover immediately.
datanode2_1  | 2022-08-22 01:19:14,536 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection5] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection5 ELECTION round 0: submit vote requests at term 3 for -1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-22 01:19:14,556 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection5] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection5: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-08-22 01:19:14,556 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection5] INFO impl.LeaderElection:   Response 0: 3100efb7-0525-45d4-a0fd-e73779181107<-61e48a95-a5d7-43eb-addf-1603d4744f3f#0:FAIL-t3
datanode2_1  | 2022-08-22 01:19:14,556 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection5] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection5 ELECTION round 0: result REJECTED
datanode2_1  | 2022-08-22 01:19:14,569 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection5] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
datanode2_1  | 2022-08-22 01:19:14,570 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection5] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection5
datanode2_1  | 2022-08-22 01:19:14,570 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection5] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState
datanode2_1  | 2022-08-22 01:19:19,658 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5088310995ns, electionTimeout:5087ms
datanode2_1  | 2022-08-22 01:19:19,659 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState
datanode2_1  | 2022-08-22 01:19:19,659 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode2_1  | 2022-08-22 01:19:19,659 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-22 01:19:19,659 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection6
datanode2_1  | 2022-08-22 01:19:19,663 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection6] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection6 ELECTION round 0: submit vote requests at term 4 for -1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-22 01:19:19,691 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection6] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection6: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-08-22 01:19:19,691 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection6] INFO impl.LeaderElection:   Response 0: 3100efb7-0525-45d4-a0fd-e73779181107<-61e48a95-a5d7-43eb-addf-1603d4744f3f#0:FAIL-t4
datanode2_1  | 2022-08-22 01:19:19,692 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection6] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection6 ELECTION round 0: result REJECTED
datanode2_1  | 2022-08-22 01:19:19,692 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection6] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode2_1  | 2022-08-22 01:19:19,692 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection6] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection6
datanode2_1  | 2022-08-22 01:19:19,692 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection6] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState
datanode2_1  | 2022-08-22 01:19:20,030 [grpc-default-executor-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: receive requestVote(ELECTION, 61e48a95-a5d7-43eb-addf-1603d4744f3f, group-C7FFD18C9838, 4, (t:0, i:0))
datanode2_1  | 2022-08-22 01:19:20,034 [grpc-default-executor-1] INFO impl.VoteContext: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FOLLOWER: reject ELECTION from 61e48a95-a5d7-43eb-addf-1603d4744f3f: already has voted for 3100efb7-0525-45d4-a0fd-e73779181107 at current term 4
datanode2_1  | 2022-08-22 01:19:20,045 [grpc-default-executor-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838 replies to ELECTION vote request: 61e48a95-a5d7-43eb-addf-1603d4744f3f<-3100efb7-0525-45d4-a0fd-e73779181107#0:FAIL-t4. Peer's state: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838:t4, leader=null, voted=3100efb7-0525-45d4-a0fd-e73779181107, raftlog=3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-22 01:19:24,706 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5013470691ns, electionTimeout:5007ms
datanode2_1  | 2022-08-22 01:19:24,706 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState
datanode2_1  | 2022-08-22 01:19:24,708 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
datanode2_1  | 2022-08-22 01:19:24,709 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode2_1  | 2022-08-22 01:19:24,709 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection7
om2_1        | 2022-08-22 01:19:22,971 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849: receive requestVote(ELECTION, om3, group-562213E44849, 2, (t:0, i:~))
om2_1        | 2022-08-22 01:19:22,972 [grpc-default-executor-0] INFO impl.VoteContext: om2@group-562213E44849-CANDIDATE: reject ELECTION from om3: already has voted for om2 at current term 2
om2_1        | 2022-08-22 01:19:22,972 [grpc-default-executor-0] INFO server.RaftServer$Division: om2@group-562213E44849 replies to ELECTION vote request: om3<-om2#0:FAIL-t2. Peer's state: om2@group-562213E44849:t2, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om2_1        | 2022-08-22 01:19:23,038 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om2_1        | 2022-08-22 01:19:23,038 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 0: om2<-om1#0:FAIL-t2
om2_1        | 2022-08-22 01:19:23,039 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 1: om2<-om3#0:FAIL-t2
om2_1        | 2022-08-22 01:19:23,040 [om2@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection2 ELECTION round 0: result REJECTED
om2_1        | 2022-08-22 01:19:23,042 [om2@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
om2_1        | 2022-08-22 01:19:23,042 [om2@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection2
om2_1        | 2022-08-22 01:19:23,042 [om2@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1        | 2022-08-22 01:19:23,230 [om2-server-thread1] INFO server.RaftServer$Division: om2@group-562213E44849: change Leader from null to om3 at term 2 for appendEntries, leader elected after 20085ms
om2_1        | 2022-08-22 01:19:23,263 [om2-server-thread2] INFO server.RaftServer$Division: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om2_1        | 2022-08-22 01:19:23,280 [om2-server-thread2] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1        | 2022-08-22 01:19:23,519 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1        | 2022-08-22 01:19:26,491 [om2@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om2_1        | [id: "om1"
om2_1        | address: "om1:9872"
om2_1        | , id: "om3"
om2_1        | address: "om3:9872"
om2_1        | , id: "om2"
om2_1        | address: "om2:9872"
om2_1        | ]
om2_1        | 2022-08-22 01:19:39,172 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52376
om2_1        | 2022-08-22 01:19:39,175 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:19:44,084 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52392
om2_1        | 2022-08-22 01:19:44,091 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:19:48,996 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52408
om2_1        | 2022-08-22 01:19:49,006 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:19:53,459 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52424
om2_1        | 2022-08-22 01:19:53,473 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:19:57,972 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52440
om2_1        | 2022-08-22 01:19:57,977 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:19:58,908 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om2_1        | 2022-08-22 01:19:59,208 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om2_1        | 2022-08-22 01:20:09,572 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52510
om2_1        | 2022-08-22 01:20:09,575 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:20:10,209 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52516
om2_1        | 2022-08-22 01:20:10,215 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:20:15,330 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52534
om2_1        | 2022-08-22 01:20:15,332 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:20:15,905 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52540
om2_1        | 2022-08-22 01:20:15,907 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:20:15,952 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om2_1        | 2022-08-22 01:20:21,137 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52556
om2_1        | 2022-08-22 01:20:21,143 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:20:29,468 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52578
om2_1        | 2022-08-22 01:20:29,476 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:20:35,155 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52618
om2_1        | 2022-08-22 01:20:35,160 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:20:35,715 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52624
om2_1        | 2022-08-22 01:20:35,719 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:20:35,795 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om2_1        | 2022-08-22 01:20:40,308 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52640
om2_1        | 2022-08-22 01:20:40,313 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:20:45,431 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52656
om2_1        | 2022-08-22 01:20:45,435 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:21:01,372 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52702
om2_1        | 2022-08-22 01:21:01,381 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:21:02,153 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:39072-source for user:testuser
om2_1        | 2022-08-22 01:21:06,530 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52744
om2_1        | 2022-08-22 01:21:06,532 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:21:07,091 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:39072-target for user:testuser
om2_1        | 2022-08-22 01:21:10,982 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52752
om2_1        | 2022-08-22 01:21:10,998 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:21:12,006 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 39072-source
om2_1        | 2022-08-22 01:21:15,880 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52770
om2_1        | 2022-08-22 01:21:15,884 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:21:23,134 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52812
om2_1        | 2022-08-22 01:21:23,140 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:21:23,820 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 39072-source
om2_1        | 2022-08-22 01:21:27,561 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52830
recon_1      | 2022-08-22 01:17:50,732 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:17:52,734 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 12 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:17:52,734 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 13 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:17:52,735 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:17:54,737 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 15 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:17:54,738 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 16 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:17:54,739 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:17:56,740 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 18 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:17:56,741 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 19 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:17:56,742 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 20 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:17:58,744 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 21 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:17:58,745 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 22 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:17:58,746 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 23 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:00,794 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 24 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:00,849 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 25 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:00,871 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 26 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:02,883 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 27 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:02,884 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 28 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:02,885 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 29 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:04,886 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 30 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:04,887 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 31 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:04,905 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 32 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:06,909 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 33 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:06,910 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 34 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:06,911 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 35 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:08,913 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 36 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:08,918 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 37 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:08,919 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 38 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:10,925 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 39 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:10,926 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 40 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:10,928 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 41 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:12,929 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 42 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:12,930 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 43 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:12,940 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 44 failover attempts. Trying to failover after sleeping for 2000ms.
datanode1_1  | 2022-08-22 01:18:59,656 [pool-23-thread-1] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: start 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState
datanode1_1  | 2022-08-22 01:18:59,681 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C7FFD18C9838,id=61e48a95-a5d7-43eb-addf-1603d4744f3f
datanode1_1  | 2022-08-22 01:19:04,360 [grpc-default-executor-0] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: receive requestVote(ELECTION, 3100efb7-0525-45d4-a0fd-e73779181107, group-C7FFD18C9838, 1, (t:0, i:0))
datanode1_1  | 2022-08-22 01:19:04,362 [grpc-default-executor-0] INFO impl.VoteContext: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FOLLOWER: reject ELECTION from 3100efb7-0525-45d4-a0fd-e73779181107: our priority 1 > candidate's priority 0
datanode1_1  | 2022-08-22 01:19:04,363 [grpc-default-executor-0] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:3100efb7-0525-45d4-a0fd-e73779181107
datanode1_1  | 2022-08-22 01:19:04,363 [grpc-default-executor-0] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: shutdown 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState
datanode1_1  | 2022-08-22 01:19:04,363 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState was interrupted
datanode1_1  | 2022-08-22 01:19:04,364 [grpc-default-executor-0] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: start 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState
datanode1_1  | 2022-08-22 01:19:04,376 [grpc-default-executor-0] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838 replies to ELECTION vote request: 3100efb7-0525-45d4-a0fd-e73779181107<-61e48a95-a5d7-43eb-addf-1603d4744f3f#0:FAIL-t1. Peer's state: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838:t1, leader=null, voted=null, raftlog=61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-22 01:19:09,478 [grpc-default-executor-0] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: receive requestVote(ELECTION, 3100efb7-0525-45d4-a0fd-e73779181107, group-C7FFD18C9838, 2, (t:0, i:0))
datanode1_1  | 2022-08-22 01:19:09,478 [grpc-default-executor-0] INFO impl.VoteContext: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FOLLOWER: reject ELECTION from 3100efb7-0525-45d4-a0fd-e73779181107: our priority 1 > candidate's priority 0
datanode1_1  | 2022-08-22 01:19:09,478 [grpc-default-executor-0] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:3100efb7-0525-45d4-a0fd-e73779181107
datanode1_1  | 2022-08-22 01:19:09,479 [grpc-default-executor-0] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: shutdown 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState
datanode1_1  | 2022-08-22 01:19:09,479 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState was interrupted
datanode1_1  | 2022-08-22 01:19:09,481 [grpc-default-executor-0] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: start 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState
datanode1_1  | 2022-08-22 01:19:09,493 [grpc-default-executor-0] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838 replies to ELECTION vote request: 3100efb7-0525-45d4-a0fd-e73779181107<-61e48a95-a5d7-43eb-addf-1603d4744f3f#0:FAIL-t2. Peer's state: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838:t2, leader=null, voted=null, raftlog=61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-22 01:19:14,541 [grpc-default-executor-0] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: receive requestVote(ELECTION, 3100efb7-0525-45d4-a0fd-e73779181107, group-C7FFD18C9838, 3, (t:0, i:0))
datanode1_1  | 2022-08-22 01:19:14,541 [grpc-default-executor-0] INFO impl.VoteContext: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FOLLOWER: reject ELECTION from 3100efb7-0525-45d4-a0fd-e73779181107: our priority 1 > candidate's priority 0
datanode1_1  | 2022-08-22 01:19:14,541 [grpc-default-executor-0] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:3100efb7-0525-45d4-a0fd-e73779181107
datanode1_1  | 2022-08-22 01:19:14,542 [grpc-default-executor-0] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: shutdown 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState
datanode1_1  | 2022-08-22 01:19:14,542 [grpc-default-executor-0] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: start 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState
datanode1_1  | 2022-08-22 01:19:14,543 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState was interrupted
datanode1_1  | 2022-08-22 01:19:14,549 [grpc-default-executor-0] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838 replies to ELECTION vote request: 3100efb7-0525-45d4-a0fd-e73779181107<-61e48a95-a5d7-43eb-addf-1603d4744f3f#0:FAIL-t3. Peer's state: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838:t3, leader=null, voted=null, raftlog=61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-22 01:19:19,559 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5016398494ns, electionTimeout:5011ms
datanode1_1  | 2022-08-22 01:19:19,559 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: shutdown 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState
datanode1_1  | 2022-08-22 01:19:19,559 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
datanode1_1  | 2022-08-22 01:19:19,559 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-08-22 01:19:14,856 [pool-23-thread-1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c: new RaftServerImpl for group-EE9A9D2C444E:[3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1] with ContainerStateMachine:uninitialized
datanode3_1  | 2022-08-22 01:19:14,861 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2022-08-22 01:19:14,861 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2022-08-22 01:19:14,861 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2022-08-22 01:19:14,861 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2022-08-22 01:19:14,861 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2022-08-22 01:19:14,862 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2022-08-22 01:19:14,864 [pool-23-thread-1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E: ConfigurationManager, init=-1: [3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2022-08-22 01:19:14,864 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2022-08-22 01:19:14,865 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2022-08-22 01:19:14,865 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2022-08-22 01:19:14,865 [pool-23-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/c5d0a770-5809-48a9-a307-ee9a9d2c444e does not exist. Creating ...
datanode3_1  | 2022-08-22 01:19:14,870 [pool-23-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/c5d0a770-5809-48a9-a307-ee9a9d2c444e/in_use.lock acquired by nodename 7@d60fa041091d
datanode3_1  | 2022-08-22 01:19:14,878 [pool-23-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/c5d0a770-5809-48a9-a307-ee9a9d2c444e has been successfully formatted.
datanode3_1  | 2022-08-22 01:19:14,880 [pool-23-thread-1] INFO ratis.ContainerStateMachine: group-EE9A9D2C444E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2022-08-22 01:19:14,880 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2022-08-22 01:19:14,880 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2022-08-22 01:19:14,881 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2022-08-22 01:19:14,881 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2022-08-22 01:19:14,881 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2022-08-22 01:19:14,882 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-22 01:19:14,882 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2022-08-22 01:19:14,882 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2022-08-22 01:19:14,890 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: new 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/c5d0a770-5809-48a9-a307-ee9a9d2c444e
datanode3_1  | 2022-08-22 01:19:14,891 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2022-08-22 01:19:14,891 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2022-08-22 01:19:14,891 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2022-08-22 01:19:14,891 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2022-08-22 01:19:14,891 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2022-08-22 01:19:14,891 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2022-08-22 01:19:14,891 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2022-08-22 01:19:14,892 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2022-08-22 01:19:14,892 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2022-08-22 01:19:14,893 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2022-08-22 01:19:14,896 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2022-08-22 01:19:14,896 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-22 01:19:14,896 [pool-23-thread-1] INFO segmented.SegmentedRaftLogWorker: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2022-08-22 01:19:14,905 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2022-08-22 01:19:14,905 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2022-08-22 01:19:14,906 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2022-08-22 01:19:14,906 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2022-08-22 01:19:14,906 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2022-08-22 01:19:14,906 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2022-08-22 01:19:14,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2022-08-22 01:19:14,910 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2022-08-22 01:19:14,911 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2022-08-22 01:19:14,912 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2022-08-22 01:19:14,913 [pool-23-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2022-08-22 01:19:14,913 [pool-23-thread-1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E: start as a follower, conf=-1: [3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-08-22 01:19:14,915 [pool-23-thread-1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2022-08-22 01:19:14,915 [pool-23-thread-1] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: start 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-FollowerState
datanode3_1  | 2022-08-22 01:19:14,921 [pool-23-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-EE9A9D2C444E,id=3c60044e-b181-445f-8fa2-782a9e9eb45c
datanode3_1  | 2022-08-22 01:19:14,936 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=c5d0a770-5809-48a9-a307-ee9a9d2c444e
datanode3_1  | 2022-08-22 01:19:14,937 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=c5d0a770-5809-48a9-a307-ee9a9d2c444e.
datanode3_1  | 2022-08-22 01:19:19,670 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: receive requestVote(ELECTION, 3100efb7-0525-45d4-a0fd-e73779181107, group-C7FFD18C9838, 4, (t:0, i:0))
datanode3_1  | 2022-08-22 01:19:19,670 [grpc-default-executor-0] INFO impl.VoteContext: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FOLLOWER: accept ELECTION from 3100efb7-0525-45d4-a0fd-e73779181107: our priority 0 <= candidate's priority 0
datanode3_1  | 2022-08-22 01:19:19,670 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:3100efb7-0525-45d4-a0fd-e73779181107
datanode3_1  | 2022-08-22 01:19:19,670 [grpc-default-executor-0] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: shutdown 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState
datanode3_1  | 2022-08-22 01:19:19,670 [grpc-default-executor-0] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: start 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState
datanode3_1  | 2022-08-22 01:19:19,670 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState was interrupted
datanode3_1  | 2022-08-22 01:19:19,679 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838 replies to ELECTION vote request: 3100efb7-0525-45d4-a0fd-e73779181107<-3c60044e-b181-445f-8fa2-782a9e9eb45c#0:OK-t4. Peer's state: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838:t4, leader=null, voted=3100efb7-0525-45d4-a0fd-e73779181107, raftlog=3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-22 01:19:19,858 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: receive requestVote(ELECTION, 61e48a95-a5d7-43eb-addf-1603d4744f3f, group-C7FFD18C9838, 4, (t:0, i:0))
datanode3_1  | 2022-08-22 01:19:19,858 [grpc-default-executor-0] INFO impl.VoteContext: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FOLLOWER: reject ELECTION from 61e48a95-a5d7-43eb-addf-1603d4744f3f: already has voted for 3100efb7-0525-45d4-a0fd-e73779181107 at current term 4
datanode3_1  | 2022-08-22 01:19:19,858 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838 replies to ELECTION vote request: 61e48a95-a5d7-43eb-addf-1603d4744f3f<-3c60044e-b181-445f-8fa2-782a9e9eb45c#0:FAIL-t4. Peer's state: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838:t4, leader=null, voted=3100efb7-0525-45d4-a0fd-e73779181107, raftlog=3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-22 01:19:19,973 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-FollowerState] INFO impl.FollowerState: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5057806672ns, electionTimeout:5047ms
datanode3_1  | 2022-08-22 01:19:19,974 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-FollowerState] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: shutdown 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-FollowerState
om1_1        | 2022-08-22 01:22:45,775 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:22:53,630 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36112
om1_1        | 2022-08-22 01:22:53,645 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:22:58,323 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36128
om1_1        | 2022-08-22 01:22:58,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:23:03,515 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36154
om1_1        | 2022-08-22 01:23:03,530 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:23:07,563 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36172
om1_1        | 2022-08-22 01:23:07,580 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:23:12,104 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36182
om1_1        | 2022-08-22 01:23:12,124 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:23:16,855 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36198
om1_1        | 2022-08-22 01:23:16,873 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:23:21,669 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36238
om1_1        | 2022-08-22 01:23:21,691 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:23:26,034 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36254
om1_1        | 2022-08-22 01:23:26,054 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:23:30,796 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36264
om1_1        | 2022-08-22 01:23:30,821 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2022-08-22 01:18:32,464 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2022-08-22 01:18:39,290 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2022-08-22 01:18:42,117 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2022-08-22 01:18:42,817 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2022-08-22 01:18:42,822 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2022-08-22 01:18:42,832 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2022-08-22 01:18:42,881 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-08-22 01:18:43,114 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om3_1        | 2022-08-22 01:18:45,302 [main] INFO reflections.Reflections: Reflections took 1553 ms to scan 1 urls, producing 113 keys and 334 values [using 2 cores]
om3_1        | 2022-08-22 01:18:46,756 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2022-08-22 01:18:46,757 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2022-08-22 01:18:46,758 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-08-22 01:18:48,797 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-08-22 01:18:48,994 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2022-08-22 01:18:53,063 [main] INFO client.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om3_1        | 2022-08-22 01:18:53,869 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/ROOTCA-1.crt.
om3_1        | 2022-08-22 01:18:53,901 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/1179274323944.crt.
om3_1        | 2022-08-22 01:18:53,983 [main] INFO client.OMCertificateClient: Added certificate from file:/data/metadata/om/certs/CA-1085506235870.crt.
om3_1        | 2022-08-22 01:18:54,200 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2022-08-22 01:18:54,912 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-08-22 01:18:54,924 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | 2022-08-22 01:18:56,067 [main] INFO om.OzoneManager: S3 Multi-Tenancy is disabled
om3_1        | 2022-08-22 01:18:56,140 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
om3_1        | 2022-08-22 01:18:56,140 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om3_1        | 2022-08-22 01:18:56,799 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om3_1        | 2022-08-22 01:18:57,250 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-08-22 01:18:57,260 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om3_1        | 2022-08-22 01:18:57,343 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1        | 2022-08-22 01:18:58,080 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1        | 2022-08-22 01:18:58,215 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1        | 2022-08-22 01:18:58,477 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: id1 and peers: om3:9872, om1:9872, om2:9872
om3_1        | 2022-08-22 01:18:58,534 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1        | 2022-08-22 01:18:59,828 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om3_1        | 2022-08-22 01:19:00,319 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
om3_1        | 2022-08-22 01:19:00,328 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-08-22 01:19:00,335 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
om3_1        | 2022-08-22 01:19:00,335 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-08-22 01:19:00,335 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1        | 2022-08-22 01:19:00,337 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1        | 2022-08-22 01:19:00,356 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-08-22 01:19:00,364 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1        | 2022-08-22 01:19:00,365 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2022-08-22 01:19:00,541 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om3_1        | 2022-08-22 01:19:00,545 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om3_1        | 2022-08-22 01:19:03,072 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1        | 2022-08-22 01:19:03,086 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om3_1        | 2022-08-22 01:19:03,094 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om3_1        | 2022-08-22 01:19:03,095 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-08-22 01:19:03,095 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-08-22 01:19:03,101 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-08-22 01:19:03,142 [main] INFO server.RaftServer: om3: addNew group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] returns group-562213E44849:java.util.concurrent.CompletableFuture@7ce09850[Not completed]
om3_1        | 2022-08-22 01:19:03,143 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1        | 2022-08-22 01:19:03,227 [pool-27-thread-1] INFO server.RaftServer$Division: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0] with OzoneManagerStateMachine:uninitialized
datanode2_1  | 2022-08-22 01:19:24,721 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection7] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection7 ELECTION round 0: submit vote requests at term 5 for -1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-22 01:19:24,755 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection7] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection7: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode2_1  | 2022-08-22 01:19:24,758 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection7] INFO impl.LeaderElection:   Response 0: 3100efb7-0525-45d4-a0fd-e73779181107<-61e48a95-a5d7-43eb-addf-1603d4744f3f#0:FAIL-t5
datanode2_1  | 2022-08-22 01:19:24,758 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection7] INFO impl.LeaderElection: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection7 ELECTION round 0: result REJECTED
datanode2_1  | 2022-08-22 01:19:24,764 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection7] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
datanode2_1  | 2022-08-22 01:19:24,764 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection7] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection7
datanode2_1  | 2022-08-22 01:19:24,764 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-LeaderElection7] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState
datanode2_1  | 2022-08-22 01:19:29,925 [grpc-default-executor-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: receive requestVote(ELECTION, 61e48a95-a5d7-43eb-addf-1603d4744f3f, group-C7FFD18C9838, 6, (t:0, i:0))
datanode2_1  | 2022-08-22 01:19:29,932 [grpc-default-executor-1] INFO impl.VoteContext: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FOLLOWER: accept ELECTION from 61e48a95-a5d7-43eb-addf-1603d4744f3f: our priority 0 <= candidate's priority 1
datanode2_1  | 2022-08-22 01:19:29,932 [grpc-default-executor-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:61e48a95-a5d7-43eb-addf-1603d4744f3f
datanode2_1  | 2022-08-22 01:19:29,932 [grpc-default-executor-1] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: shutdown 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState
datanode2_1  | 2022-08-22 01:19:29,932 [grpc-default-executor-1] INFO impl.RoleInfo: 3100efb7-0525-45d4-a0fd-e73779181107: start 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState
datanode2_1  | 2022-08-22 01:19:29,941 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FollowerState was interrupted
datanode2_1  | 2022-08-22 01:19:29,952 [grpc-default-executor-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838 replies to ELECTION vote request: 61e48a95-a5d7-43eb-addf-1603d4744f3f<-3100efb7-0525-45d4-a0fd-e73779181107#0:OK-t6. Peer's state: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838:t6, leader=null, voted=61e48a95-a5d7-43eb-addf-1603d4744f3f, raftlog=3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|priority:0], old=null
datanode2_1  | 2022-08-22 01:19:30,212 [3100efb7-0525-45d4-a0fd-e73779181107-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C7FFD18C9838 with new leaderId: 61e48a95-a5d7-43eb-addf-1603d4744f3f
datanode2_1  | 2022-08-22 01:19:30,213 [3100efb7-0525-45d4-a0fd-e73779181107-server-thread1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: change Leader from null to 61e48a95-a5d7-43eb-addf-1603d4744f3f at term 6 for appendEntries, leader elected after 31228ms
datanode2_1  | 2022-08-22 01:19:30,242 [3100efb7-0525-45d4-a0fd-e73779181107-server-thread1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: set configuration 0: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-08-22 01:19:30,247 [3100efb7-0525-45d4-a0fd-e73779181107-server-thread1] INFO segmented.SegmentedRaftLogWorker: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-SegmentedRaftLogWorker: Starting segment from index:0
datanode2_1  | 2022-08-22 01:19:30,259 [3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838/current/log_inprogress_0
datanode2_1  | 2022-08-22 01:19:30,646 [grpc-default-executor-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838: receive requestVote(ELECTION, 3c60044e-b181-445f-8fa2-782a9e9eb45c, group-C7FFD18C9838, 6, (t:0, i:0))
datanode2_1  | 2022-08-22 01:19:30,646 [grpc-default-executor-1] INFO impl.VoteContext: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-FOLLOWER: reject ELECTION from 3c60044e-b181-445f-8fa2-782a9e9eb45c: already has voted for 61e48a95-a5d7-43eb-addf-1603d4744f3f at current term 6
datanode2_1  | 2022-08-22 01:19:30,646 [grpc-default-executor-1] INFO server.RaftServer$Division: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838 replies to ELECTION vote request: 3c60044e-b181-445f-8fa2-782a9e9eb45c<-3100efb7-0525-45d4-a0fd-e73779181107#0:FAIL-t6. Peer's state: 3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838:t6, leader=61e48a95-a5d7-43eb-addf-1603d4744f3f, voted=61e48a95-a5d7-43eb-addf-1603d4744f3f, raftlog=3100efb7-0525-45d4-a0fd-e73779181107@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c0, conf=0: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode2_1  | 2022-08-22 01:19:58,946 [java.util.concurrent.ThreadPoolExecutor$Worker@5abed121[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3,entriesCount=1,lastEntry=(t:1, i:0)
datanode2_1  | 2022-08-22 01:20:02,784 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:1179274323944.
om2_1        | 2022-08-22 01:21:27,572 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:21:28,159 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 39072-target
om2_1        | 2022-08-22 01:21:32,322 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52846
om2_1        | 2022-08-22 01:21:32,323 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:21:32,892 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 39072-target
om2_1        | 2022-08-22 01:21:36,713 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52862
om2_1        | 2022-08-22 01:21:36,719 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:21:37,290 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 39072-target
om2_1        | 2022-08-22 01:21:41,145 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52870
om2_1        | 2022-08-22 01:21:41,156 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:21:45,453 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52886
om2_1        | 2022-08-22 01:21:45,461 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:21:49,983 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52926
datanode1_1  | 2022-08-22 01:19:19,560 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: start 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection2
datanode1_1  | 2022-08-22 01:19:19,564 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection2] INFO impl.LeaderElection: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection2 ELECTION round 0: submit vote requests at term 4 for -1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-22 01:19:19,678 [grpc-default-executor-0] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: receive requestVote(ELECTION, 3100efb7-0525-45d4-a0fd-e73779181107, group-C7FFD18C9838, 4, (t:0, i:0))
datanode1_1  | 2022-08-22 01:19:19,678 [grpc-default-executor-0] INFO impl.VoteContext: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-CANDIDATE: reject ELECTION from 3100efb7-0525-45d4-a0fd-e73779181107: already has voted for 61e48a95-a5d7-43eb-addf-1603d4744f3f at current term 4
datanode1_1  | 2022-08-22 01:19:19,678 [grpc-default-executor-0] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838 replies to ELECTION vote request: 3100efb7-0525-45d4-a0fd-e73779181107<-61e48a95-a5d7-43eb-addf-1603d4744f3f#0:FAIL-t4. Peer's state: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838:t4, leader=null, voted=61e48a95-a5d7-43eb-addf-1603d4744f3f, raftlog=61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-22 01:19:20,061 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection2] INFO impl.LeaderElection: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode1_1  | 2022-08-22 01:19:20,062 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection2] INFO impl.LeaderElection:   Response 0: 61e48a95-a5d7-43eb-addf-1603d4744f3f<-3c60044e-b181-445f-8fa2-782a9e9eb45c#0:FAIL-t4
datanode1_1  | 2022-08-22 01:19:20,062 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection2] INFO impl.LeaderElection:   Response 1: 61e48a95-a5d7-43eb-addf-1603d4744f3f<-3100efb7-0525-45d4-a0fd-e73779181107#0:FAIL-t4
datanode1_1  | 2022-08-22 01:19:20,062 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection2] INFO impl.LeaderElection: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection2 ELECTION round 0: result REJECTED
datanode1_1  | 2022-08-22 01:19:20,062 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection2] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
datanode1_1  | 2022-08-22 01:19:20,064 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection2] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: shutdown 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection2
datanode1_1  | 2022-08-22 01:19:20,065 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection2] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: start 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState
datanode1_1  | 2022-08-22 01:19:24,729 [grpc-default-executor-2] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: receive requestVote(ELECTION, 3100efb7-0525-45d4-a0fd-e73779181107, group-C7FFD18C9838, 5, (t:0, i:0))
datanode1_1  | 2022-08-22 01:19:24,731 [grpc-default-executor-2] INFO impl.VoteContext: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FOLLOWER: reject ELECTION from 3100efb7-0525-45d4-a0fd-e73779181107: our priority 1 > candidate's priority 0
datanode1_1  | 2022-08-22 01:19:24,733 [grpc-default-executor-2] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:3100efb7-0525-45d4-a0fd-e73779181107
datanode1_1  | 2022-08-22 01:19:24,733 [grpc-default-executor-2] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: shutdown 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState
datanode1_1  | 2022-08-22 01:19:24,734 [grpc-default-executor-2] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: start 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState
datanode1_1  | 2022-08-22 01:19:24,735 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState was interrupted
datanode1_1  | 2022-08-22 01:19:24,743 [grpc-default-executor-2] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838 replies to ELECTION vote request: 3100efb7-0525-45d4-a0fd-e73779181107<-61e48a95-a5d7-43eb-addf-1603d4744f3f#0:FAIL-t5. Peer's state: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838:t5, leader=null, voted=null, raftlog=61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-22 01:19:29,903 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5168805622ns, electionTimeout:5160ms
datanode1_1  | 2022-08-22 01:19:29,903 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: shutdown 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState
datanode1_1  | 2022-08-22 01:19:29,904 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
datanode1_1  | 2022-08-22 01:19:29,904 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode1_1  | 2022-08-22 01:19:29,904 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: start 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3
om3_1        | 2022-08-22 01:19:03,242 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om3_1        | 2022-08-22 01:19:03,256 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om3_1        | 2022-08-22 01:19:03,257 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om3_1        | 2022-08-22 01:19:03,257 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1        | 2022-08-22 01:19:03,257 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1        | 2022-08-22 01:19:03,258 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om3_1        | 2022-08-22 01:19:03,298 [pool-27-thread-1] INFO server.RaftServer$Division: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null, confs=<EMPTY_MAP>
om3_1        | 2022-08-22 01:19:03,300 [main] INFO om.OzoneManager: Creating RPC Server
om3_1        | 2022-08-22 01:19:03,303 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1        | 2022-08-22 01:19:03,330 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1        | 2022-08-22 01:19:03,332 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om3_1        | 2022-08-22 01:19:03,344 [pool-27-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1        | 2022-08-22 01:19:03,480 [pool-27-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@om3
om3_1        | 2022-08-22 01:19:03,557 [pool-27-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1        | 2022-08-22 01:19:03,573 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1        | 2022-08-22 01:19:03,578 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1        | 2022-08-22 01:19:03,644 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1        | 2022-08-22 01:19:03,657 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-08-22 01:19:03,658 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om3_1        | 2022-08-22 01:19:03,844 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-08-22 01:19:04,008 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1        | 2022-08-22 01:19:04,016 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om3_1        | 2022-08-22 01:19:04,042 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1        | 2022-08-22 01:19:04,058 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1        | 2022-08-22 01:19:04,069 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1        | 2022-08-22 01:19:04,071 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1        | 2022-08-22 01:19:04,096 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1        | 2022-08-22 01:19:04,099 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1        | 2022-08-22 01:19:04,115 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1        | 2022-08-22 01:19:04,131 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1        | 2022-08-22 01:19:04,132 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1        | 2022-08-22 01:19:04,243 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1        | 2022-08-22 01:19:04,249 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om3_1        | 2022-08-22 01:19:04,257 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1        | 2022-08-22 01:19:04,338 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
recon_1      | 2022-08-22 01:18:14,941 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 45 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:14,942 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 46 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:14,943 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 47 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:16,945 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 48 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:16,946 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 49 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:16,947 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 50 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:18,955 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 51 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:18,964 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 52 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:18,969 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 53 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:20,972 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 54 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:20,973 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 55 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:20,974 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 56 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:22,976 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 57 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:22,977 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 58 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:22,978 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 59 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:24,980 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 60 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:24,981 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 61 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:24,982 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 62 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:26,985 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 63 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:26,986 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 64 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:26,990 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 65 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:28,992 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 66 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:28,997 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 67 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:28,999 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 68 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:31,001 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 69 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:31,002 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 70 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:31,003 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 71 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:33,004 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 72 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:33,005 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 73 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:33,006 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 74 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:35,007 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 75 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:35,008 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 76 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:35,009 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 77 failover attempts. Trying to failover after sleeping for 2000ms.
om1_1        | 2022-08-22 01:23:35,478 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36280
om1_1        | 2022-08-22 01:23:35,505 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:23:39,989 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36296
om1_1        | 2022-08-22 01:23:40,006 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:23:44,798 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36312
om1_1        | 2022-08-22 01:23:44,820 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:23:49,766 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36352
om1_1        | 2022-08-22 01:23:49,802 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:23:50,532 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 39072-target
om1_1        | 2022-08-22 01:23:54,430 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36360
om1_1        | 2022-08-22 01:23:54,445 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:23:55,170 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:39072-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:23:59,044 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36386
om1_1        | 2022-08-22 01:23:59,071 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:23:59,718 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 39072-target
om1_1        | 2022-08-22 01:24:03,610 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36404
om1_1        | 2022-08-22 01:24:03,641 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:24:04,468 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:39072-target
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:24:08,373 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36422
om1_1        | 2022-08-22 01:24:08,405 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:24:13,206 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36430
om1_1        | 2022-08-22 01:24:13,221 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:24:17,660 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36446
om1_1        | 2022-08-22 01:24:17,682 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:24:22,443 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36486
om1_1        | 2022-08-22 01:24:22,467 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:24:26,808 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36504
om1_1        | 2022-08-22 01:24:26,824 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:24:27,508 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 39072-target
om1_1        | 2022-08-22 01:24:31,339 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36512
om1_1        | 2022-08-22 01:24:31,361 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:24:32,019 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 39072-target
om1_1        | 2022-08-22 01:24:35,721 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36528
datanode3_1  | 2022-08-22 01:19:19,974 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-FollowerState] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2022-08-22 01:19:19,976 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-08-22 01:19:19,976 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-FollowerState] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: start 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1
datanode3_1  | 2022-08-22 01:19:19,985 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO impl.LeaderElection: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|priority:1], old=null
datanode3_1  | 2022-08-22 01:19:19,986 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO impl.LeaderElection: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2022-08-22 01:19:19,987 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: shutdown 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1
datanode3_1  | 2022-08-22 01:19:19,987 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2022-08-22 01:19:19,987 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-EE9A9D2C444E with new leaderId: 3c60044e-b181-445f-8fa2-782a9e9eb45c
datanode3_1  | 2022-08-22 01:19:19,997 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E: change Leader from null to 3c60044e-b181-445f-8fa2-782a9e9eb45c at term 1 for becomeLeader, leader elected after 5107ms
datanode3_1  | 2022-08-22 01:19:19,998 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2022-08-22 01:19:20,023 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-08-22 01:19:20,025 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2022-08-22 01:19:20,035 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2022-08-22 01:19:20,037 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2022-08-22 01:19:20,037 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2022-08-22 01:19:20,051 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2022-08-22 01:19:20,057 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2022-08-22 01:19:20,073 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: start 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderStateImpl
datanode3_1  | 2022-08-22 01:19:20,086 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-08-22 01:19:20,094 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/c5d0a770-5809-48a9-a307-ee9a9d2c444e/current/log_inprogress_0
datanode3_1  | 2022-08-22 01:19:20,110 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E-LeaderElection1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-EE9A9D2C444E: set configuration 0: [3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:1], old=null
datanode3_1  | 2022-08-22 01:19:24,733 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: receive requestVote(ELECTION, 3100efb7-0525-45d4-a0fd-e73779181107, group-C7FFD18C9838, 5, (t:0, i:0))
datanode3_1  | 2022-08-22 01:19:24,733 [grpc-default-executor-0] INFO impl.VoteContext: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FOLLOWER: accept ELECTION from 3100efb7-0525-45d4-a0fd-e73779181107: our priority 0 <= candidate's priority 0
datanode3_1  | 2022-08-22 01:19:24,733 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:3100efb7-0525-45d4-a0fd-e73779181107
datanode3_1  | 2022-08-22 01:19:24,733 [grpc-default-executor-0] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: shutdown 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState
datanode3_1  | 2022-08-22 01:19:24,733 [grpc-default-executor-0] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: start 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState
datanode3_1  | 2022-08-22 01:19:24,734 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState was interrupted
datanode3_1  | 2022-08-22 01:19:24,757 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838 replies to ELECTION vote request: 3100efb7-0525-45d4-a0fd-e73779181107<-3c60044e-b181-445f-8fa2-782a9e9eb45c#0:OK-t5. Peer's state: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838:t5, leader=null, voted=3100efb7-0525-45d4-a0fd-e73779181107, raftlog=3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-22 01:19:29,899 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState] INFO impl.FollowerState: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5141799360ns, electionTimeout:5135ms
datanode3_1  | 2022-08-22 01:19:29,899 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: shutdown 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState
datanode3_1  | 2022-08-22 01:19:29,899 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
datanode3_1  | 2022-08-22 01:19:29,899 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode3_1  | 2022-08-22 01:19:29,899 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: start 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-LeaderElection2
datanode3_1  | 2022-08-22 01:19:29,911 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-LeaderElection2] INFO impl.LeaderElection: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-LeaderElection2 ELECTION round 0: submit vote requests at term 6 for -1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-22 01:19:30,115 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: receive requestVote(ELECTION, 61e48a95-a5d7-43eb-addf-1603d4744f3f, group-C7FFD18C9838, 6, (t:0, i:0))
datanode3_1  | 2022-08-22 01:19:30,117 [grpc-default-executor-0] INFO impl.VoteContext: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-CANDIDATE: reject ELECTION from 61e48a95-a5d7-43eb-addf-1603d4744f3f: already has voted for 3c60044e-b181-445f-8fa2-782a9e9eb45c at current term 6
datanode3_1  | 2022-08-22 01:19:30,117 [grpc-default-executor-0] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838 replies to ELECTION vote request: 61e48a95-a5d7-43eb-addf-1603d4744f3f<-3c60044e-b181-445f-8fa2-782a9e9eb45c#0:FAIL-t6. Peer's state: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838:t6, leader=null, voted=3c60044e-b181-445f-8fa2-782a9e9eb45c, raftlog=3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c-1, conf=-1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-22 01:19:30,182 [3c60044e-b181-445f-8fa2-782a9e9eb45c-server-thread1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: changes role from CANDIDATE to FOLLOWER at term 6 for appendEntries
datanode1_1  | 2022-08-22 01:19:29,920 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO impl.LeaderElection: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3 ELECTION round 0: submit vote requests at term 6 for -1: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-22 01:19:29,969 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO impl.LeaderElection: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
datanode1_1  | 2022-08-22 01:19:29,970 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO impl.LeaderElection:   Response 0: 61e48a95-a5d7-43eb-addf-1603d4744f3f<-3100efb7-0525-45d4-a0fd-e73779181107#0:OK-t6
datanode1_1  | 2022-08-22 01:19:29,970 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO impl.LeaderElection: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3 ELECTION round 0: result PASSED
datanode1_1  | 2022-08-22 01:19:29,970 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: shutdown 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3
datanode1_1  | 2022-08-22 01:19:29,970 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: changes role from CANDIDATE to LEADER at term 6 for changeToLeader
datanode1_1  | 2022-08-22 01:19:29,970 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C7FFD18C9838 with new leaderId: 61e48a95-a5d7-43eb-addf-1603d4744f3f
datanode1_1  | 2022-08-22 01:19:29,996 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: change Leader from null to 61e48a95-a5d7-43eb-addf-1603d4744f3f at term 6 for becomeLeader, leader elected after 30395ms
datanode1_1  | 2022-08-22 01:19:29,996 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2022-08-22 01:19:30,025 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-08-22 01:19:30,027 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2022-08-22 01:19:30,027 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2022-08-22 01:19:30,027 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2022-08-22 01:19:30,028 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2022-08-22 01:19:30,028 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2022-08-22 01:19:30,029 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2022-08-22 01:19:30,064 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2022-08-22 01:19:30,064 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-08-22 01:19:30,065 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2022-08-22 01:19:30,072 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2022-08-22 01:19:30,073 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-08-22 01:19:30,074 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-08-22 01:19:30,090 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode1_1  | 2022-08-22 01:19:30,091 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2022-08-22 01:19:30,092 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode1_1  | 2022-08-22 01:19:30,092 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode1_1  | 2022-08-22 01:19:30,092 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2022-08-22 01:19:30,092 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2022-08-22 01:19:30,103 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO impl.RoleInfo: 61e48a95-a5d7-43eb-addf-1603d4744f3f: start 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderStateImpl
datanode1_1  | 2022-08-22 01:19:30,105 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2022-08-22 01:19:30,111 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838/current/log_inprogress_0
datanode1_1  | 2022-08-22 01:19:30,122 [61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LeaderElection3] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: set configuration 0: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-22 01:19:30,609 [grpc-default-executor-2] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838: receive requestVote(ELECTION, 3c60044e-b181-445f-8fa2-782a9e9eb45c, group-C7FFD18C9838, 6, (t:0, i:0))
datanode1_1  | 2022-08-22 01:19:30,609 [grpc-default-executor-2] INFO impl.VoteContext: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-LEADER: reject ELECTION from 3c60044e-b181-445f-8fa2-782a9e9eb45c: already has voted for 61e48a95-a5d7-43eb-addf-1603d4744f3f at current term 6
datanode1_1  | 2022-08-22 01:19:30,609 [grpc-default-executor-2] INFO server.RaftServer$Division: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838 replies to ELECTION vote request: 3c60044e-b181-445f-8fa2-782a9e9eb45c<-61e48a95-a5d7-43eb-addf-1603d4744f3f#0:FAIL-t6. Peer's state: 61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838:t6, leader=61e48a95-a5d7-43eb-addf-1603d4744f3f, voted=61e48a95-a5d7-43eb-addf-1603d4744f3f, raftlog=61e48a95-a5d7-43eb-addf-1603d4744f3f@group-C7FFD18C9838-SegmentedRaftLog:OPENED:c0, conf=0: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode1_1  | 2022-08-22 01:20:03,070 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:1179274323944.
om3_1        | 2022-08-22 01:19:04,354 [pool-27-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1        | 2022-08-22 01:19:04,390 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1        | 2022-08-22 01:19:04,487 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1        | 2022-08-22 01:19:04,497 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1        | 2022-08-22 01:19:04,503 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1        | 2022-08-22 01:19:04,520 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1        | 2022-08-22 01:19:04,522 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om3_1        | 2022-08-22 01:19:04,817 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2022-08-22 01:19:04,818 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om3_1        | 2022-08-22 01:19:04,818 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om3_1        | 2022-08-22 01:19:04,818 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om3_1        | 2022-08-22 01:19:04,819 [pool-27-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om3_1        | 2022-08-22 01:19:05,620 [main] INFO reflections.Reflections: Reflections took 1958 ms to scan 8 urls, producing 23 keys and 517 values [using 2 cores]
om3_1        | 2022-08-22 01:19:06,855 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1        | 2022-08-22 01:19:06,903 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1        | 2022-08-22 01:19:10,742 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1        | 2022-08-22 01:19:10,806 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1        | 2022-08-22 01:19:10,814 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1        | 2022-08-22 01:19:10,988 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.25.0.113:9862
om3_1        | 2022-08-22 01:19:10,991 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1        | 2022-08-22 01:19:11,004 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-22 01:19:11,012 [om3-impl-thread1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1        | 2022-08-22 01:19:11,017 [om3-impl-thread1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-08-22 01:19:11,032 [om3-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1        | 2022-08-22 01:19:11,034 [Listener at om3/9862] INFO server.RaftServer: om3: start RPC server
om3_1        | 2022-08-22 01:19:11,201 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 9872
om3_1        | 2022-08-22 01:19:11,217 [Listener at om3/9862] INFO om.OzoneManager: Starting OM block token secret manager
om3_1        | 2022-08-22 01:19:11,218 [Listener at om3/9862] INFO token.OzoneBlockTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-08-22 01:19:11,219 [Listener at om3/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
om3_1        | 2022-08-22 01:19:11,226 [Listener at om3/9862] INFO security.OzoneDelegationTokenSecretManager: Updating the current master key for generating tokens
om3_1        | 2022-08-22 01:19:11,227 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$452/0x00000008405b2040@1d27d981] INFO util.JvmPauseMonitor: JvmPauseMonitor-om3: Started
om3_1        | 2022-08-22 01:19:11,232 [Listener at om3/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om3_1        | 2022-08-22 01:19:11,239 [Thread[Thread-18,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om3_1        | 2022-08-22 01:19:11,324 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1        | 2022-08-22 01:19:11,324 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2022-08-22 01:19:11,325 [Listener at om3/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
om3_1        | 2022-08-22 01:19:11,464 [Listener at om3/9862] INFO util.log: Logging initialized @47665ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1        | 2022-08-22 01:19:11,889 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1        | 2022-08-22 01:19:11,916 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1        | 2022-08-22 01:19:11,930 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om3_1        | 2022-08-22 01:19:11,931 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om3_1        | 2022-08-22 01:19:11,931 [Listener at om3/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om3_1        | 2022-08-22 01:19:11,965 [Listener at om3/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
om3_1        | 2022-08-22 01:19:12,149 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1        | 2022-08-22 01:19:12,158 [Listener at om3/9862] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
om3_1        | 2022-08-22 01:19:12,277 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1        | 2022-08-22 01:19:12,278 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1        | 2022-08-22 01:19:12,298 [Listener at om3/9862] INFO server.session: node0 Scavenging every 600000ms
om3_1        | 2022-08-22 01:19:12,358 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-08-22 01:19:12,369 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@8be6fcf{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1        | 2022-08-22 01:24:35,740 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:24:36,366 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 39072-target
om1_1        | 2022-08-22 01:24:39,885 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36544
om1_1        | 2022-08-22 01:24:39,903 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:24:44,322 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36560
om1_1        | 2022-08-22 01:24:44,341 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:24:45,219 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 39072-target
om1_1        | 2022-08-22 01:24:49,253 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36592
om1_1        | 2022-08-22 01:24:49,265 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:24:56,752 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36620
om1_1        | 2022-08-22 01:24:56,769 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:25:03,367 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36650
om1_1        | 2022-08-22 01:25:03,382 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:25:07,817 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36668
om1_1        | 2022-08-22 01:25:07,830 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:25:12,391 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36676
om1_1        | 2022-08-22 01:25:12,406 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:25:17,028 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36692
om1_1        | 2022-08-22 01:25:17,043 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:25:17,708 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 39072-target
om1_1        | 2022-08-22 01:25:22,005 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36732
om1_1        | 2022-08-22 01:25:22,022 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:25:22,784 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:39072-target
om1_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:25:26,633 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:36742
om1_1        | 2022-08-22 01:25:26,654 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:26:06,094 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37056
om1_1        | 2022-08-22 01:26:06,123 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:26:11,651 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:35013
om1_1        | 2022-08-22 01:26:11,673 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:21:49,985 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:21:53,924 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52934
om2_1        | 2022-08-22 01:21:53,935 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:21:58,270 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52950
om2_1        | 2022-08-22 01:21:58,280 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:22:02,974 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52976
om2_1        | 2022-08-22 01:22:02,978 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:22:03,631 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 39072-target
om2_1        | 2022-08-22 01:22:07,287 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:52994
om2_1        | 2022-08-22 01:22:07,300 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:22:11,986 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53006
om2_1        | 2022-08-22 01:22:12,001 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:22:12,718 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 39072-target
om2_1        | 2022-08-22 01:22:16,614 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53022
om2_1        | 2022-08-22 01:22:16,624 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:22:17,266 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 39072-source
om2_1        | 2022-08-22 01:22:21,715 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53062
om2_1        | 2022-08-22 01:22:21,720 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:22:31,666 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53092
om2_1        | 2022-08-22 01:22:31,672 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:22:38,569 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53112
om2_1        | 2022-08-22 01:22:38,579 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:22:45,817 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53132
om2_1        | 2022-08-22 01:22:45,822 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:22:53,676 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53176
om2_1        | 2022-08-22 01:22:53,686 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:22:58,374 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53192
om2_1        | 2022-08-22 01:22:58,379 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:23:03,565 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53218
om2_1        | 2022-08-22 01:23:03,568 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:23:07,614 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53236
om2_1        | 2022-08-22 01:23:07,625 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:23:12,148 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53246
om2_1        | 2022-08-22 01:23:12,151 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:23:16,910 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53262
om2_1        | 2022-08-22 01:23:16,914 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:23:21,733 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53302
om2_1        | 2022-08-22 01:23:21,740 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:19:12,370 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@8e41d4c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1        | 2022-08-22 01:19:12,755 [Listener at om3/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/om@EXAMPLE.COM
om3_1        | 2022-08-22 01:19:12,805 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5f3072ac{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_3_0-SNAPSHOT_jar-_-any-9152237268768076304/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0-SNAPSHOT.jar!/webapps/ozoneManager}
om3_1        | 2022-08-22 01:19:12,837 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@1b14ace7{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1        | 2022-08-22 01:19:12,837 [Listener at om3/9862] INFO server.Server: Started @49038ms
om3_1        | 2022-08-22 01:19:12,839 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1        | 2022-08-22 01:19:12,842 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1        | 2022-08-22 01:19:12,853 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1        | 2022-08-22 01:19:12,864 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1        | 2022-08-22 01:19:12,865 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1        | 2022-08-22 01:19:13,025 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted won't move to trash
om3_1        | 2022-08-22 01:19:13,327 [Listener at om3/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om3_1        | 2022-08-22 01:19:13,393 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:37923
om3_1        | 2022-08-22 01:19:13,419 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:19:13,421 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2356947a] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1        | 2022-08-22 01:19:16,195 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5178217742ns, electionTimeout:5127ms
om3_1        | 2022-08-22 01:19:16,205 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-08-22 01:19:16,210 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1        | 2022-08-22 01:19:16,218 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2022-08-22 01:19:16,225 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1        | 2022-08-22 01:19:16,245 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-22 01:19:17,600 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-08-22 01:19:17,602 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om3 at current term 1
om3_1        | 2022-08-22 01:19:17,636 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-22 01:19:17,688 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59556
om3_1        | 2022-08-22 01:19:17,694 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:19:17,866 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
om3_1        | 2022-08-22 01:19:17,866 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 0: om3<-om1#0:FAIL-t1
om3_1        | 2022-08-22 01:19:17,867 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection:   Response 1: om3<-om2#0:FAIL-t1
om3_1        | 2022-08-22 01:19:17,867 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1 ELECTION round 0: result REJECTED
om3_1        | 2022-08-22 01:19:17,879 [om3@group-562213E44849-LeaderElection1] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om3_1        | 2022-08-22 01:19:17,880 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om3_1        | 2022-08-22 01:19:17,881 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1        | 2022-08-22 01:19:18,095 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om1, group-562213E44849, 1, (t:0, i:~))
om3_1        | 2022-08-22 01:19:18,095 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-FOLLOWER: reject ELECTION from om1: already has voted for om3 at current term 1
om3_1        | 2022-08-22 01:19:18,095 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om1<-om3#0:FAIL-t1. Peer's state: om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-22 01:19:22,924 [om3@group-562213E44849-FollowerState] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5042812507ns, electionTimeout:5037ms
om3_1        | 2022-08-22 01:19:22,926 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1        | 2022-08-22 01:19:22,927 [om3@group-562213E44849-FollowerState] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om3_1        | 2022-08-22 01:19:22,928 [om3@group-562213E44849-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om3_1        | 2022-08-22 01:19:22,928 [om3@group-562213E44849-FollowerState] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection2
om3_1        | 2022-08-22 01:19:22,937 [om3@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-22 01:19:22,983 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849: receive requestVote(ELECTION, om2, group-562213E44849, 2, (t:0, i:~))
datanode2_1  | 2022-08-22 01:21:02,726 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=243,entriesCount=1,lastEntry=(t:1, i:1)
datanode2_1  | 2022-08-22 01:21:02,737 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=244,entriesCount=1,lastEntry=(t:1, i:2)
datanode2_1  | 2022-08-22 01:21:03,888 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=245,entriesCount=1,lastEntry=(t:1, i:3)
datanode2_1  | 2022-08-22 01:21:03,888 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=246,entriesCount=1,lastEntry=(t:1, i:4)
datanode2_1  | 2022-08-22 01:21:23,683 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=282,entriesCount=1,lastEntry=(t:1, i:5)
datanode2_1  | 2022-08-22 01:21:23,696 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=283,entriesCount=1,lastEntry=(t:1, i:6)
datanode2_1  | 2022-08-22 01:21:23,709 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=284,entriesCount=1,lastEntry=(t:1, i:7)
datanode2_1  | 2022-08-22 01:21:23,727 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=287,entriesCount=1,lastEntry=(t:1, i:8)
datanode2_1  | 2022-08-22 01:23:24,555 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=389,entriesCount=1,lastEntry=(t:1, i:9)
datanode2_1  | 2022-08-22 01:23:24,567 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=390,entriesCount=1,lastEntry=(t:1, i:10)
datanode2_1  | 2022-08-22 01:23:24,586 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=393,entriesCount=1,lastEntry=(t:1, i:11)
datanode2_1  | 2022-08-22 01:23:24,599 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=395,entriesCount=1,lastEntry=(t:1, i:12)
datanode2_1  | 2022-08-22 01:25:51,866 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=695,entriesCount=1,lastEntry=(t:1, i:13)
datanode2_1  | 2022-08-22 01:25:51,881 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=696,entriesCount=1,lastEntry=(t:1, i:14)
datanode2_1  | 2022-08-22 01:25:51,896 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=697,entriesCount=1,lastEntry=(t:1, i:15)
datanode2_1  | 2022-08-22 01:25:51,902 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=699,entriesCount=1,lastEntry=(t:1, i:16)
datanode2_1  | 2022-08-22 01:27:21,647 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=789,entriesCount=1,lastEntry=(t:1, i:17)
datanode2_1  | 2022-08-22 01:27:21,654 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=790,entriesCount=1,lastEntry=(t:1, i:18)
datanode2_1  | 2022-08-22 01:27:21,665 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=791,entriesCount=1,lastEntry=(t:1, i:19)
datanode2_1  | 2022-08-22 01:27:21,695 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=793,entriesCount=1,lastEntry=(t:1, i:20)
datanode2_1  | 2022-08-22 01:27:34,732 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=894,entriesCount=1,lastEntry=(t:1, i:21)
datanode2_1  | 2022-08-22 01:27:34,741 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=895,entriesCount=1,lastEntry=(t:1, i:22)
datanode2_1  | 2022-08-22 01:27:34,755 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=896,entriesCount=1,lastEntry=(t:1, i:23)
datanode2_1  | 2022-08-22 01:27:34,755 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=897,entriesCount=1,lastEntry=(t:1, i:24)
om1_1        | 2022-08-22 01:26:12,254 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6690263611 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:26:15,949 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37088
om1_1        | 2022-08-22 01:26:15,978 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:26:19,499 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8018651496 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:26:30,630 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37160
om1_1        | 2022-08-22 01:26:30,645 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:26:34,029 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5317785265 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:26:34,624 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-pkkavrhdbq of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:26:39,064 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-emlxgnryiv of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:26:46,463 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37212
om1_1        | 2022-08-22 01:26:46,480 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:26:50,063 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7025562811 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:26:50,717 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9097171453 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:26:51,427 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7237953091 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:26:52,117 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-7237953091 in volume:s3v
om1_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:26:53,767 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6286737048 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:26:57,683 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37264
om1_1        | 2022-08-22 01:26:57,700 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:27:02,307 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37290
om1_1        | 2022-08-22 01:27:02,318 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:27:05,816 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6031205182 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:06,433 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4059376425 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:07,713 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-4695970515 in volume:s3v
om1_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2498)
om1_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2468)
om1_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om1_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:27:11,355 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37324
om1_1        | 2022-08-22 01:27:11,376 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:27:14,791 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5013695993 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:19,699 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37372
datanode3_1  | 2022-08-22 01:19:30,225 [3c60044e-b181-445f-8fa2-782a9e9eb45c-server-thread1] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: shutdown 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-LeaderElection2
datanode3_1  | 2022-08-22 01:19:30,225 [3c60044e-b181-445f-8fa2-782a9e9eb45c-server-thread1] INFO impl.RoleInfo: 3c60044e-b181-445f-8fa2-782a9e9eb45c: start 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-FollowerState
datanode3_1  | 2022-08-22 01:19:30,227 [3c60044e-b181-445f-8fa2-782a9e9eb45c-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C7FFD18C9838 with new leaderId: 61e48a95-a5d7-43eb-addf-1603d4744f3f
datanode3_1  | 2022-08-22 01:19:30,227 [3c60044e-b181-445f-8fa2-782a9e9eb45c-server-thread1] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: change Leader from null to 61e48a95-a5d7-43eb-addf-1603d4744f3f at term 6 for appendEntries, leader elected after 30149ms
datanode3_1  | 2022-08-22 01:19:30,277 [3c60044e-b181-445f-8fa2-782a9e9eb45c-server-thread2] INFO server.RaftServer$Division: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838: set configuration 0: [61e48a95-a5d7-43eb-addf-1603d4744f3f|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:|priority:1, 3c60044e-b181-445f-8fa2-782a9e9eb45c|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:|priority:0, 3100efb7-0525-45d4-a0fd-e73779181107|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:|priority:0], old=null
datanode3_1  | 2022-08-22 01:19:30,290 [3c60044e-b181-445f-8fa2-782a9e9eb45c-server-thread2] INFO segmented.SegmentedRaftLogWorker: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2022-08-22 01:19:30,302 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/85ae3250-a1a7-4fa0-96fb-c7ffd18c9838/current/log_inprogress_0
datanode3_1  | 2022-08-22 01:19:30,639 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-LeaderElection2] INFO impl.LeaderElection: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-LeaderElection2: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode3_1  | 2022-08-22 01:19:30,640 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-LeaderElection2] INFO impl.LeaderElection:   Response 0: 3c60044e-b181-445f-8fa2-782a9e9eb45c<-61e48a95-a5d7-43eb-addf-1603d4744f3f#0:FAIL-t6
datanode3_1  | 2022-08-22 01:19:30,640 [3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-LeaderElection2] INFO impl.LeaderElection: 3c60044e-b181-445f-8fa2-782a9e9eb45c@group-C7FFD18C9838-LeaderElection2 ELECTION round 0: result REJECTED
datanode3_1  | 2022-08-22 01:20:02,959 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:1179274323944.
recon_1      | 2022-08-22 01:18:37,012 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 78 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:37,013 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 79 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:37,013 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 80 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:38,223 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39752
recon_1      | 2022-08-22 01:18:38,355 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:18:39,040 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 81 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:39,045 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 82 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:39,045 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 83 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:39,201 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58444
recon_1      | 2022-08-22 01:18:39,376 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:18:41,054 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 84 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:41,055 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 85 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:41,064 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 86 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:41,713 [IPC Server handler 70 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/61e48a95-a5d7-43eb-addf-1603d4744f3f
recon_1      | 2022-08-22 01:18:41,764 [IPC Server handler 70 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [], networkLocation: /default-rack, certSerialId: 1171297874022, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:18:41,965 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 61e48a95-a5d7-43eb-addf-1603d4744f3f to Node DB.
recon_1      | 2022-08-22 01:18:42,296 [IPC Server handler 3 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3c60044e-b181-445f-8fa2-782a9e9eb45c
recon_1      | 2022-08-22 01:18:42,297 [IPC Server handler 3 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171021466938, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:18:42,299 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 3c60044e-b181-445f-8fa2-782a9e9eb45c to Node DB.
recon_1      | 2022-08-22 01:18:42,672 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38422
recon_1      | 2022-08-22 01:18:42,711 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:18:42,991 [IPC Server handler 2 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-22 01:18:43,066 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 87 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:43,068 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 88 failover attempts. Trying to failover immediately.
om2_1        | 2022-08-22 01:23:26,150 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53318
om2_1        | 2022-08-22 01:23:26,154 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:23:30,859 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53328
om2_1        | 2022-08-22 01:23:30,865 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:23:35,545 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53344
om2_1        | 2022-08-22 01:23:35,550 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:23:40,039 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53360
om2_1        | 2022-08-22 01:23:40,047 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:23:44,860 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53376
om2_1        | 2022-08-22 01:23:44,869 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:23:49,847 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53416
om2_1        | 2022-08-22 01:23:49,851 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:23:50,522 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 39072-target
om2_1        | 2022-08-22 01:23:54,479 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53424
om2_1        | 2022-08-22 01:23:54,485 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:23:55,180 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:39072-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:23:59,105 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53450
om2_1        | 2022-08-22 01:23:59,113 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:23:59,726 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 39072-target
om2_1        | 2022-08-22 01:24:03,671 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53468
om2_1        | 2022-08-22 01:24:03,676 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:24:04,484 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:39072-target
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:24:08,436 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53486
om2_1        | 2022-08-22 01:24:08,441 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:24:13,266 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53502
om2_1        | 2022-08-22 01:24:13,274 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:24:17,713 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53510
om2_1        | 2022-08-22 01:24:17,716 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:24:22,499 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53550
om1_1        | 2022-08-22 01:27:19,717 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:27:23,200 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4194492066 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:27,519 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37394
om1_1        | 2022-08-22 01:27:27,541 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:27:32,720 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37412
om1_1        | 2022-08-22 01:27:32,743 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:27:40,382 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg9 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,398 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg6 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,420 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg8 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,449 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg3 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,462 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg4 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,473 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg5 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,488 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg7 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,492 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg1 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,518 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg0 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,548 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg2 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,597 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg16 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,666 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg11 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,679 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg19 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,759 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg17 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,782 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg20 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,791 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg10 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,792 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg12 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,801 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg15 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,825 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg13 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,832 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg18 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,836 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg14 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,908 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg24 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,920 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg23 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,924 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg25 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,941 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg22 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,956 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg28 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,958 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg29 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:40,962 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg27 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,008 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg21 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,040 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg30 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,053 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg26 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,055 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg31 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,074 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg32 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,188 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg35 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,194 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg33 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,204 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg38 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,227 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg36 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,245 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg39 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,246 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg37 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,253 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg41 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,259 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg40 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,262 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg34 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,270 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg42 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,315 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg44 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,338 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg45 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,363 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg46 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,366 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg51 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,405 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg48 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,407 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg50 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,411 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg49 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,446 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg52 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,462 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg47 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,468 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg43 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,481 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg53 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,544 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg60 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,546 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg61 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,576 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg55 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,602 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg58 of layout LEGACY in volume: s3v
recon_1      | 2022-08-22 01:18:43,075 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 89 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:44,039 [IPC Server handler 3 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-22 01:18:44,768 [IPC Server handler 67 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-22 01:18:45,008 [IPC Server handler 3 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3100efb7-0525-45d4-a0fd-e73779181107
recon_1      | 2022-08-22 01:18:45,009 [IPC Server handler 3 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1174539974108, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:18:45,009 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 3100efb7-0525-45d4-a0fd-e73779181107 to Node DB.
recon_1      | 2022-08-22 01:18:45,086 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 90 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:45,088 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 91 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:45,091 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 92 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:46,351 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=23fafdf1-808a-47f3-a6c2-33e77642bffd. Trying to get from SCM.
recon_1      | 2022-08-22 01:18:46,502 [IPC Server handler 17 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-22 01:18:46,745 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 23fafdf1-808a-47f3-a6c2-33e77642bffd, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:61e48a95-a5d7-43eb-addf-1603d4744f3f, CreationTimestamp2022-08-22T01:18:43.865Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-08-22 01:18:46,945 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 23fafdf1-808a-47f3-a6c2-33e77642bffd, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:61e48a95-a5d7-43eb-addf-1603d4744f3f, CreationTimestamp2022-08-22T01:18:43.865Z[UTC]].
recon_1      | 2022-08-22 01:18:46,972 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=23fafdf1-808a-47f3-a6c2-33e77642bffd reported by 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171297874022, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:18:46,976 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 23fafdf1-808a-47f3-a6c2-33e77642bffd, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:61e48a95-a5d7-43eb-addf-1603d4744f3f, CreationTimestamp2022-08-22T01:18:43.865Z[UTC]] moved to OPEN state
recon_1      | 2022-08-22 01:18:47,092 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 93 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:47,094 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 94 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:47,095 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 95 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:48,308 [IPC Server handler 6 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-22 01:18:49,096 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 96 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:49,098 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 97 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:49,099 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 98 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:49,997 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=6bb8ab60-60a4-4383-9c3b-7719fba37020. Trying to get from SCM.
recon_1      | 2022-08-22 01:18:50,015 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 6bb8ab60-60a4-4383-9c3b-7719fba37020, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.397Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-08-22 01:18:50,016 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6bb8ab60-60a4-4383-9c3b-7719fba37020, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.397Z[UTC]].
recon_1      | 2022-08-22 01:18:50,016 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=6bb8ab60-60a4-4383-9c3b-7719fba37020 reported by 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1174539974108, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:18:50,017 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6bb8ab60-60a4-4383-9c3b-7719fba37020, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.397Z[UTC]] moved to OPEN state
recon_1      | 2022-08-22 01:18:50,867 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=fcac9307-f9c6-4fe2-a014-be98e62d2a2a. Trying to get from SCM.
recon_1      | 2022-08-22 01:18:50,879 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-08-22 01:18:50,880 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]].
recon_1      | 2022-08-22 01:18:50,880 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=fcac9307-f9c6-4fe2-a014-be98e62d2a2a reported by 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1174539974108, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:18:51,101 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 99 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:51,103 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 100 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:51,104 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 101 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:53,105 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 102 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:53,106 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 103 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:53,107 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 104 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:55,108 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 105 failover attempts. Trying to failover immediately.
om1_1        | 2022-08-22 01:27:41,603 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg63 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,619 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg56 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,621 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg54 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,624 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg62 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,646 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg57 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,647 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg59 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,659 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg65 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,672 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg64 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,721 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg66 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,765 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg67 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,767 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg68 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,822 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg72 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,824 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg71 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,855 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg76 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,857 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg74 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,866 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg70 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,868 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg78 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,885 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg69 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,893 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg73 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,899 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg75 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,910 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg77 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:41,973 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg82 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,020 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg79 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,054 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg84 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,083 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg81 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,109 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg80 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,117 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg88 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,124 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg85 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,130 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg83 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,137 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg87 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,139 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg86 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:24:22,503 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:24:26,865 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53568
om2_1        | 2022-08-22 01:24:26,873 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:24:27,498 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 39072-target
om2_1        | 2022-08-22 01:24:31,399 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53584
om2_1        | 2022-08-22 01:24:31,405 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:24:32,031 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 39072-target
om2_1        | 2022-08-22 01:24:35,764 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53592
om2_1        | 2022-08-22 01:24:35,772 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:24:36,370 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 39072-target
om2_1        | 2022-08-22 01:24:39,944 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53608
om2_1        | 2022-08-22 01:24:39,948 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:24:44,381 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53624
om2_1        | 2022-08-22 01:24:44,385 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:24:45,225 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 39072-target
om2_1        | 2022-08-22 01:24:49,302 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53664
om2_1        | 2022-08-22 01:24:49,316 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:24:56,795 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53684
om2_1        | 2022-08-22 01:24:56,804 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:25:03,411 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53714
om2_1        | 2022-08-22 01:25:03,418 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:25:07,863 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53732
om2_1        | 2022-08-22 01:25:07,869 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:25:12,438 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53740
om2_1        | 2022-08-22 01:25:12,440 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:25:17,084 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53756
om2_1        | 2022-08-22 01:25:17,088 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:25:17,712 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 39072-target
om2_1        | 2022-08-22 01:25:22,066 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53796
om2_1        | 2022-08-22 01:25:22,074 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:25:22,787 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:39072-target
om2_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:25:26,677 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:53806
om2_1        | 2022-08-22 01:25:26,689 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:26:06,150 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54120
om2_1        | 2022-08-22 01:26:06,157 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:26:11,706 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:40477
om2_1        | 2022-08-22 01:26:11,707 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:26:12,263 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6690263611 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:26:16,006 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54152
om2_1        | 2022-08-22 01:26:16,009 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:26:19,512 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8018651496 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:26:30,674 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54224
om2_1        | 2022-08-22 01:26:30,680 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:26:34,034 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5317785265 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:26:34,621 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-pkkavrhdbq of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:26:39,062 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-emlxgnryiv of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:26:46,527 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54276
om2_1        | 2022-08-22 01:26:46,536 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:26:50,055 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7025562811 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:26:50,707 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9097171453 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:26:51,437 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7237953091 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:26:52,114 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-7237953091 in volume:s3v
om2_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:26:53,746 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6286737048 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:26:57,737 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54330
om2_1        | 2022-08-22 01:26:57,742 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:27:02,345 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54354
om2_1        | 2022-08-22 01:27:02,359 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:27:05,795 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6031205182 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:06,436 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4059376425 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:07,707 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-4695970515 in volume:s3v
om2_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2498)
om2_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2468)
om2_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om2_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 2022-08-22 01:27:42,176 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg91 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,244 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg95 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,261 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg92 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,268 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg90 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,277 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg98 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,280 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg93 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,293 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg94 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,295 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg89 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,297 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg96 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,301 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg97 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:42,311 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg99 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:27:46,690 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37466
om1_1        | 2022-08-22 01:27:46,705 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:27:50,198 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5441601222 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:28:11,359 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-5441601222/ozone-test-7042174042/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om1_1        | 2022-08-22 01:28:11,380 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7042174042/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om1_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-7042174042/multipartKey2. Entity too small.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:28:12,720 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1        | partName: "etag1"
om1_1        | , partNumber: 2
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-08-22 01:28:12,734 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:28:13,349 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1        | partName: "etag1"
om1_1        | , partNumber: 1
om1_1        | partName: "etag2"
om1_1        | ]
om1_1        | 2022-08-22 01:28:13,350 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2022-08-22 01:16:37,286 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1        | 2022-08-22 01:16:37,286 [main] INFO s3.Gateway: S3Gateway login successful.
s3g_1        | 2022-08-22 01:16:37,506 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2022-08-22 01:16:37,506 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2022-08-22 01:16:37,507 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2022-08-22 01:16:37,680 [main] INFO util.log: Logging initialized @4856ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2022-08-22 01:16:38,183 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2022-08-22 01:16:38,214 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2022-08-22 01:16:38,221 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2022-08-22 01:16:38,224 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2022-08-22 01:16:38,225 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2022-08-22 01:16:38,234 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2022-08-22 01:16:38,473 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.2.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.33.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.33.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.33.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.33.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.33.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.33.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.33.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
s3g_1        | STARTUP_MSG:   java = 11.0.14.1
s3g_1        | ************************************************************/
s3g_1        | 2022-08-22 01:16:38,490 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2022-08-22 01:16:38,534 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2022-08-22 01:16:38,773 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 2022-08-22 01:16:39,253 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 2022-08-22 01:16:39,253 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1        | 2022-08-22 01:16:39,414 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2022-08-22 01:16:39,421 [main] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
s3g_1        | 2022-08-22 01:16:39,559 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2022-08-22 01:16:39,571 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2022-08-22 01:16:39,574 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1        | 2022-08-22 01:16:39,652 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2022-08-22 01:16:39,694 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1cb3ec38{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2022-08-22 01:16:39,695 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7859e786{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode2_1  | 2022-08-22 01:27:36,051 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=939,entriesCount=1,lastEntry=(t:1, i:25)
datanode2_1  | 2022-08-22 01:27:36,059 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=940,entriesCount=1,lastEntry=(t:1, i:26)
datanode2_1  | 2022-08-22 01:27:36,303 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=941,entriesCount=1,lastEntry=(t:1, i:27)
datanode2_1  | 2022-08-22 01:27:36,303 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=942,entriesCount=1,lastEntry=(t:1, i:28)
datanode2_1  | 2022-08-22 01:27:36,369 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=948,entriesCount=1,lastEntry=(t:1, i:29)
datanode2_1  | 2022-08-22 01:27:36,558 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=963,entriesCount=1,lastEntry=(t:1, i:30)
datanode2_1  | 2022-08-22 01:27:36,577 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=964,entriesCount=1,lastEntry=(t:1, i:31)
datanode2_1  | 2022-08-22 01:27:36,614 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=968,entriesCount=1,lastEntry=(t:1, i:32)
datanode2_1  | 2022-08-22 01:27:36,676 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=975,entriesCount=1,lastEntry=(t:1, i:33)
datanode2_1  | 2022-08-22 01:27:36,693 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=977,entriesCount=1,lastEntry=(t:1, i:34)
datanode2_1  | 2022-08-22 01:28:51,860 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1107,entriesCount=1,lastEntry=(t:1, i:35)
datanode2_1  | 2022-08-22 01:28:51,952 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1108,entriesCount=1,lastEntry=(t:1, i:36)
datanode2_1  | 2022-08-22 01:28:51,966 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1109,entriesCount=1,lastEntry=(t:1, i:37)
datanode2_1  | 2022-08-22 01:28:52,080 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1110,entriesCount=1,lastEntry=(t:1, i:38)
datanode2_1  | 2022-08-22 01:28:52,117 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1114,entriesCount=1,lastEntry=(t:1, i:39)
datanode2_1  | 2022-08-22 01:28:52,140 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1116,entriesCount=1,lastEntry=(t:1, i:40)
datanode2_1  | 2022-08-22 01:28:59,163 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1217,entriesCount=1,lastEntry=(t:1, i:41)
datanode2_1  | 2022-08-22 01:28:59,164 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1218,entriesCount=1,lastEntry=(t:1, i:42)
datanode2_1  | 2022-08-22 01:28:59,164 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1219,entriesCount=1,lastEntry=(t:1, i:43)
datanode2_1  | 2022-08-22 01:28:59,336 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1220,entriesCount=1,lastEntry=(t:1, i:44)
datanode2_1  | 2022-08-22 01:28:59,361 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1223,entriesCount=1,lastEntry=(t:1, i:45)
datanode2_1  | 2022-08-22 01:28:59,367 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1224,entriesCount=1,lastEntry=(t:1, i:46)
datanode2_1  | 2022-08-22 01:29:02,242 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1355,entriesCount=1,lastEntry=(t:1, i:47)
datanode2_1  | 2022-08-22 01:29:02,281 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1356,entriesCount=1,lastEntry=(t:1, i:48)
datanode2_1  | 2022-08-22 01:29:02,296 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1357,entriesCount=1,lastEntry=(t:1, i:49)
datanode2_1  | 2022-08-22 01:29:02,525 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1358,entriesCount=1,lastEntry=(t:1, i:50)
datanode2_1  | 2022-08-22 01:29:02,538 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1360,entriesCount=1,lastEntry=(t:1, i:51)
datanode2_1  | 2022-08-22 01:29:02,556 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1362,entriesCount=1,lastEntry=(t:1, i:52)
datanode2_1  | 2022-08-22 01:29:03,969 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1426,entriesCount=1,lastEntry=(t:1, i:53)
datanode2_1  | 2022-08-22 01:29:03,983 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1427,entriesCount=1,lastEntry=(t:1, i:54)
datanode2_1  | 2022-08-22 01:29:03,989 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1428,entriesCount=1,lastEntry=(t:1, i:55)
datanode2_1  | 2022-08-22 01:29:04,001 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1430,entriesCount=1,lastEntry=(t:1, i:56)
datanode2_1  | 2022-08-22 01:29:09,534 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1596,entriesCount=1,lastEntry=(t:1, i:57)
datanode2_1  | 2022-08-22 01:29:09,548 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1597,entriesCount=1,lastEntry=(t:1, i:58)
datanode2_1  | 2022-08-22 01:29:09,548 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1598,entriesCount=1,lastEntry=(t:1, i:59)
datanode2_1  | 2022-08-22 01:29:09,567 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1600,entriesCount=1,lastEntry=(t:1, i:60)
datanode2_1  | 2022-08-22 01:29:15,517 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1712,entriesCount=1,lastEntry=(t:1, i:61)
datanode2_1  | 2022-08-22 01:29:15,522 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1713,entriesCount=1,lastEntry=(t:1, i:62)
datanode2_1  | 2022-08-22 01:29:15,528 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1714,entriesCount=1,lastEntry=(t:1, i:63)
datanode2_1  | 2022-08-22 01:29:15,730 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1716,entriesCount=1,lastEntry=(t:1, i:64)
datanode2_1  | 2022-08-22 01:29:15,748 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1717,entriesCount=1,lastEntry=(t:1, i:65)
datanode2_1  | 2022-08-22 01:29:15,760 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1719,entriesCount=1,lastEntry=(t:1, i:66)
datanode2_1  | 2022-08-22 01:29:19,192 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1969,entriesCount=1,lastEntry=(t:1, i:67)
datanode2_1  | 2022-08-22 01:29:19,221 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1970,entriesCount=1,lastEntry=(t:1, i:68)
datanode2_1  | 2022-08-22 01:29:19,221 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1971,entriesCount=1,lastEntry=(t:1, i:69)
datanode2_1  | 2022-08-22 01:29:19,237 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1973,entriesCount=1,lastEntry=(t:1, i:70)
datanode2_1  | 2022-08-22 01:29:34,166 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2128,entriesCount=1,lastEntry=(t:1, i:71)
datanode2_1  | 2022-08-22 01:29:34,294 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2129,entriesCount=1,lastEntry=(t:1, i:72)
datanode2_1  | 2022-08-22 01:29:34,429 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2130,entriesCount=1,lastEntry=(t:1, i:73)
datanode2_1  | 2022-08-22 01:29:34,552 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2131,entriesCount=1,lastEntry=(t:1, i:74)
datanode2_1  | 2022-08-22 01:29:34,657 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2136,entriesCount=1,lastEntry=(t:1, i:75)
datanode2_1  | 2022-08-22 01:29:34,714 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2142,entriesCount=1,lastEntry=(t:1, i:76)
datanode2_1  | 2022-08-22 01:29:34,790 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2150,entriesCount=1,lastEntry=(t:1, i:77)
datanode2_1  | 2022-08-22 01:29:34,811 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2153,entriesCount=1,lastEntry=(t:1, i:78)
datanode2_1  | 2022-08-22 01:29:34,819 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2154,entriesCount=1,lastEntry=(t:1, i:79)
datanode2_1  | 2022-08-22 01:29:34,846 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2159,entriesCount=1,lastEntry=(t:1, i:80)
datanode2_1  | 2022-08-22 01:29:34,854 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2160,entriesCount=1,lastEntry=(t:1, i:81)
datanode2_1  | 2022-08-22 01:29:34,865 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2162,entriesCount=1,lastEntry=(t:1, i:82)
datanode2_1  | 2022-08-22 01:29:38,737 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2259,entriesCount=1,lastEntry=(t:1, i:83)
datanode2_1  | 2022-08-22 01:29:38,751 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2260,entriesCount=1,lastEntry=(t:1, i:84)
datanode2_1  | 2022-08-22 01:29:38,795 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2261,entriesCount=1,lastEntry=(t:1, i:85)
datanode2_1  | 2022-08-22 01:29:38,874 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2262,entriesCount=1,lastEntry=(t:1, i:86)
datanode2_1  | 2022-08-22 01:29:38,913 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2265,entriesCount=1,lastEntry=(t:1, i:87)
datanode2_1  | 2022-08-22 01:29:38,915 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2266,entriesCount=1,lastEntry=(t:1, i:88)
datanode2_1  | 2022-08-22 01:29:42,226 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2453,entriesCount=1,lastEntry=(t:1, i:89)
datanode2_1  | 2022-08-22 01:29:42,312 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2454,entriesCount=1,lastEntry=(t:1, i:90)
datanode2_1  | 2022-08-22 01:29:42,336 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2455,entriesCount=1,lastEntry=(t:1, i:91)
datanode2_1  | 2022-08-22 01:29:42,341 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2456,entriesCount=1,lastEntry=(t:1, i:92)
datanode2_1  | 2022-08-22 01:29:42,364 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2459,entriesCount=1,lastEntry=(t:1, i:93)
datanode2_1  | 2022-08-22 01:29:42,372 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2460,entriesCount=1,lastEntry=(t:1, i:94)
datanode2_1  | 2022-08-22 01:29:45,683 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2554,entriesCount=1,lastEntry=(t:1, i:95)
datanode2_1  | 2022-08-22 01:29:45,833 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2556,entriesCount=1,lastEntry=(t:1, i:96)
datanode2_1  | 2022-08-22 01:29:45,882 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2557,entriesCount=1,lastEntry=(t:1, i:97)
datanode2_1  | 2022-08-22 01:29:45,891 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2558,entriesCount=1,lastEntry=(t:1, i:98)
datanode2_1  | 2022-08-22 01:29:45,923 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2562,entriesCount=1,lastEntry=(t:1, i:99)
datanode2_1  | 2022-08-22 01:29:46,071 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2574,entriesCount=1,lastEntry=(t:1, i:100)
datanode2_1  | 2022-08-22 01:29:46,108 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2578,entriesCount=1,lastEntry=(t:1, i:101)
datanode2_1  | 2022-08-22 01:29:46,129 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2581,entriesCount=1,lastEntry=(t:1, i:102)
datanode2_1  | 2022-08-22 01:29:51,485 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2810,entriesCount=1,lastEntry=(t:1, i:103)
datanode2_1  | 2022-08-22 01:29:51,486 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2811,entriesCount=1,lastEntry=(t:1, i:104)
datanode2_1  | 2022-08-22 01:29:51,501 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2812,entriesCount=1,lastEntry=(t:1, i:105)
datanode2_1  | 2022-08-22 01:29:51,501 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2813,entriesCount=1,lastEntry=(t:1, i:106)
datanode2_1  | 2022-08-22 01:29:55,889 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3001,entriesCount=1,lastEntry=(t:1, i:107)
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2022-08-22 01:16:45,592 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Aug 22, 2022 1:16:48 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2022-08-22 01:16:48,041 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6a902015{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_3_0-SNAPSHOT_jar-_-any-13557249339856961538/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.3.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2022-08-22 01:16:48,052 [main] INFO server.AbstractConnector: Started ServerConnector@307765b4{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2022-08-22 01:16:48,052 [main] INFO server.Server: Started @15228ms
s3g_1        | 2022-08-22 01:16:48,055 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2022-08-22 01:16:48,055 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2022-08-22 01:16:48,058 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1        | 2022-08-22 01:26:10,379 [qtp1122233828-22] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
s3g_1        | 2022-08-22 01:26:10,425 [qtp1122233828-22] INFO audit.AuditLogger: Refresh DebugCmdSet for S3GAudit to [].
s3g_1        | 2022-08-22 01:26:10,437 [qtp1122233828-22] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
s3g_1        | 2022-08-22 01:26:11,710 [qtp1122233828-22] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
s3g_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
s3g_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
s3g_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
s3g_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
s3g_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
s3g_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
s3g_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | , while invoking $Proxy119.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
s3g_1        | 2022-08-22 01:26:12,216 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6690263611, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:26:19,484 [qtp1122233828-18] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8018651496, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:26:20,419 [qtp1122233828-24] WARN impl.MetricsSystemImpl: S3Gateway metrics system already initialized!
s3g_1        | 2022-08-22 01:26:20,751 [qtp1122233828-24] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1        | 2022-08-22 01:26:34,007 [qtp1122233828-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5317785265, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:26:34,592 [qtp1122233828-24] INFO rpc.RpcClient: Creating Bucket: s3v/ozone-test-pkkavrhdbq, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:26:39,050 [qtp1122233828-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-emlxgnryiv, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:26:50,026 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-7025562811, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:26:50,689 [qtp1122233828-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-9097171453, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:26:51,411 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-7237953091, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:26:52,095 [qtp1122233828-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-7237953091, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:26:53,729 [qtp1122233828-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6286737048, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:05,774 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-6031205182, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:06,420 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4059376425, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:14,755 [qtp1122233828-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5013695993, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:23,179 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-4194492066, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | Aug 22, 2022 1:27:29 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1        | WARNING: The following warnings have been detected: WARNING: Unknown HK2 failure detected:
s3g_1        | MultiException stack 1 of 1
s3g_1        | javax.ws.rs.WebApplicationException: The authorization header you provided is invalid.
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.wrapOS3Exception(OzoneClientProducer.java:141)
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:102)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:88)
s3g_1        | 	at org.jboss.weld.injection.StaticMethodInjectionPoint.invoke(StaticMethodInjectionPoint.java:78)
s3g_1        | 	at org.jboss.weld.injection.producer.ProducerMethodProducer.produce(ProducerMethodProducer.java:100)
s3g_1        | 	at org.jboss.weld.injection.producer.AbstractMemberProducer.produce(AbstractMemberProducer.java:161)
s3g_1        | 	at org.jboss.weld.bean.AbstractProducerBean.create(AbstractProducerBean.java:180)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:27:11,436 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54390
recon_1      | 2022-08-22 01:18:55,111 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 106 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:55,112 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 107 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:55,211 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39810
recon_1      | 2022-08-22 01:18:55,243 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:18:55,244 [IPC Server handler 6 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2022-08-22 01:18:55,245 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=fcac9307-f9c6-4fe2-a014-be98e62d2a2a reported by 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171021466938, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:18:55,777 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=fcac9307-f9c6-4fe2-a014-be98e62d2a2a reported by 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1174539974108, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:18:57,114 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 108 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:57,116 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 109 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:57,117 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 110 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:57,383 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=fcac9307-f9c6-4fe2-a014-be98e62d2a2a reported by 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1174539974108, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:18:58,571 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=fcac9307-f9c6-4fe2-a014-be98e62d2a2a reported by 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171297874022, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
om2_1        | 2022-08-22 01:27:11,446 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:27:14,790 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5013695993 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:19,743 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54436
om2_1        | 2022-08-22 01:27:19,748 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:27:23,208 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4194492066 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:27,581 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54458
om2_1        | 2022-08-22 01:27:27,585 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:27:32,770 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54476
om2_1        | 2022-08-22 01:27:32,772 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:27:40,383 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg9 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,402 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg6 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,415 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg8 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,444 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg3 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,446 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg4 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,476 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg5 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,483 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg7 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,484 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg1 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,529 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg0 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,550 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg2 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,593 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg16 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,662 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg11 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,680 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg19 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,745 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg17 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,754 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg20 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,774 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg10 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,783 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg12 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,796 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg15 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,798 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg13 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,803 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg18 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,810 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg14 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,902 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg24 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,920 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg23 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,925 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg25 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,926 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg22 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,928 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg28 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,932 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg29 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,934 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg27 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,974 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg21 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,976 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg30 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,977 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg26 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:40,992 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg31 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,038 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg32 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,163 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg35 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,182 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg33 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,183 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg38 of layout LEGACY in volume: s3v
datanode2_1  | 2022-08-22 01:29:56,069 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3003,entriesCount=1,lastEntry=(t:1, i:108)
datanode2_1  | 2022-08-22 01:29:56,158 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3014,entriesCount=1,lastEntry=(t:1, i:109)
datanode2_1  | 2022-08-22 01:29:56,174 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3016,entriesCount=1,lastEntry=(t:1, i:110)
datanode2_1  | 2022-08-22 01:29:56,183 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3017,entriesCount=1,lastEntry=(t:1, i:111)
datanode2_1  | 2022-08-22 01:29:56,238 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3023,entriesCount=1,lastEntry=(t:1, i:112)
datanode2_1  | 2022-08-22 01:29:56,258 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3025,entriesCount=1,lastEntry=(t:1, i:113)
datanode2_1  | 2022-08-22 01:30:04,681 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3252,entriesCount=1,lastEntry=(t:1, i:114)
datanode2_1  | 2022-08-22 01:30:04,690 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3253,entriesCount=1,lastEntry=(t:1, i:115)
datanode2_1  | 2022-08-22 01:30:04,706 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3255,entriesCount=1,lastEntry=(t:1, i:116)
datanode2_1  | 2022-08-22 01:30:04,717 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3256,entriesCount=1,lastEntry=(t:1, i:117)
datanode2_1  | 2022-08-22 01:30:20,965 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3399,entriesCount=1,lastEntry=(t:1, i:118)
datanode2_1  | 2022-08-22 01:30:20,965 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3400,entriesCount=1,lastEntry=(t:1, i:119)
datanode2_1  | 2022-08-22 01:30:20,973 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3401,entriesCount=1,lastEntry=(t:1, i:120)
datanode2_1  | 2022-08-22 01:30:20,975 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3402,entriesCount=1,lastEntry=(t:1, i:121)
datanode2_1  | 2022-08-22 01:30:22,446 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3418,entriesCount=1,lastEntry=(t:1, i:122)
datanode2_1  | 2022-08-22 01:30:22,448 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3419,entriesCount=1,lastEntry=(t:1, i:123)
datanode2_1  | 2022-08-22 01:30:22,455 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3420,entriesCount=1,lastEntry=(t:1, i:124)
datanode2_1  | 2022-08-22 01:30:22,476 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3422,entriesCount=1,lastEntry=(t:1, i:125)
datanode2_1  | 2022-08-22 01:30:34,603 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3542,entriesCount=1,lastEntry=(t:1, i:126)
datanode2_1  | 2022-08-22 01:30:34,614 [java.util.concurrent.ThreadPoolExecutor$Worker@5564db7c[State = -1, empty queue]] WARN server.GrpcLogAppender: 3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A->61e48a95-a5d7-43eb-addf-1603d4744f3f-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3543,entriesCount=1,lastEntry=(t:1, i:127)
datanode2_1  | 2022-08-22 01:32:34,688 [null-request--thread7] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-E2EA2A181E60->3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A, cid=165, seq=0, Watch-ALL_COMMITTED(128), Message:<EMPTY>, reply=RaftClientReply:client-E2EA2A181E60->3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A, cid=165, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 165 and log index 128 is not yet replicated to ALL_COMMITTED, logIndex=128, commits[3100efb7-0525-45d4-a0fd-e73779181107:c136, 61e48a95-a5d7-43eb-addf-1603d4744f3f:c127, 3c60044e-b181-445f-8fa2-782a9e9eb45c:c136]
datanode2_1  | 2022-08-22 01:33:40,687 [null-request--thread7] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-F21596E3032F->3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A, cid=172, seq=0, Watch-ALL_COMMITTED(132), Message:<EMPTY>, reply=RaftClientReply:client-F21596E3032F->3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A, cid=172, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 172 and log index 132 is not yet replicated to ALL_COMMITTED, logIndex=132, commits[3100efb7-0525-45d4-a0fd-e73779181107:c140, 61e48a95-a5d7-43eb-addf-1603d4744f3f:c127, 3c60044e-b181-445f-8fa2-782a9e9eb45c:c140]
datanode2_1  | 2022-08-22 01:35:16,686 [null-request--thread7] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-10A3EB62A174->3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A, cid=184, seq=0, Watch-ALL_COMMITTED(135), Message:<EMPTY>, reply=RaftClientReply:client-10A3EB62A174->3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A, cid=184, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 184 and log index 135 is not yet replicated to ALL_COMMITTED, logIndex=135, commits[3100efb7-0525-45d4-a0fd-e73779181107:c144, 61e48a95-a5d7-43eb-addf-1603d4744f3f:c127, 3c60044e-b181-445f-8fa2-782a9e9eb45c:c144]
datanode2_1  | 2022-08-22 01:36:16,687 [null-request--thread7] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-656EC7F7C978->3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A, cid=189, seq=0, Watch-ALL_COMMITTED(139), Message:<EMPTY>, reply=RaftClientReply:client-656EC7F7C978->3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A, cid=189, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 189 and log index 139 is not yet replicated to ALL_COMMITTED, logIndex=139, commits[3100efb7-0525-45d4-a0fd-e73779181107:c148, 61e48a95-a5d7-43eb-addf-1603d4744f3f:c127, 3c60044e-b181-445f-8fa2-782a9e9eb45c:c148]
datanode2_1  | 2022-08-22 01:37:18,697 [null-request--thread7] INFO server.GrpcClientProtocolService: Failed RaftClientRequest:client-B1B8634771F1->3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A, cid=197, seq=0, Watch-ALL_COMMITTED(142), Message:<EMPTY>, reply=RaftClientReply:client-B1B8634771F1->3100efb7-0525-45d4-a0fd-e73779181107@group-BE98E62D2A2A, cid=197, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 197 and log index 142 is not yet replicated to ALL_COMMITTED, logIndex=142, commits[3100efb7-0525-45d4-a0fd-e73779181107:c152, 61e48a95-a5d7-43eb-addf-1603d4744f3f:c127, 3c60044e-b181-445f-8fa2-782a9e9eb45c:c152]
om2_1        | 2022-08-22 01:27:41,214 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg36 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,216 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg39 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,217 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg37 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,222 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg41 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,230 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg40 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,236 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg34 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,241 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg42 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,307 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg44 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,353 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg45 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,365 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg46 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,366 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg51 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,392 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg48 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,399 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg50 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,401 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg49 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,402 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg52 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,442 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg47 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,446 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg43 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,458 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg53 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,550 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg60 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,552 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg61 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,587 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg55 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,610 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg58 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,615 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg63 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,630 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg56 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,635 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg54 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,636 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg62 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,652 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg57 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,657 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg59 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,667 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg65 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,714 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg64 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,732 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg66 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,771 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg67 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,781 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg68 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,841 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg72 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,843 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg71 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,874 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg76 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,885 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg74 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,906 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg70 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,915 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg78 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,921 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg69 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,956 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg73 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,959 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg75 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,974 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg77 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:41,988 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg82 of layout LEGACY in volume: s3v
recon_1      | 2022-08-22 01:18:58,571 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]] moved to OPEN state
recon_1      | 2022-08-22 01:18:59,008 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=85ae3250-a1a7-4fa0-96fb-c7ffd18c9838. Trying to get from SCM.
recon_1      | 2022-08-22 01:18:59,028 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 85ae3250-a1a7-4fa0-96fb-c7ffd18c9838, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:46.948Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-08-22 01:18:59,029 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 85ae3250-a1a7-4fa0-96fb-c7ffd18c9838, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:46.948Z[UTC]].
recon_1      | 2022-08-22 01:18:59,030 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 reported by 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1174539974108, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:18:59,118 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 111 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:59,119 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 112 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:18:59,120 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 113 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:18:59,603 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 reported by 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171297874022, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:19:00,099 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 reported by 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171021466938, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:19:01,122 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 114 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:01,123 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 115 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:01,123 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 116 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:19:03,125 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 117 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:03,126 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 118 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:03,127 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 119 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:19:05,128 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 120 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:05,129 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 121 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:05,130 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 122 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:19:07,131 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 123 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:13,209 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 124 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:14,018 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 125 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:19:14,989 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39878
recon_1      | 2022-08-22 01:19:15,013 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:19:15,014 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 reported by 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171021466938, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:19:15,015 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=c5d0a770-5809-48a9-a307-ee9a9d2c444e. Trying to get from SCM.
recon_1      | 2022-08-22 01:19:15,046 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: c5d0a770-5809-48a9-a307-ee9a9d2c444e, Nodes: 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:3c60044e-b181-445f-8fa2-782a9e9eb45c, CreationTimestamp2022-08-22T01:18:42.911Z[UTC]] to Recon pipeline metadata.
recon_1      | 2022-08-22 01:19:15,047 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: c5d0a770-5809-48a9-a307-ee9a9d2c444e, Nodes: 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:3c60044e-b181-445f-8fa2-782a9e9eb45c, CreationTimestamp2022-08-22T01:18:42.911Z[UTC]].
recon_1      | 2022-08-22 01:19:16,962 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1        | 2022-08-22 01:28:21,450 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3-2d359484-8cfb-483b-aa3b-b8082765a51b-108863926568681508-1
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:28:22,080 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om1_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3-2d359484-8cfb-483b-aa3b-b8082765a51b-108863926568681508-2
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:28:22,687 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3
om1_1        | 2022-08-22 01:28:22,690 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om1_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3 because parts are in Invalid order.
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:28:26,230 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-2706775452/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-5441601222
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-5441601222key: ozone-test-2706775452/multipartKey5
om1_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:28:26,877 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-5441601222, Key:ozone-test-7590568313/multipartKey. 
om1_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:759)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:283)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 2022-08-22 01:27:42,008 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg79 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,029 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg84 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,073 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg81 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,086 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg80 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,122 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg88 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,134 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg85 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,137 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg83 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,154 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg87 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,156 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg86 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,180 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg91 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,241 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg95 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,271 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg92 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,285 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg90 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,286 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg98 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,287 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg93 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,292 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg94 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,295 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg89 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,296 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg96 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,301 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg97 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:42,309 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg99 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:27:46,742 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54530
om2_1        | 2022-08-22 01:27:46,745 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:27:50,196 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5441601222 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:28:11,368 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-5441601222/ozone-test-7042174042/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1        | 2022-08-22 01:28:11,373 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7042174042/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om2_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-7042174042/multipartKey2. Entity too small.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 2022-08-22 01:19:22,983 [grpc-default-executor-1] INFO impl.VoteContext: om3@group-562213E44849-CANDIDATE: reject ELECTION from om2: already has voted for om3 at current term 2
om3_1        | 2022-08-22 01:19:22,984 [grpc-default-executor-1] INFO server.RaftServer$Division: om3@group-562213E44849 replies to ELECTION vote request: om2<-om3#0:FAIL-t2. Peer's state: om3@group-562213E44849:t2, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1, conf=-1: [om1|rpc:om1:9872|priority:0, om3|rpc:om3:9872|priority:0, om2|rpc:om2:9872|priority:0], old=null
om3_1        | 2022-08-22 01:19:23,049 [om3@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection2: ELECTION PASSED received 2 response(s) and 0 exception(s):
om3_1        | 2022-08-22 01:19:23,050 [om3@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 0: om3<-om1#0:OK-t2
om3_1        | 2022-08-22 01:19:23,050 [om3@group-562213E44849-LeaderElection2] INFO impl.LeaderElection:   Response 1: om3<-om2#0:FAIL-t2
om3_1        | 2022-08-22 01:19:23,050 [om3@group-562213E44849-LeaderElection2] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection2 ELECTION round 0: result PASSED
om3_1        | 2022-08-22 01:19:23,050 [om3@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection2
om3_1        | 2022-08-22 01:19:23,050 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om3@group-562213E44849: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
om3_1        | 2022-08-22 01:19:23,050 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om3@group-562213E44849: change Leader from null to om3 at term 2 for becomeLeader, leader elected after 19477ms
om3_1        | 2022-08-22 01:19:23,063 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om3_1        | 2022-08-22 01:19:23,075 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om3_1        | 2022-08-22 01:19:23,076 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om3_1        | 2022-08-22 01:19:23,084 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om3_1        | 2022-08-22 01:19:23,084 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om3_1        | 2022-08-22 01:19:23,084 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om3_1        | 2022-08-22 01:19:23,099 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om3_1        | 2022-08-22 01:19:23,101 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om3_1        | 2022-08-22 01:19:23,117 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om3_1        | 2022-08-22 01:19:23,118 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-08-22 01:19:23,118 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om3_1        | 2022-08-22 01:19:23,121 [om3@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om3_1        | 2022-08-22 01:19:23,122 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2022-08-22 01:19:23,122 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2022-08-22 01:19:23,124 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om3_1        | 2022-08-22 01:19:23,124 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1        | 2022-08-22 01:19:23,125 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om3_1        | 2022-08-22 01:19:23,125 [om3@group-562213E44849-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om3_1        | 2022-08-22 01:19:23,126 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1        | 2022-08-22 01:19:23,126 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1        | 2022-08-22 01:19:23,130 [om3@group-562213E44849-LeaderElection2] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderStateImpl
om3_1        | 2022-08-22 01:19:23,150 [om3@group-562213E44849-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1        | 2022-08-22 01:19:23,178 [om3@group-562213E44849-LeaderElection2] INFO server.RaftServer$Division: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|admin:|client:|dataStream:|priority:0, om3|rpc:om3:9872|admin:|client:|dataStream:|priority:0, om2|rpc:om2:9872|admin:|client:|dataStream:|priority:0], old=null
om3_1        | 2022-08-22 01:19:23,372 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1        | 2022-08-22 01:19:23,545 [om3@group-562213E44849-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om3_1        | [id: "om1"
om3_1        | address: "om1:9872"
om3_1        | , id: "om3"
om3_1        | address: "om3:9872"
om3_1        | , id: "om2"
om3_1        | address: "om2:9872"
om3_1        | ]
om3_1        | 2022-08-22 01:19:39,204 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59626
om3_1        | 2022-08-22 01:19:39,210 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:19:44,125 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59642
om3_1        | 2022-08-22 01:19:44,147 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:19:49,022 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59658
om3_1        | 2022-08-22 01:19:49,027 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:19:53,497 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59674
om3_1        | 2022-08-22 01:19:53,504 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getInjectableReference(BeanManagerImpl.java:885)
s3g_1        | 	at org.jboss.weld.injection.FieldInjectionPoint.inject(FieldInjectionPoint.java:92)
s3g_1        | 	at org.jboss.weld.util.Beans.injectBoundFields(Beans.java:358)
s3g_1        | 	at org.jboss.weld.util.Beans.injectFieldsAndInitializers(Beans.java:369)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector$1.proceed(ResourceInjector.java:70)
s3g_1        | 	at org.jboss.weld.injection.InjectionContextImpl.run(InjectionContextImpl.java:48)
s3g_1        | 	at org.jboss.weld.injection.producer.ResourceInjector.inject(ResourceInjector.java:72)
s3g_1        | 	at org.jboss.weld.injection.producer.BasicInjectionTarget.inject(BasicInjectionTarget.java:117)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiComponentProvider$InjectionManagerInjectedCdiTarget.inject(CdiComponentProvider.java:874)
s3g_1        | 	at org.jboss.weld.bean.ManagedBean.create(ManagedBean.java:159)
s3g_1        | 	at org.jboss.weld.context.unbound.DependentContextImpl.get(DependentContextImpl.java:70)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstanceStrategy$DefaultContextualInstanceStrategy.get(ContextualInstanceStrategy.java:100)
s3g_1        | 	at org.jboss.weld.bean.ContextualInstance.get(ContextualInstance.java:50)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:785)
s3g_1        | 	at org.jboss.weld.manager.BeanManagerImpl.getReference(BeanManagerImpl.java:808)
s3g_1        | 	at org.jboss.weld.util.ForwardingBeanManager.getReference(ForwardingBeanManager.java:61)
s3g_1        | 	at org.jboss.weld.bean.builtin.BeanManagerProxy.getReference(BeanManagerProxy.java:85)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.CdiUtil.getBeanReference(CdiUtil.java:127)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier$1.getInstance(AbstractCdiBeanSupplier.java:69)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.AbstractCdiBeanSupplier._provide(AbstractCdiBeanSupplier.java:103)
s3g_1        | 	at org.glassfish.jersey.ext.cdi1x.internal.RequestScopedCdiBeanSupplier.get(RequestScopedCdiBeanSupplier.java:46)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.InstanceSupplierFactoryBridge.provide(InstanceSupplierFactoryBridge.java:53)
s3g_1        | 	at org.jvnet.hk2.internal.FactoryCreator.create(FactoryCreator.java:129)
s3g_1        | 	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
s3g_1        | 	at org.jvnet.hk2.internal.PerLookupContext.findOrCreate(PerLookupContext.java:46)
s3g_1        | 	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
s3g_1        | 	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
s3g_1        | 	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
s3g_1        | 	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
s3g_1        | 	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
s3g_1        | 	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
s3g_1        | 	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:29:14,681 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37876
om1_1        | 2022-08-22 01:29:14,697 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:29:18,022 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8219884435 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:29:18,663 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-36340 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:29:30,383 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:37966
om1_1        | 2022-08-22 01:29:30,406 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:29:33,861 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8362820054 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:30:38,823 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-8362820054, Key:thereisnosuchfile.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:31:42,913 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-8362820054, Key:ozone-test-8204563195/deletetestapidir/key=value/.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:31:46,899 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-8362820054, Key:ozone-test-8204563195/deletetestapiprefix/key=value/file.
om1_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om1_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om1_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om1_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om1_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om1_1        | 2022-08-22 01:31:55,633 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38384
om1_1        | 2022-08-22 01:31:55,667 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:31:59,538 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1571071876 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:32:10,404 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:38434
om1_1        | 2022-08-22 01:32:10,427 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:32:15,264 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2080259004 of layout LEGACY in volume: s3v
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 126 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:16,974 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 127 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:16,993 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:28:12,724 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om2_1        | partName: "etag1"
om2_1        | , partNumber: 2
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-08-22 01:28:12,726 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:28:13,341 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1        | partName: "etag1"
om2_1        | , partNumber: 1
om2_1        | partName: "etag2"
om2_1        | ]
om2_1        | 2022-08-22 01:28:13,341 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3
om3_1        | 2022-08-22 01:19:57,994 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59690
om3_1        | 2022-08-22 01:19:58,001 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:19:58,808 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
om3_1        | 2022-08-22 01:19:59,146 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om3_1        | 2022-08-22 01:20:09,594 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59760
om3_1        | 2022-08-22 01:20:09,596 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:20:10,239 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59766
om3_1        | 2022-08-22 01:20:10,244 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:20:15,349 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59784
om3_1        | 2022-08-22 01:20:15,353 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:20:15,925 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59790
om3_1        | 2022-08-22 01:20:15,927 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:20:15,946 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombg0 of layout LEGACY in volume: vol1
om3_1        | 2022-08-22 01:20:21,170 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59806
om3_1        | 2022-08-22 01:20:21,176 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:20:25,940 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41589
om3_1        | 2022-08-22 01:20:25,949 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:20:29,493 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59828
om3_1        | 2022-08-22 01:20:29,496 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:20:35,179 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59868
om3_1        | 2022-08-22 01:20:35,181 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:20:35,754 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59874
om3_1        | 2022-08-22 01:20:35,758 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:20:35,771 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ombr0 of layout LEGACY in volume: vol1
om3_1        | 2022-08-22 01:20:40,341 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59890
om3_1        | 2022-08-22 01:20:40,344 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:20:45,462 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59906
om3_1        | 2022-08-22 01:20:45,466 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:21:01,405 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59952
om3_1        | 2022-08-22 01:21:01,409 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:21:02,138 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:39072-source for user:testuser
om3_1        | 2022-08-22 01:21:06,545 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:59994
om3_1        | 2022-08-22 01:21:06,551 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:21:07,076 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:39072-target for user:testuser
om3_1        | 2022-08-22 01:21:11,013 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60002
om3_1        | 2022-08-22 01:21:11,014 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:21:11,993 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 39072-source
om3_1        | 2022-08-22 01:21:15,903 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60020
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:139)
s3g_1        | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:126)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor.parseSignature(AWSSignatureProcessor.java:86)
s3g_1        | 	at org.apache.hadoop.ozone.s3.signature.AWSSignatureProcessor$Proxy$_$$_WeldClientProxy.parseSignature(Unknown Source)
s3g_1        | 	at org.apache.hadoop.ozone.s3.OzoneClientProducer.getSignature(OzoneClientProducer.java:81)
s3g_1        | 	... 114 more
s3g_1        | 
s3g_1        | 
s3g_1        | 2022-08-22 01:27:40,361 [qtp1122233828-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg9, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,361 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg6, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,365 [qtp1122233828-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg5, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,368 [qtp1122233828-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg3, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,370 [qtp1122233828-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg7, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,371 [qtp1122233828-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg4, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,372 [qtp1122233828-19] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg8, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:28:21,451 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3-2d359484-8cfb-483b-aa3b-b8082765a51b-108863926568681508-1
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:28:22,084 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om2_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3-2d359484-8cfb-483b-aa3b-b8082765a51b-108863926568681508-2
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:28:22,683 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3
om2_1        | 2022-08-22 01:28:22,686 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om2_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3 because parts are in Invalid order.
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:28:26,208 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-2706775452/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-5441601222
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-5441601222key: ozone-test-2706775452/multipartKey5
om2_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:28:26,869 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-5441601222, Key:ozone-test-7590568313/multipartKey. 
om2_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:759)
om1_1        | 2022-08-22 01:37:23,313 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39246
om1_1        | 2022-08-22 01:37:23,332 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:37:28,115 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2019065808 of layout LEGACY in volume: s3v
om1_1        | 2022-08-22 01:37:49,766 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:39360
om1_1        | 2022-08-22 01:37:49,800 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om1_1        | 2022-08-22 01:37:54,273 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0209209266 of layout LEGACY in volume: s3v
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 128 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:19:18,997 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 129 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:19,005 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 130 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:19,015 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om3_1        | 2022-08-22 01:21:15,911 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:21:23,161 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60062
om3_1        | 2022-08-22 01:21:23,168 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:21:23,795 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 39072-source
om3_1        | 2022-08-22 01:21:26,010 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42573
om3_1        | 2022-08-22 01:21:26,015 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:21:27,587 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60080
om3_1        | 2022-08-22 01:21:27,589 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:21:28,141 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 39072-target
om3_1        | 2022-08-22 01:21:32,341 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60096
om3_1        | 2022-08-22 01:21:32,347 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:21:32,881 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 39072-target
om3_1        | 2022-08-22 01:21:36,737 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60112
om3_1        | 2022-08-22 01:21:36,741 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:21:37,277 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 39072-target
om3_1        | 2022-08-22 01:21:41,182 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60120
om3_1        | 2022-08-22 01:21:41,188 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:21:45,486 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60136
om3_1        | 2022-08-22 01:21:45,497 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:21:50,005 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60176
om3_1        | 2022-08-22 01:21:50,009 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:21:53,956 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60184
om3_1        | 2022-08-22 01:21:53,960 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:21:58,297 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60200
om3_1        | 2022-08-22 01:21:58,301 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:22:02,992 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60226
om3_1        | 2022-08-22 01:22:03,005 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:22:03,624 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 39072-target
om3_1        | 2022-08-22 01:22:07,323 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60244
om3_1        | 2022-08-22 01:22:07,330 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:22:12,023 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60256
om3_1        | 2022-08-22 01:22:12,025 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:22:12,706 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 39072-target
om3_1        | 2022-08-22 01:22:16,639 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60272
om3_1        | 2022-08-22 01:22:16,643 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:22:17,247 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 39072-source
om3_1        | 2022-08-22 01:22:21,734 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60312
om3_1        | 2022-08-22 01:22:21,743 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:22:26,043 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41115
s3g_1        | 2022-08-22 01:27:40,376 [qtp1122233828-81] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg0, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,376 [qtp1122233828-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg1, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,377 [qtp1122233828-79] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg2, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,577 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg11, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,578 [qtp1122233828-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg16, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,632 [qtp1122233828-84] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg13, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,639 [qtp1122233828-79] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg18, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 131 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:19:19,998 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 reported by 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171021466938, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:19:21,018 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 132 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:21,022 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
s3g_1        | 2022-08-22 01:27:40,645 [qtp1122233828-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg15, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,648 [qtp1122233828-19] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg19, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,650 [qtp1122233828-81] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg20, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,654 [qtp1122233828-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg17, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,653 [qtp1122233828-82] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg10, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,652 [qtp1122233828-83] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg12, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,695 [qtp1122233828-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg14, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,773 [qtp1122233828-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg23, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,780 [qtp1122233828-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg24, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,803 [qtp1122233828-19] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg22, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,830 [qtp1122233828-81] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg25, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,847 [qtp1122233828-82] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg28, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,851 [qtp1122233828-84] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg29, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,857 [qtp1122233828-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg27, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,875 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg21, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,902 [qtp1122233828-83] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg26, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,902 [qtp1122233828-79] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg30, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,927 [qtp1122233828-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg31, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:40,999 [qtp1122233828-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg32, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,090 [qtp1122233828-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg37, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,107 [qtp1122233828-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg38, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,131 [qtp1122233828-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg34, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,134 [qtp1122233828-81] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg33, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,136 [qtp1122233828-84] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg35, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,140 [qtp1122233828-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg42, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,145 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg39, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,145 [qtp1122233828-19] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg40, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,148 [qtp1122233828-82] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg36, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,160 [qtp1122233828-83] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg41, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,284 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg46, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,295 [qtp1122233828-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg45, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,293 [qtp1122233828-79] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg44, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,314 [qtp1122233828-19] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg48, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,316 [qtp1122233828-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg51, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,348 [qtp1122233828-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg50, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,355 [qtp1122233828-82] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg47, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,357 [qtp1122233828-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg52, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,374 [qtp1122233828-84] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg49, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,381 [qtp1122233828-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg53, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,383 [qtp1122233828-81] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg43, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,513 [qtp1122233828-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg60, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,514 [qtp1122233828-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg61, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,523 [qtp1122233828-83] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg63, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,527 [qtp1122233828-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg58, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,530 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg55, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,534 [qtp1122233828-79] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg54, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,538 [qtp1122233828-82] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg62, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,538 [qtp1122233828-19] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg56, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,582 [qtp1122233828-81] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg59, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,593 [qtp1122233828-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg57, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,615 [qtp1122233828-84] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg65, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,621 [qtp1122233828-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg64, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,691 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg66, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,699 [qtp1122233828-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg68, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,731 [qtp1122233828-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg67, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,786 [qtp1122233828-83] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg71, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,787 [qtp1122233828-84] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg72, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,798 [qtp1122233828-79] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg70, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,801 [qtp1122233828-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg76, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,801 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg75, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,802 [qtp1122233828-19] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg69, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,809 [qtp1122233828-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg73, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,811 [qtp1122233828-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg78, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,812 [qtp1122233828-82] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg74, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,826 [qtp1122233828-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg77, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,933 [qtp1122233828-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg82, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,943 [qtp1122233828-82] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg84, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,944 [qtp1122233828-84] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg79, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,975 [qtp1122233828-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg81, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 133 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:21,030 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
om3_1        | 2022-08-22 01:22:26,048 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:22:31,713 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60342
om3_1        | 2022-08-22 01:22:31,718 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:22:38,602 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60362
om3_1        | 2022-08-22 01:22:38,605 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:22:45,847 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60382
om3_1        | 2022-08-22 01:22:45,853 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:22:53,702 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60426
om3_1        | 2022-08-22 01:22:53,712 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:22:58,400 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60442
om3_1        | 2022-08-22 01:22:58,402 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:03,590 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60468
om3_1        | 2022-08-22 01:23:03,603 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:07,640 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60486
om3_1        | 2022-08-22 01:23:07,644 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:12,164 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60496
om3_1        | 2022-08-22 01:23:12,170 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:16,946 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60512
om3_1        | 2022-08-22 01:23:16,955 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:21,770 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60552
om3_1        | 2022-08-22 01:23:21,777 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:26,084 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:39369
om3_1        | 2022-08-22 01:23:26,098 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:26,183 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60570
om3_1        | 2022-08-22 01:23:26,192 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:30,889 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60578
om3_1        | 2022-08-22 01:23:30,893 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:35,575 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60594
om3_1        | 2022-08-22 01:23:35,580 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:40,066 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60610
om3_1        | 2022-08-22 01:23:40,071 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:44,896 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60626
om3_1        | 2022-08-22 01:23:44,900 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:49,871 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60666
om3_1        | 2022-08-22 01:23:49,876 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:50,516 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 39072-target
om3_1        | 2022-08-22 01:23:54,502 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60674
s3g_1        | 2022-08-22 01:27:41,976 [qtp1122233828-83] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg80, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,977 [qtp1122233828-25] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg86, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,985 [qtp1122233828-21] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg83, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,978 [qtp1122233828-79] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg85, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,994 [qtp1122233828-19] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg88, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:41,996 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg87, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:42,115 [qtp1122233828-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg91, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:42,158 [qtp1122233828-18] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg90, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:42,162 [qtp1122233828-83] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg98, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:42,161 [qtp1122233828-79] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg93, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:42,162 [qtp1122233828-19] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg92, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:42,162 [qtp1122233828-84] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg94, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:42,161 [qtp1122233828-81] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg95, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:42,162 [qtp1122233828-78] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg89, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:42,172 [qtp1122233828-24] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg96, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:42,168 [qtp1122233828-22] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg97, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:42,249 [qtp1122233828-23] INFO rpc.RpcClient: Creating Bucket: s3v/s3bg99, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:27:50,181 [qtp1122233828-85] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-5441601222, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:29:18,007 [qtp1122233828-78] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8219884435, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:29:18,629 [qtp1122233828-83] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-36340, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:29:33,827 [qtp1122233828-83] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-8362820054, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:31:59,525 [qtp1122233828-85] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-1571071876, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:32:15,253 [qtp1122233828-84] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2080259004, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:32:34,643 [qtp1122233828-78] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #165 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:104)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:409)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:569)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:583)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:145)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:493)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:467)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:520)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:262)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 134 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:19:23,043 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 135 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:23,046 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:283)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:29:14,725 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:54940
om2_1        | 2022-08-22 01:29:14,732 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:29:18,023 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8219884435 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:29:18,651 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-36340 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:29:30,443 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55030
om2_1        | 2022-08-22 01:29:30,448 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:29:33,863 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8362820054 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:30:38,807 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-8362820054, Key:thereisnosuchfile.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:31:42,916 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-8362820054, Key:ozone-test-8204563195/deletetestapidir/key=value/.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:31:46,904 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-8362820054, Key:ozone-test-8204563195/deletetestapiprefix/key=value/file.
om2_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om2_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om2_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om2_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om2_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om2_1        | 2022-08-22 01:31:55,722 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55448
om2_1        | 2022-08-22 01:31:55,726 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:31:59,539 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1571071876 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:32:10,485 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:55498
om2_1        | 2022-08-22 01:32:10,492 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:32:15,271 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2080259004 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:37:23,407 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56310
om3_1        | 2022-08-22 01:23:54,505 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:55,164 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:39072-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:23:59,125 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60700
om3_1        | 2022-08-22 01:23:59,130 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:23:59,713 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 39072-target
om3_1        | 2022-08-22 01:24:03,700 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60718
om3_1        | 2022-08-22 01:24:03,708 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:24:04,463 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:39072-target
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:24:08,462 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60736
om3_1        | 2022-08-22 01:24:08,465 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:24:13,288 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60752
om3_1        | 2022-08-22 01:24:13,289 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:24:13,855 [IPC Server handler 20 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket Volume:39072-target Bucket:unreadable-link 
om3_1        | 2022-08-22 01:24:17,739 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60760
om3_1        | 2022-08-22 01:24:17,748 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:24:22,517 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60800
om3_1        | 2022-08-22 01:24:22,523 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:24:23,124 [IPC Server handler 50 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket Volume:39072-source Bucket:unreadable-bucket Key:
om3_1        | 2022-08-22 01:24:26,133 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36007
om3_1        | 2022-08-22 01:24:26,146 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:24:26,885 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60818
om3_1        | 2022-08-22 01:24:26,892 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:24:27,493 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 39072-target
om3_1        | 2022-08-22 01:24:31,421 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60834
om3_1        | 2022-08-22 01:24:31,428 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:24:32,021 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 39072-target
om3_1        | 2022-08-22 01:24:35,796 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60842
om3_1        | 2022-08-22 01:24:35,801 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:24:36,354 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 39072-target
om3_1        | 2022-08-22 01:24:39,967 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60858
om3_1        | 2022-08-22 01:24:39,975 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:24:44,410 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60874
om3_1        | 2022-08-22 01:24:44,416 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:24:45,208 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 39072-target
om3_1        | 2022-08-22 01:24:49,335 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60914
om3_1        | 2022-08-22 01:24:49,343 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:24:56,818 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60934
om3_1        | 2022-08-22 01:24:56,821 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:25:03,433 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60964
om3_1        | 2022-08-22 01:25:03,441 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:25:07,893 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60982
om3_1        | 2022-08-22 01:25:07,897 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:25:12,458 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:60990
om3_1        | 2022-08-22 01:25:12,465 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:25:17,106 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:32774
om3_1        | 2022-08-22 01:25:17,110 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:25:17,698 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 39072-target
om3_1        | 2022-08-22 01:25:22,098 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:32814
om3_1        | 2022-08-22 01:25:22,107 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:25:22,784 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:39072-target
om3_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 136 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:23,049 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om3 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-08-22 01:16:53,209 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-08-22 01:16:53,238 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-08-22 01:16:53,367 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-08-22 01:16:53,427 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-08-22 01:16:53,427 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-08-22 01:16:53,545 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-08-22 01:16:53,546 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-08-22 01:16:53,885 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-08-22 01:16:53,885 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-08-22 01:16:53,966 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2022-08-22 01:16:56,430 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-22 01:16:58,432 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-22 01:17:00,433 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-22 01:17:03,689 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:e5262d73-6b1c-4541-a42b-1a92d56a8751 is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-22 01:17:05,704 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-22 01:17:07,711 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:e5262d73-6b1c-4541-a42b-1a92d56a8751 is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 137 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2022-08-22 01:19:25,053 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om1 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 138 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:25,056 [pool-28-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException): OM:om2 is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:248)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:235)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:228)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:175)
recon_1      | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
recon_1      | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
recon_1      | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
recon_1      | , while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 139 failover attempts. Trying to failover immediately.
recon_1      | 2022-08-22 01:19:25,917 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-22 01:17:09,713 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2022-08-22 01:17:11,925 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm2.org_1   | 2022-08-22 01:17:12,783 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm2.org_1   | 2022-08-22 01:17:12,787 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2022-08-22 01:17:12,789 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm2.org_1   | 2022-08-22 01:17:14,698 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2022-08-22 01:17:14,746 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2022-08-22 01:17:14,748 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2022-08-22 01:17:14,751 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:613adbf7-7795-42d5-82ba-29b8ddf9dabc,clusterId:CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5,subject:scm-sub@scm2.org
scm2.org_1   | 2022-08-22 01:17:16,558 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm2.org_1   | 2022-08-22 01:17:16,579 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5, SCMID 613adbf7-7795-42d5-82ba-29b8ddf9dabc
scm2.org_1   | 2022-08-22 01:17:16,579 [main] INFO server.StorageContainerManager: Primary SCM Node ID e5262d73-6b1c-4541-a42b-1a92d56a8751
scm2.org_1   | 2022-08-22 01:17:16,635 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2022-08-22 01:17:20,108 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2022-08-22 01:17:20,121 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2022-08-22 01:17:20,230 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-08-22 01:17:20,334 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2022-08-22 01:17:20,364 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2022-08-22 01:17:20,538 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2022-08-22 01:17:20,544 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2022-08-22 01:17:21,851 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2022-08-22 01:17:22,208 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2022-08-22 01:17:22,224 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/1112518331559.crt.
scm2.org_1   | 2022-08-22 01:17:22,228 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm2.org_1   | 2022-08-22 01:17:22,543 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2022-08-22 01:17:22,543 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2022-08-22 01:17:22,612 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-08-22 01:17:23,045 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2022-08-22 01:17:23,913 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2022-08-22 01:17:23,914 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm2.org_1   | 2022-08-22 01:17:24,151 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2022-08-22 01:17:24,228 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:613adbf7-7795-42d5-82ba-29b8ddf9dabc
scm2.org_1   | 2022-08-22 01:17:24,431 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2022-08-22 01:17:24,598 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm2.org_1   | 2022-08-22 01:17:24,599 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-08-22 01:17:24,599 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm2.org_1   | 2022-08-22 01:17:24,599 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-08-22 01:17:24,599 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2022-08-22 01:17:24,600 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm2.org_1   | 2022-08-22 01:17:24,614 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-08-22 01:17:24,614 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm2.org_1   | 2022-08-22 01:17:24,615 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2022-08-22 01:17:24,636 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm2.org_1   | 2022-08-22 01:17:24,637 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm2.org_1   | 2022-08-22 01:17:26,274 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm2.org_1   | 2022-08-22 01:17:26,292 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm2.org_1   | 2022-08-22 01:17:26,293 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm2.org_1   | 2022-08-22 01:17:26,293 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-08-22 01:17:26,294 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-08-22 01:17:26,296 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-08-22 01:17:26,330 [main] INFO server.RaftServer: 613adbf7-7795-42d5-82ba-29b8ddf9dabc: addNew group-0782CA3657A5:[] returns group-0782CA3657A5:java.util.concurrent.CompletableFuture@67328bcb[Not completed]
scm2.org_1   | 2022-08-22 01:17:26,477 [pool-16-thread-1] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc: new RaftServerImpl for group-0782CA3657A5:[] with SCMStateMachine:uninitialized
scm2.org_1   | 2022-08-22 01:17:26,485 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2022-08-22 01:17:26,487 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm2.org_1   | 2022-08-22 01:17:26,487 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm2.org_1   | 2022-08-22 01:17:26,487 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2022-08-22 01:17:26,487 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2022-08-22 01:17:26,487 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:19:29,067 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38572
recon_1      | 2022-08-22 01:19:29,117 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:19:29,714 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58616
recon_1      | 2022-08-22 01:19:29,748 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:19:29,991 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 reported by 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171297874022, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2022-08-22 01:19:29,991 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 85ae3250-a1a7-4fa0-96fb-c7ffd18c9838, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:61e48a95-a5d7-43eb-addf-1603d4744f3f, CreationTimestamp2022-08-22T01:18:46.948Z[UTC]] moved to OPEN state
recon_1      | 2022-08-22 01:19:50,062 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40008
recon_1      | 2022-08-22 01:19:50,102 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:19:59,061 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38690
recon_1      | 2022-08-22 01:19:59,100 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:20:00,004 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58742
recon_1      | 2022-08-22 01:20:00,073 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:20:03,339 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #1 got from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net.
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:25:26,188 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34869
om3_1        | 2022-08-22 01:25:26,201 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:25:26,714 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:32824
om3_1        | 2022-08-22 01:25:26,718 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:26:06,174 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33138
om3_1        | 2022-08-22 01:26:06,175 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:26:11,723 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:35253
om3_1        | 2022-08-22 01:26:11,738 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:26:12,113 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:12,229 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:12,239 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6690263611 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:26:16,032 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33170
om3_1        | 2022-08-22 01:26:16,040 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:26:19,482 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:19,487 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:19,495 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8018651496 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:26:20,143 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:20,150 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:20,174 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:22,706 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:23,401 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:23,410 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:23,414 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:23,559 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:24,197 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:24,202 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:24,214 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:24,224 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:24,884 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:24,888 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:24,893 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:24,897 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:25,476 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:25,484 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:25,492 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:25,495 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:26,137 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:26,144 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #165 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-08-22 01:32:34,664 [qtp1122233828-78] INFO scm.XceiverClientRatis: Could not commit index 128 on pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]] to all the nodes. Server 61e48a95-a5d7-43eb-addf-1603d4744f3f has failed. Committed by majority.
s3g_1        | 2022-08-22 01:32:34,665 [qtp1122233828-78] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200049 bcsId: 128 on Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]]. Failed nodes: [61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-08-22 01:33:40,358 [qtp1122233828-83] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #172 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:104)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:409)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:569)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:583)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:145)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:493)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:467)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:520)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:262)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
om3_1        | 2022-08-22 01:26:26,149 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:26,231 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43845
om3_1        | 2022-08-22 01:26:26,242 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:26:26,322 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:26,968 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:26,971 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:26,973 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:26,978 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:30,700 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33242
om3_1        | 2022-08-22 01:26:30,705 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:26:34,005 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:34,011 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:34,028 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5317785265 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:26:34,590 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:34,594 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:34,607 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: ozone-test-pkkavrhdbq of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:26:34,641 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:34,646 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:34,649 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,175 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,214 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,219 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,223 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,317 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,356 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,361 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,364 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,465 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,501 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,508 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,520 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,653 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,658 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,700 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,725 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,729 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:35,836 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:37,681 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:37,683 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:37,826 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:37,852 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:37,946 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:37,953 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:37,968 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:38,044 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:38,047 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:38,084 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:38,105 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:38,120 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:38,148 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:38,812 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:38,964 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,010 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,013 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,049 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,052 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,059 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-emlxgnryiv of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:26:39,078 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,088 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,094 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,109 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,115 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,124 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,128 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
recon_1      | 2022-08-22 01:20:03,569 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
recon_1      | 2022-08-22 01:20:03,678 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40080
recon_1      | 2022-08-22 01:20:03,748 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:20:25,919 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:20:25,919 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:20:25,978 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:20:33,323 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38824
recon_1      | 2022-08-22 01:20:33,360 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:20:33,539 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40194
om3_1        | 2022-08-22 01:26:39,157 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,160 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,164 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,277 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,322 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,334 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,350 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,352 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,366 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,368 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,603 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,607 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,613 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,638 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,736 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,740 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,764 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,766 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,769 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,803 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,809 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,828 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:39,926 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:41,179 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:41,251 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:41,255 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:41,280 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:41,359 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:42,449 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:42,499 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:42,510 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:46,558 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33294
om3_1        | 2022-08-22 01:26:46,564 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:26:50,023 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:50,027 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:50,041 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7025562811 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:26:50,683 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:50,691 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:50,701 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-9097171453 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:26:51,409 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:51,413 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:51,421 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-7237953091 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:26:52,094 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:52,097 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:52,104 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-ozone-test-7237953091 in volume:s3v
om3_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:206)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:26:52,771 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:53,725 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:53,731 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:26:53,737 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6286737048 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:26:57,772 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33354
om3_1        | 2022-08-22 01:26:57,780 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:27:02,375 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33372
om3_1        | 2022-08-22 01:27:02,379 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:27:05,760 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:45841
om3_1        | 2022-08-22 01:27:05,761 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:27:05,762 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:05,777 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #172 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
scm2.org_1   | 2022-08-22 01:17:26,503 [pool-16-thread-1] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2022-08-22 01:17:26,503 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2022-08-22 01:17:26,510 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2022-08-22 01:17:26,511 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm2.org_1   | 2022-08-22 01:17:26,512 [pool-16-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5 does not exist. Creating ...
scm2.org_1   | 2022-08-22 01:17:26,528 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/in_use.lock acquired by nodename 7@scm2.org
scm2.org_1   | 2022-08-22 01:17:26,558 [pool-16-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5 has been successfully formatted.
scm2.org_1   | 2022-08-22 01:17:26,560 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm2.org_1   | 2022-08-22 01:17:26,564 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2022-08-22 01:17:26,575 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm2.org_1   | 2022-08-22 01:17:26,576 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2022-08-22 01:17:26,583 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm2.org_1   | 2022-08-22 01:17:26,732 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-08-22 01:17:26,749 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2022-08-22 01:17:26,749 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2022-08-22 01:17:26,766 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5
scm2.org_1   | 2022-08-22 01:17:26,766 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2022-08-22 01:17:26,767 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2022-08-22 01:17:26,767 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2022-08-22 01:17:26,768 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm2.org_1   | 2022-08-22 01:17:26,768 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2022-08-22 01:17:26,770 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2022-08-22 01:17:26,770 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2022-08-22 01:17:26,770 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2022-08-22 01:17:26,790 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2022-08-22 01:17:26,791 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm2.org_1   | 2022-08-22 01:17:26,791 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2022-08-22 01:17:26,803 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-08-22 01:17:26,803 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2022-08-22 01:17:26,811 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2022-08-22 01:17:26,812 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2022-08-22 01:17:26,812 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2022-08-22 01:17:26,812 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2022-08-22 01:17:26,814 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2022-08-22 01:17:26,814 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2022-08-22 01:17:26,940 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2022-08-22 01:17:26,945 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm2.org_1   | 2022-08-22 01:17:26,945 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm2.org_1   | 2022-08-22 01:17:26,946 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm2.org_1   | 2022-08-22 01:17:26,946 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm2.org_1   | 2022-08-22 01:17:26,948 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2022-08-22 01:17:26,949 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2022-08-22 01:17:26,950 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2022-08-22 01:17:27,426 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm2.org_1   | 2022-08-22 01:17:27,622 [main] INFO reflections.Reflections: Reflections took 147 ms to scan 3 urls, producing 110 keys and 247 values 
scm2.org_1   | 2022-08-22 01:17:27,700 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm2.org_1   | 2022-08-22 01:17:27,700 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2022-08-22 01:17:27,704 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm2.org_1   | 2022-08-22 01:17:27,706 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2022-08-22 01:17:27,762 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2022-08-22 01:17:27,776 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2022-08-22 01:17:27,778 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm2.org_1   | 2022-08-22 01:17:27,789 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2022-08-22 01:17:27,836 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2022-08-22 01:17:27,837 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm2.org_1   | 2022-08-22 01:17:27,842 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2022-08-22 01:17:27,843 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2022-08-22 01:17:27,847 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm2.org_1   | 2022-08-22 01:17:27,847 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm2.org_1   | 2022-08-22 01:17:27,854 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm2.org_1   | 2022-08-22 01:17:27,855 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm2.org_1   | 2022-08-22 01:17:27,891 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2022-08-22 01:17:27,915 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2022-08-22 01:17:27,960 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2022-08-22 01:17:27,986 [main] INFO UnderReplicatedQueueThread: Starting UnderReplicatedQueueThread Service.
scm2.org_1   | 2022-08-22 01:17:27,987 [main] INFO ha.SCMServiceManager: Registering service UnderReplicatedQueueThread.
scm2.org_1   | 2022-08-22 01:17:27,991 [main] INFO OverReplicatedQueueThread: Starting OverReplicatedQueueThread Service.
scm2.org_1   | 2022-08-22 01:17:27,990 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-22 01:17:27,996 [main] INFO ha.SCMServiceManager: Registering service OverReplicatedQueueThread.
scm2.org_1   | 2022-08-22 01:17:27,996 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm2.org_1   | 2022-08-22 01:17:28,006 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm2.org_1   | 2022-08-22 01:17:28,011 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:17:28,023 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-08-22 01:17:28,067 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm2.org_1   | 2022-08-22 01:17:28,096 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-08-22 01:17:28,132 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm2.org_1   | 2022-08-22 01:17:28,803 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-08-22 01:17:28,811 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-08-22 01:17:28,815 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2022-08-22 01:17:28,839 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-08-22 01:17:28,844 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-08-22 01:17:28,844 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2022-08-22 01:17:28,867 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2022-08-22 01:17:28,875 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2022-08-22 01:17:28,876 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm2.org_1   | 2022-08-22 01:17:29,037 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm2.org_1   | 2022-08-22 01:17:29,039 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm2.org_1   | Container Balancer status:
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        false
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                                                Value
scm2.org_1   | Threshold                                          10
scm2.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm2.org_1   | Max Size to Move per Iteration                     500GB
scm2.org_1   | Max Size Entering Target per Iteration             26GB
scm2.org_1   | Max Size Leaving Source per Iteration              26GB
scm2.org_1   | 
scm2.org_1   | 2022-08-22 01:17:29,039 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-08-22 01:17:29,039 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm2.org_1   | 2022-08-22 01:17:29,047 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2022-08-22 01:17:29,049 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2022-08-22 01:17:29,050 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-impl-thread1] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: start with initializing state, conf=-1: [], old=null
scm2.org_1   | 2022-08-22 01:17:29,050 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-impl-thread1] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: changes role from      null to FOLLOWER at term 0 for startInitializing
recon_1      | 2022-08-22 01:20:33,563 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:20:33,686 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58886
recon_1      | 2022-08-22 01:20:33,707 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:21:03,339 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:38944
recon_1      | 2022-08-22 01:21:03,378 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:21:03,542 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40308
recon_1      | 2022-08-22 01:21:03,609 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:21:03,679 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:58998
recon_1      | 2022-08-22 01:21:03,741 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:21:18,705 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39028
recon_1      | 2022-08-22 01:21:18,730 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40394
recon_1      | 2022-08-22 01:21:18,757 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59064
recon_1      | 2022-08-22 01:21:18,810 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:21:18,811 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-08-22 01:21:18,859 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:21:18,880 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:21:18,879 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: New container #2 got from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net.
recon_1      | 2022-08-22 01:21:18,914 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-08-22 01:21:18,941 [FixedThreadPoolWithAffinityExecutor-1-0] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1      | 2022-08-22 01:21:25,985 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:21:25,986 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:21:26,029 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
om2_1        | 2022-08-22 01:37:23,411 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:37:28,113 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2019065808 of layout LEGACY in volume: s3v
om2_1        | 2022-08-22 01:37:49,842 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:56424
om2_1        | 2022-08-22 01:37:49,847 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om2_1        | 2022-08-22 01:37:54,277 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0209209266 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:05,790 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-6031205182 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:06,419 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:06,422 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:06,429 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4059376425 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:07,067 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:07,070 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:07,691 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:07,695 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:07,703 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket-ozone-test-4695970515 in volume:s3v
om3_1        | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket not found
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2498)
om3_1        | 	at org.apache.hadoop.ozone.om.OzoneManager.getBucketOwner(OzoneManager.java:2468)
om3_1        | 	at org.apache.hadoop.ozone.om.request.OMClientRequest.checkAcls(OMClientRequest.java:217)
om3_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:108)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:27:11,468 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33408
om3_1        | 2022-08-22 01:27:11,470 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:27:14,753 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:14,760 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:14,769 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5013695993 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:15,370 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:15,377 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:16,036 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:16,038 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:19,769 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33454
om3_1        | 2022-08-22 01:27:19,776 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:27:23,164 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:23,182 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:23,201 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-4194492066 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:23,823 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:23,831 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:23,834 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:26,345 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40615
om3_1        | 2022-08-22 01:27:26,351 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:27:27,599 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33476
om3_1        | 2022-08-22 01:27:27,603 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:27:32,811 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33494
om3_1        | 2022-08-22 01:27:32,814 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:27:40,298 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:33319
om3_1        | 2022-08-22 01:27:40,317 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:27:40,320 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,329 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,330 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,331 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,332 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,334 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,335 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,341 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,347 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,355 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,362 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,366 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,373 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,375 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,381 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,382 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,384 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,386 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,381 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
s3g_1        | 2022-08-22 01:33:40,364 [qtp1122233828-83] INFO scm.XceiverClientRatis: Could not commit index 132 on pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]] to all the nodes. Server 61e48a95-a5d7-43eb-addf-1603d4744f3f has failed. Committed by majority.
s3g_1        | 2022-08-22 01:33:40,364 [qtp1122233828-83] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200051 bcsId: 132 on Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]]. Failed nodes: [61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-08-22 01:35:16,041 [qtp1122233828-84] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #184 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:104)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:409)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:569)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:583)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:145)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:493)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:467)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:520)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:262)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
scm2.org_1   | 2022-08-22 01:17:29,052 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0782CA3657A5,id=613adbf7-7795-42d5-82ba-29b8ddf9dabc
scm2.org_1   | 2022-08-22 01:17:29,063 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 613adbf7-7795-42d5-82ba-29b8ddf9dabc: start RPC server
scm2.org_1   | 2022-08-22 01:17:29,159 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 613adbf7-7795-42d5-82ba-29b8ddf9dabc: GrpcService started, listening on 9894
scm2.org_1   | 2022-08-22 01:17:29,172 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$468/0x0000000840560440@44a7a331] INFO util.JvmPauseMonitor: JvmPauseMonitor-613adbf7-7795-42d5-82ba-29b8ddf9dabc: Started
scm2.org_1   | 2022-08-22 01:17:29,174 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2022-08-22 01:17:29,954 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: receive installSnapshot: e5262d73-6b1c-4541-a42b-1a92d56a8751->613adbf7-7795-42d5-82ba-29b8ddf9dabc#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2022-08-22 01:17:29,965 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2022-08-22 01:17:29,965 [grpc-default-executor-0] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: change Leader from null to e5262d73-6b1c-4541-a42b-1a92d56a8751 at term 2 for installSnapshot, leader elected after 3405ms
scm2.org_1   | 2022-08-22 01:17:29,971 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: Received notification to install snapshot at index 0
scm2.org_1   | 2022-08-22 01:17:29,972 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm2.org_1   | 2022-08-22 01:17:30,233 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "e5262d73-6b1c-4541-a42b-1a92d56a8751"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2022-08-22 01:17:30,234 [grpc-default-executor-0] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: set configuration 1: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-22 01:17:30,264 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: reply installSnapshot: e5262d73-6b1c-4541-a42b-1a92d56a8751<-613adbf7-7795-42d5-82ba-29b8ddf9dabc#0:FAIL-t0,ALREADY_INSTALLED
scm2.org_1   | 2022-08-22 01:17:30,292 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 613adbf7-7795-42d5-82ba-29b8ddf9dabc: Completed INSTALL_SNAPSHOT, lastRequest: e5262d73-6b1c-4541-a42b-1a92d56a8751->613adbf7-7795-42d5-82ba-29b8ddf9dabc#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2022-08-22 01:17:30,407 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread1] INFO impl.RoleInfo: 613adbf7-7795-42d5-82ba-29b8ddf9dabc: start 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-FollowerState
scm2.org_1   | 2022-08-22 01:17:30,422 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread1] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2022-08-22 01:17:30,425 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread1] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: inconsistency entries. Reply:e5262d73-6b1c-4541-a42b-1a92d56a8751<-613adbf7-7795-42d5-82ba-29b8ddf9dabc#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-08-22 01:17:30,450 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread2] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2022-08-22 01:17:30,450 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread2] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: inconsistency entries. Reply:e5262d73-6b1c-4541-a42b-1a92d56a8751<-613adbf7-7795-42d5-82ba-29b8ddf9dabc#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm2.org_1   | 2022-08-22 01:17:30,466 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread1] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: set configuration 0: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-22 01:17:30,466 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread1] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: set configuration 1: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-22 01:17:30,479 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread1] INFO segmented.SegmentedRaftLogWorker: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-SegmentedRaftLogWorker: Starting segment from index:0
scm2.org_1   | 2022-08-22 01:17:30,565 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread1] INFO segmented.SegmentedRaftLogWorker: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm2.org_1   | 2022-08-22 01:17:30,588 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread2] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: set configuration 0: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-22 01:17:30,589 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread2] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: set configuration 1: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | Sleeping for 5 seconds
scm3.org_1   | Waiting for the service scm2.org:9894
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-08-22 01:17:33,368 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
scm2.org_1   | 2022-08-22 01:17:30,733 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/current/log_inprogress_0
scm2.org_1   | 2022-08-22 01:17:30,738 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/current/log_inprogress_0 to /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/current/log_0-0
scm2.org_1   | 2022-08-22 01:17:30,790 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/current/log_inprogress_1
scm2.org_1   | 2022-08-22 01:17:30,802 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:17:30,803 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2022-08-22 01:17:30,803 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2022-08-22 01:17:30,803 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2022-08-22 01:17:30,817 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm2.org_1   | 2022-08-22 01:17:31,176 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-08-22 01:17:31,221 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread2] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: set configuration 7: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-08-22 01:17:31,266 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread2] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: set configuration 9: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-22 01:17:31,377 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:17:31,395 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm2.org_1   | 2022-08-22 01:17:31,395 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm2.org_1   | 2022-08-22 01:17:31,427 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-0782CA3657A5:[613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-08-22 01:17:31,436 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2022-08-22 01:17:31,438 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm2.org_1   | 2022-08-22 01:17:31,444 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm2.org_1   | 2022-08-22 01:17:31,439 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:17:31,631 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2022-08-22 01:17:31,683 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2022-08-22 01:17:31,683 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2022-08-22 01:17:32,325 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2022-08-22 01:17:32,333 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-08-22 01:17:32,381 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2022-08-22 01:17:32,418 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2022-08-22 01:17:32,419 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2022-08-22 01:17:32,419 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-08-22 01:17:32,420 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2022-08-22 01:17:32,499 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2022-08-22 01:17:32,520 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2022-08-22 01:17:32,520 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2022-08-22 01:17:32,524 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2022-08-22 01:17:32,759 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-08-22 01:17:32,768 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2022-08-22 01:17:32,768 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2022-08-22 01:17:33,077 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1085506235870 on Scm Bootstrap Node 613adbf7-7795-42d5-82ba-29b8ddf9dabc
scm2.org_1   | 2022-08-22 01:17:33,088 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 613adbf7-7795-42d5-82ba-29b8ddf9dabc
scm2.org_1   | 2022-08-22 01:17:33,137 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@545ffe1] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm2.org_1   | 2022-08-22 01:17:33,192 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2022-08-22 01:17:33,193 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om3_1        | 2022-08-22 01:27:40,381 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,390 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg9 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,394 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg6 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,408 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg8 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,486 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg3 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,497 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg4 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,501 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg5 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,507 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg7 of layout LEGACY in volume: s3v
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-08-22 01:17:33,390 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-08-22 01:17:33,599 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-08-22 01:17:33,691 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-08-22 01:17:33,691 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-08-22 01:17:33,792 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-08-22 01:17:33,793 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-08-22 01:17:34,228 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-08-22 01:17:34,228 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-08-22 01:17:34,349 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2022-08-22 01:17:34,951 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2022-08-22 01:17:35,768 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm3.org_1   | 2022-08-22 01:17:35,768 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2022-08-22 01:17:35,769 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm3.org_1   | 2022-08-22 01:17:36,744 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm3.org_1   | 2022-08-22 01:17:36,799 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2022-08-22 01:17:36,800 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2022-08-22 01:17:36,808 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:d6d7ecb5-2d4f-4c0f-84db-7d6627418147,clusterId:CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5,subject:scm-sub@scm3.org
scm3.org_1   | 2022-08-22 01:17:37,843 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2022-08-22 01:17:37,873 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5, SCMID d6d7ecb5-2d4f-4c0f-84db-7d6627418147
scm3.org_1   | 2022-08-22 01:17:37,873 [main] INFO server.StorageContainerManager: Primary SCM Node ID e5262d73-6b1c-4541-a42b-1a92d56a8751
scm3.org_1   | 2022-08-22 01:17:37,899 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2022-08-22 01:17:39,810 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:21:48,697 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39134
recon_1      | 2022-08-22 01:21:48,718 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40504
recon_1      | 2022-08-22 01:21:48,723 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:21:48,738 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:21:48,757 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59190
recon_1      | 2022-08-22 01:21:48,798 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:22:18,693 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39270
recon_1      | 2022-08-22 01:22:18,726 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40640
recon_1      | 2022-08-22 01:22:18,733 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59314
recon_1      | 2022-08-22 01:22:18,767 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:22:18,781 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:22:18,788 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:22:25,769 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 18 milliseconds to process 0 existing database records.
recon_1      | 2022-08-22 01:22:25,777 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 9 milliseconds for processing 2 containers.
recon_1      | 2022-08-22 01:22:25,966 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-08-22 01:22:25,970 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 31 milliseconds.
recon_1      | 2022-08-22 01:22:26,034 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:22:26,034 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:22:26,065 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2022-08-22 01:17:39,822 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2022-08-22 01:17:39,903 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-08-22 01:17:39,926 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2022-08-22 01:17:39,935 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2022-08-22 01:17:39,963 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2022-08-22 01:17:39,963 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2022-08-22 01:17:40,363 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2022-08-22 01:17:40,470 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2022-08-22 01:17:40,475 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/1134508804803.crt.
scm3.org_1   | 2022-08-22 01:17:40,478 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2022-08-22 01:17:40,594 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2022-08-22 01:17:40,594 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2022-08-22 01:17:40,636 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-08-22 01:17:40,767 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2022-08-22 01:17:41,170 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm3.org_1   | 2022-08-22 01:17:41,170 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm3.org_1   | 2022-08-22 01:17:41,289 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2022-08-22 01:17:41,337 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:d6d7ecb5-2d4f-4c0f-84db-7d6627418147
scm3.org_1   | 2022-08-22 01:17:41,498 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm3.org_1   | 2022-08-22 01:17:41,618 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm3.org_1   | 2022-08-22 01:17:41,619 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-08-22 01:17:41,621 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm3.org_1   | 2022-08-22 01:17:41,621 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-08-22 01:17:41,621 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2022-08-22 01:17:41,622 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm3.org_1   | 2022-08-22 01:17:41,625 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-08-22 01:17:41,626 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2022-08-22 01:17:41,626 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2022-08-22 01:17:41,654 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm3.org_1   | 2022-08-22 01:17:41,660 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm3.org_1   | 2022-08-22 01:17:42,657 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2022-08-22 01:17:42,659 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm3.org_1   | 2022-08-22 01:17:42,660 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm3.org_1   | 2022-08-22 01:17:42,660 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-08-22 01:17:42,661 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-08-22 01:17:42,663 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-08-22 01:17:42,672 [main] INFO server.RaftServer: d6d7ecb5-2d4f-4c0f-84db-7d6627418147: addNew group-0782CA3657A5:[] returns group-0782CA3657A5:java.util.concurrent.CompletableFuture@191a0351[Not completed]
scm3.org_1   | 2022-08-22 01:17:42,692 [pool-16-thread-1] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147: new RaftServerImpl for group-0782CA3657A5:[] with SCMStateMachine:uninitialized
scm3.org_1   | 2022-08-22 01:17:42,694 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | 2022-08-22 01:17:42,694 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2022-08-22 01:17:42,695 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm3.org_1   | 2022-08-22 01:17:42,695 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2022-08-22 01:17:42,695 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2022-08-22 01:17:42,696 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2022-08-22 01:17:42,702 [pool-16-thread-1] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2022-08-22 01:17:42,703 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2022-08-22 01:17:42,707 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2022-08-22 01:16:42,135 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-08-22 01:16:42,180 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-08-22 01:16:42,494 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-22 01:16:42,755 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-08-22 01:16:42,812 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-08-22 01:16:43,109 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-08-22 01:16:43,113 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-08-22 01:16:43,166 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2022-08-22 01:16:45,882 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2022-08-22 01:16:45,882 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2022-08-22 01:16:45,894 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2022-08-22 01:16:47,238 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2022-08-22 01:16:47,901 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-08-22 01:16:47,901 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-08-22 01:16:48,104 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2022-08-22 01:16:48,105 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2022-08-22 01:16:48,106 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:e5262d73-6b1c-4541-a42b-1a92d56a8751,clusterId:CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5,subject:scm-sub@scm1.org
scm1.org_1   | 2022-08-22 01:16:48,236 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2022-08-22 01:16:48,397 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-08-22 01:16:48,557 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-08-22 01:16:48,565 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-22 01:16:48,566 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-08-22 01:16:48,567 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-22 01:16:48,567 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-22 01:16:48,569 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-08-22 01:16:48,574 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-22 01:16:48,577 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-08-22 01:16:48,578 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-08-22 01:16:48,601 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2022-08-22 01:16:48,609 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2022-08-22 01:16:49,032 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-08-22 01:16:49,035 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm1.org_1   | 2022-08-22 01:16:49,041 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2022-08-22 01:16:49,041 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-08-22 01:16:49,041 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-08-22 01:16:49,045 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-08-22 01:16:49,074 [main] INFO server.RaftServer: e5262d73-6b1c-4541-a42b-1a92d56a8751: addNew group-0782CA3657A5:[e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|priority:0] returns group-0782CA3657A5:java.util.concurrent.CompletableFuture@5e922647[Not completed]
scm1.org_1   | 2022-08-22 01:16:49,128 [pool-2-thread-1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751: new RaftServerImpl for group-0782CA3657A5:[e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|priority:0] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-08-22 01:16:49,131 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-08-22 01:16:49,133 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-08-22 01:16:49,134 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-08-22 01:16:49,134 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-08-22 01:16:49,134 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-08-22 01:16:49,135 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-08-22 01:16:49,153 [pool-2-thread-1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: ConfigurationManager, init=-1: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|priority:0], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-08-22 01:16:49,153 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-08-22 01:16:49,161 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-08-22 01:16:49,162 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2022-08-22 01:16:49,164 [pool-2-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5 does not exist. Creating ...
scm1.org_1   | 2022-08-22 01:16:49,206 [pool-2-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/in_use.lock acquired by nodename 84@scm1.org
scm1.org_1   | 2022-08-22 01:16:49,234 [pool-2-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5 has been successfully formatted.
scm1.org_1   | 2022-08-22 01:16:49,247 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-08-22 01:16:49,254 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-08-22 01:16:49,268 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-08-22 01:16:49,269 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-22 01:16:49,270 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2022-08-22 01:16:49,294 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-08-22 01:16:49,490 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-08-22 01:16:49,501 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-08-22 01:16:49,501 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-08-22 01:16:49,506 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: new e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5
scm1.org_1   | 2022-08-22 01:16:49,506 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-08-22 01:16:49,507 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-08-22 01:16:49,507 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-08-22 01:16:49,508 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-08-22 01:16:49,508 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-08-22 01:16:49,509 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-08-22 01:16:49,509 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-08-22 01:16:49,509 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-08-22 01:16:49,528 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-08-22 01:16:49,528 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2022-08-22 01:16:49,529 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-08-22 01:16:49,534 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-08-22 01:16:49,534 [pool-2-thread-1] INFO segmented.SegmentedRaftLogWorker: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-08-22 01:16:49,538 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-08-22 01:16:49,539 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-08-22 01:16:49,539 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-08-22 01:16:49,540 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-08-22 01:16:49,542 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-08-22 01:16:49,551 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-08-22 01:16:49,624 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-08-22 01:16:49,628 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2022-08-22 01:16:49,631 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2022-08-22 01:16:49,632 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2022-08-22 01:16:49,632 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2022-08-22 01:16:49,634 [e5262d73-6b1c-4541-a42b-1a92d56a8751-impl-thread1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: start as a follower, conf=-1: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-08-22 01:16:49,635 [e5262d73-6b1c-4541-a42b-1a92d56a8751-impl-thread1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2022-08-22 01:16:49,636 [e5262d73-6b1c-4541-a42b-1a92d56a8751-impl-thread1] INFO impl.RoleInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751: start e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState
scm1.org_1   | 2022-08-22 01:16:49,653 [e5262d73-6b1c-4541-a42b-1a92d56a8751-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0782CA3657A5,id=e5262d73-6b1c-4541-a42b-1a92d56a8751
scm1.org_1   | 2022-08-22 01:16:49,656 [main] INFO server.RaftServer: e5262d73-6b1c-4541-a42b-1a92d56a8751: start RPC server
scm1.org_1   | 2022-08-22 01:16:49,793 [main] INFO server.GrpcService: e5262d73-6b1c-4541-a42b-1a92d56a8751: GrpcService started, listening on 9894
scm1.org_1   | 2022-08-22 01:16:49,805 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$354/0x000000084031f040@4c361f63] INFO util.JvmPauseMonitor: JvmPauseMonitor-e5262d73-6b1c-4541-a42b-1a92d56a8751: Started
scm1.org_1   | 2022-08-22 01:16:54,752 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState] INFO impl.FollowerState: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5117000502ns, electionTimeout:5102ms
scm1.org_1   | 2022-08-22 01:16:54,754 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState] INFO impl.RoleInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751: shutdown e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState
scm1.org_1   | 2022-08-22 01:16:54,754 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm1.org_1   | 2022-08-22 01:16:54,757 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm3.org_1   | 2022-08-22 01:17:42,710 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2022-08-22 01:17:42,712 [pool-16-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5 does not exist. Creating ...
scm3.org_1   | 2022-08-22 01:17:42,736 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/in_use.lock acquired by nodename 7@scm3.org
scm3.org_1   | 2022-08-22 01:17:42,774 [pool-16-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5 has been successfully formatted.
scm3.org_1   | 2022-08-22 01:17:42,777 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm3.org_1   | 2022-08-22 01:17:42,779 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2022-08-22 01:17:42,803 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2022-08-22 01:17:42,803 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2022-08-22 01:17:42,811 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm3.org_1   | 2022-08-22 01:17:42,985 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-08-22 01:17:42,997 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2022-08-22 01:17:42,997 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm3.org_1   | 2022-08-22 01:17:43,003 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5
scm3.org_1   | 2022-08-22 01:17:43,004 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2022-08-22 01:17:43,004 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm3.org_1   | 2022-08-22 01:17:43,005 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2022-08-22 01:17:43,006 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm3.org_1   | 2022-08-22 01:17:43,013 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2022-08-22 01:17:43,014 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm3.org_1   | 2022-08-22 01:17:43,016 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2022-08-22 01:17:43,016 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #184 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-08-22 01:35:16,056 [qtp1122233828-84] INFO scm.XceiverClientRatis: Could not commit index 135 on pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]] to all the nodes. Server 61e48a95-a5d7-43eb-addf-1603d4744f3f has failed. Committed by majority.
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm3.org_1   | 2022-08-22 01:17:43,029 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm3.org_1   | 2022-08-22 01:17:43,030 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm3.org_1   | 2022-08-22 01:17:43,031 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2022-08-22 01:17:43,043 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-08-22 01:17:43,043 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2022-08-22 01:17:43,047 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm3.org_1   | 2022-08-22 01:17:43,047 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm3.org_1   | 2022-08-22 01:17:43,048 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm3.org_1   | 2022-08-22 01:17:43,048 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2022-08-22 01:17:43,058 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2022-08-22 01:17:43,058 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | 2022-08-22 01:17:43,130 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2022-08-22 01:17:43,131 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm3.org_1   | 2022-08-22 01:17:43,131 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm3.org_1   | 2022-08-22 01:17:43,131 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm3.org_1   | 2022-08-22 01:17:43,132 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm3.org_1   | 2022-08-22 01:17:43,134 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2022-08-22 01:17:43,135 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2022-08-22 01:17:43,135 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm3.org_1   | 2022-08-22 01:17:43,573 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm3.org_1   | 2022-08-22 01:17:43,782 [main] INFO reflections.Reflections: Reflections took 159 ms to scan 3 urls, producing 110 keys and 247 values 
scm3.org_1   | 2022-08-22 01:17:43,953 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm3.org_1   | 2022-08-22 01:17:43,953 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2022-08-22 01:17:43,956 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2022-08-22 01:17:43,960 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm3.org_1   | 2022-08-22 01:17:44,075 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | 2022-08-22 01:17:44,106 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2022-08-22 01:17:44,107 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2022-08-22 01:17:44,127 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm3.org_1   | 2022-08-22 01:17:44,185 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm3.org_1   | 2022-08-22 01:17:44,185 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2022-08-22 01:17:44,194 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm3.org_1   | 2022-08-22 01:17:44,195 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2022-08-22 01:17:44,209 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm3.org_1   | 2022-08-22 01:17:44,220 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm3.org_1   | 2022-08-22 01:17:44,233 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm3.org_1   | 2022-08-22 01:17:44,242 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm3.org_1   | 2022-08-22 01:17:44,335 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm3.org_1   | 2022-08-22 01:17:44,364 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm3.org_1   | 2022-08-22 01:17:44,466 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2022-08-22 01:17:44,533 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-22 01:17:44,535 [main] INFO UnderReplicatedQueueThread: Starting UnderReplicatedQueueThread Service.
scm3.org_1   | 2022-08-22 01:17:44,539 [main] INFO ha.SCMServiceManager: Registering service UnderReplicatedQueueThread.
scm3.org_1   | 2022-08-22 01:17:44,544 [main] INFO OverReplicatedQueueThread: Starting OverReplicatedQueueThread Service.
scm3.org_1   | 2022-08-22 01:17:44,548 [main] INFO ha.SCMServiceManager: Registering service OverReplicatedQueueThread.
scm3.org_1   | 2022-08-22 01:17:44,548 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2022-08-22 01:17:44,564 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2022-08-22 01:17:44,567 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:17:44,575 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-08-22 01:17:44,658 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | 2022-08-22 01:17:44,793 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-08-22 01:17:44,864 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm3.org_1   | 2022-08-22 01:17:46,339 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-08-22 01:17:46,354 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-08-22 01:17:46,355 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:22:48,656 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40742
recon_1      | 2022-08-22 01:22:48,722 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:22:48,730 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59414
recon_1      | 2022-08-22 01:22:48,745 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39394
recon_1      | 2022-08-22 01:22:48,789 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:22:48,805 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:23:18,691 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39508
recon_1      | 2022-08-22 01:23:18,716 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59552
recon_1      | 2022-08-22 01:23:18,725 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40880
recon_1      | 2022-08-22 01:23:18,747 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:23:18,752 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:23:18,765 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:23:26,067 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:23:26,068 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:23:26,121 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
scm2.org_1   | 2022-08-22 01:17:33,194 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2022-08-22 01:17:33,283 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @16094ms to org.eclipse.jetty.util.log.Slf4jLog
scm2.org_1   | 2022-08-22 01:17:33,672 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2022-08-22 01:17:33,693 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2022-08-22 01:17:33,694 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm2.org_1   | 2022-08-22 01:17:33,700 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2022-08-22 01:17:33,700 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm2.org_1   | 2022-08-22 01:17:33,703 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm2.org_1   | 2022-08-22 01:17:33,788 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2022-08-22 01:17:33,789 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm2.org_1   | 2022-08-22 01:17:33,921 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2022-08-22 01:17:33,922 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2022-08-22 01:17:33,923 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm2.org_1   | 2022-08-22 01:17:33,976 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-08-22 01:17:33,978 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7a506493{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2022-08-22 01:17:33,992 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5312c883{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2022-08-22 01:17:34,270 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2022-08-22 01:17:34,323 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@292109c7{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-10515491863964187878/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm2.org_1   | 2022-08-22 01:17:34,347 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@7e4f42c0{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm2.org_1   | 2022-08-22 01:17:34,347 [Listener at 0.0.0.0/9860] INFO server.Server: Started @17158ms
scm2.org_1   | 2022-08-22 01:17:34,351 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2022-08-22 01:17:34,354 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2022-08-22 01:17:34,355 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm2.org_1   | 2022-08-22 01:17:37,715 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:17:52,171 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread2] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: set configuration 13: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, d6d7ecb5-2d4f-4c0f-84db-7d6627418147|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=[613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm2.org_1   | 2022-08-22 01:17:52,195 [613adbf7-7795-42d5-82ba-29b8ddf9dabc-server-thread2] INFO server.RaftServer$Division: 613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5: set configuration 15: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, d6d7ecb5-2d4f-4c0f-84db-7d6627418147|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm2.org_1   | 2022-08-22 01:18:13,959 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:18:14,193 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:18:17,339 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:18:21,930 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:18:22,319 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:18:24,505 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:18:38,350 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59362
scm2.org_1   | 2022-08-22 01:18:38,439 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:18:39,005 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$468/0x0000000840560440@44a7a331] WARN util.JvmPauseMonitor: JvmPauseMonitor-613adbf7-7795-42d5-82ba-29b8ddf9dabc: Detected pause in JVM or host machine (eg GC): pause of approximately 133840386ns.
scm2.org_1   | GC pool 'ParNew' had collection(s): count=1 time=116ms
scm2.org_1   | 2022-08-22 01:18:39,287 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35118
scm2.org_1   | 2022-08-22 01:18:39,390 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
s3g_1        | 2022-08-22 01:35:16,057 [qtp1122233828-84] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200055 bcsId: 135 on Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]]. Failed nodes: [61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-08-22 01:36:16,219 [qtp1122233828-85] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #189 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:104)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:409)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:569)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:583)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:145)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:493)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:467)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:520)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:262)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om3_1        | 2022-08-22 01:27:40,526 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg1 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,528 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg0 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,542 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg2 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,575 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,575 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,579 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,586 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg16 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,629 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,631 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,630 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,630 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,636 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,634 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,633 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,633 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,632 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,653 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,666 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,670 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,668 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,669 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,669 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,668 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,668 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,690 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,695 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg11 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,695 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg19 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,704 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,728 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg17 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,734 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg20 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,739 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg10 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,750 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg12 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,755 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,755 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,774 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,779 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg15 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,785 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg13 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,790 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg18 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,793 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,800 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg14 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,812 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,814 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,843 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,845 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,844 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:23:48,700 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40984
recon_1      | 2022-08-22 01:23:48,702 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39636
recon_1      | 2022-08-22 01:23:48,725 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:23:48,754 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:23:48,767 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59658
recon_1      | 2022-08-22 01:23:48,789 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:24:18,706 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41118
recon_1      | 2022-08-22 01:24:18,709 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39748
scm3.org_1   | 2022-08-22 01:17:46,479 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-08-22 01:17:46,501 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-08-22 01:17:46,508 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2022-08-22 01:17:46,572 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2022-08-22 01:17:46,597 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2022-08-22 01:17:46,598 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm3.org_1   | 2022-08-22 01:17:46,864 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm3.org_1   | 2022-08-22 01:17:46,873 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | Container Balancer status:
scm3.org_1   | Key                            Value
scm3.org_1   | Running                        false
scm3.org_1   | Container Balancer Configuration values:
scm3.org_1   | Key                                                Value
scm3.org_1   | Threshold                                          10
scm3.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm3.org_1   | Max Size to Move per Iteration                     500GB
scm3.org_1   | Max Size Entering Target per Iteration             26GB
scm3.org_1   | Max Size Leaving Source per Iteration              26GB
scm3.org_1   | 
scm3.org_1   | 2022-08-22 01:17:46,873 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-08-22 01:17:46,873 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm3.org_1   | 2022-08-22 01:17:46,879 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2022-08-22 01:17:46,883 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm3.org_1   | 2022-08-22 01:17:46,892 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-impl-thread1] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: start with initializing state, conf=-1: [], old=null
scm3.org_1   | 2022-08-22 01:17:46,895 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-impl-thread1] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2022-08-22 01:17:46,897 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0782CA3657A5,id=d6d7ecb5-2d4f-4c0f-84db-7d6627418147
scm3.org_1   | 2022-08-22 01:17:46,915 [Listener at 0.0.0.0/9860] INFO server.RaftServer: d6d7ecb5-2d4f-4c0f-84db-7d6627418147: start RPC server
scm3.org_1   | 2022-08-22 01:17:47,021 [Listener at 0.0.0.0/9860] INFO server.GrpcService: d6d7ecb5-2d4f-4c0f-84db-7d6627418147: GrpcService started, listening on 9894
scm3.org_1   | 2022-08-22 01:17:47,032 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$468/0x0000000840560440@72f71ea2] INFO util.JvmPauseMonitor: JvmPauseMonitor-d6d7ecb5-2d4f-4c0f-84db-7d6627418147: Started
scm3.org_1   | 2022-08-22 01:17:47,036 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2022-08-22 01:17:49,571 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: receive installSnapshot: e5262d73-6b1c-4541-a42b-1a92d56a8751->d6d7ecb5-2d4f-4c0f-84db-7d6627418147#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2022-08-22 01:17:49,622 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm3.org_1   | 2022-08-22 01:17:49,623 [grpc-default-executor-0] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: change Leader from null to e5262d73-6b1c-4541-a42b-1a92d56a8751 at term 2 for installSnapshot, leader elected after 6845ms
scm3.org_1   | 2022-08-22 01:17:49,625 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: Received notification to install snapshot at index 0
scm3.org_1   | 2022-08-22 01:17:49,633 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm3.org_1   | 2022-08-22 01:17:50,334 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "613adbf7-7795-42d5-82ba-29b8ddf9dabc"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "e5262d73-6b1c-4541-a42b-1a92d56a8751"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2022-08-22 01:17:50,364 [grpc-default-executor-0] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: set configuration 9: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-22 01:17:50,414 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: reply installSnapshot: e5262d73-6b1c-4541-a42b-1a92d56a8751<-d6d7ecb5-2d4f-4c0f-84db-7d6627418147#0:FAIL-t0,ALREADY_INSTALLED
scm3.org_1   | 2022-08-22 01:17:50,487 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: d6d7ecb5-2d4f-4c0f-84db-7d6627418147: Completed INSTALL_SNAPSHOT, lastRequest: e5262d73-6b1c-4541-a42b-1a92d56a8751->d6d7ecb5-2d4f-4c0f-84db-7d6627418147#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2022-08-22 01:17:50,621 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread1] INFO impl.RoleInfo: d6d7ecb5-2d4f-4c0f-84db-7d6627418147: start d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-FollowerState
scm3.org_1   | 2022-08-22 01:17:50,660 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread1] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm3.org_1   | 2022-08-22 01:17:50,663 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread1] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: inconsistency entries. Reply:e5262d73-6b1c-4541-a42b-1a92d56a8751<-d6d7ecb5-2d4f-4c0f-84db-7d6627418147#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-08-22 01:17:50,725 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread1] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
recon_1      | 2022-08-22 01:24:18,716 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59804
recon_1      | 2022-08-22 01:24:18,731 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:24:18,735 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:24:18,738 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:24:26,122 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm1.org_1   | 2022-08-22 01:16:54,757 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState] INFO impl.RoleInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751: start e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1
scm1.org_1   | 2022-08-22 01:16:54,773 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO impl.LeaderElection: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|priority:0], old=null
scm1.org_1   | 2022-08-22 01:16:54,774 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO impl.LeaderElection: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2022-08-22 01:16:54,774 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO impl.RoleInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751: shutdown e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1
scm1.org_1   | 2022-08-22 01:16:54,775 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm1.org_1   | 2022-08-22 01:16:54,775 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: change Leader from null to e5262d73-6b1c-4541-a42b-1a92d56a8751 at term 1 for becomeLeader, leader elected after 5528ms
scm1.org_1   | 2022-08-22 01:16:54,780 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-08-22 01:16:54,784 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-08-22 01:16:54,785 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-08-22 01:16:54,790 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-08-22 01:16:54,790 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-08-22 01:16:54,791 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-08-22 01:16:54,800 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-08-22 01:16:54,802 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-08-22 01:16:54,809 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO impl.RoleInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751: start e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderStateImpl
scm1.org_1   | 2022-08-22 01:16:54,838 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2022-08-22 01:16:54,922 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: set configuration 0: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-22 01:16:55,015 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/current/log_inprogress_0
scm1.org_1   | 2022-08-22 01:16:55,809 [main] INFO server.RaftServer: e5262d73-6b1c-4541-a42b-1a92d56a8751: close
scm1.org_1   | 2022-08-22 01:16:55,810 [main] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: shutdown
scm1.org_1   | 2022-08-22 01:16:55,810 [main] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0782CA3657A5,id=e5262d73-6b1c-4541-a42b-1a92d56a8751
scm1.org_1   | 2022-08-22 01:16:55,811 [main] INFO impl.RoleInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751: shutdown e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderStateImpl
scm1.org_1   | 2022-08-22 01:16:55,815 [main] INFO impl.PendingRequests: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-PendingRequests: sendNotLeaderResponses
scm1.org_1   | 2022-08-22 01:16:55,817 [main] INFO impl.StateMachineUpdater: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2022-08-22 01:16:55,818 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO impl.StateMachineUpdater: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2022-08-22 01:16:55,818 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO impl.StateMachineUpdater: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2022-08-22 01:16:55,822 [main] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: closes. applyIndex: 0
scm1.org_1   | 2022-08-22 01:16:55,824 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm1.org_1   | 2022-08-22 01:16:55,825 [main] INFO segmented.SegmentedRaftLogWorker: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker close()
scm1.org_1   | 2022-08-22 01:16:55,826 [main] INFO server.GrpcService: e5262d73-6b1c-4541-a42b-1a92d56a8751: shutdown server with port 9894 now
scm1.org_1   | 2022-08-22 01:16:55,832 [main] INFO server.GrpcService: e5262d73-6b1c-4541-a42b-1a92d56a8751: shutdown server with port 9894 successfully
scm1.org_1   | 2022-08-22 01:16:55,832 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$354/0x000000084031f040@4c361f63] INFO util.JvmPauseMonitor: JvmPauseMonitor-e5262d73-6b1c-4541-a42b-1a92d56a8751: Stopped
scm1.org_1   | 2022-08-22 01:16:55,857 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-22 01:16:55,859 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-b7b9d2d2-be60-416a-87ab-0782ca3657a5; layoutVersion=4; scmId=e5262d73-6b1c-4541-a42b-1a92d56a8751
scm1.org_1   | 2022-08-22 01:16:55,868 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm1.org_1   | ************************************************************/
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #189 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-08-22 01:36:16,223 [qtp1122233828-85] INFO scm.XceiverClientRatis: Could not commit index 139 on pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]] to all the nodes. Server 61e48a95-a5d7-43eb-addf-1603d4744f3f has failed. Committed by majority.
s3g_1        | 2022-08-22 01:36:16,223 [qtp1122233828-85] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200056 bcsId: 139 on Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]]. Failed nodes: [61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
scm2.org_1   | 2022-08-22 01:18:42,472 [IPC Server handler 99 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3c60044e-b181-445f-8fa2-782a9e9eb45c
scm2.org_1   | 2022-08-22 01:18:42,507 [IPC Server handler 99 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171021466938, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-08-22 01:18:42,611 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-08-22 01:18:42,650 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm2.org_1   | 2022-08-22 01:18:42,742 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58736
scm2.org_1   | 2022-08-22 01:18:42,865 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:18:42,916 [IPC Server handler 46 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/61e48a95-a5d7-43eb-addf-1603d4744f3f
scm2.org_1   | 2022-08-22 01:18:42,921 [IPC Server handler 46 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171297874022, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-08-22 01:18:42,929 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm2.org_1   | 2022-08-22 01:18:42,930 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-08-22 01:18:44,411 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: c5d0a770-5809-48a9-a307-ee9a9d2c444e, Nodes: 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:42.911Z[UTC]].
scm2.org_1   | 2022-08-22 01:18:44,440 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:18:44,521 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 23fafdf1-808a-47f3-a6c2-33e77642bffd, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:43.865Z[UTC]].
scm2.org_1   | 2022-08-22 01:18:44,534 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:18:46,322 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3100efb7-0525-45d4-a0fd-e73779181107
scm2.org_1   | 2022-08-22 01:18:46,325 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1174539974108, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2022-08-22 01:18:46,326 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-08-22 01:18:46,327 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm2.org_1   | 2022-08-22 01:18:46,327 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2022-08-22 01:18:46,327 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2022-08-22 01:18:46,327 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-08-22 01:18:46,330 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2022-08-22 01:18:46,330 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2022-08-22 01:18:46,460 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 23fafdf1-808a-47f3-a6c2-33e77642bffd, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:61e48a95-a5d7-43eb-addf-1603d4744f3f, CreationTimestamp2022-08-22T01:18:43.865Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-08-22 01:18:46,648 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6bb8ab60-60a4-4383-9c3b-7719fba37020, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:46.397Z[UTC]].
scm2.org_1   | 2022-08-22 01:18:46,649 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:18:46,799 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]].
scm2.org_1   | 2022-08-22 01:18:46,800 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:18:46,911 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:18:47,274 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 85ae3250-a1a7-4fa0-96fb-c7ffd18c9838, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:46.948Z[UTC]].
scm2.org_1   | 2022-08-22 01:18:47,288 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:18:49,978 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6bb8ab60-60a4-4383-9c3b-7719fba37020, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.397Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-08-22 01:18:50,070 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:18:50,850 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-22 01:18:52,345 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-22 01:18:55,412 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59422
scm2.org_1   | 2022-08-22 01:18:55,472 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:18:55,780 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-22 01:18:57,386 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-22 01:18:58,557 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-08-22 01:18:58,560 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-22 01:18:58,642 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm2.org_1   | 2022-08-22 01:18:59,003 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm2.org_1   | 2022-08-22 01:18:59,003 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm2.org_1   | 2022-08-22 01:18:59,003 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm2.org_1   | 2022-08-22 01:18:59,003 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm2.org_1   | 2022-08-22 01:18:59,004 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm2.org_1   | 2022-08-22 01:18:59,004 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
om3_1        | 2022-08-22 01:27:40,844 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,844 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,867 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,868 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,868 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,871 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,871 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,873 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg24 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,874 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,892 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,916 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg23 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,908 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,908 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,906 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,933 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,946 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg25 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,948 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg22 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:40,975 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:40,978 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg28 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,003 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg29 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,008 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg27 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,014 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,033 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg21 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,049 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,053 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg30 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,055 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg26 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,062 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg31 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,065 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg32 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,078 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,080 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,084 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,087 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,137 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,140 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,142 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,143 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,142 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,142 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,141 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,141 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,141 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,152 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,154 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,154 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,153 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,153 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
scm1.org_1   | 2022-08-22 01:16:57,479 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.3.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ozone-annotation-processing-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.2.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.29.5.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.3.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.2.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.3.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.3.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.2.2.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/a1ba9eaa55bb795e165f3082da7d99d953c5688f ; compiled by 'runner' on 2022-08-22T00:51Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2022-08-22 01:16:57,491 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2022-08-22 01:16:57,569 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-22 01:16:57,635 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2022-08-22 01:16:57,662 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2022-08-22 01:16:57,718 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2022-08-22 01:16:57,718 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2022-08-22 01:16:58,163 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm1.org_1   | 2022-08-22 01:16:58,306 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2022-08-22 01:16:58,309 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/1085506235870.crt.
scm1.org_1   | 2022-08-22 01:16:58,314 [main] INFO client.SCMCertificateClient: Added certificate from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2022-08-22 01:16:58,477 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2022-08-22 01:16:58,477 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2022-08-22 01:16:58,535 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-22 01:16:58,727 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2022-08-22 01:16:59,150 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0-SNAPSHOT.jar!/network-topology-default.xml]
scm1.org_1   | 2022-08-22 01:16:59,151 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm1.org_1   | 2022-08-22 01:16:59,218 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2022-08-22 01:16:59,240 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:e5262d73-6b1c-4541-a42b-1a92d56a8751
scm1.org_1   | 2022-08-22 01:16:59,343 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2022-08-22 01:16:59,415 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = -1 (default)
scm1.org_1   | 2022-08-22 01:16:59,418 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-22 01:16:59,418 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = -1 (default)
scm1.org_1   | 2022-08-22 01:16:59,418 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-22 01:16:59,419 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2022-08-22 01:16:59,419 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2022-08-22 01:16:59,421 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-22 01:16:59,421 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2022-08-22 01:16:59,422 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-08-22 01:16:59,436 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2022-08-22 01:16:59,436 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2022-08-22 01:17:00,149 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2022-08-22 01:17:00,152 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm1.org_1   | 2022-08-22 01:17:00,152 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2022-08-22 01:17:00,153 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-08-22 01:17:00,153 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-08-22 01:17:00,156 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-08-22 01:17:00,173 [e5262d73-6b1c-4541-a42b-1a92d56a8751-impl-thread1] INFO server.RaftServer: e5262d73-6b1c-4541-a42b-1a92d56a8751: found a subdirectory /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5
scm1.org_1   | 2022-08-22 01:17:00,181 [main] INFO server.RaftServer: e5262d73-6b1c-4541-a42b-1a92d56a8751: addNew group-0782CA3657A5:[] returns group-0782CA3657A5:java.util.concurrent.CompletableFuture@191a0351[Not completed]
scm1.org_1   | 2022-08-22 01:17:00,224 [pool-16-thread-1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751: new RaftServerImpl for group-0782CA3657A5:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2022-08-22 01:17:00,229 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2022-08-22 01:17:00,229 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2022-08-22 01:17:00,229 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2022-08-22 01:17:00,229 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2022-08-22 01:17:00,230 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2022-08-22 01:17:00,230 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2022-08-22 01:17:00,238 [pool-16-thread-1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: ConfigurationManager, init=-1: [], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2022-08-22 01:17:00,239 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2022-08-22 01:17:00,241 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2022-08-22 01:17:00,242 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2022-08-22 01:17:50,725 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread1] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: inconsistency entries. Reply:e5262d73-6b1c-4541-a42b-1a92d56a8751<-d6d7ecb5-2d4f-4c0f-84db-7d6627418147#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1
scm3.org_1   | 2022-08-22 01:17:50,750 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread1] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: set configuration 0: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-22 01:17:50,759 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread1] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: set configuration 1: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-22 01:17:50,764 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread1] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: set configuration 7: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-08-22 01:17:50,777 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread1] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: set configuration 9: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-22 01:17:50,830 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread1] INFO segmented.SegmentedRaftLogWorker: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-SegmentedRaftLogWorker: Starting segment from index:0
scm3.org_1   | 2022-08-22 01:17:50,934 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread1] INFO segmented.SegmentedRaftLogWorker: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm3.org_1   | 2022-08-22 01:17:51,019 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread2] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: set configuration 0: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-22 01:17:51,025 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread2] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: set configuration 1: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-22 01:17:51,025 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread2] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: set configuration 7: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-08-22 01:17:51,028 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread2] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: set configuration 9: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-22 01:17:51,519 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/current/log_inprogress_0
scm3.org_1   | 2022-08-22 01:17:51,527 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/current/log_inprogress_0 to /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/current/log_0-0
scm3.org_1   | 2022-08-22 01:17:51,628 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/current/log_inprogress_1
scm3.org_1   | 2022-08-22 01:17:51,737 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:17:51,742 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm3.org_1   | 2022-08-22 01:17:51,745 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2022-08-22 01:17:51,765 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2022-08-22 01:17:51,822 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-08-22 01:17:51,834 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm3.org_1   | 2022-08-22 01:17:52,488 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-0782CA3657A5:[613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-08-22 01:17:52,496 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2022-08-22 01:17:52,538 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$468/0x0000000840560440@72f71ea2] WARN util.JvmPauseMonitor: JvmPauseMonitor-d6d7ecb5-2d4f-4c0f-84db-7d6627418147: Detected pause in JVM or host machine (eg GC): pause of approximately 408219533ns. No GCs detected.
scm3.org_1   | 2022-08-22 01:17:52,568 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread2] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: set configuration 13: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, d6d7ecb5-2d4f-4c0f-84db-7d6627418147|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=[613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm3.org_1   | 2022-08-22 01:17:52,575 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147-server-thread2] INFO server.RaftServer$Division: d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5: set configuration 15: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, d6d7ecb5-2d4f-4c0f-84db-7d6627418147|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm3.org_1   | 2022-08-22 01:17:52,612 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2022-08-22 01:17:52,660 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm2.org_1   | 2022-08-22 01:19:14,980 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59492
scm2.org_1   | 2022-08-22 01:19:14,995 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:19:14,998 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c5d0a770-5809-48a9-a307-ee9a9d2c444e, Nodes: 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3c60044e-b181-445f-8fa2-782a9e9eb45c, CreationTimestamp2022-08-22T01:18:42.911Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-08-22 01:19:29,079 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58886
scm2.org_1   | 2022-08-22 01:19:29,122 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:19:29,639 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35288
scm2.org_1   | 2022-08-22 01:19:29,672 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:19:29,977 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 85ae3250-a1a7-4fa0-96fb-c7ffd18c9838, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:61e48a95-a5d7-43eb-addf-1603d4744f3f, CreationTimestamp2022-08-22T01:18:46.948Z[UTC]] moved to OPEN state
scm2.org_1   | 2022-08-22 01:19:50,064 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59612
scm2.org_1   | 2022-08-22 01:19:50,083 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:19:59,069 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59000
scm2.org_1   | 2022-08-22 01:19:59,129 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:19:59,771 [613adbf7-7795-42d5-82ba-29b8ddf9dabc@group-0782CA3657A5-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm2.org_1   | 2022-08-22 01:19:59,997 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35408
scm2.org_1   | 2022-08-22 01:20:00,037 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:20:03,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59690
scm2.org_1   | 2022-08-22 01:20:03,748 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:20:33,331 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59140
scm2.org_1   | 2022-08-22 01:20:33,363 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:20:33,538 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59804
scm2.org_1   | 2022-08-22 01:20:33,563 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:20:33,741 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35552
scm2.org_1   | 2022-08-22 01:20:33,756 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:21:03,342 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59252
scm2.org_1   | 2022-08-22 01:21:03,384 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:21:03,574 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:59920
scm2.org_1   | 2022-08-22 01:21:03,611 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:21:03,677 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35672
scm2.org_1   | 2022-08-22 01:21:03,741 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:21:18,747 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35732
scm2.org_1   | 2022-08-22 01:21:18,774 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59332
recon_1      | 2022-08-22 01:24:26,122 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:24:26,172 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:24:48,677 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:59904
recon_1      | 2022-08-22 01:24:48,714 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39880
recon_1      | 2022-08-22 01:24:48,744 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:24:48,745 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm3.org_1   | 2022-08-22 01:17:53,212 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:17:53,239 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2022-08-22 01:17:53,257 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2022-08-22 01:17:53,405 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:17:53,455 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:17:53,716 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2022-08-22 01:17:53,844 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm3.org_1   | 2022-08-22 01:17:53,845 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm3.org_1   | 2022-08-22 01:17:55,785 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2022-08-22 01:17:55,817 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-08-22 01:17:55,988 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   | 2022-08-22 01:17:56,145 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   | 2022-08-22 01:17:56,145 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2022-08-22 01:17:56,161 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-08-22 01:17:56,161 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2022-08-22 01:17:56,362 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2022-08-22 01:17:56,376 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2022-08-22 01:17:56,377 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2022-08-22 01:17:56,378 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2022-08-22 01:17:56,742 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-08-22 01:17:56,742 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2022-08-22 01:17:56,742 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2022-08-22 01:17:57,823 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1085506235870 on Scm Bootstrap Node d6d7ecb5-2d4f-4c0f-84db-7d6627418147
scm3.org_1   | 2022-08-22 01:17:57,853 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node d6d7ecb5-2d4f-4c0f-84db-7d6627418147
scm3.org_1   | 2022-08-22 01:17:58,012 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@23faae85] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2022-08-22 01:17:58,181 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm3.org_1   | 2022-08-22 01:17:58,189 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2022-08-22 01:17:58,190 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2022-08-22 01:17:58,437 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @20203ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2022-08-22 01:17:59,040 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2022-08-22 01:17:59,104 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2022-08-22 01:17:59,114 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2022-08-22 01:17:59,114 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2022-08-22 01:17:59,114 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2022-08-22 01:17:59,135 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm3.org_1   | 2022-08-22 01:17:59,567 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2022-08-22 01:17:59,587 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm3.org_1   | 2022-08-22 01:17:59,822 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2022-08-22 01:17:59,822 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2022-08-22 01:17:59,823 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm3.org_1   | 2022-08-22 01:17:59,967 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-08-22 01:18:00,002 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7277fa93{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2022-08-22 01:18:00,003 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@cec9f23{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2022-08-22 01:18:01,376 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2022-08-22 01:18:01,488 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@605ef319{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-3916143253570255212/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2022-08-22 01:18:01,588 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@3cc3914a{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2022-08-22 01:18:01,588 [Listener at 0.0.0.0/9860] INFO server.Server: Started @23354ms
scm2.org_1   | 2022-08-22 01:21:18,801 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60004
scm2.org_1   | 2022-08-22 01:21:18,823 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:21:18,827 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:21:18,867 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:21:48,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35864
scm2.org_1   | 2022-08-22 01:21:48,694 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59448
scm2.org_1   | 2022-08-22 01:21:48,718 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60108
scm2.org_1   | 2022-08-22 01:21:48,737 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:21:48,746 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:21:48,748 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:22:18,684 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59584
scm2.org_1   | 2022-08-22 01:22:18,716 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60242
scm2.org_1   | 2022-08-22 01:22:18,729 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:35976
scm2.org_1   | 2022-08-22 01:22:18,739 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:22:18,776 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:22:18,782 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:22:27,996 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-22 01:22:48,724 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60352
scm2.org_1   | 2022-08-22 01:22:48,735 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36086
scm2.org_1   | 2022-08-22 01:22:48,781 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:22:48,801 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:22:48,829 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59702
scm2.org_1   | 2022-08-22 01:22:48,879 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:23:18,735 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60482
scm2.org_1   | 2022-08-22 01:23:18,758 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36216
scm2.org_1   | 2022-08-22 01:23:18,777 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59822
scm2.org_1   | 2022-08-22 01:23:18,786 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:23:18,791 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:23:18,795 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:23:48,701 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60590
scm2.org_1   | 2022-08-22 01:23:48,703 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36330
scm2.org_1   | 2022-08-22 01:23:48,732 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59942
scm2.org_1   | 2022-08-22 01:23:48,743 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:23:48,759 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:23:48,759 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:24:18,768 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60062
scm2.org_1   | 2022-08-22 01:24:18,798 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60720
scm2.org_1   | 2022-08-22 01:24:18,811 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36478
recon_1      | 2022-08-22 01:24:48,756 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41230
recon_1      | 2022-08-22 01:24:48,796 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:25:18,674 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60038
om3_1        | 2022-08-22 01:27:41,161 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,190 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg35 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,192 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg33 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,210 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg38 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,219 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg36 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,223 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg39 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,237 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg37 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,239 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg41 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,259 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg40 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,263 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg34 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,270 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg42 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,283 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,289 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,294 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,297 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,299 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,313 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg44 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,315 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,321 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,334 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,339 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,344 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,341 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,339 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,339 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,371 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,372 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,372 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,372 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,372 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,371 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,378 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,382 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,385 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,403 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg45 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,422 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg46 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,423 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg51 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,444 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg48 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,445 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,461 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg50 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,466 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg49 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,471 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg52 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,485 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg47 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,485 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,486 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg43 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,488 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg53 of layout LEGACY in volume: s3v
s3g_1        | 2022-08-22 01:37:18,420 [qtp1122233828-78] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]]
s3g_1        | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #197 timeout 180s
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1        | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1        | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:284)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.RatisBlockOutputStream.sendWatchForCommit(RatisBlockOutputStream.java:104)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:409)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:569)
s3g_1        | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:583)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:145)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:493)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:467)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:520)
s3g_1        | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:61)
s3g_1        | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:262)
s3g_1        | 	at jdk.internal.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)
s3g_1        | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1        | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:124)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:167)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
s3g_1        | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
s3g_1        | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
s3g_1        | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
s3g_1        | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
s3g_1        | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
s3g_1        | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
s3g_1        | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
s3g_1        | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
s3g_1        | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1        | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.ozone.s3.EmptyContentTypeFilter.doFilter(EmptyContentTypeFilter.java:76)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1678)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1        | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1        | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1        | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1        | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1        | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1        | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
scm1.org_1   | 2022-08-22 01:17:00,287 [pool-16-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/in_use.lock acquired by nodename 8@scm1.org
scm1.org_1   | 2022-08-22 01:17:00,297 [pool-16-thread-1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=e5262d73-6b1c-4541-a42b-1a92d56a8751} from /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/current/raft-meta
scm1.org_1   | 2022-08-22 01:17:00,331 [pool-16-thread-1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: set configuration 0: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-22 01:17:00,332 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2022-08-22 01:17:00,333 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2022-08-22 01:17:00,339 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2022-08-22 01:17:00,339 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-22 01:17:00,341 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2022-08-22 01:17:00,452 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-08-22 01:17:00,459 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2022-08-22 01:17:00,460 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2022-08-22 01:17:00,465 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: new e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5
scm1.org_1   | 2022-08-22 01:17:00,465 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-08-22 01:17:00,466 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2022-08-22 01:17:00,467 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2022-08-22 01:17:00,467 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2022-08-22 01:17:00,467 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2022-08-22 01:17:00,468 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2022-08-22 01:17:00,469 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2022-08-22 01:17:00,469 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2022-08-22 01:17:00,477 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2022-08-22 01:17:00,478 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2022-08-22 01:17:00,479 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2022-08-22 01:17:00,499 [pool-16-thread-1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: set configuration 0: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-22 01:17:00,499 [pool-16-thread-1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/current/log_inprogress_0
scm1.org_1   | 2022-08-22 01:17:00,502 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-22 01:17:00,502 [pool-16-thread-1] INFO segmented.SegmentedRaftLogWorker: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2022-08-22 01:17:00,546 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2022-08-22 01:17:00,546 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2022-08-22 01:17:00,547 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2022-08-22 01:17:00,547 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2022-08-22 01:17:00,577 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2022-08-22 01:17:00,577 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2022-08-22 01:17:00,615 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-08-22 01:17:00,621 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2022-08-22 01:17:00,627 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2022-08-22 01:17:00,628 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2022-08-22 01:17:00,628 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2022-08-22 01:17:00,631 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2022-08-22 01:17:00,631 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2022-08-22 01:17:00,631 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2022-08-22 01:17:00,791 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm1.org_1   | 2022-08-22 01:17:00,961 [main] INFO reflections.Reflections: Reflections took 142 ms to scan 3 urls, producing 110 keys and 247 values 
scm1.org_1   | 2022-08-22 01:17:01,045 [main] INFO ha.SequenceIdGenerator: upgrade localId to 109611004723200000
scm1.org_1   | 2022-08-22 01:17:01,046 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm1.org_1   | 2022-08-22 01:17:01,050 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2022-08-22 01:17:01,052 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2022-08-22 01:17:01,116 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2022-08-22 01:17:01,134 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2022-08-22 01:17:01,135 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm1.org_1   | 2022-08-22 01:17:01,145 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
om3_1        | 2022-08-22 01:27:41,506 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,507 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,520 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,521 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,521 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,522 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,523 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,525 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,524 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,536 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,537 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg60 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,549 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg61 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,554 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,558 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,568 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,561 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,561 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,561 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,587 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,589 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,597 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,594 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,591 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg55 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,623 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg58 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,631 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg63 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,637 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,640 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,660 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg56 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,664 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg54 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,666 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,677 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg62 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,679 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg57 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,680 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg59 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,684 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg65 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,685 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg64 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,689 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,693 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,702 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,717 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg66 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,735 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,739 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,767 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg67 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,769 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg68 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,782 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,783 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,785 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
recon_1      | 2022-08-22 01:25:18,727 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41374
recon_1      | 2022-08-22 01:25:18,753 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40006
recon_1      | 2022-08-22 01:25:18,771 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:25:18,779 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:25:18,825 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:25:26,174 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:25:26,174 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:25:26,216 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
scm3.org_1   | 2022-08-22 01:18:01,634 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2022-08-22 01:18:01,634 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2022-08-22 01:18:01,638 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm3.org_1   | 2022-08-22 01:18:13,997 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:18:14,205 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:18:17,324 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:18:21,919 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:18:22,310 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:18:24,510 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:18:38,347 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36898
scm3.org_1   | 2022-08-22 01:18:38,423 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:18:39,113 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42536
scm3.org_1   | 2022-08-22 01:18:39,389 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:18:42,409 [IPC Server handler 42 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3c60044e-b181-445f-8fa2-782a9e9eb45c
scm3.org_1   | 2022-08-22 01:18:42,440 [IPC Server handler 42 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171021466938, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-08-22 01:18:42,512 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-08-22 01:18:42,551 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2022-08-22 01:18:42,862 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55926
scm3.org_1   | 2022-08-22 01:18:42,873 [IPC Server handler 88 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/61e48a95-a5d7-43eb-addf-1603d4744f3f
scm3.org_1   | 2022-08-22 01:18:42,908 [IPC Server handler 88 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171297874022, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-08-22 01:18:42,908 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-08-22 01:18:42,922 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm3.org_1   | 2022-08-22 01:18:42,936 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:18:43,814 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: c5d0a770-5809-48a9-a307-ee9a9d2c444e, Nodes: 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:42.911Z[UTC]].
scm3.org_1   | 2022-08-22 01:18:43,927 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:18:44,310 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 23fafdf1-808a-47f3-a6c2-33e77642bffd, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:43.865Z[UTC]].
scm3.org_1   | 2022-08-22 01:18:44,342 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:18:46,310 [IPC Server handler 52 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3100efb7-0525-45d4-a0fd-e73779181107
scm3.org_1   | 2022-08-22 01:18:46,313 [IPC Server handler 52 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1174539974108, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2022-08-22 01:18:46,313 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm3.org_1   | 2022-08-22 01:18:46,314 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm3.org_1   | 2022-08-22 01:18:46,314 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm3.org_1   | 2022-08-22 01:18:46,314 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
s3g_1        | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1        | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
s3g_1        | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
s3g_1        | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
s3g_1        | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1        | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1        | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
s3g_1        | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
s3g_1        | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
s3g_1        | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
s3g_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
s3g_1        | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #197 timeout 180s
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:384)
s3g_1        | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:389)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:384)
s3g_1        | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:373)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1        | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1        | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1        | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1        | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1        | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1        | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1        | 	... 1 more
s3g_1        | 2022-08-22 01:37:18,444 [qtp1122233828-78] INFO scm.XceiverClientRatis: Could not commit index 142 on pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]] to all the nodes. Server 61e48a95-a5d7-43eb-addf-1603d4744f3f has failed. Committed by majority.
s3g_1        | 2022-08-22 01:37:18,444 [qtp1122233828-78] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 109611004723200058 bcsId: 142 on Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]]. Failed nodes: [61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: null, host: null, ports: [], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1        | 2022-08-22 01:37:28,094 [qtp1122233828-78] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-2019065808, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
s3g_1        | 2022-08-22 01:37:54,253 [qtp1122233828-85] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-ozone-test-0209209266, with server-side default bucket layout, testuser as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:25:48,677 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41654
scm2.org_1   | 2022-08-22 01:24:18,816 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:24:18,822 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:24:18,832 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:24:48,669 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36576
scm2.org_1   | 2022-08-22 01:24:48,704 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60848
scm2.org_1   | 2022-08-22 01:24:48,707 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60190
scm2.org_1   | 2022-08-22 01:24:48,726 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:24:48,749 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:24:48,760 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:25:18,665 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36710
scm2.org_1   | 2022-08-22 01:25:18,707 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:25:18,724 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:60980
scm2.org_1   | 2022-08-22 01:25:18,755 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60316
scm2.org_1   | 2022-08-22 01:25:18,789 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:25:18,825 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:25:48,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33028
scm2.org_1   | 2022-08-22 01:25:48,721 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60600
scm2.org_1   | 2022-08-22 01:25:48,722 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:36996
scm2.org_1   | 2022-08-22 01:25:48,732 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:25:48,754 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:25:48,758 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:26:18,698 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37102
scm2.org_1   | 2022-08-22 01:26:18,699 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60720
scm2.org_1   | 2022-08-22 01:26:18,744 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:26:18,745 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33130
scm2.org_1   | 2022-08-22 01:26:18,747 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:26:18,804 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:26:48,696 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60828
scm2.org_1   | 2022-08-22 01:26:48,740 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33260
scm2.org_1   | 2022-08-22 01:26:48,747 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:26:48,792 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37242
scm2.org_1   | 2022-08-22 01:26:48,800 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:26:48,810 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:27:18,707 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37354
scm2.org_1   | 2022-08-22 01:27:18,722 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60966
scm2.org_1   | 2022-08-22 01:27:18,733 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33394
scm2.org_1   | 2022-08-22 01:27:18,761 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:27:18,789 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:27:18,803 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:27:27,996 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-22 01:27:48,690 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:32854
scm2.org_1   | 2022-08-22 01:27:48,725 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:27:48,739 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33518
scm2.org_1   | 2022-08-22 01:27:48,748 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37478
scm2.org_1   | 2022-08-22 01:27:48,753 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:27:48,786 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:28:18,717 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33010
scm2.org_1   | 2022-08-22 01:28:18,743 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37624
scm2.org_1   | 2022-08-22 01:28:18,746 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33654
scm2.org_1   | 2022-08-22 01:28:18,778 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:28:18,780 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:28:18,797 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:28:48,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37768
scm2.org_1   | 2022-08-22 01:28:48,702 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33802
scm2.org_1   | 2022-08-22 01:28:48,708 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:28:48,725 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:28:48,738 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33156
scm2.org_1   | 2022-08-22 01:28:48,761 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:29:18,698 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33286
scm2.org_1   | 2022-08-22 01:29:18,728 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33930
scm2.org_1   | 2022-08-22 01:29:18,747 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37900
scm2.org_1   | 2022-08-22 01:29:18,756 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:29:18,766 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:29:18,787 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:29:48,673 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34054
scm2.org_1   | 2022-08-22 01:29:48,688 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:29:48,723 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33394
scm2.org_1   | 2022-08-22 01:29:48,739 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38012
scm2.org_1   | 2022-08-22 01:29:48,752 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:29:48,781 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:30:18,689 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38098
scm2.org_1   | 2022-08-22 01:30:18,693 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33466
scm2.org_1   | 2022-08-22 01:30:18,716 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:30:18,733 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34128
scm2.org_1   | 2022-08-22 01:30:18,767 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:18:46,315 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-08-22 01:18:46,317 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm3.org_1   | 2022-08-22 01:18:46,318 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2022-08-22 01:18:46,413 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 23fafdf1-808a-47f3-a6c2-33e77642bffd, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:61e48a95-a5d7-43eb-addf-1603d4744f3f, CreationTimestamp2022-08-22T01:18:43.865Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-22 01:18:46,556 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6bb8ab60-60a4-4383-9c3b-7719fba37020, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:46.397Z[UTC]].
scm3.org_1   | 2022-08-22 01:18:46,587 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:18:46,802 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]].
scm3.org_1   | 2022-08-22 01:18:46,807 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:18:46,903 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:18:47,230 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 85ae3250-a1a7-4fa0-96fb-c7ffd18c9838, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:46.948Z[UTC]].
scm3.org_1   | 2022-08-22 01:18:47,230 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:18:49,981 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6bb8ab60-60a4-4383-9c3b-7719fba37020, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.397Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-22 01:18:50,085 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:18:50,854 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-22 01:18:52,354 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-22 01:18:55,411 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36952
scm3.org_1   | 2022-08-22 01:18:55,478 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:18:55,765 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-22 01:18:57,411 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-22 01:17:01,230 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm1.org_1   | 2022-08-22 01:17:01,230 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm1.org_1   | 2022-08-22 01:17:01,236 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm1.org_1   | 2022-08-22 01:17:01,237 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm1.org_1   | 2022-08-22 01:17:01,240 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm1.org_1   | 2022-08-22 01:17:01,240 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm1.org_1   | 2022-08-22 01:17:01,246 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm1.org_1   | 2022-08-22 01:17:01,246 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm1.org_1   | 2022-08-22 01:17:01,280 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2022-08-22 01:17:01,302 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2022-08-22 01:17:01,347 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2022-08-22 01:17:01,371 [main] INFO UnderReplicatedQueueThread: Starting UnderReplicatedQueueThread Service.
scm1.org_1   | 2022-08-22 01:17:01,372 [main] INFO ha.SCMServiceManager: Registering service UnderReplicatedQueueThread.
scm1.org_1   | 2022-08-22 01:17:01,376 [main] INFO OverReplicatedQueueThread: Starting OverReplicatedQueueThread Service.
scm1.org_1   | 2022-08-22 01:17:01,375 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-08-22 01:17:01,377 [main] INFO ha.SCMServiceManager: Registering service OverReplicatedQueueThread.
scm1.org_1   | 2022-08-22 01:17:01,377 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2022-08-22 01:17:01,389 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm1.org_1   | 2022-08-22 01:17:01,394 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:17:01,396 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-08-22 01:17:01,433 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-08-22 01:17:01,443 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2022-08-22 01:17:01,445 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 1085506235870 on primary SCM
scm1.org_1   | 2022-08-22 01:17:01,451 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm1.org_1   | 2022-08-22 01:17:01,483 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-08-22 01:17:01,523 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2022-08-22 01:17:02,242 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-08-22 01:17:02,250 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-08-22 01:17:02,252 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm1.org_1   | 2022-08-22 01:17:02,280 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-08-22 01:17:02,284 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-08-22 01:17:02,288 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2022-08-22 01:17:02,357 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2022-08-22 01:17:02,375 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2022-08-22 01:17:02,387 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm1.org_1   | 2022-08-22 01:17:02,493 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm1.org_1   | 2022-08-22 01:17:02,494 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | Container Balancer status:
scm1.org_1   | Key                            Value
scm1.org_1   | Running                        false
scm1.org_1   | Container Balancer Configuration values:
scm1.org_1   | Key                                                Value
scm1.org_1   | Threshold                                          10
scm1.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm1.org_1   | Max Size to Move per Iteration                     500GB
scm1.org_1   | Max Size Entering Target per Iteration             26GB
scm1.org_1   | Max Size Leaving Source per Iteration              26GB
scm1.org_1   | 
scm1.org_1   | 2022-08-22 01:17:02,494 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-08-22 01:17:02,494 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm1.org_1   | 2022-08-22 01:17:02,504 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm1.org_1   | 2022-08-22 01:17:02,505 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm1.org_1   | 2022-08-22 01:17:02,506 [e5262d73-6b1c-4541-a42b-1a92d56a8751-impl-thread1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: start as a follower, conf=0: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-22 01:17:02,506 [e5262d73-6b1c-4541-a42b-1a92d56a8751-impl-thread1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm1.org_1   | 2022-08-22 01:17:02,507 [e5262d73-6b1c-4541-a42b-1a92d56a8751-impl-thread1] INFO impl.RoleInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751: start e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState
scm1.org_1   | 2022-08-22 01:17:02,516 [e5262d73-6b1c-4541-a42b-1a92d56a8751-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0782CA3657A5,id=e5262d73-6b1c-4541-a42b-1a92d56a8751
scm1.org_1   | 2022-08-22 01:17:02,519 [Listener at 0.0.0.0/9860] INFO server.RaftServer: e5262d73-6b1c-4541-a42b-1a92d56a8751: start RPC server
scm1.org_1   | 2022-08-22 01:17:02,582 [Listener at 0.0.0.0/9860] INFO server.GrpcService: e5262d73-6b1c-4541-a42b-1a92d56a8751: GrpcService started, listening on 9894
scm1.org_1   | 2022-08-22 01:17:02,589 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-08-22 01:17:02,589 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm1.org_1   | 2022-08-22 01:17:02,590 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2022-08-22 01:17:02,590 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating the current master key for generating tokens
scm1.org_1   | 2022-08-22 01:17:02,590 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$485/0x0000000840552840@6dccdc50] INFO util.JvmPauseMonitor: JvmPauseMonitor-e5262d73-6b1c-4541-a42b-1a92d56a8751: Started
scm1.org_1   | 2022-08-22 01:17:02,745 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2022-08-22 01:17:02,772 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2022-08-22 01:17:02,776 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2022-08-22 01:17:03,013 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2022-08-22 01:17:03,014 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-08-22 01:17:03,015 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm1.org_1   | 2022-08-22 01:17:03,036 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm1.org_1   | 2022-08-22 01:17:03,061 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm1.org_1   | 2022-08-22 01:17:03,063 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-08-22 01:17:03,064 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm1.org_1   | 2022-08-22 01:17:03,090 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2022-08-22 01:17:03,091 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-08-22 01:17:03,091 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm1.org_1   | 2022-08-22 01:17:03,092 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2022-08-22 01:17:03,251 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61ee9672] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2022-08-22 01:17:03,315 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2022-08-22 01:17:03,316 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2022-08-22 01:17:03,317 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | 2022-08-22 01:17:03,383 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @7033ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2022-08-22 01:17:03,400 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:58296
scm1.org_1   | 2022-08-22 01:17:03,434 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:17:03,587 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm1.org_1   | 2022-08-22 01:17:03,600 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm1.org_1   | 2022-08-22 01:17:03,606 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2022-08-22 01:17:03,607 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm1.org_1   | 2022-08-22 01:17:03,607 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2022-08-22 01:17:03,612 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
om3_1        | 2022-08-22 01:27:41,785 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,787 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,786 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,803 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,803 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,805 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,804 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,804 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,812 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,813 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,815 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,815 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,816 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,816 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,816 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,818 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,832 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg72 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,837 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,839 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg71 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,846 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg76 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,863 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg74 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,888 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg70 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,890 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg78 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,890 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg69 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,904 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg73 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,907 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,908 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg75 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,925 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg77 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:41,935 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,935 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,936 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,939 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,960 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,965 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,966 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,966 [IPC Server handler 94 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,965 [IPC Server handler 93 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,967 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,983 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,984 [IPC Server handler 7 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,987 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,988 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,994 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,997 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,998 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,997 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:41,995 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,000 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg82 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,022 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg79 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,026 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg84 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,030 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg81 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,036 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg80 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,039 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg88 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,048 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg85 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,066 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg83 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,067 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg87 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,077 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,089 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg86 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,118 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,122 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,120 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,121 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,120 [IPC Server handler 8 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,147 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,151 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,151 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,148 [IPC Server handler 41 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,154 [IPC Server handler 43 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,160 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg91 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,164 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,167 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,172 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,173 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,173 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,176 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,188 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,192 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,193 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,212 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg95 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,218 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg92 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,229 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg90 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,233 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,237 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg98 of layout LEGACY in volume: s3v
scm3.org_1   | 2022-08-22 01:18:58,555 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-22 01:18:58,557 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-22 01:18:58,665 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm3.org_1   | 2022-08-22 01:18:59,008 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm3.org_1   | 2022-08-22 01:18:59,008 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm3.org_1   | 2022-08-22 01:18:59,008 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm3.org_1   | 2022-08-22 01:18:59,008 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm3.org_1   | 2022-08-22 01:18:59,008 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm3.org_1   | 2022-08-22 01:18:59,008 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm3.org_1   | 2022-08-22 01:19:14,960 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37020
scm3.org_1   | 2022-08-22 01:19:14,983 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:19:14,984 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c5d0a770-5809-48a9-a307-ee9a9d2c444e, Nodes: 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3c60044e-b181-445f-8fa2-782a9e9eb45c, CreationTimestamp2022-08-22T01:18:42.911Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-22 01:19:29,069 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56076
scm3.org_1   | 2022-08-22 01:19:29,096 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:19:29,642 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42710
scm3.org_1   | 2022-08-22 01:19:29,751 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:19:30,007 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 85ae3250-a1a7-4fa0-96fb-c7ffd18c9838, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:61e48a95-a5d7-43eb-addf-1603d4744f3f, CreationTimestamp2022-08-22T01:18:46.948Z[UTC]] moved to OPEN state
scm3.org_1   | 2022-08-22 01:19:50,086 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37142
scm3.org_1   | 2022-08-22 01:19:50,110 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:19:59,063 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56198
scm3.org_1   | 2022-08-22 01:19:59,094 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:19:59,779 [d6d7ecb5-2d4f-4c0f-84db-7d6627418147@group-0782CA3657A5-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm3.org_1   | 2022-08-22 01:20:00,050 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42830
scm3.org_1   | 2022-08-22 01:20:00,072 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:20:03,632 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37224
scm3.org_1   | 2022-08-22 01:20:03,738 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:20:33,344 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56332
scm2.org_1   | 2022-08-22 01:30:18,772 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:30:48,685 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34224
scm2.org_1   | 2022-08-22 01:30:48,699 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33552
scm2.org_1   | 2022-08-22 01:30:48,714 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:30:48,719 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:30:48,754 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38180
scm2.org_1   | 2022-08-22 01:30:48,772 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:31:18,657 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38264
scm2.org_1   | 2022-08-22 01:31:18,670 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34294
scm2.org_1   | 2022-08-22 01:31:18,722 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:31:18,727 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:31:18,754 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33648
scm2.org_1   | 2022-08-22 01:31:18,766 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:31:48,677 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33732
scm2.org_1   | 2022-08-22 01:31:48,698 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34380
scm2.org_1   | 2022-08-22 01:31:48,708 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38348
scm2.org_1   | 2022-08-22 01:31:48,711 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:31:48,733 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:31:48,755 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:32:18,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38464
scm2.org_1   | 2022-08-22 01:32:18,680 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34506
scm2.org_1   | 2022-08-22 01:32:18,698 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:32:18,730 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:32:18,759 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33838
scm2.org_1   | 2022-08-22 01:32:18,766 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:32:27,997 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-22 01:32:48,688 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33902
scm2.org_1   | 2022-08-22 01:32:48,728 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38550
scm2.org_1   | 2022-08-22 01:32:48,735 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34564
scm2.org_1   | 2022-08-22 01:32:48,742 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:32:48,745 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:32:48,761 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:33:18,652 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38624
scm2.org_1   | 2022-08-22 01:33:18,667 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34652
scm2.org_1   | 2022-08-22 01:33:18,705 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:33984
scm2.org_1   | 2022-08-22 01:33:18,722 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:33:18,751 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:33:18,769 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-08-22 01:25:48,710 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60322
recon_1      | 2022-08-22 01:25:48,718 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:25:48,725 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40298
recon_1      | 2022-08-22 01:25:48,753 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:25:48,757 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:26:18,690 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60430
recon_1      | 2022-08-22 01:26:18,692 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41758
recon_1      | 2022-08-22 01:26:18,698 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40406
recon_1      | 2022-08-22 01:26:18,714 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:26:18,740 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:26:18,804 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:26:26,218 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:26:26,218 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:26:26,311 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
scm1.org_1   | 2022-08-22 01:17:03,677 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm1.org_1   | 2022-08-22 01:17:03,679 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.14.1+1-LTS
scm1.org_1   | 2022-08-22 01:17:03,721 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm1.org_1   | 2022-08-22 01:17:03,722 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm1.org_1   | 2022-08-22 01:17:03,723 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm1.org_1   | 2022-08-22 01:17:03,742 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-08-22 01:17:03,746 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@762261fd{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm1.org_1   | 2022-08-22 01:17:03,748 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7e5b449c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | 2022-08-22 01:17:03,835 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2022-08-22 01:17:03,849 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3aee72d8{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0-SNAPSHOT_jar-_-any-5044873948820232635/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2022-08-22 01:17:03,856 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@3aede2ff{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm1.org_1   | 2022-08-22 01:17:03,856 [Listener at 0.0.0.0/9860] INFO server.Server: Started @7507ms
scm1.org_1   | 2022-08-22 01:17:03,866 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm1.org_1   | 2022-08-22 01:17:03,866 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm1.org_1   | 2022-08-22 01:17:03,868 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2022-08-22 01:17:04,032 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35313
scm1.org_1   | 2022-08-22 01:17:04,076 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm2.org_1   | 2022-08-22 01:33:48,655 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34712
scm2.org_1   | 2022-08-22 01:33:48,692 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:33:48,716 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38698
scm2.org_1   | 2022-08-22 01:33:48,717 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34052
scm2.org_1   | 2022-08-22 01:33:48,756 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:33:48,791 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:34:18,682 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34134
scm2.org_1   | 2022-08-22 01:34:18,706 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34806
scm2.org_1   | 2022-08-22 01:34:18,717 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38772
scm2.org_1   | 2022-08-22 01:34:18,733 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:34:18,740 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:34:18,758 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:34:48,670 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34204
scm2.org_1   | 2022-08-22 01:34:48,686 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34876
scm2.org_1   | 2022-08-22 01:34:48,723 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:34:48,742 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:34:48,746 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38838
scm2.org_1   | 2022-08-22 01:34:48,761 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:35:18,664 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38920
scm2.org_1   | 2022-08-22 01:35:18,678 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34280
scm2.org_1   | 2022-08-22 01:35:18,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34948
scm2.org_1   | 2022-08-22 01:35:18,700 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:35:18,725 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:35:18,759 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:35:48,731 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35020
scm2.org_1   | 2022-08-22 01:35:48,732 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34356
scm2.org_1   | 2022-08-22 01:35:48,733 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:38982
scm2.org_1   | 2022-08-22 01:35:48,744 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:35:48,755 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:35:48,762 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:36:18,668 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35100
scm2.org_1   | 2022-08-22 01:36:18,690 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34442
scm2.org_1   | 2022-08-22 01:36:18,697 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39070
scm2.org_1   | 2022-08-22 01:36:18,722 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:36:18,752 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:36:18,767 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:36:48,695 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34502
scm2.org_1   | 2022-08-22 01:36:48,705 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35176
scm2.org_1   | 2022-08-22 01:36:48,749 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39136
scm3.org_1   | 2022-08-22 01:20:33,381 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:20:33,536 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37332
scm3.org_1   | 2022-08-22 01:20:33,562 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:20:33,707 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:42974
scm3.org_1   | 2022-08-22 01:20:33,748 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:21:03,327 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56448
scm3.org_1   | 2022-08-22 01:21:03,378 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:21:03,534 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37450
scm3.org_1   | 2022-08-22 01:21:03,588 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:21:03,678 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43090
scm3.org_1   | 2022-08-22 01:21:03,736 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:21:18,700 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37530
scm3.org_1   | 2022-08-22 01:21:18,714 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56536
scm3.org_1   | 2022-08-22 01:21:18,717 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:21:18,801 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:21:18,817 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43148
scm3.org_1   | 2022-08-22 01:21:18,853 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:21:48,761 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43278
scm3.org_1   | 2022-08-22 01:21:48,762 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56644
scm3.org_1   | 2022-08-22 01:21:48,764 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37638
scm3.org_1   | 2022-08-22 01:21:48,769 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:21:48,783 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:21:48,806 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:22:18,723 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37776
scm3.org_1   | 2022-08-22 01:22:18,731 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43392
scm3.org_1   | 2022-08-22 01:22:18,765 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:22:18,780 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:22:18,794 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56770
scm3.org_1   | 2022-08-22 01:22:18,807 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:22:44,534 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-22 01:22:48,723 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37880
scm3.org_1   | 2022-08-22 01:22:48,740 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43502
scm3.org_1   | 2022-08-22 01:22:48,776 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:22:48,799 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:22:48,829 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:56894
scm3.org_1   | 2022-08-22 01:22:48,882 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:23:18,683 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43644
scm3.org_1   | 2022-08-22 01:23:18,751 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:26:48,660 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41880
recon_1      | 2022-08-22 01:26:48,697 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:26:48,699 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40518
recon_1      | 2022-08-22 01:26:48,732 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60574
recon_1      | 2022-08-22 01:26:48,799 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:26:48,815 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:27:18,681 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60686
recon_1      | 2022-08-22 01:27:18,717 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40652
recon_1      | 2022-08-22 01:27:18,723 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42022
recon_1      | 2022-08-22 01:27:18,757 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:27:18,761 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:27:18,791 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:27:25,779 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds to process 0 existing database records.
recon_1      | 2022-08-22 01:27:25,783 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 4 milliseconds for processing 2 containers.
recon_1      | 2022-08-22 01:27:26,002 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-08-22 01:27:26,006 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 33 milliseconds.
recon_1      | 2022-08-22 01:27:26,326 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:27:26,326 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:27:26,377 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 2022-08-22 01:36:48,753 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:36:48,759 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:36:48,779 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:37:18,675 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39218
scm2.org_1   | 2022-08-22 01:37:18,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35248
scm2.org_1   | 2022-08-22 01:37:18,751 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:37:18,783 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:37:18,813 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34604
scm2.org_1   | 2022-08-22 01:37:18,835 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:37:27,997 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2022-08-22 01:37:48,700 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39342
scm2.org_1   | 2022-08-22 01:37:48,717 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35382
scm2.org_1   | 2022-08-22 01:37:48,726 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:37:48,734 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34724
scm2.org_1   | 2022-08-22 01:37:48,744 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:37:48,767 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:38:18,781 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35470
scm2.org_1   | 2022-08-22 01:38:18,800 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:34810
scm2.org_1   | 2022-08-22 01:38:18,838 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:38:18,859 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:39432
scm2.org_1   | 2022-08-22 01:38:18,859 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2022-08-22 01:38:18,901 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2022-08-22 01:27:42,257 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 24797460233419ce95c47aeca2e5480260eaed56ed8d67e92d5e7a38e776a803
om3_1        | 2022-08-22 01:27:42,260 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg93 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,268 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg94 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,270 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg89 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,277 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg96 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,279 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg97 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:42,303 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: s3bg99 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:46,769 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33548
scm1.org_1   | 2022-08-22 01:17:04,178 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.25.0.115:35313
scm1.org_1   | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:e5262d73-6b1c-4541-a42b-1a92d56a8751 is not the leader. Could not determine the leader node.
scm1.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
scm1.org_1   | 2022-08-22 01:17:06,906 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40434
scm1.org_1   | 2022-08-22 01:17:06,918 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:17:07,635 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState] INFO impl.FollowerState: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5128416476ns, electionTimeout:5119ms
scm1.org_1   | 2022-08-22 01:17:07,636 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState] INFO impl.RoleInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751: shutdown e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState
scm1.org_1   | 2022-08-22 01:17:07,637 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm1.org_1   | 2022-08-22 01:17:07,640 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm1.org_1   | 2022-08-22 01:17:07,640 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-FollowerState] INFO impl.RoleInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751: start e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1
scm1.org_1   | 2022-08-22 01:17:07,655 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO impl.LeaderElection: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-22 01:17:07,656 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO impl.LeaderElection: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm1.org_1   | 2022-08-22 01:17:07,656 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO impl.RoleInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751: shutdown e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1
scm1.org_1   | 2022-08-22 01:17:07,657 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm1.org_1   | 2022-08-22 01:17:07,657 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm1.org_1   | 2022-08-22 01:17:07,657 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm1.org_1   | 2022-08-22 01:17:07,659 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: change Leader from null to e5262d73-6b1c-4541-a42b-1a92d56a8751 at term 2 for becomeLeader, leader elected after 7326ms
scm1.org_1   | 2022-08-22 01:17:07,664 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2022-08-22 01:17:07,667 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-08-22 01:17:07,668 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2022-08-22 01:17:07,672 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2022-08-22 01:17:07,672 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2022-08-22 01:17:07,673 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2022-08-22 01:17:07,677 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2022-08-22 01:17:07,678 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2022-08-22 01:17:07,679 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO impl.RoleInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751: start e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderStateImpl
scm1.org_1   | 2022-08-22 01:17:07,729 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm1.org_1   | 2022-08-22 01:17:07,733 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/current/log_inprogress_0 to /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/current/log_0-0
scm1.org_1   | 2022-08-22 01:17:07,760 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderElection1] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: set configuration 1: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-22 01:17:07,777 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/b7b9d2d2-be60-416a-87ab-0782ca3657a5/current/log_inprogress_1
scm1.org_1   | 2022-08-22 01:17:07,784 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm1.org_1   | 2022-08-22 01:17:07,787 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm1.org_1   | 2022-08-22 01:17:07,795 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:17:07,796 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2022-08-22 01:17:07,797 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2022-08-22 01:17:07,797 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2022-08-22 01:17:07,802 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2022-08-22 01:17:07,819 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2022-08-22 01:17:10,222 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: 03572105-3616-4cb9-be90-2b90b909c2fa
scm1.org_1   | 2022-08-22 01:17:10,416 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:17:10,416 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2022-08-22 01:17:10,416 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm1.org_1   | 2022-08-22 01:17:15,151 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:39182
scm1.org_1   | 2022-08-22 01:17:15,161 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:17:15,162 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: 613adbf7-7795-42d5-82ba-29b8ddf9dabc
scm1.org_1   | 2022-08-22 01:17:16,446 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:17:24,817 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41077
scm1.org_1   | 2022-08-22 01:17:24,840 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:17:26,884 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40748
scm1.org_1   | 2022-08-22 01:17:26,921 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:17:29,367 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:58730
scm1.org_1   | 2022-08-22 01:17:29,391 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:17:29,393 [IPC Server handler 0 on default port 9863] INFO ha.SCMRatisServerImpl: e5262d73-6b1c-4541-a42b-1a92d56a8751: Submitting SetConfiguration request to Ratis server with new SCM peers list: [e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-08-22 01:17:29,395 [IPC Server handler 0 on default port 9863] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: receive setConfiguration SetConfigurationRequest:client-1B1875F391A4->e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5, cid=1, seq=0, RW, null, peers:[e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-08-22 01:17:29,395 [IPC Server handler 0 on default port 9863] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-1B1875F391A4->e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5, cid=1, seq=0, RW, null, peers:[e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, 613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|priority:0]
scm1.org_1   | 2022-08-22 01:17:29,407 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-08-22 01:17:29,407 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-22 01:17:29,408 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-08-22 01:17:29,415 [IPC Server handler 0 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2022-08-22 01:17:29,416 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-08-22 01:17:29,416 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-08-22 01:17:29,424 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->613adbf7-7795-42d5-82ba-29b8ddf9dabc-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->613adbf7-7795-42d5-82ba-29b8ddf9dabc-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2022-08-22 01:17:29,432 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->613adbf7-7795-42d5-82ba-29b8ddf9dabc-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->613adbf7-7795-42d5-82ba-29b8ddf9dabc-GrpcLogAppender: send e5262d73-6b1c-4541-a42b-1a92d56a8751->613adbf7-7795-42d5-82ba-29b8ddf9dabc#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2022-08-22 01:23:18,784 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57008
scm3.org_1   | 2022-08-22 01:23:18,793 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38016
scm3.org_1   | 2022-08-22 01:23:18,805 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:23:18,823 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:23:48,709 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43746
scm3.org_1   | 2022-08-22 01:23:48,725 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57138
scm3.org_1   | 2022-08-22 01:23:48,727 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38132
scm3.org_1   | 2022-08-22 01:23:48,739 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:23:48,751 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:23:48,772 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:24:18,723 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38256
scm3.org_1   | 2022-08-22 01:24:18,752 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57262
scm3.org_1   | 2022-08-22 01:24:18,753 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:24:18,759 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43892
scm3.org_1   | 2022-08-22 01:24:18,797 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:24:18,821 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:24:48,741 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:43998
scm3.org_1   | 2022-08-22 01:24:48,753 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38382
scm3.org_1   | 2022-08-22 01:24:48,772 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:24:48,780 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57382
scm3.org_1   | 2022-08-22 01:24:48,787 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:24:48,796 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:25:18,673 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44126
scm3.org_1   | 2022-08-22 01:25:18,743 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38510
scm3.org_1   | 2022-08-22 01:25:18,754 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57514
scm3.org_1   | 2022-08-22 01:25:18,789 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:25:18,797 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:25:18,826 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:25:48,675 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38790
scm3.org_1   | 2022-08-22 01:25:48,694 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:25:48,723 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44414
scm3.org_1   | 2022-08-22 01:25:48,767 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57786
scm3.org_1   | 2022-08-22 01:25:48,779 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:25:48,782 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:26:18,700 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57910
scm3.org_1   | 2022-08-22 01:26:18,732 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38896
scm3.org_1   | 2022-08-22 01:26:18,754 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:26:18,772 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44518
om3_1        | 2022-08-22 01:27:46,773 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:27:50,179 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:50,182 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:50,193 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-5441601222 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:27:50,919 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:50,924 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:50,928 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:51,632 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:51,635 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:51,660 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:53,092 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:53,787 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:53,791 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:53,814 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:54,080 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:54,765 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:54,768 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:55,391 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:55,393 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:56,381 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:56,384 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:56,389 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:57,064 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:57,066 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:57,071 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:57,832 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:57,835 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:57,861 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:58,249 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:58,992 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:58,996 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:27:59,017 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:00,658 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:01,309 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:01,314 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:01,317 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:02,083 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:02,088 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:02,109 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:03,198 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:03,907 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:03,910 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:03,928 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:05,668 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:06,343 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
scm3.org_1   | 2022-08-22 01:26:18,787 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:26:18,817 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:26:48,651 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39026
scm3.org_1   | 2022-08-22 01:26:48,698 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:26:48,700 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58020
scm3.org_1   | 2022-08-22 01:26:48,734 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44660
scm3.org_1   | 2022-08-22 01:26:48,794 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:26:48,811 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:27:18,685 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44778
scm3.org_1   | 2022-08-22 01:27:18,711 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58162
scm3.org_1   | 2022-08-22 01:27:18,745 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39156
scm3.org_1   | 2022-08-22 01:27:18,775 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:27:18,780 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:27:18,797 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:27:44,534 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-22 01:27:48,750 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39280
scm3.org_1   | 2022-08-22 01:27:48,750 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:44910
scm3.org_1   | 2022-08-22 01:27:48,764 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58282
scm3.org_1   | 2022-08-22 01:27:48,767 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:27:48,777 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:27:48,784 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:28:18,681 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39416
scm3.org_1   | 2022-08-22 01:28:18,682 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45042
scm3.org_1   | 2022-08-22 01:28:18,718 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58432
scm3.org_1   | 2022-08-22 01:28:18,726 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:28:18,753 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:28:18,785 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:28:48,706 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39560
scm3.org_1   | 2022-08-22 01:28:48,732 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45190
scm3.org_1   | 2022-08-22 01:28:48,746 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:28:48,757 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58580
scm3.org_1   | 2022-08-22 01:28:48,773 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:28:48,787 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:29:18,704 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58708
scm3.org_1   | 2022-08-22 01:29:18,714 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39698
scm3.org_1   | 2022-08-22 01:29:18,718 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45340
scm3.org_1   | 2022-08-22 01:29:18,734 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:29:18,763 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:27:48,689 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40770
recon_1      | 2022-08-22 01:27:48,713 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42146
recon_1      | 2022-08-22 01:27:48,725 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60812
recon_1      | 2022-08-22 01:27:48,732 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:27:48,736 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:27:48,741 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:28:18,717 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60948
recon_1      | 2022-08-22 01:28:18,741 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:28:18,749 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42280
recon_1      | 2022-08-22 01:28:18,774 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:28:18,788 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:40928
recon_1      | 2022-08-22 01:28:18,822 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:28:26,381 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:28:26,381 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:28:26,422 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
scm3.org_1   | 2022-08-22 01:29:18,776 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:29:48,697 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58822
scm3.org_1   | 2022-08-22 01:29:48,707 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39810
scm3.org_1   | 2022-08-22 01:29:48,723 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:29:48,730 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45438
scm3.org_1   | 2022-08-22 01:29:48,757 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:29:48,785 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:30:18,699 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45512
scm3.org_1   | 2022-08-22 01:30:18,714 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58884
scm3.org_1   | 2022-08-22 01:30:18,719 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39894
scm3.org_1   | 2022-08-22 01:30:18,743 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:30:18,760 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:30:18,765 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:30:48,695 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:39986
scm3.org_1   | 2022-08-22 01:30:48,704 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:58986
scm3.org_1   | 2022-08-22 01:30:48,715 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:30:48,739 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:30:48,765 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45614
scm3.org_1   | 2022-08-22 01:30:48,789 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:31:18,686 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40056
scm3.org_1   | 2022-08-22 01:31:18,704 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59076
scm3.org_1   | 2022-08-22 01:31:18,706 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45680
scm3.org_1   | 2022-08-22 01:31:18,722 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:31:18,747 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:31:18,754 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:31:48,677 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40148
scm3.org_1   | 2022-08-22 01:31:48,707 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45766
scm3.org_1   | 2022-08-22 01:31:48,716 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59162
scm3.org_1   | 2022-08-22 01:31:48,731 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:31:48,751 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:31:48,768 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:32:18,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40272
scm3.org_1   | 2022-08-22 01:32:18,697 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:32:18,719 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45886
scm3.org_1   | 2022-08-22 01:32:18,733 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:32:18,786 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59266
scm3.org_1   | 2022-08-22 01:32:18,801 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:17:30,292 [grpc-default-executor-0] INFO server.GrpcLogAppender: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->613adbf7-7795-42d5-82ba-29b8ddf9dabc-InstallSnapshotResponseHandler: received the first reply e5262d73-6b1c-4541-a42b-1a92d56a8751<-613adbf7-7795-42d5-82ba-29b8ddf9dabc#0:FAIL-t0,ALREADY_INSTALLED
scm1.org_1   | 2022-08-22 01:17:30,294 [grpc-default-executor-0] INFO server.GrpcLogAppender: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->613adbf7-7795-42d5-82ba-29b8ddf9dabc-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2022-08-22 01:17:30,301 [grpc-default-executor-0] INFO leader.FollowerInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->613adbf7-7795-42d5-82ba-29b8ddf9dabc: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-22 01:17:30,301 [grpc-default-executor-0] INFO leader.FollowerInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->613adbf7-7795-42d5-82ba-29b8ddf9dabc: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-22 01:17:30,301 [grpc-default-executor-0] INFO leader.FollowerInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->613adbf7-7795-42d5-82ba-29b8ddf9dabc: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2022-08-22 01:17:30,301 [grpc-default-executor-0] INFO leader.FollowerInfo: Follower e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->613adbf7-7795-42d5-82ba-29b8ddf9dabc acknowledged installing snapshot
scm1.org_1   | 2022-08-22 01:17:30,301 [grpc-default-executor-0] INFO leader.FollowerInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->613adbf7-7795-42d5-82ba-29b8ddf9dabc: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2022-08-22 01:17:30,434 [grpc-default-executor-0] INFO leader.FollowerInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->613adbf7-7795-42d5-82ba-29b8ddf9dabc: nextIndex: updateUnconditionally 7 -> 0
scm1.org_1   | 2022-08-22 01:17:30,460 [grpc-default-executor-0] INFO leader.FollowerInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->613adbf7-7795-42d5-82ba-29b8ddf9dabc: nextIndex: updateUnconditionally 7 -> 0
scm1.org_1   | 2022-08-22 01:17:31,220 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderStateImpl] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: set configuration 7: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=[e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-08-22 01:17:31,249 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderStateImpl] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: set configuration 9: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0], old=null
scm1.org_1   | 2022-08-22 01:17:31,315 [IPC Server handler 0 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 613adbf7-7795-42d5-82ba-29b8ddf9dabc.
scm1.org_1   | 2022-08-22 01:17:32,979 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:39460
scm1.org_1   | 2022-08-22 01:17:32,986 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:17:34,857 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:57284
scm1.org_1   | 2022-08-22 01:17:34,889 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:17:37,185 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:33872
scm1.org_1   | 2022-08-22 01:17:37,189 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:17:37,189 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: d6d7ecb5-2d4f-4c0f-84db-7d6627418147
scm1.org_1   | 2022-08-22 01:17:37,703 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:17:38,427 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40924
scm1.org_1   | 2022-08-22 01:17:38,449 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:17:47,761 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:57458
scm1.org_1   | 2022-08-22 01:17:47,995 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:17:47,998 [IPC Server handler 37 on default port 9863] INFO ha.SCMRatisServerImpl: e5262d73-6b1c-4541-a42b-1a92d56a8751: Submitting SetConfiguration request to Ratis server with new SCM peers list: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, d6d7ecb5-2d4f-4c0f-84db-7d6627418147|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-08-22 01:17:48,001 [IPC Server handler 37 on default port 9863] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: receive setConfiguration SetConfigurationRequest:client-1B1875F391A4->e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5, cid=2, seq=0, RW, null, peers:[613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, d6d7ecb5-2d4f-4c0f-84db-7d6627418147|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-08-22 01:17:48,002 [IPC Server handler 37 on default port 9863] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-1B1875F391A4->e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5, cid=2, seq=0, RW, null, peers:[613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, d6d7ecb5-2d4f-4c0f-84db-7d6627418147|rpc:scm3.org:9894|priority:0]
scm1.org_1   | 2022-08-22 01:17:48,007 [IPC Server handler 37 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2022-08-22 01:17:48,014 [IPC Server handler 37 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2022-08-22 01:17:48,014 [IPC Server handler 37 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2022-08-22 01:17:48,033 [IPC Server handler 37 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm3.org_1   | 2022-08-22 01:32:44,535 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-22 01:32:48,706 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59330
scm3.org_1   | 2022-08-22 01:32:48,744 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:45964
scm3.org_1   | 2022-08-22 01:32:48,761 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40330
scm3.org_1   | 2022-08-22 01:32:48,763 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:32:48,764 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:32:48,802 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:33:18,705 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40420
scm3.org_1   | 2022-08-22 01:33:18,707 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59408
scm3.org_1   | 2022-08-22 01:33:18,718 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46042
scm3.org_1   | 2022-08-22 01:33:18,724 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:33:18,741 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:33:18,767 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:33:48,702 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40480
scm3.org_1   | 2022-08-22 01:33:48,710 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:33:48,739 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46114
scm3.org_1   | 2022-08-22 01:33:48,744 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59476
scm3.org_1   | 2022-08-22 01:33:48,770 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:33:48,794 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:34:18,683 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59574
scm3.org_1   | 2022-08-22 01:34:18,692 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40572
scm3.org_1   | 2022-08-22 01:34:18,733 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:34:18,745 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:34:18,754 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46186
scm3.org_1   | 2022-08-22 01:34:18,763 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:34:48,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59628
scm3.org_1   | 2022-08-22 01:34:48,685 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40636
scm3.org_1   | 2022-08-22 01:34:48,709 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:34:48,743 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46264
scm3.org_1   | 2022-08-22 01:34:48,748 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:34:48,762 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:35:18,698 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40714
scm3.org_1   | 2022-08-22 01:35:18,704 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59704
scm3.org_1   | 2022-08-22 01:35:18,707 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46334
scm3.org_1   | 2022-08-22 01:35:18,713 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:35:18,733 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:35:18,759 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:35:48,734 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59780
om3_1        | 2022-08-22 01:28:06,345 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:07,008 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:07,010 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:07,986 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:07,988 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:07,992 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:08,638 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:08,640 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:08,662 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:08,782 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:09,488 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:09,490 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:09,507 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:10,672 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:11,341 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:11,344 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:11,351 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-ozone-test-5441601222/ozone-test-7042174042/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om3_1        | 2022-08-22 01:28:11,352 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-7042174042/multipartKey2 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om3_1        | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-7042174042/multipartKey2. Entity too small.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:535)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:28:12,018 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:12,023 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:12,027 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:12,702 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:12,705 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:12,713 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om3_1        | partName: "etag1"
om3_1        | , partNumber: 2
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-08-22 01:28:12,714 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm1.org_1   | 2022-08-22 01:17:48,033 [IPC Server handler 37 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2022-08-22 01:17:48,040 [IPC Server handler 37 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2022-08-22 01:17:48,041 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->d6d7ecb5-2d4f-4c0f-84db-7d6627418147-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->d6d7ecb5-2d4f-4c0f-84db-7d6627418147-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2022-08-22 01:17:48,050 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->d6d7ecb5-2d4f-4c0f-84db-7d6627418147-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->d6d7ecb5-2d4f-4c0f-84db-7d6627418147-GrpcLogAppender: send e5262d73-6b1c-4541-a42b-1a92d56a8751->d6d7ecb5-2d4f-4c0f-84db-7d6627418147#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2022-08-22 01:17:50,486 [grpc-default-executor-1] INFO server.GrpcLogAppender: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->d6d7ecb5-2d4f-4c0f-84db-7d6627418147-InstallSnapshotResponseHandler: received the first reply e5262d73-6b1c-4541-a42b-1a92d56a8751<-d6d7ecb5-2d4f-4c0f-84db-7d6627418147#0:FAIL-t0,ALREADY_INSTALLED
scm1.org_1   | 2022-08-22 01:17:50,486 [grpc-default-executor-1] INFO server.GrpcLogAppender: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->d6d7ecb5-2d4f-4c0f-84db-7d6627418147-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2022-08-22 01:17:50,499 [grpc-default-executor-1] INFO leader.FollowerInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->d6d7ecb5-2d4f-4c0f-84db-7d6627418147: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-22 01:17:50,542 [grpc-default-executor-1] INFO leader.FollowerInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->d6d7ecb5-2d4f-4c0f-84db-7d6627418147: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2022-08-22 01:17:50,542 [grpc-default-executor-1] INFO leader.FollowerInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->d6d7ecb5-2d4f-4c0f-84db-7d6627418147: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2022-08-22 01:17:50,544 [grpc-default-executor-1] INFO leader.FollowerInfo: Follower e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->d6d7ecb5-2d4f-4c0f-84db-7d6627418147 acknowledged installing snapshot
scm1.org_1   | 2022-08-22 01:17:50,544 [grpc-default-executor-1] INFO leader.FollowerInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->d6d7ecb5-2d4f-4c0f-84db-7d6627418147: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2022-08-22 01:17:50,743 [grpc-default-executor-1] INFO leader.FollowerInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->d6d7ecb5-2d4f-4c0f-84db-7d6627418147: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2022-08-22 01:17:50,748 [grpc-default-executor-1] INFO leader.FollowerInfo: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5->d6d7ecb5-2d4f-4c0f-84db-7d6627418147: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2022-08-22 01:17:52,149 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderStateImpl] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: set configuration 13: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, d6d7ecb5-2d4f-4c0f-84db-7d6627418147|rpc:scm3.org:9894|priority:0], old=[613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0]
scm1.org_1   | 2022-08-22 01:17:52,182 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-LeaderStateImpl] INFO server.RaftServer$Division: e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5: set configuration 15: [613adbf7-7795-42d5-82ba-29b8ddf9dabc|rpc:scm2.org:9894|priority:0, e5262d73-6b1c-4541-a42b-1a92d56a8751|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0, d6d7ecb5-2d4f-4c0f-84db-7d6627418147|rpc:scm3.org:9894|priority:0], old=null
scm1.org_1   | 2022-08-22 01:17:52,251 [IPC Server handler 37 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: d6d7ecb5-2d4f-4c0f-84db-7d6627418147.
scm1.org_1   | 2022-08-22 01:17:54,934 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41090
scm1.org_1   | 2022-08-22 01:17:55,177 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:17:57,477 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:34058
scm1.org_1   | 2022-08-22 01:17:57,498 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:18:10,878 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:37790
scm1.org_1   | 2022-08-22 01:18:10,979 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:18:11,197 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:55510
scm1.org_1   | 2022-08-22 01:18:11,313 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:18:12,900 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:47722
scm1.org_1   | 2022-08-22 01:18:12,948 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:18:13,495 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37658
scm1.org_1   | 2022-08-22 01:18:13,590 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51918
scm1.org_1   | 2022-08-22 01:18:13,667 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:18:13,674 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn d60fa041091d, UUID: 3c60044e-b181-445f-8fa2-782a9e9eb45c
scm1.org_1   | 2022-08-22 01:18:13,779 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:18:13,780 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 2cdeb7efff84, UUID: 61e48a95-a5d7-43eb-addf-1603d4744f3f
scm1.org_1   | 2022-08-22 01:18:13,959 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:18:14,187 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:18:17,165 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36824
scm1.org_1   | 2022-08-22 01:18:17,195 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:18:17,195 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 07ab41f3ff0f, UUID: 3100efb7-0525-45d4-a0fd-e73779181107
scm1.org_1   | 2022-08-22 01:18:17,303 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:18:21,373 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:39966
scm1.org_1   | 2022-08-22 01:18:21,388 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:18:21,413 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: 68cc5bac-fffc-4cee-9395-816514f7bb6e
scm1.org_1   | 2022-08-22 01:18:21,653 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:48674
scm1.org_1   | 2022-08-22 01:18:21,670 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:18:21,670 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: 0f5b9cb6-da3b-47fe-b422-90e2b9454112
scm1.org_1   | 2022-08-22 01:18:21,925 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:18:22,296 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:18:24,026 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37684
scm1.org_1   | 2022-08-22 01:18:24,077 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:44774
scm1.org_1   | 2022-08-22 01:18:24,140 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:18:24,163 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51946
scm1.org_1   | 2022-08-22 01:18:24,199 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:18:24,203 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: e7090255-f709-4c90-8a9e-bc1f2b2eff12
scm1.org_1   | 2022-08-22 01:18:24,219 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:18:24,495 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:18:27,645 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36856
scm1.org_1   | 2022-08-22 01:18:27,673 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:18:32,235 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41186
scm1.org_1   | 2022-08-22 01:18:32,411 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:18:38,087 [org.apache.ratis.util.JvmPauseMonitor$$Lambda$485/0x0000000840552840@6dccdc50] WARN util.JvmPauseMonitor: JvmPauseMonitor-e5262d73-6b1c-4541-a42b-1a92d56a8751: Detected pause in JVM or host machine (eg GC): pause of approximately 118543237ns.
scm1.org_1   | GC pool 'ParNew' had collection(s): count=1 time=129ms
scm1.org_1   | 2022-08-22 01:18:38,209 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33902
scm1.org_1   | 2022-08-22 01:18:38,365 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:18:39,133 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:48936
scm1.org_1   | 2022-08-22 01:18:39,368 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:18:42,609 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50828
scm1.org_1   | 2022-08-22 01:18:42,642 [IPC Server handler 69 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3c60044e-b181-445f-8fa2-782a9e9eb45c
scm1.org_1   | 2022-08-22 01:18:42,648 [IPC Server handler 69 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171021466938, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-08-22 01:18:42,811 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:18:42,882 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-08-22 01:18:42,942 [IPC Server handler 87 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/61e48a95-a5d7-43eb-addf-1603d4744f3f
scm3.org_1   | 2022-08-22 01:35:48,736 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40786
scm3.org_1   | 2022-08-22 01:35:48,741 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46412
scm3.org_1   | 2022-08-22 01:35:48,753 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:35:48,758 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:35:48,765 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:36:18,689 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46488
scm3.org_1   | 2022-08-22 01:36:18,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59870
scm3.org_1   | 2022-08-22 01:36:18,702 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40868
scm3.org_1   | 2022-08-22 01:36:18,729 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:36:18,752 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:36:18,769 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:36:48,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46564
scm3.org_1   | 2022-08-22 01:36:48,695 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:59930
scm3.org_1   | 2022-08-22 01:36:48,717 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:40936
scm3.org_1   | 2022-08-22 01:36:48,751 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:36:48,766 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:36:48,783 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:37:18,680 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46640
scm3.org_1   | 2022-08-22 01:37:18,692 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41014
scm3.org_1   | 2022-08-22 01:37:18,707 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:37:18,732 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60026
scm3.org_1   | 2022-08-22 01:37:18,782 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:37:18,818 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:37:44,535 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2022-08-22 01:37:48,680 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41148
scm3.org_1   | 2022-08-22 01:37:48,686 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46764
scm3.org_1   | 2022-08-22 01:37:48,708 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60148
scm3.org_1   | 2022-08-22 01:37:48,721 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:37:48,740 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:37:48,766 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:38:18,724 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:41230
scm3.org_1   | 2022-08-22 01:38:18,756 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:46870
scm3.org_1   | 2022-08-22 01:38:18,776 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:38:18,801 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:60230
scm3.org_1   | 2022-08-22 01:38:18,844 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2022-08-22 01:38:18,865 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:18:43,029 [IPC Server handler 87 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1171297874022, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-08-22 01:18:43,150 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-08-22 01:18:43,169 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2022-08-22 01:18:43,298 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2022-08-22 01:18:43,346 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c5d0a770-5809-48a9-a307-ee9a9d2c444e to datanode:3c60044e-b181-445f-8fa2-782a9e9eb45c
scm1.org_1   | 2022-08-22 01:18:43,691 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: c5d0a770-5809-48a9-a307-ee9a9d2c444e, Nodes: 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:42.911Z[UTC]].
scm1.org_1   | 2022-08-22 01:18:43,720 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:18:43,865 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=23fafdf1-808a-47f3-a6c2-33e77642bffd to datanode:61e48a95-a5d7-43eb-addf-1603d4744f3f
scm1.org_1   | 2022-08-22 01:18:44,107 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 23fafdf1-808a-47f3-a6c2-33e77642bffd, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:43.865Z[UTC]].
scm1.org_1   | 2022-08-22 01:18:44,107 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:18:46,310 [IPC Server handler 45 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3100efb7-0525-45d4-a0fd-e73779181107
scm1.org_1   | 2022-08-22 01:18:46,315 [IPC Server handler 45 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1174539974108, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2022-08-22 01:18:46,317 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2022-08-22 01:18:46,317 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2022-08-22 01:18:46,319 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2022-08-22 01:18:46,322 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-08-22 01:18:46,323 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2022-08-22 01:18:46,323 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-08-22 01:18:46,397 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6bb8ab60-60a4-4383-9c3b-7719fba37020 to datanode:3100efb7-0525-45d4-a0fd-e73779181107
scm1.org_1   | 2022-08-22 01:18:46,419 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2022-08-22 01:18:46,490 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 6bb8ab60-60a4-4383-9c3b-7719fba37020, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:46.397Z[UTC]].
scm1.org_1   | 2022-08-22 01:18:46,501 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:18:46,630 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fcac9307-f9c6-4fe2-a014-be98e62d2a2a to datanode:3100efb7-0525-45d4-a0fd-e73779181107
scm1.org_1   | 2022-08-22 01:18:46,651 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fcac9307-f9c6-4fe2-a014-be98e62d2a2a to datanode:3c60044e-b181-445f-8fa2-782a9e9eb45c
scm1.org_1   | 2022-08-22 01:18:46,651 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fcac9307-f9c6-4fe2-a014-be98e62d2a2a to datanode:61e48a95-a5d7-43eb-addf-1603d4744f3f
scm1.org_1   | 2022-08-22 01:18:46,650 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42981
scm1.org_1   | 2022-08-22 01:18:46,674 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om3_1        | 2022-08-22 01:28:13,328 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:13,330 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:28:48,659 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42424
recon_1      | 2022-08-22 01:28:48,734 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:28:48,745 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:32864
recon_1      | 2022-08-22 01:28:48,758 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41072
recon_1      | 2022-08-22 01:28:48,780 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:28:48,789 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:29:18,708 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41204
recon_1      | 2022-08-22 01:29:18,720 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33006
recon_1      | 2022-08-22 01:29:18,721 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42552
recon_1      | 2022-08-22 01:29:18,753 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:29:18,775 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:29:18,787 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:29:26,425 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:29:26,425 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:29:26,458 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
om3_1        | 2022-08-22 01:28:13,339 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om3_1        | partName: "etag1"
om3_1        | , partNumber: 1
om3_1        | partName: "etag2"
om3_1        | ]
om3_1        | 2022-08-22 01:28:13,342 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:187)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:28:14,029 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:14,037 [IPC Server handler 81 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:14,058 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:14,522 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:15,366 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:15,369 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:15,394 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:18,232 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:19,148 [IPC Server handler 10 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:19,150 [IPC Server handler 36 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:19,165 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:20,736 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:21,431 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:21,434 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:21,442 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3-2d359484-8cfb-483b-aa3b-b8082765a51b-108863926568681508-1
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:28:22,064 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:22,067 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:22,076 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om3_1        | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3-2d359484-8cfb-483b-aa3b-b8082765a51b-108863926568681508-2
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getMultipartDataSize(S3MultipartUploadCompleteRequest.java:512)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:198)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:28:22,667 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:22,671 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:22,679 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-ozone-test-5441601222/ozone-test-0021973633/multipartKey3
om3_1        | 2022-08-22 01:28:22,680 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: ozone-test-0021973633/multipartKey3 in Volume/Bucket s3v/bucket-ozone-test-5441601222
om3_1        | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-ozone-test-5441601222 key: ozone-test-0021973633/multipartKey3 because parts are in Invalid order.
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.getPartsListSize(S3MultipartUploadCompleteRequest.java:478)
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:194)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:28:23,270 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:23,273 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:23,916 [IPC Server handler 71 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:23,920 [IPC Server handler 56 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:24,898 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:24,903 [IPC Server handler 72 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:24,904 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:25,581 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:25,587 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:26,195 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:26,197 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:26,206 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName ozone-test-2706775452/multipartKey5 in VolumeName/Bucket s3v/bucket-ozone-test-5441601222
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-ozone-test-5441601222key: ozone-test-2706775452/multipartKey5
om3_1        | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:161)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:29:48,642 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41306
recon_1      | 2022-08-22 01:29:48,709 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42676
recon_1      | 2022-08-22 01:29:48,720 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:29:48,733 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:29:48,736 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33106
recon_1      | 2022-08-22 01:29:48,790 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:30:18,684 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41398
recon_1      | 2022-08-22 01:30:18,725 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33208
recon_1      | 2022-08-22 01:30:18,731 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:30:18,735 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42750
recon_1      | 2022-08-22 01:30:18,773 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:30:18,786 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:30:26,461 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:30:26,461 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
scm1.org_1   | 2022-08-22 01:18:46,734 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]].
scm1.org_1   | 2022-08-22 01:18:46,772 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:18:46,785 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 23fafdf1-808a-47f3-a6c2-33e77642bffd, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:61e48a95-a5d7-43eb-addf-1603d4744f3f, CreationTimestamp2022-08-22T01:18:43.865Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-08-22 01:18:46,897 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:18:46,948 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 to datanode:61e48a95-a5d7-43eb-addf-1603d4744f3f
scm1.org_1   | 2022-08-22 01:18:47,138 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 to datanode:3c60044e-b181-445f-8fa2-782a9e9eb45c
scm1.org_1   | 2022-08-22 01:18:47,140 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 to datanode:3100efb7-0525-45d4-a0fd-e73779181107
scm1.org_1   | 2022-08-22 01:18:47,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-22 01:18:47,186 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 85ae3250-a1a7-4fa0-96fb-c7ffd18c9838, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2022-08-22T01:18:46.948Z[UTC]].
scm1.org_1   | 2022-08-22 01:18:47,229 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:18:47,241 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=85ae3250-a1a7-4fa0-96fb-c7ffd18c9838 contains same datanodes as previous pipelines: PipelineID=fcac9307-f9c6-4fe2-a014-be98e62d2a2a nodeIds: 61e48a95-a5d7-43eb-addf-1603d4744f3f, 3c60044e-b181-445f-8fa2-782a9e9eb45c, 3100efb7-0525-45d4-a0fd-e73779181107
scm1.org_1   | 2022-08-22 01:18:48,946 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:37908
scm1.org_1   | 2022-08-22 01:18:48,987 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:18:49,826 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:55628
scm1.org_1   | 2022-08-22 01:18:49,884 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:18:49,992 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 6bb8ab60-60a4-4383-9c3b-7719fba37020, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.397Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-08-22 01:18:50,034 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:18:50,044 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-22 01:18:50,832 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-22 01:18:51,467 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:47832
scm1.org_1   | 2022-08-22 01:18:51,563 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:18:52,388 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-22 01:18:55,427 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:33962
scm1.org_1   | 2022-08-22 01:18:55,492 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:18:55,803 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-22 01:18:57,396 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-22 01:18:58,511 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:40096
scm1.org_1   | 2022-08-22 01:18:58,544 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:18:58,569 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fcac9307-f9c6-4fe2-a014-be98e62d2a2a, Nodes: 3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3100efb7-0525-45d4-a0fd-e73779181107, CreationTimestamp2022-08-22T01:18:46.630Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-08-22 01:18:58,637 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm1.org_1   | 2022-08-22 01:18:58,645 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm1.org_1   | 2022-08-22 01:18:58,658 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm1.org_1   | 2022-08-22 01:18:58,658 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm1.org_1   | 2022-08-22 01:18:58,658 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm1.org_1   | 2022-08-22 01:18:58,659 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
scm1.org_1   | 2022-08-22 01:18:58,662 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm1.org_1   | 2022-08-22 01:18:58,663 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
scm1.org_1   | 2022-08-22 01:18:58,664 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
scm1.org_1   | 2022-08-22 01:18:58,664 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO UnderReplicatedQueueThread: Service UnderReplicatedQueueThread transitions to RUNNING.
scm1.org_1   | 2022-08-22 01:18:58,665 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO OverReplicatedQueueThread: Service OverReplicatedQueueThread transitions to RUNNING.
scm1.org_1   | 2022-08-22 01:18:58,666 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm1.org_1   | 2022-08-22 01:18:58,667 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
scm1.org_1   | 2022-08-22 01:18:59,419 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:48804
scm1.org_1   | 2022-08-22 01:18:59,432 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:19:01,945 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:44906
scm1.org_1   | 2022-08-22 01:19:01,986 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:19:04,639 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:41302
scm1.org_1   | 2022-08-22 01:19:04,773 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:19:14,987 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34028
scm1.org_1   | 2022-08-22 01:19:15,010 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:19:15,012 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c5d0a770-5809-48a9-a307-ee9a9d2c444e, Nodes: 3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3c60044e-b181-445f-8fa2-782a9e9eb45c, CreationTimestamp2022-08-22T01:18:42.911Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-08-22 01:19:15,040 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43221
scm1.org_1   | 2022-08-22 01:19:15,042 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:19:29,075 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:50978
scm1.org_1   | 2022-08-22 01:19:29,119 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:19:29,711 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49116
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:28:26,396 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36771
om3_1        | 2022-08-22 01:28:26,408 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:28:26,855 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:26,858 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:26,865 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-ozone-test-5441601222, Key:ozone-test-7590568313/multipartKey. 
om3_1        | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartFileInfo(OMKeyRequest.java:759)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareFileInfo(OMKeyRequest.java:646)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:623)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:283)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:28:27,467 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:27,474 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:27,480 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:28,266 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:28,269 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:28,291 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:28,756 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:29,513 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:29,515 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:29,526 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:29,605 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:30,276 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:30,279 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:30,282 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:31,014 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:31,018 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:31,019 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:31,744 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:31,760 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:31,763 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:32,429 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:32,431 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:33,283 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:33,285 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:33,287 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:33,401 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:33,404 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:33,418 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:33,499 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:33,508 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:33,509 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:33,526 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:33,547 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:33,612 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:33,994 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:35,759 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:35,774 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:35,821 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:35,830 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:36,469 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:36,471 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:36,491 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:36,493 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:36,508 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:36,509 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:36,511 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:36,512 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:37,797 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:37,799 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:38,624 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:38,626 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:38,628 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:40,768 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:41,365 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:41,367 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:41,370 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:42,023 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:42,026 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:42,049 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:42,090 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:43,270 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:43,931 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:43,933 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:44,551 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:44,556 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:45,521 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:45,524 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:45,531 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:48,393 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:49,208 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
recon_1      | 2022-08-22 01:30:26,505 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:30:48,667 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42850
recon_1      | 2022-08-22 01:30:48,705 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:30:48,716 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41474
recon_1      | 2022-08-22 01:30:48,731 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33290
recon_1      | 2022-08-22 01:30:48,740 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:30:48,762 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:31:18,674 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:42920
recon_1      | 2022-08-22 01:31:18,695 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41566
scm1.org_1   | 2022-08-22 01:19:29,725 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:19:30,003 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 85ae3250-a1a7-4fa0-96fb-c7ffd18c9838, Nodes: 61e48a95-a5d7-43eb-addf-1603d4744f3f{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c60044e-b181-445f-8fa2-782a9e9eb45c{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3100efb7-0525-45d4-a0fd-e73779181107{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:61e48a95-a5d7-43eb-addf-1603d4744f3f, CreationTimestamp2022-08-22T01:18:46.948Z[UTC]] moved to OPEN state
scm1.org_1   | 2022-08-22 01:19:50,076 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34152
scm1.org_1   | 2022-08-22 01:19:50,096 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:19:59,107 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51096
scm1.org_1   | 2022-08-22 01:19:59,140 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:19:59,500 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:55884
scm1.org_1   | 2022-08-22 01:19:59,530 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:19:59,626 [IPC Server handler 83 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm1.org_1   | 2022-08-22 01:19:59,767 [e5262d73-6b1c-4541-a42b-1a92d56a8751@group-0782CA3657A5-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 109611004723200000.
scm1.org_1   | 2022-08-22 01:19:59,798 [IPC Server handler 83 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 109611004723200000 to 109611004723201000.
scm1.org_1   | 2022-08-22 01:20:00,016 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49230
scm1.org_1   | 2022-08-22 01:20:00,070 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:20:02,868 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:37202
scm1.org_1   | 2022-08-22 01:20:02,901 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:20:03,004 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38042
scm1.org_1   | 2022-08-22 01:20:03,014 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:20:03,131 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52302
scm1.org_1   | 2022-08-22 01:20:03,151 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2022-08-22 01:20:03,430 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36649
scm1.org_1   | 2022-08-22 01:20:03,443 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:20:03,550 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34224
scm1.org_1   | 2022-08-22 01:20:03,596 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:20:10,260 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:55942
scm1.org_1   | 2022-08-22 01:20:10,267 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:20:21,777 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:55982
scm1.org_1   | 2022-08-22 01:20:21,782 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:20:33,357 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51240
scm1.org_1   | 2022-08-22 01:20:33,385 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:20:33,570 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34336
scm1.org_1   | 2022-08-22 01:20:33,583 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:20:33,743 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49374
scm1.org_1   | 2022-08-22 01:20:33,760 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1      | 2022-08-22 01:31:18,708 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33356
recon_1      | 2022-08-22 01:31:18,720 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:31:18,736 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:31:18,736 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:31:26,536 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:31:26,536 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:31:26,580 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:31:48,678 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33450
recon_1      | 2022-08-22 01:31:48,684 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41654
scm1.org_1   | 2022-08-22 01:20:46,132 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:58032
scm1.org_1   | 2022-08-22 01:20:46,134 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:21:03,403 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51356
scm1.org_1   | 2022-08-22 01:21:03,413 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:21:03,554 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34452
scm1.org_1   | 2022-08-22 01:21:03,615 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:21:03,685 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49490
scm1.org_1   | 2022-08-22 01:21:03,733 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:21:11,360 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:56178
scm1.org_1   | 2022-08-22 01:21:11,364 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:21:11,429 [IPC Server handler 27 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
scm1.org_1   | 2022-08-22 01:21:18,720 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51436
scm1.org_1   | 2022-08-22 01:21:18,721 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34538
scm1.org_1   | 2022-08-22 01:21:18,769 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49550
scm1.org_1   | 2022-08-22 01:21:18,798 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:21:18,815 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:21:18,856 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:33921
scm1.org_1   | 2022-08-22 01:21:18,858 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:21:18,898 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:21:48,787 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49686
scm1.org_1   | 2022-08-22 01:21:48,797 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34648
scm1.org_1   | 2022-08-22 01:21:48,813 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51542
scm1.org_1   | 2022-08-22 01:21:48,816 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:21:48,817 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:21:48,817 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:22:01,377 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2022-08-22 01:22:18,798 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49802
scm1.org_1   | 2022-08-22 01:22:18,810 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34784
scm1.org_1   | 2022-08-22 01:22:18,817 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:22:18,834 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51670
scm1.org_1   | 2022-08-22 01:22:18,836 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:22:18,845 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:22:22,558 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:56488
scm1.org_1   | 2022-08-22 01:22:22,563 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:22:25,949 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41237
scm1.org_1   | 2022-08-22 01:22:25,956 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:22:32,440 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:58468
scm1.org_1   | 2022-08-22 01:22:32,444 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1      | 2022-08-22 01:31:48,709 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43006
recon_1      | 2022-08-22 01:31:48,719 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:31:48,724 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:31:48,755 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:32:18,677 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33560
recon_1      | 2022-08-22 01:32:18,687 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43128
recon_1      | 2022-08-22 01:32:18,703 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:32:18,729 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:32:18,775 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41764
recon_1      | 2022-08-22 01:32:18,803 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:32:25,786 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1      | 2022-08-22 01:32:25,792 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 6 milliseconds for processing 2 containers.
recon_1      | 2022-08-22 01:32:26,069 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-08-22 01:32:26,082 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 66 milliseconds.
recon_1      | 2022-08-22 01:32:26,581 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:32:26,581 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:32:26,615 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
scm1.org_1   | 2022-08-22 01:22:39,239 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:56538
scm1.org_1   | 2022-08-22 01:22:39,247 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:22:46,502 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:58508
scm1.org_1   | 2022-08-22 01:22:46,515 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:22:48,751 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49912
scm1.org_1   | 2022-08-22 01:22:48,785 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:34884
scm1.org_1   | 2022-08-22 01:22:48,797 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:22:48,821 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:22:48,833 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51802
scm1.org_1   | 2022-08-22 01:22:48,884 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:23:11,341 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:56664
scm1.org_1   | 2022-08-22 01:23:11,351 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:23:18,760 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35024
scm1.org_1   | 2022-08-22 01:23:18,773 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50038
scm1.org_1   | 2022-08-22 01:23:18,789 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:51910
scm1.org_1   | 2022-08-22 01:23:18,804 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:23:18,804 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:23:18,805 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:23:48,721 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50148
scm1.org_1   | 2022-08-22 01:23:48,774 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:23:48,789 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35126
scm1.org_1   | 2022-08-22 01:23:48,796 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:23:48,806 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52038
scm1.org_1   | 2022-08-22 01:23:48,816 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:24:01,387 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:24:01,441 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:24:18,747 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35256
scm1.org_1   | 2022-08-22 01:24:18,765 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52156
scm1.org_1   | 2022-08-22 01:24:18,789 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:24:18,794 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50300
scm1.org_1   | 2022-08-22 01:24:18,804 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:24:18,818 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:24:31,387 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:24:31,441 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:24:48,818 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50396
scm1.org_1   | 2022-08-22 01:24:48,821 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35374
scm1.org_1   | 2022-08-22 01:24:48,821 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52284
scm1.org_1   | 2022-08-22 01:24:48,825 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:24:48,836 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:24:48,837 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:24:49,964 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:57090
scm1.org_1   | 2022-08-22 01:24:49,973 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:24:57,383 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:59060
scm1.org_1   | 2022-08-22 01:24:57,390 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:25:01,388 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:25:01,441 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:25:18,702 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35514
scm1.org_1   | 2022-08-22 01:25:18,704 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52412
scm1.org_1   | 2022-08-22 01:25:18,713 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50528
scm1.org_1   | 2022-08-22 01:25:18,750 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:25:18,798 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:25:18,816 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:25:31,388 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:25:31,442 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:25:48,737 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35794
scm1.org_1   | 2022-08-22 01:25:48,747 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:25:48,767 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52688
scm1.org_1   | 2022-08-22 01:25:48,777 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:25:48,778 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50810
scm1.org_1   | 2022-08-22 01:25:48,799 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:26:01,388 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:26:01,442 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:26:18,750 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:35898
scm1.org_1   | 2022-08-22 01:26:18,759 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:50936
scm1.org_1   | 2022-08-22 01:26:18,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52820
scm1.org_1   | 2022-08-22 01:26:18,767 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:26:18,789 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:26:18,819 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:26:20,196 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:57606
scm1.org_1   | 2022-08-22 01:26:20,208 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:26:31,389 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:26:31,442 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:26:39,381 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:59618
scm1.org_1   | 2022-08-22 01:26:39,384 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:26:48,706 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:52922
scm1.org_1   | 2022-08-22 01:26:48,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36028
scm1.org_1   | 2022-08-22 01:26:48,772 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:26:48,802 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51054
scm1.org_1   | 2022-08-22 01:26:48,817 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2022-08-22 01:28:49,210 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:49,215 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:49,941 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:49,946 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:49,962 [IPC Server handler 2 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:49,999 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:50,701 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:51,377 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:51,380 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:51,396 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:51,449 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:53,400 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:54,085 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:54,087 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:54,707 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:54,709 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:55,818 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:55,824 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:55,828 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:58,796 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:59,505 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:59,508 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:28:59,512 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:00,279 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:00,281 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:01,654 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:01,656 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:01,678 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:01,702 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:02,433 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:02,440 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:02,452 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:02,469 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:03,199 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:03,202 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:03,220 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:03,258 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:03,850 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:04,605 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:04,607 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:04,625 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:04,656 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:06,098 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:06,792 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:06,794 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:06,807 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:06,834 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:07,330 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:08,005 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:08,007 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:08,599 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:08,601 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:09,604 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:09,605 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:09,607 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:10,317 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:10,319 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:10,321 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:11,010 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:11,012 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:11,016 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:14,752 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:33958
om3_1        | 2022-08-22 01:29:14,760 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:29:18,004 [IPC Server handler 91 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:18,008 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:18,016 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8219884435 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:29:18,628 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:18,631 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:18,645 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: destbucket-36340 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:29:19,429 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:19,431 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:19,433 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:19,578 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:20,218 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:20,220 [IPC Server handler 29 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:20,222 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:20,224 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:20,844 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:20,845 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:20,847 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:20,868 [IPC Server handler 85 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:20,878 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:21,126 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:21,136 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:21,758 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:21,760 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:21,763 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:21,765 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:22,379 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:22,381 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:22,383 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:22,395 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:22,401 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:23,634 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:23,655 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:24,251 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:24,253 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:24,257 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:24,259 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:24,842 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:24,844 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:25,481 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:25,483 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:25,485 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:26,143 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:26,146 [IPC Server handler 5 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:26,444 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:44473
om3_1        | 2022-08-22 01:29:26,449 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:29:26,808 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:26,810 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
scm1.org_1   | 2022-08-22 01:26:48,828 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:27:01,379 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm1.org_1   | 2022-08-22 01:27:01,389 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:27:01,442 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:27:11,328 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:57810
scm1.org_1   | 2022-08-22 01:27:11,330 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:27:18,757 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51176
scm1.org_1   | 2022-08-22 01:27:18,764 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36166
scm1.org_1   | 2022-08-22 01:27:18,772 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53060
scm1.org_1   | 2022-08-22 01:27:18,793 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:27:18,800 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:27:18,810 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:27:25,992 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:41285
scm1.org_1   | 2022-08-22 01:27:25,999 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:27:31,389 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:27:31,442 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:27:48,739 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53176
scm1.org_1   | 2022-08-22 01:27:48,755 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51312
scm1.org_1   | 2022-08-22 01:27:48,757 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36290
scm1.org_1   | 2022-08-22 01:27:48,763 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:27:48,773 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:27:48,787 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:27:51,688 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:57986
scm1.org_1   | 2022-08-22 01:27:51,715 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:27:55,417 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:59956
scm1.org_1   | 2022-08-22 01:27:55,420 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:28:01,389 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:28:01,443 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:28:07,047 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:60006
scm1.org_1   | 2022-08-22 01:28:07,058 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:28:18,661 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36420
scm1.org_1   | 2022-08-22 01:28:18,740 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51444
scm1.org_1   | 2022-08-22 01:28:18,770 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:28:18,801 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:28:18,805 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53334
scm1.org_1   | 2022-08-22 01:28:18,830 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:28:23,950 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:60092
scm1.org_1   | 2022-08-22 01:28:23,953 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:28:31,389 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:28:31,443 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:28:36,532 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:60156
scm1.org_1   | 2022-08-22 01:28:36,545 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:28:48,779 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36568
scm1.org_1   | 2022-08-22 01:28:48,790 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53480
scm1.org_1   | 2022-08-22 01:28:48,794 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51588
scm1.org_1   | 2022-08-22 01:28:48,801 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:28:48,802 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:28:48,805 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:29:01,390 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:29:01,443 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:29:18,746 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51722
scm1.org_1   | 2022-08-22 01:29:18,747 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36696
scm1.org_1   | 2022-08-22 01:29:18,758 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53618
scm1.org_1   | 2022-08-22 01:29:18,766 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:29:18,776 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:29:18,793 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:29:20,857 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:60360
scm1.org_1   | 2022-08-22 01:29:20,863 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:29:31,390 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:29:31,444 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:29:34,518 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:58468
scm1.org_1   | 2022-08-22 01:29:34,526 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:29:48,711 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36814
scm1.org_1   | 2022-08-22 01:29:48,715 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53714
scm1.org_1   | 2022-08-22 01:29:48,737 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:29:48,760 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:29:48,774 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51834
scm1.org_1   | 2022-08-22 01:29:48,789 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:30:01,390 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:30:01,444 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:30:11,343 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:58558
scm1.org_1   | 2022-08-22 01:30:11,350 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:30:18,685 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:51914
scm1.org_1   | 2022-08-22 01:30:18,692 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53794
scm1.org_1   | 2022-08-22 01:30:18,716 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:30:18,731 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36894
scm1.org_1   | 2022-08-22 01:30:18,762 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2022-08-22 01:29:26,812 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:30,469 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34048
om3_1        | 2022-08-22 01:29:30,477 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:29:33,823 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:33,830 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:33,853 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-8362820054 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:29:34,504 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:34,507 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:29:34,508 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:26,488 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35343
om3_1        | 2022-08-22 01:30:26,491 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:30:34,827 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:46631
om3_1        | 2022-08-22 01:30:34,833 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:30:34,833 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:34,837 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:34,841 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:34,997 [IPC Server handler 98 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:35,728 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:35,733 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:35,734 [IPC Server handler 53 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:35,737 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:36,513 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:36,514 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:37,220 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:37,222 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:37,224 [IPC Server handler 18 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:38,016 [IPC Server handler 45 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:38,019 [IPC Server handler 60 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:38,029 [IPC Server handler 6 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:38,788 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:38,790 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:38,801 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-8362820054, Key:thereisnosuchfile.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:30:39,485 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:39,487 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:39,492 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:40,234 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:40,237 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:30:40,239 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:32:48,664 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43186
recon_1      | 2022-08-22 01:32:48,711 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41820
recon_1      | 2022-08-22 01:32:48,724 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33644
recon_1      | 2022-08-22 01:32:48,724 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:32:48,745 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:32:48,763 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:33:18,652 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33708
recon_1      | 2022-08-22 01:33:18,668 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43278
recon_1      | 2022-08-22 01:33:18,719 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:33:18,745 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:33:18,760 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41906
recon_1      | 2022-08-22 01:33:18,775 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:33:26,616 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:33:26,616 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:33:26,654 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
scm1.org_1   | 2022-08-22 01:30:18,768 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:30:31,393 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:30:31,444 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:30:34,865 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:58620
scm1.org_1   | 2022-08-22 01:30:34,867 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:30:48,668 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:36990
scm1.org_1   | 2022-08-22 01:30:48,715 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:30:48,720 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53886
scm1.org_1   | 2022-08-22 01:30:48,727 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52012
scm1.org_1   | 2022-08-22 01:30:48,749 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:30:48,762 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:31:01,393 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:31:01,444 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:31:11,350 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:58728
scm1.org_1   | 2022-08-22 01:31:11,354 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:31:18,657 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52086
scm1.org_1   | 2022-08-22 01:31:18,683 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:31:18,688 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37060
scm1.org_1   | 2022-08-22 01:31:18,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53974
scm1.org_1   | 2022-08-22 01:31:18,723 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:31:18,728 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:31:31,393 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:31:31,444 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:31:41,215 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:58794
scm1.org_1   | 2022-08-22 01:31:41,221 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:31:48,684 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52168
scm1.org_1   | 2022-08-22 01:31:48,700 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37148
scm1.org_1   | 2022-08-22 01:31:48,727 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:31:48,764 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:31:48,772 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54050
scm1.org_1   | 2022-08-22 01:31:48,787 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:32:00,280 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:58888
scm1.org_1   | 2022-08-22 01:32:00,283 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:32:01,380 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm1.org_1   | 2022-08-22 01:32:01,394 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:32:01,445 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:32:11,330 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:58924
scm1.org_1   | 2022-08-22 01:32:11,333 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:32:18,669 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52296
scm1.org_1   | 2022-08-22 01:32:18,682 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37272
scm1.org_1   | 2022-08-22 01:32:18,711 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:32:18,725 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:32:18,776 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54176
scm1.org_1   | 2022-08-22 01:32:18,795 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:32:26,046 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43725
scm1.org_1   | 2022-08-22 01:32:26,051 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:32:31,394 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:32:31,445 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:33:48,677 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43338
recon_1      | 2022-08-22 01:33:48,693 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:33:48,718 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33794
recon_1      | 2022-08-22 01:33:48,766 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:41974
recon_1      | 2022-08-22 01:33:48,772 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:33:48,780 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:34:18,670 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43434
recon_1      | 2022-08-22 01:34:18,683 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42058
recon_1      | 2022-08-22 01:34:18,690 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:34:18,714 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33872
recon_1      | 2022-08-22 01:34:18,729 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:34:18,761 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:34:26,655 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:34:26,655 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:34:26,682 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
recon_1      | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
scm1.org_1   | 2022-08-22 01:32:48,692 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54228
scm1.org_1   | 2022-08-22 01:32:48,749 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:32:48,777 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52372
scm1.org_1   | 2022-08-22 01:32:48,787 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37330
scm1.org_1   | 2022-08-22 01:32:48,804 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:32:48,811 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:33:01,394 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:33:01,445 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:33:16,120 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:59086
scm1.org_1   | 2022-08-22 01:33:16,128 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:33:18,668 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37420
scm1.org_1   | 2022-08-22 01:33:18,689 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54318
scm1.org_1   | 2022-08-22 01:33:18,719 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:33:18,741 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:33:18,747 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52444
scm1.org_1   | 2022-08-22 01:33:18,772 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:33:31,394 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:33:31,445 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:33:48,669 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37480
scm1.org_1   | 2022-08-22 01:33:48,690 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:33:48,706 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54378
scm1.org_1   | 2022-08-22 01:33:48,720 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52500
scm1.org_1   | 2022-08-22 01:33:48,753 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:33:48,781 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:34:01,395 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:34:01,447 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:34:17,433 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:59236
scm1.org_1   | 2022-08-22 01:34:17,442 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:34:18,690 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54476
scm1.org_1   | 2022-08-22 01:34:18,693 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37574
scm1.org_1   | 2022-08-22 01:34:18,725 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52594
om3_1        | 2022-08-22 01:31:26,556 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:40679
om3_1        | 2022-08-22 01:31:26,564 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:31:41,122 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:42739
om3_1        | 2022-08-22 01:31:41,132 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:31:41,135 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:41,144 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:41,194 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:41,428 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:42,082 [IPC Server handler 99 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:42,084 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:42,086 [IPC Server handler 9 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:42,090 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:42,899 [IPC Server handler 46 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:42,902 [IPC Server handler 48 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:42,910 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-8362820054, Key:ozone-test-8204563195/deletetestapidir/key=value/.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:31:43,662 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:43,669 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:43,672 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:43,676 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:44,513 [IPC Server handler 33 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:44,514 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:45,311 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:45,313 [IPC Server handler 51 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:45,316 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:45,397 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:46,101 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:46,110 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:46,112 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:46,114 [IPC Server handler 50 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:46,876 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:46,879 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:46,885 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyDeleteRequest: Key delete failed. Volume:s3v, Bucket:bucket-ozone-test-8362820054, Key:ozone-test-8204563195/deletetestapiprefix/key=value/file.
om3_1        | KEY_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Key not found
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:152)
om3_1        | 	at org.apache.hadoop.ozone.om.request.key.OMKeyDeleteRequest.validateAndUpdateCache(OMKeyDeleteRequest.java:98)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:304)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:529)
om3_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om3_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm1.org_1   | 2022-08-22 01:34:18,737 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:34:18,744 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:34:18,754 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:34:31,395 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:34:31,447 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:34:48,689 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52664
scm1.org_1   | 2022-08-22 01:34:48,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37640
scm1.org_1   | 2022-08-22 01:34:48,691 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54530
scm1.org_1   | 2022-08-22 01:34:48,720 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:34:48,737 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:34:48,749 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:35:01,395 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:35:01,447 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:35:18,678 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52740
scm1.org_1   | 2022-08-22 01:35:18,694 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37722
scm1.org_1   | 2022-08-22 01:35:18,704 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54606
scm1.org_1   | 2022-08-22 01:35:18,713 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:35:18,733 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:35:18,764 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:35:18,866 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:59412
scm1.org_1   | 2022-08-22 01:35:18,877 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:35:31,395 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:35:31,448 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:35:48,676 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52826
scm1.org_1   | 2022-08-22 01:35:48,690 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54690
scm1.org_1   | 2022-08-22 01:35:48,694 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37788
scm1.org_1   | 2022-08-22 01:35:48,706 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:35:48,719 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:35:48,738 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:36:01,396 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:36:01,448 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:36:11,346 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:59528
scm1.org_1   | 2022-08-22 01:36:11,348 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:36:18,688 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52888
scm1.org_1   | 2022-08-22 01:36:18,692 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54760
scm1.org_1   | 2022-08-22 01:36:18,716 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:36:18,729 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:36:18,749 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37876
scm1.org_1   | 2022-08-22 01:36:18,777 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om3_1        | 2022-08-22 01:31:47,531 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:47,536 [IPC Server handler 12 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:47,538 [IPC Server handler 67 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:47,540 [IPC Server handler 26 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:48,201 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:48,204 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:49,108 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:49,110 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:55,766 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34466
om3_1        | 2022-08-22 01:31:55,778 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:31:59,517 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:35989
om3_1        | 2022-08-22 01:31:59,522 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:31:59,523 [IPC Server handler 75 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:59,526 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:31:59,532 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-1571071876 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:32:00,263 [IPC Server handler 38 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:00,265 [IPC Server handler 14 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:00,268 [IPC Server handler 16 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:00,381 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:01,110 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:01,112 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:01,756 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:01,758 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:02,415 [IPC Server handler 17 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:02,418 [IPC Server handler 68 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:03,066 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:03,068 [IPC Server handler 82 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:10,515 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:34516
om3_1        | 2022-08-22 01:32:10,527 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:32:15,244 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:43323
om3_1        | 2022-08-22 01:32:15,247 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:32:15,248 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:15,254 [IPC Server handler 11 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:15,259 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2080259004 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:32:15,957 [IPC Server handler 89 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:15,959 [IPC Server handler 95 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:15,963 [IPC Server handler 70 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:32:26,598 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35847
om3_1        | 2022-08-22 01:32:26,602 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:32:34,721 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:36829
om3_1        | 2022-08-22 01:32:34,726 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:32:34,727 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:34:48,675 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33940
recon_1      | 2022-08-22 01:34:48,677 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42126
recon_1      | 2022-08-22 01:34:48,689 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43498
recon_1      | 2022-08-22 01:34:48,718 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:34:48,738 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:34:48,748 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:35:18,677 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34016
recon_1      | 2022-08-22 01:35:18,680 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42202
recon_1      | 2022-08-22 01:35:18,695 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43570
recon_1      | 2022-08-22 01:35:18,700 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:35:18,727 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:35:18,751 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:35:26,683 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:35:26,683 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:35:26,706 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
scm1.org_1   | 2022-08-22 01:36:31,396 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:36:31,451 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:36:48,671 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:52966
scm1.org_1   | 2022-08-22 01:36:48,707 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54830
scm1.org_1   | 2022-08-22 01:36:48,732 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:36:48,746 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:37940
scm1.org_1   | 2022-08-22 01:36:48,758 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:36:48,785 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:37:01,380 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm1.org_1   | 2022-08-22 01:37:01,396 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:37:01,451 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:37:11,349 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:59676
scm1.org_1   | 2022-08-22 01:37:11,351 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:37:18,711 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53038
scm1.org_1   | 2022-08-22 01:37:18,723 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38016
scm1.org_1   | 2022-08-22 01:37:18,761 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:37:18,813 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:37:18,839 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:54936
scm1.org_1   | 2022-08-22 01:37:18,862 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:37:26,102 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42435
scm1.org_1   | 2022-08-22 01:37:26,108 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:37:31,396 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:37:31,451 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:37:31,898 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:33476
scm1.org_1   | 2022-08-22 01:37:31,908 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2022-08-22 01:37:48,740 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53164
scm1.org_1   | 2022-08-22 01:37:48,746 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55048
scm1.org_1   | 2022-08-22 01:37:48,756 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38150
scm1.org_1   | 2022-08-22 01:37:48,757 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:37:48,777 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:37:48,786 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:38:01,397 [UnderReplicatedQueueThreadThread] INFO replication.UnderReplicatedProcessor: Processed 0 under replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:38:01,451 [OverReplicatedQueueThreadThread] INFO replication.OverReplicatedProcessor: Processed 0 over replicated containers, failed processing 0
scm1.org_1   | 2022-08-22 01:38:11,338 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:59898
scm1.org_1   | 2022-08-22 01:38:11,342 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2022-08-22 01:38:18,709 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55138
scm1.org_1   | 2022-08-22 01:38:18,710 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:38242
scm1.org_1   | 2022-08-22 01:38:18,767 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:38:18,779 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:53254
scm1.org_1   | 2022-08-22 01:38:18,789 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2022-08-22 01:38:18,854 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om3_1        | 2022-08-22 01:33:16,093 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:32869
om3_1        | 2022-08-22 01:33:16,095 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:33:16,095 [IPC Server handler 97 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:33:16,099 [IPC Server handler 92 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:33:16,103 [IPC Server handler 3 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:33:26,640 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:36827
om3_1        | 2022-08-22 01:33:26,644 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:33:40,713 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:36019
om3_1        | 2022-08-22 01:33:40,715 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:33:40,716 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:34:17,397 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:45157
om3_1        | 2022-08-22 01:34:17,402 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:34:17,402 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:34:17,405 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:34:17,408 [IPC Server handler 15 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:34:17,541 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:34:18,339 [IPC Server handler 40 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:34:18,341 [IPC Server handler 64 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:34:18,343 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:34:26,664 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:42911
om3_1        | 2022-08-22 01:34:26,668 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:35:16,718 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:42151
om3_1        | 2022-08-22 01:35:16,721 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:35:16,722 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:35:18,848 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:35:18,852 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:35:18,855 [IPC Server handler 86 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:35:19,030 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:35:19,781 [IPC Server handler 52 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:35:19,783 [IPC Server handler 32 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:35:19,785 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:35:26,694 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:35317
om3_1        | 2022-08-22 01:35:26,696 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:36:16,700 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:44973
om3_1        | 2022-08-22 01:36:16,701 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:36:16,702 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:36:20,421 [IPC Server handler 55 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:36:20,423 [IPC Server handler 34 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:36:20,426 [IPC Server handler 58 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:36:26,727 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:34353
om3_1        | 2022-08-22 01:36:26,735 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:37:18,734 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:44663
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor56.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:35:48,678 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42278
recon_1      | 2022-08-22 01:35:48,679 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43648
recon_1      | 2022-08-22 01:35:48,684 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34102
recon_1      | 2022-08-22 01:35:48,705 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:35:48,718 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:35:48,733 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:36:18,675 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34164
recon_1      | 2022-08-22 01:36:18,691 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42352
recon_1      | 2022-08-22 01:36:18,703 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43726
recon_1      | 2022-08-22 01:36:18,716 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:36:18,724 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:36:18,767 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:36:26,707 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:36:26,707 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:36:26,748 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor56.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:36:48,677 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34238
recon_1      | 2022-08-22 01:36:48,696 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43798
recon_1      | 2022-08-22 01:36:48,707 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:36:48,738 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:36:48,741 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42428
recon_1      | 2022-08-22 01:36:48,768 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:37:18,644 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34314
recon_1      | 2022-08-22 01:37:18,687 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:43876
recon_1      | 2022-08-22 01:37:18,737 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:37:18,750 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42522
om3_1        | 2022-08-22 01:37:18,751 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:37:18,752 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:20,820 [IPC Server handler 31 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:20,823 [IPC Server handler 69 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:20,842 [IPC Server handler 65 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:20,984 [IPC Server handler 76 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:23,447 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35328
om3_1        | 2022-08-22 01:37:23,452 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:37:26,763 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43647
om3_1        | 2022-08-22 01:37:26,765 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:37:28,092 [IPC Server handler 1 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:28,095 [IPC Server handler 88 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:28,104 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-2019065808 of layout LEGACY in volume: s3v
om3_1        | 2022-08-22 01:37:28,860 [IPC Server handler 19 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:28,863 [IPC Server handler 84 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:28,865 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:28,954 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:29,780 [IPC Server handler 83 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:29,782 [IPC Server handler 59 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:29,783 [IPC Server handler 23 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:29,788 [IPC Server handler 57 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:30,531 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:30,532 [IPC Server handler 21 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:30,535 [IPC Server handler 66 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:30,564 [IPC Server handler 30 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:31,285 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:31,286 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:31,288 [IPC Server handler 42 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:31,290 [IPC Server handler 49 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:31,883 [IPC Server handler 79 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:31,885 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:32,027 [IPC Server handler 2 on default port 9862] ERROR security.OzoneDelegationTokenSecretManager: Error while validating S3 identifier:OzoneToken owner=scm/scm@EXAMPLE.COM, renewer=, realUser=, issueDate=1970-01-01T00:00:00Z, maxDate=1970-01-01T00:00:00Z, sequenceNumber=0, masterKeyId=0, strToSign=, signature=asdfqwerty, awsAccessKeyId=scm/scm@EXAMPLE.COM, omServiceId=null
om3_1        | org.apache.hadoop.hdds.security.OzoneSecurityException: S3 secret not found for awsAccessKeyId scm/scm@EXAMPLE.COM
om3_1        | 	at org.apache.hadoop.ozone.om.S3SecretManagerImpl.getS3UserSecretString(S3SecretManagerImpl.java:96)
om3_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3AuthInfo(OzoneDelegationTokenSecretManager.java:515)
om3_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:431)
om3_1        | 	at org.apache.hadoop.ozone.security.S3SecurityUtil.validateS3Credential(S3SecurityUtil.java:61)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:166)
om3_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
om3_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om3_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om3_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
om3_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om3_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om3_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
recon_1      | 2022-08-22 01:37:18,752 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:37:18,828 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:37:25,794 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1      | 2022-08-22 01:37:25,798 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 5 milliseconds for processing 2 containers.
recon_1      | 2022-08-22 01:37:26,113 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 5 pipelines in house.
recon_1      | 2022-08-22 01:37:26,123 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 35 milliseconds.
recon_1      | 2022-08-22 01:37:26,749 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2022-08-22 01:37:26,749 [pool-28-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2022-08-22 01:37:26,787 [pool-28-thread-1] ERROR impl.OzoneManagerServiceProviderImpl: Unable to update Recon's metadata with new OM DB. 
recon_1      | java.lang.reflect.UndeclaredThrowableException
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)
recon_1      | 	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:312)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:344)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:483)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
recon_1      | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1      | 	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
recon_1      | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1      | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1      | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: Error while authenticating with endpoint: http://om3:9874/dbCheckpoint
recon_1      | 	at jdk.internal.reflect.GeneratedConstructorAccessor56.newInstance(Unknown Source)
recon_1      | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1      | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.wrapExceptionWithMessage(KerberosAuthenticator.java:232)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:219)
recon_1      | 	at org.apache.hadoop.security.authentication.client.AuthenticatedURL.openConnection(AuthenticatedURL.java:350)
recon_1      | 	at org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:186)
recon_1      | 	at org.apache.hadoop.ozone.recon.ReconUtils.makeHttpCall(ReconUtils.java:244)
recon_1      | 	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:313)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	... 12 more
recon_1      | Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:360)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.authenticate(KerberosAuthenticator.java:204)
recon_1      | 	... 19 more
recon_1      | Caused by: GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:773)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:266)
recon_1      | 	at java.security.jgss/sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:196)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:336)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator$1.run(KerberosAuthenticator.java:310)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.authentication.client.KerberosAuthenticator.doSpnegoSequence(KerberosAuthenticator.java:310)
recon_1      | 	... 20 more
recon_1      | Caused by: KrbException: Server not found in Kerberos database (7) - LOOKING_UP_SERVER
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:73)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.getReply(KrbTgsReq.java:226)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsReq.sendAndGetCreds(KrbTgsReq.java:237)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCredsSingle(CredentialsUtil.java:477)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:340)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.serviceCreds(CredentialsUtil.java:314)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.CredentialsUtil.acquireServiceCreds(CredentialsUtil.java:169)
recon_1      | 	at java.security.jgss/sun.security.krb5.Credentials.acquireServiceCreds(Credentials.java:490)
recon_1      | 	at java.security.jgss/sun.security.jgss.krb5.Krb5Context.initSecContext(Krb5Context.java:697)
recon_1      | 	... 27 more
recon_1      | Caused by: KrbException: Identifier doesn't match expected value (906)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.KDCRep.init(KDCRep.java:140)
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.init(TGSRep.java:65)
om3_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om3_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om3_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
om3_1        | 2022-08-22 01:37:32,028 [IPC Server handler 2 on default port 9862] ERROR protocolPB.OzoneManagerProtocolServerSideTranslatorPB: signatures do NOT match for S3 identifier:OzoneToken owner=scm/scm@EXAMPLE.COM, renewer=, realUser=, issueDate=1970-01-01T00:00:00Z, maxDate=1970-01-01T00:00:00Z, sequenceNumber=0, masterKeyId=0, strToSign=, signature=asdfqwerty, awsAccessKeyId=scm/scm@EXAMPLE.COM, omServiceId=null
om3_1        | org.apache.hadoop.security.token.SecretManager$InvalidToken: No S3 secret found for S3 identifier:OzoneToken owner=scm/scm@EXAMPLE.COM, renewer=, realUser=, issueDate=1970-01-01T00:00:00Z, maxDate=1970-01-01T00:00:00Z, sequenceNumber=0, masterKeyId=0, strToSign=, signature=asdfqwerty, awsAccessKeyId=scm/scm@EXAMPLE.COM, omServiceId=null
om3_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.validateS3AuthInfo(OzoneDelegationTokenSecretManager.java:520)
om3_1        | 	at org.apache.hadoop.ozone.security.OzoneDelegationTokenSecretManager.retrievePassword(OzoneDelegationTokenSecretManager.java:431)
om3_1        | 	at org.apache.hadoop.ozone.security.S3SecurityUtil.validateS3Credential(S3SecurityUtil.java:61)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:166)
om3_1        | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om3_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:147)
om3_1        | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om3_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:466)
om3_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:574)
om3_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)
om3_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om3_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)
om3_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)
om3_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om3_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om3_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)
om3_1        | 2022-08-22 01:37:32,631 [IPC Server handler 47 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:32,633 [IPC Server handler 54 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:33,278 [IPC Server handler 27 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:33,282 [IPC Server handler 25 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:33,956 [IPC Server handler 80 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:33,958 [IPC Server handler 73 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:34,697 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:34,701 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:35,384 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:35,386 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:36,239 [IPC Server handler 96 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:36,242 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:37,059 [IPC Server handler 0 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:37,061 [IPC Server handler 78 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:37,911 [IPC Server handler 90 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:37,913 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:38,660 [IPC Server handler 61 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:38,664 [IPC Server handler 77 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:39,376 [IPC Server handler 28 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:39,378 [IPC Server handler 13 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:40,139 [IPC Server handler 4 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:40,143 [IPC Server handler 87 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:40,915 [IPC Server handler 39 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:40,917 [IPC Server handler 63 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:41,705 [IPC Server handler 62 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:41,707 [IPC Server handler 35 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:42,506 [IPC Server handler 74 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:42,508 [IPC Server handler 22 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
recon_1      | 	at java.security.jgss/sun.security.krb5.internal.TGSRep.<init>(TGSRep.java:60)
recon_1      | 	at java.security.jgss/sun.security.krb5.KrbTgsRep.<init>(KrbTgsRep.java:55)
recon_1      | 	... 35 more
recon_1      | 2022-08-22 01:37:48,666 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44008
recon_1      | 2022-08-22 01:37:48,674 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34444
recon_1      | 2022-08-22 01:37:48,698 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42640
recon_1      | 2022-08-22 01:37:48,725 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:37:48,735 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:37:48,760 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:38:18,673 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:44092
recon_1      | 2022-08-22 01:38:18,725 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:42726
recon_1      | 2022-08-22 01:38:18,807 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:38:18,836 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2022-08-22 01:38:18,846 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:34550
recon_1      | 2022-08-22 01:38:18,899 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om3_1        | 2022-08-22 01:37:43,168 [IPC Server handler 44 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:43,171 [IPC Server handler 37 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:49,885 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:35442
om3_1        | 2022-08-22 01:37:49,888 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:37:54,239 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.114:44867
om3_1        | 2022-08-22 01:37:54,248 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for s3g/s3g@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om3_1        | 2022-08-22 01:37:54,249 [IPC Server handler 20 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:54,255 [IPC Server handler 24 on default port 9862] INFO security.AWSV4AuthValidator: 9f88ea5aa3a4a1433127b0d58aa94e444442276d42e5e4d8bc2b41c2d9749e3c
om3_1        | 2022-08-22 01:37:54,262 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket-ozone-test-0209209266 of layout LEGACY in volume: s3v
